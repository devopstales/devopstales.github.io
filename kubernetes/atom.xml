<?xml version="1.0" encoding="utf-8"?> 
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <generator uri="https://gohugo.io/" version="0.145.0">Hugo</generator><title type="html"><![CDATA[Kubernetes on devopstales]]></title>
    
        <subtitle type="html"><![CDATA[Blog about dev and ops stuff]]></subtitle>
    
    
    
            <link href="https://devopstales.github.io/kubernetes/" rel="alternate" type="text/html" title="html" />
            <link href="https://devopstales.github.io/kubernetes/index.xml" rel="alternate" type="application/rss+xml" title="rss" />
            <link href="https://devopstales.github.io/kubernetes/atom.xml" rel="self" type="application/atom+xml" title="atom" />
    <updated>2025-06-13T11:15:41+00:00</updated>
    
    
    
    
        <id>https://devopstales.github.io/kubernetes/</id>
    
        
        <entry>
            <title type="html"><![CDATA[Why Kubernetes Pods See Host Resources (And How to Fix It)]]></title>
            <link href="https://devopstales.github.io/kubernetes/kubernetes-resource-visibility/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/cluster-api/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Cluster API: a step by stap guide" />
                <link href="https://devopstales.github.io/kubernetes/automatic-k8s-certificate-renewal/?utm_source=atom_feed" rel="related" type="text/html" title="Automatic Kubernetes Certificate Renewal" />
                <link href="https://devopstales.github.io/kubernetes/rke2-ingress-loadbalancer/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 With MetalLB and NGINX Ingress Controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-change-ip/?utm_source=atom_feed" rel="related" type="text/html" title="How to Change IP on Kubernetes node." />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
            
                <id>https://devopstales.github.io/kubernetes/kubernetes-resource-visibility/</id>
            
            
            <published>2025-05-15T00:00:00+00:00</published>
            <updated>2025-05-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>When you check resource usage inside a Kubernetes pod, you might be surprised to see the full host machine&rsquo;s resources - even when you&rsquo;ve set strict limits. Let&rsquo;s explore why this happens and how to fix it.</p>
<h2 id="why-do-pods-see-host-resources">Why Do Pods See Host Resources?</h2>
<p>Even if you define resource <code>limits</code> in a Kubernetes pod spec, tools inside the container like:</p>
<ul>
<li><code>free</code>, <code>top</code></li>
<li><code>cat /proc/meminfo</code></li>
<li><code>cat /proc/cpuinfo</code></li>
</ul>
<p>&hellip;still show <strong>total host resources</strong> by default.</p>
<p>This is because Linux containers are just processes on the host, and unless further isolated, they have visibility into the full <code>/proc</code> filesystem of the host kernel.</p>
<hr>
<h2 id="what-kubernetes-actually-enforces">What Kubernetes Actually Enforces</h2>
<p>Kubernetes uses <strong>Linux cgroups</strong> to <strong>enforce limits</strong> on:</p>
<ul>
<li><strong>CPU usage</strong> (throttled)</li>
<li><strong>Memory usage</strong> (killed on OOM)</li>
</ul>
<p>So while the <strong>usage is constrained</strong>, <strong>visibility is not</strong> — unless additional isolation is applied.</p>
<hr>
<h2 id="solutions-to-limit-resource-visibility">Solutions to Limit Resource Visibility</h2>
<p>Here are your options to make pods see only their allocated resources, listed from most lightweight to most secure:</p>
<h3 id="option-1-use-cgroup-v2--cgroup-namespaces-limited-visibility-fix">Option 1: Use cgroup v2 + Cgroup Namespaces (Limited Visibility Fix)</h3>
<p>With cgroup v2 and cgroup namespaces, the pod can be made to see only its limited resources.</p>
<p>Requirements:</p>
<ul>
<li>Linux kernel 5.14+ (some features in 5.10+)</li>
<li>Container runtime that supports cgroup v2 and namespaces:</li>
<li>containerd v1.5+</li>
<li>CRI-O v1.22+</li>
<li>Kubernetes v1.25+ (improved cgroup v2 support)</li>
</ul>
<p>How to enable:</p>
<p>Edit your bootloader configuration (e.g., GRUB) to enable systemd&rsquo;s unified cgroup hierarchy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># On your node, edit /etc/default/grub and add:</span>
</span></span><span style="display:flex;"><span>GRUB_CMDLINE_LINUX<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;systemd.unified_cgroup_hierarchy=1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Then update grub and reboot</span>
</span></span><span style="display:flex;"><span>sudo update-grub
</span></span><span style="display:flex;"><span>sudo reboot
</span></span></code></pre></div><p>Configure your runtime to use cgroup v2 (example for containerd):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-toml" data-lang="toml"><span style="display:flex;"><span>[<span style="color:#a6e22e">plugins</span>.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.<span style="color:#a6e22e">containerd</span>.<span style="color:#a6e22e">runtimes</span>.<span style="color:#a6e22e">runc</span>.<span style="color:#a6e22e">options</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">SystemdCgroup</span> = <span style="color:#66d9ef">true</span>
</span></span></code></pre></div><p>Confirm Kubernetes and Kernel Support</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat /proc/filesystems | grep cgroup2
</span></span><span style="display:flex;"><span>mount | grep cgroup2
</span></span></code></pre></div><p>Verify from Inside the Pod</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat /sys/fs/cgroup/memory.max
</span></span><span style="display:flex;"><span>cat /sys/fs/cgroup/cpu.max
</span></span></code></pre></div><p>More on User namespace configuration <a href="/kubernetes/k8s-user-namespace/">HERE</a></p>
<h3 id="option-2-use-gvisor--kata-containers-sandboxed-runtimes">Option 2: Use gVisor / Kata Containers (Sandboxed Runtimes)</h3>
<p>These are sandboxed container runtimes that offer much stronger isolation:</p>
<ul>
<li>gVisor: User-space kernel; better isolation, lower performance.</li>
<li>Kata Containers: Lightweight VMs per pod.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">node.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RuntimeClass</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">gvisor</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">handler</span>: <span style="color:#ae81ff">runsc</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">runtimeClassName</span>: <span style="color:#ae81ff">gvisor</span>
</span></span></code></pre></div><p>More abaut gvisor <a href="/kubernetes/gvisor-cri-o/">HERE</a> and <a href="/kubernetes/gvisor-containerd/">HERE</a></p>
<h3 id="option-3-use-lxcfs-fakes-proc-files-for-containers">Option 3: Use lxcfs (Fakes /proc Files for Containers)</h3>
<p><code>lxcfs</code> is a FUSE filesystem that virtualizes /proc/meminfo, /proc/cpuinfo, and /proc/stat to show only the container&rsquo;s assigned resources.</p>
<p>How to Enable lxcfs in Kubernetes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt install lxcfs -y  <span style="color:#75715e"># Debian/Ubuntu</span>
</span></span><span style="display:flex;"><span>sudo yum install lxcfs -y  <span style="color:#75715e"># RHEL/CentOS</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">lxcfs-pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">myapp</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;top&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;256Mi&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#e6db74">&#34;500m&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">lxcfs-proc</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/proc/meminfo</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">subPath</span>: <span style="color:#ae81ff">meminfo</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">lxcfs-proc</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/proc/cpuinfo</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">subPath</span>: <span style="color:#ae81ff">cpuinfo</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">lxcfs-proc</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hostPath</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/var/lib/lxcfs/proc/</span>
</span></span></code></pre></div><h3 id="option-4-use-a-sidecar-container-to-override-proc">Option 4: Use a Sidecar Container to Override /proc</h3>
<p>Some tools (like <code>frappe/k8s-proc-limits</code>) dynamically modify /proc files inside the container to reflect limits.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">proc-limited-pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">app</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;256Mi&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#e6db74">&#34;500m&#34;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">proc-limiter</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">frappe/k8s-proc-limits</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/host/proc</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">proc</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">MEMORY_LIMIT</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">valueFrom</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">resourceFieldRef</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">resource</span>: <span style="color:#ae81ff">limits.memory</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">CPU_LIMIT</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">valueFrom</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">resourceFieldRef</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">resource</span>: <span style="color:#ae81ff">limits.cpu</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">proc</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hostPath</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/proc</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="gvisor" term="gvisor" label="gvisor" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Cluster API: a step by stap guide]]></title>
            <link href="https://devopstales.github.io/kubernetes/cluster-api/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/automatic-k8s-certificate-renewal/?utm_source=atom_feed" rel="related" type="text/html" title="Automatic Kubernetes Certificate Renewal" />
                <link href="https://devopstales.github.io/kubernetes/rke2-ingress-loadbalancer/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 With MetalLB and NGINX Ingress Controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-change-ip/?utm_source=atom_feed" rel="related" type="text/html" title="How to Change IP on Kubernetes node." />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
            
                <id>https://devopstales.github.io/kubernetes/cluster-api/</id>
            
            
            <published>2025-04-06T00:00:00+00:00</published>
            <updated>2025-04-06T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can install and manage a Kubernetes cluster with Cluster API.</p>
<h2 id="what-is-clusterapi">What is ClusterAPI?</h2>
<p>The Cluster API project was started by the Kubernetes Special Interest Group (SIG) Cluster Lifecycle and automates cluster lifecycle management for platform operators using Kubernetes-style APIs and conventions. Currently, more than 100 Kubernetes installers and distributions exist, each with a unique default configurations. Acknowledging this ClusterAPI concentrated on community based providers that bootstrap different kinds of Kubernetes clusters and architectures.</p>
<p>The most commonly used providers are cloud based solutions like AWS, Azure or GCP, or private cloud providers (CloudStack, OpenStack, OpenNebula), but you can also use virtualization engines like vSphere, Proxmox, Nautanix, KubVirt, Virtink, Harwester. The most intrestingsolutions are the hardware based providers like Metal3.</p>
<h2 id="create-clusterapi-clusters-with-kind">Create ClusterAPI Clusters with Kind</h2>
<p>For this demo I will use ClusterAPI&rsquo;s kind provider to create a cluster. The only dependencies are kubectl and kind. The we will install ClusterAPI&rsquo;s client.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -L https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.0.4/clusterctl-linux-amd64 -o clusterctl
</span></span><span style="display:flex;"><span>chmod +x ./clusterctl
</span></span><span style="display:flex;"><span>sudo mv ./clusterctl /usr/local/bin/clusterctl
</span></span><span style="display:flex;"><span>clusterctl version
</span></span><span style="display:flex;"><span><span style="color:#75715e"># OR</span>
</span></span><span style="display:flex;"><span>brew install kind
</span></span><span style="display:flex;"><span>brew install kubernetes-cli
</span></span><span style="display:flex;"><span>brew install kubectx
</span></span><span style="display:flex;"><span>brew install clusterctl
</span></span></code></pre></div><p>To manage the new clusters we need a management kubernetes cluster where we will install the ClusterAPI controller and it&rsquo;s CRDs. For this demo I will use a kind cluster for this porpose too.</p>
<p>Fo this the management kind cluster need to be communicat with the underlying docker engine on the host. To do that we need to mount the docker engine socket into the kind cluster&rsquo;s vm.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &gt; cluster-mgmt.yaml &lt;&lt;EOF</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kind.x-k8s.io/v1alpha4</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodes</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraMounts</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hostPath</span>: <span style="color:#ae81ff">/var/lib/docker</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">containerPath</span>: <span style="color:#ae81ff">/var/lib/docker</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hostPath</span>: <span style="color:#ae81ff">/var/run/docker.sock</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">containerPath</span>: <span style="color:#ae81ff">/var/run/docker.sock</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kind create cluster --config cluster-mgmt.yaml --name mgmt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>docker ps                                                                                                                   
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CONTAINER ID   IMAGE                  COMMAND                  CREATED              STATUS          PORTS                                      NAMES
</span></span><span style="display:flex;"><span>414fd857c0fb   kindest/node:v1.32.2   <span style="color:#e6db74">&#34;/usr/local/bin/entr…&#34;</span>   About a minute ago   Up <span style="color:#ae81ff">58</span> seconds   127.0.0.1:43483-&gt;6443/tcp                  mgmt-control-plane
</span></span><span style="display:flex;"><span>1815dce2b51f   nginx:latest           <span style="color:#e6db74">&#34;/docker-entrypoint.…&#34;</span>   <span style="color:#ae81ff">2</span> weeks ago          Up <span style="color:#ae81ff">49</span> minutes   0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp   kubedash-proxy
</span></span></code></pre></div><p>Install the ClusterAPI operator and CRDs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export CLUSTER_TOPOLOGY<span style="color:#f92672">=</span>true
</span></span><span style="display:flex;"><span>clusterctl init --infrastructure docker
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pod -n capd-system                                                                      
</span></span><span style="display:flex;"><span>kubectl get pod -n capi-kubeadm-bootstrap-system
</span></span><span style="display:flex;"><span>kubectl get pod -n capi-kubeadm-control-plane-system
</span></span><span style="display:flex;"><span>kubectl get crd | grep cluster
</span></span></code></pre></div><p>Once the management cluster is ready, you can create your first workload cluster.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>clusterctl generate cluster capi-quickstart --flavor development <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--kubernetes-version v1.31.0 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--control-plane-machine-count<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--worker-machine-count<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>&gt; capi-quickstart.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f capi-quickstart.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get cluster
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>clusterctl describe cluster capi-quickstart
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get kubeadmcontrolplane
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>NAME              CLUSTERCLASS   PHASE         AGE     VERSION
</span></span><span style="display:flex;"><span>capi-quickstart   quick-start    Provisioned   5m47s   v1.31.0
</span></span></code></pre></div><h3 id="deploy-cni">Deploy CNI</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># First, get the kubeconfig</span>
</span></span><span style="display:flex;"><span>clusterctl get kubeconfig capi-quickstart &gt; kubeconfig.capi-quickstart.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Install Calico</span>
</span></span><span style="display:flex;"><span>kubectl --kubeconfig<span style="color:#f92672">=</span>./kubeconfig.capi-quickstart.yaml apply <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/calico.yaml
</span></span></code></pre></div><h2 id="upgrade-cluster">Upgrade cluster</h2>
<p>As I sead earlier ClusterApi is a Kubernetes cluster lifecycle manager so you can use it to upgrade your cluster:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get kubeadmcontrolplane,machinedeployments
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl patch cluster capi-quickstart --type json <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--patch <span style="color:#e6db74">&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/topology/version&#34;, &#34;value&#34;: &#34;v1.32.2&#34;}]&#39;</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Automatic Kubernetes Certificate Renewal]]></title>
            <link href="https://devopstales.github.io/kubernetes/automatic-k8s-certificate-renewal/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/rke2-ingress-loadbalancer/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 With MetalLB and NGINX Ingress Controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-change-ip/?utm_source=atom_feed" rel="related" type="text/html" title="How to Change IP on Kubernetes node." />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
                <link href="https://devopstales.github.io/kubernetes/k8s-prometheus-stack/?utm_source=atom_feed" rel="related" type="text/html" title="K8S Logging And Monitoring" />
            
                <id>https://devopstales.github.io/kubernetes/automatic-k8s-certificate-renewal/</id>
            
            
            <published>2024-12-20T00:00:00+00:00</published>
            <updated>2024-12-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can automate the Kubernetes Certificate renewal.</p>
<p>Create a Bash script for renewing the certificates:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /usr/local/bin/k8s-certs-renew.sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;## Expiration before renewal ##&#34;</span>
</span></span><span style="display:flex;"><span>/usr/local/bin/kubeadm certs check-expiration
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;## Renewing certificates managed by kubeadm ##&#34;</span>
</span></span><span style="display:flex;"><span>/usr/local/bin/kubeadm certs renew all
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;## Restarting control plane pods managed by kubeadm ##&#34;</span>
</span></span><span style="display:flex;"><span>/usr/local/bin/crictl pods --namespace kube-system --name <span style="color:#e6db74">&#39;kube-scheduler-*|kube-controller-manager-*|kube-apiserver-*|etcd-*&#39;</span> -q | /usr/bin/xargs /usr/local/bin/crictl rmp -f
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;## Updating /root/.kube/config ##&#34;</span>
</span></span><span style="display:flex;"><span>cp /etc/kubernetes/admin.conf /root/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;## Waiting for apiserver to be up again ##&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">until</span> printf <span style="color:#e6db74">&#34;&#34;</span> 2&gt;&gt;/dev/null &gt;&gt;/dev/tcp/127.0.0.1/6443; <span style="color:#66d9ef">do</span> sleep 1; <span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;## Expiration after renewal ##&#34;</span>
</span></span><span style="display:flex;"><span>/usr/local/bin/kubeadm certs check-expiration
</span></span></code></pre></div><p>Create a systemd service to call the script:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>/etc/systemd/system/k8s-certs-renew.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Unit<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Description<span style="color:#f92672">=</span>Renew K8S control plane certificates
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Service<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Type<span style="color:#f92672">=</span>oneshot
</span></span><span style="display:flex;"><span>ExecStart<span style="color:#f92672">=</span>/usr/local/bin/k8s-certs-renew.sh
</span></span></code></pre></div><p>Create a systemd timer to trigger the service at regular intervals:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat /etc/systemd/system/k8s-certs-renew.timer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Unit<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Description<span style="color:#f92672">=</span>Timer to renew K8S control plane certificates
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Timer<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>OnCalendar<span style="color:#f92672">=</span>Fri *-*-1,2,3,4,5,6,7 03:10:00
</span></span><span style="display:flex;"><span>RandomizedDelaySec<span style="color:#f92672">=</span>30min
</span></span><span style="display:flex;"><span>Persistent<span style="color:#f92672">=</span>yes
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Install<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>WantedBy<span style="color:#f92672">=</span>multi-user.target
</span></span></code></pre></div><p>Execute the following commands to complete the process:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl daemon-reload
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl restart k8s-certs-renew.timer
</span></span></code></pre></div><p><a href="https://github.com/yuyicai/update-kube-cert">https://github.com/yuyicai/update-kube-cert</a></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[What is RBAC in Kubernetes?]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-rbac/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-custom-kube-scheduler/?utm_source=atom_feed" rel="related" type="text/html" title="Custom Kube-Scheduler" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kube-scheduler-profile/?utm_source=atom_feed" rel="related" type="text/html" title="Kube-Scheduler Profile" />
                <link href="https://devopstales.github.io/kubernetes/k8s-hierarchical-namespace-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Hierarchical namespace controller" />
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-dmz-vxlan/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes with external Ingress Controller with Haproxy and VXLAN" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-rbac/</id>
            
            
            <published>2024-11-23T00:00:00+00:00</published>
            <updated>2024-11-23T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use RBAC in kubernetes.</p>
<h3 id="what-is-rbac">What is RBAC?</h3>
<p>RBAC stands for Role-Based Access Control. It is an approach that is used for restricting access to resources dor users based on roles. Kubernetes use RBAC for authorization, for example to giving access to users and groups to certain Kubernetes resources. It uses roles to adding or removing permissions. For Kubernetes RBAC is the way to restrict who can access what whitin the cluster.</p>
<h3 id="why-rbac">Why RBAC?</h3>
<p>A kubernetes cluster is beeing used by multiple users. This users can be different types od users, for example developers, testers, application administrators and cluster administrators. This groups of userc need different permissions to do there jobs. That is where the notion of RBAC or Role-Based Access Control comes into play. You can create different roles for this groups and associate the roles with the users or groups.</p>
<p><img src="/img/include/rbac01.webp" alt="RBAC"  class="zoomable" /></p>
<h3 id="role">Role</h3>
<p>A role defines what you can do to a specific kubernetes resource. So the role is containing two main part, one is representing what permissions you have and another represents the kubernetes resource in the kubernetes api structure.</p>
<p>Here is a simple example for Roles, where the user has permission to just get and list the pods:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">elasticsearch</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">pods</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">verb</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">get</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">list</span>
</span></span></code></pre></div><h3 id="clusterrole">ClusterRole</h3>
<p>Roles are used to assigning resources for a namespace, but if you need to assign resources on a cluster level, you need to use ClusterRole. It is similar to Roles, but it can grant permissions that are cluster-scoped such as giving resource permissions across all namespaces in the cluster.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rbac.authorization.kubernetes.io/autoupdate</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes.io/bootstrapping</span>: <span style="color:#ae81ff">rbac-defaults</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-admin</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#e6db74">&#34;*&#34;</span>
</span></span></code></pre></div><h3 id="rolebinding">RoleBinding</h3>
<p>RoleBinding is used for granting permission to a Subject in a Kubernetes cluster. Subjects can be users, service accounts or groups trying to access Kubernetes API.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">elasticsearch</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">elasticsearch</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">User</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">John</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span></code></pre></div><p>Below is an example of RoleBinding where <code>roleRef</code> is being used to bind user <code>John</code> with the previously created <code>elasticsearch</code> role in the <code>default</code> namespace.</p>
<h3 id="clusterrolebinding">ClusterRoleBinding</h3>
<p>ClusterRoleBinding is used to grant permission to a subject on a cluster-level in all the namespaces.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-admin</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-admin</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">name</span>: <span style="color:#ae81ff">masters</span>
</span></span></code></pre></div><h3 id="what-can-i-bind-with-what">What can I bind with what?</h3>
<p>Usually you use RoleBinding to bind Role and ClusterRoleBinding to bind ClusterRole, but you can use RoleBinding to bind ClusterRole to a specific namespace. It is a best practice to create global ClusterRoles for specific tasks and bind them to namespaces with RoleBinding.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">developer-binding-to-default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">template-namespaced-resources---developer</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">developer-team</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span></code></pre></div><h3 id="aggregated-clusterroles">Aggregated ClusterRoles</h3>
<p>You can aggregate several ClusterRoles into one combined ClusterRole.  If you create a ClusterRole with aggregationRule the controller in the Kubernetes cluster will search fo the ClusterRoles with the matching labels and combines ther roles into the Aggregated ClusterRole.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">monitoring</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">aggregationRule</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">clusterRoleSelectors</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">rbac.example.com/aggregate-to-monitoring</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>: [] <span style="color:#75715e"># The control plane automatically fills in the rules</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">monitoring-endpoints</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rbac.example.com/aggregate-to-monitoring</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># When you create the &#34;monitoring-endpoints&#34; ClusterRole,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># the rules below will be added to the &#34;monitoring&#34; ClusterRole.</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;services&#34;</span>, <span style="color:#e6db74">&#34;endpointslices&#34;</span>, <span style="color:#e6db74">&#34;pods&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;get&#34;</span>, <span style="color:#e6db74">&#34;list&#34;</span>, <span style="color:#e6db74">&#34;watch&#34;</span>]
</span></span></code></pre></div><p>The default ClusterRoles are using ClusterRole aggregation. This lets you include rules for custom resources defined by CustomResourceDefinition to extend the default roles.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">aggregate-cron-tabs-edit</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Add these permissions to the &#34;admin&#34; and &#34;edit&#34; default roles.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rbac.authorization.k8s.io/aggregate-to-admin</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rbac.authorization.k8s.io/aggregate-to-edit</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;stable.example.com&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;crontabs&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;get&#34;</span>, <span style="color:#e6db74">&#34;list&#34;</span>, <span style="color:#e6db74">&#34;watch&#34;</span>, <span style="color:#e6db74">&#34;create&#34;</span>, <span style="color:#e6db74">&#34;update&#34;</span>, <span style="color:#e6db74">&#34;patch&#34;</span>, <span style="color:#e6db74">&#34;delete&#34;</span>]
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">aggregate-cron-tabs-view</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Add these permissions to the &#34;view&#34; default role.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rbac.authorization.k8s.io/aggregate-to-view</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;stable.example.com&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;crontabs&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;get&#34;</span>, <span style="color:#e6db74">&#34;list&#34;</span>, <span style="color:#e6db74">&#34;watch&#34;</span>]
</span></span></code></pre></div>]]></content>
            
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="K8S" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Hierarchical namespace controller]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-hierarchical-namespace-controller/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-custom-kube-scheduler/?utm_source=atom_feed" rel="related" type="text/html" title="Custom Kube-Scheduler" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kube-scheduler-profile/?utm_source=atom_feed" rel="related" type="text/html" title="Kube-Scheduler Profile" />
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-dmz-vxlan/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes with external Ingress Controller with Haproxy and VXLAN" />
                <link href="https://devopstales.github.io/kubernetes/k8s-dmz-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes with external Ingress Controller with Haproxy and BGP" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-hierarchical-namespace-controller/</id>
            
            
            <published>2024-10-25T00:00:00+00:00</published>
            <updated>2024-10-25T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how to install Hierarchical namespace controller (HNC) on k8s.</p>
<h3 id="what-is-hierarchical-namespace-controller">What is Hierarchical namespace controller?</h3>
<p>Hierarchical namespace controller is a controller that allows you to create a hierarchy between namespace objects.</p>
<h3 id="installing">Installing</h3>
<p>You can install or upgrade HNC on your cluster using the following commands (admin privileges required):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Select the latest version of HNC</span>
</span></span><span style="display:flex;"><span>HNC_VERSION<span style="color:#f92672">=</span>v1.1.0
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Select the variant of HNC you like. Other than &#39;default&#39;, options include:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># &#39;hrq&#39;: Like default, but with hierarchical quotas.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># &#39;ha&#39;: Like default, but with two deployments: one single-pod for the controller, and one three-pod for the webhooks</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># &#39;default-cm&#39;: Like default, but without the built-in cert rotator, and with support for cert-manager</span>
</span></span><span style="display:flex;"><span>HNC_VARIANT<span style="color:#f92672">=</span>default
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Install HNC. Afterwards, wait up to 30s for HNC to refresh the certificates on its webhooks.</span>
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/kubernetes-sigs/hierarchical-namespaces/releases/download/<span style="color:#e6db74">${</span>HNC_VERSION<span style="color:#e6db74">}</span>/<span style="color:#e6db74">${</span>HNC_VARIANT<span style="color:#e6db74">}</span>.yaml 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Install kubectl plugin with krew</span>
</span></span><span style="display:flex;"><span>kubectl krew install hns
</span></span></code></pre></div><h3 id="basic-functionality">Basic functionality</h3>
<blockquote>
<p>Demonstrates: setting parent-child relationships, subnamespace creation, RBAC propagation, hierarchy modification.</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create namespace acme-org
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create namespace team-a
</span></span><span style="display:flex;"><span>kubectl create namespace service-1
</span></span></code></pre></div><p>By default, there&rsquo;s no relationship between these namespaces. Let&rsquo;s make <code>acme-org</code> the parent of <code>team-a</code>, and <code>team-a</code> the parent of <code>service-1</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Make acme-org the parent of team-a</span>
</span></span><span style="display:flex;"><span>kubectl hns set team-a --parent acme-org
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># This won&#39;t work, will be rejected since it would cause a cycle. Try it!</span>
</span></span><span style="display:flex;"><span>kubectl hns set acme-org --parent team-a
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Make team-a the parent of service-1</span>
</span></span><span style="display:flex;"><span>kubectl hns set service-1 --parent team-a
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the hierarchy</span>
</span></span><span style="display:flex;"><span>kubectl hns tree acme-org
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Output:</span>
</span></span><span style="display:flex;"><span>acme-org
</span></span><span style="display:flex;"><span>└── team-a
</span></span><span style="display:flex;"><span>     └── service-1
</span></span></code></pre></div><h3 id="subnamespaces">Subnamespaces</h3>
<p>Imagine you have a team called <code>team-b</code> under the org called <code>acme-org</code>. You are the admin of the namespace <code>team-b</code> and have no cluster-wide permissions to create namespaces, but you do have a <code>RoleBinding</code> in <code>team-b</code> that gives you permission to create a <code>SubnamespaceAnchor</code> object in that namespace.</p>
<p>Now you would like to create three <code>subnamespaces</code> for services owned by your team, say <code>service-1</code>, <code>service-2</code> and <code>service-3</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl hns create service-1 -n team-b
</span></span><span style="display:flex;"><span>kubectl hns create service-2 -n team-b
</span></span><span style="display:flex;"><span>kubectl hns create service-3 -n team-b
</span></span><span style="display:flex;"><span>kubectl hns tree team-a
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Expected output:</span>
</span></span><span style="display:flex;"><span>team-b
</span></span><span style="display:flex;"><span>├── <span style="color:#f92672">[</span>s<span style="color:#f92672">]</span> service-1
</span></span><span style="display:flex;"><span>├── <span style="color:#f92672">[</span>s<span style="color:#f92672">]</span> service-2
</span></span><span style="display:flex;"><span>└── <span style="color:#f92672">[</span>s<span style="color:#f92672">]</span> service-3
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>s<span style="color:#f92672">]</span> Indicates subnamespace
</span></span></code></pre></div><p>As with regular namespaces (&ldquo;full namespaces,&rdquo; in HNC terms), subnamespaces must have unique names.</p>
<h3 id="hierarchical-rbac">Hierarchical RBAC</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl -n team-a create role team-a-sre --verb<span style="color:#f92672">=</span>update --resource<span style="color:#f92672">=</span>deployments
</span></span><span style="display:flex;"><span>kubectl -n team-a create rolebinding team-a-sres --role team-a-sre --serviceaccount<span style="color:#f92672">=</span>team-a:default
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl -n acme-org create role org-sre --verb<span style="color:#f92672">=</span>update --resource<span style="color:#f92672">=</span>deployments
</span></span><span style="display:flex;"><span>kubectl -n acme-org create rolebinding org-sres --role org-sre --serviceaccount<span style="color:#f92672">=</span>acme-org:default
</span></span></code></pre></div><p>Now, if we check <code>service-1</code>, we&rsquo;ll see that the rolebindings from the ancestor namespaces have been propagated to the child namespace.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl -n service-1 describe roles
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Output: you should see two roles, one propagated from acme-org and the other</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># from team-a.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl -n service-1 get rolebindings
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Output: similarly, you should see two propagated rolebindings.</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe rolebinding org-sres -n team-a
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Output:</span>
</span></span><span style="display:flex;"><span>Name:         sres
</span></span><span style="display:flex;"><span>Labels:       hnc.x-k8s.io/inheritedFrom<span style="color:#f92672">=</span>acme-org  <span style="color:#75715e"># inserted by HNC</span>
</span></span><span style="display:flex;"><span>Annotations:  &lt;none&gt;
</span></span><span style="display:flex;"><span>Role:
</span></span><span style="display:flex;"><span>  Kind:  ClusterRole
</span></span><span style="display:flex;"><span>  Name:  admin
</span></span><span style="display:flex;"><span>Subjects: ...
</span></span></code></pre></div><p>The controller keeps the RBAC objects in sync with the current hierarchy.</p>
<h3 id="hierarchical-network-policy">Hierarchical network policy</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl hns create service-2 -n team-a
</span></span><span style="display:flex;"><span>kubectl hns tree acme-org
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>acme-org
</span></span><span style="display:flex;"><span>├── team-a
</span></span><span style="display:flex;"><span>│   ├── service-1
</span></span><span style="display:flex;"><span>│   └── <span style="color:#f92672">[</span>s<span style="color:#f92672">]</span> service-2
</span></span><span style="display:flex;"><span>└── <span style="color:#f92672">[</span>s<span style="color:#f92672">]</span> team-b
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run s2 -n service-2 --image<span style="color:#f92672">=</span>nginxinc/nginx-unprivileged --restart<span style="color:#f92672">=</span>Never --expose --port <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Verify that it&#39;s running:</span>
</span></span><span style="display:flex;"><span>kubectl get service,pod -o wide -n service-2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># To test that the service is accessible from workloads in different namespaces, start a client pod in service-1 and confirm that the service is reachable.</span>
</span></span><span style="display:flex;"><span>kubectl run client -n service-1 -it --image<span style="color:#f92672">=</span>alpine --restart<span style="color:#f92672">=</span>Never --rm -- sh
</span></span><span style="display:flex;"><span>wget -qO- --timeout <span style="color:#ae81ff">2</span> http://s2.service-2:8080
</span></span></code></pre></div><p>Now we&rsquo;ll create a default network policy that blocks any ingress from other namespaces:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl apply -f - &lt;&lt; EOF</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">deny-from-other-namespaces</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">acme-org</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSelector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">from</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">podSelector</span>: {}
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>Now let&rsquo;s ensure this policy can be propagated to its descendants.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl hns config set-resource networkpolicies --group networking.k8s.io --mode Propagate
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># And verify it got propagated:</span>
</span></span><span style="display:flex;"><span>kubectl get netpol --all-namespaces | grep deny
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Expected output:</span>
</span></span><span style="display:flex;"><span>acme-org    deny-from-other-namespaces   &lt;none&gt;         37s
</span></span><span style="display:flex;"><span>service-1   deny-from-other-namespaces   &lt;none&gt;         0s
</span></span><span style="display:flex;"><span>service-2   deny-from-other-namespaces   &lt;none&gt;         0s
</span></span><span style="display:flex;"><span>team-a      deny-from-other-namespaces   &lt;none&gt;         0s
</span></span><span style="display:flex;"><span>team-b      deny-from-other-namespaces   &lt;none&gt;         0s
</span></span></code></pre></div><p>If network policies have been correctly enabled on your cluster, we&rsquo;ll now see that we can no longer access <code>service-2</code> from a client in <code>service-1</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run client -n service-1 -it --image<span style="color:#f92672">=</span>alpine --restart<span style="color:#f92672">=</span>Never --rm -- sh
</span></span><span style="display:flex;"><span>wget -qO- --timeout <span style="color:#ae81ff">2</span> http://s2.service-2:8080
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Observe timeout</span>
</span></span></code></pre></div><p>But in this example, we&rsquo;d like all service from a specific team to be able to interact with each other, so we&rsquo;ll create a second network policy as shown below that will allow all namespaces within team-a to be able to communicate with each other.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl apply -f - &lt;&lt; EOF</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">allow-team-a</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">team-a</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSelector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">from</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">namespaceSelector</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">matchExpressions</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">key</span>: <span style="color:#e6db74">&#39;team-a.tree.hnc.x-k8s.io/depth&#39;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">operator</span>: <span style="color:#ae81ff">Exists</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><h3 id="hierarchical-resource-quotas-hrqs">Hierarchical resource quotas (HRQs)</h3>
<p>Let&rsquo;s assume you own acme-org from the previous example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>acme-org
</span></span><span style="display:flex;"><span>├── <span style="color:#f92672">[</span>s<span style="color:#f92672">]</span> team-a
</span></span><span style="display:flex;"><span>└── <span style="color:#f92672">[</span>s<span style="color:#f92672">]</span> team-b
</span></span></code></pre></div><p>If you create a <code>HierarchicalResourceQuota</code> in namespace <code>acme-org</code>, the sum of all <code>subnamespaces</code> resources can&rsquo;t surpass the <code>HRQ</code>.</p>
<p>Create the HRQ:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl apply -f - &lt;&lt; EOF</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">hnc.x-k8s.io/v1alpha2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HierarchicalResourceQuota</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">acme-org-hrq</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">acme-org</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hard</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">services</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create service clusterip team-a-svc --clusterip<span style="color:#f92672">=</span>None -n team-a
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Now, when you try to create a Service in namespace team-b:</span>
</span></span><span style="display:flex;"><span>kubectl create service clusterip team-b-svc --clusterip<span style="color:#f92672">=</span>None -n team-b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># You get an error:</span>
</span></span><span style="display:flex;"><span>Error from server <span style="color:#f92672">(</span>Forbidden<span style="color:#f92672">)</span>:
</span></span><span style="display:flex;"><span>  error when creating <span style="color:#e6db74">&#34;STDIN&#34;</span>:
</span></span><span style="display:flex;"><span>    admission webhood <span style="color:#e6db74">&#34;resourcesquotasstatus.hnc.x-k8s.io&#34;</span> denied the request:
</span></span><span style="display:flex;"><span>      exceeded hierarchical quota in namespace <span style="color:#e6db74">&#34;acme-org&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;acme-org-hrq&#34;</span>, requested: services<span style="color:#f92672">=</span>1, used: services<span style="color:#f92672">=</span>1, limited: services<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="K8S" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Custom Kube-Scheduler]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-custom-kube-scheduler/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-kube-scheduler-profile/?utm_source=atom_feed" rel="related" type="text/html" title="Kube-Scheduler Profile" />
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-dmz-vxlan/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes with external Ingress Controller with Haproxy and VXLAN" />
                <link href="https://devopstales.github.io/kubernetes/k8s-dmz-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes with external Ingress Controller with Haproxy and BGP" />
                <link href="https://devopstales.github.io/kubernetes/cni-genie/?utm_source=atom_feed" rel="related" type="text/html" title="CNI-Genie: network separation with multiple CNI" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-custom-kube-scheduler/</id>
            
            
            <published>2024-10-24T00:00:00+00:00</published>
            <updated>2024-10-24T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can create a custom Kube-Scheduler to chaneg scheduling options.</p>
<h3 id="what-is-kube-scheduler">What is Kube-Scheduler?</h3>
<p>Kube-Scheduler is the component that is makes decisions on where to run Pods based on various criteria such as node selectors, affinities, hardware constraints, resource limits. By default the sheduler schedules the pods to the lease used node. In this example I will change this to the <img src="https://kubernetes.io/docs/concepts/scheduling-eviction/resource-bin-packing/#enabling-bin-packing-using-mostallocated-strategy" alt="MostAllocated strategy"  class="zoomable" />. With this configuration you can save resources and mony.</p>
<blockquote>
<p>This post was tested on Kubernetes version 1.25 and later.</p></blockquote>
<h3 id="create-config-for-the-scheduler">Create Config for the scheduler</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubescheduler.config.k8s.io/v1beta2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeSchedulerConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">leaderElection</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">leaderElect</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">profiles</span>:
</span></span><span style="display:flex;"><span>   - <span style="color:#f92672">schedulerName</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">pluginConfig</span>:
</span></span><span style="display:flex;"><span>       - <span style="color:#f92672">args</span>:
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubescheduler.config.k8s.io/v1beta2</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NodeResourcesFitArgs</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">scoringStrategy</span>:
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>                   - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cpu</span>
</span></span><span style="display:flex;"><span>                     <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>                   - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">memory</span>
</span></span><span style="display:flex;"><span>                     <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">type</span>: <span style="color:#ae81ff">MostAllocated</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">name</span>: <span style="color:#ae81ff">NodeResourcesFit</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">plugins</span>:
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">score</span>:
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">enabled</span>:
</span></span><span style="display:flex;"><span>               - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">NodeResourcesFit</span>
</span></span><span style="display:flex;"><span>                 <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">1</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create configmap custom-scheduler-config -n kube-system --from-file<span style="color:#f92672">=</span>scheduler-config.yaml
</span></span></code></pre></div><h3 id="create-the-serviceaccount-for-the-custom-kube-scheduler">Create the ServiceAccount for the custom kube-scheduler</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceAccount</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">pods</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">pods/status</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">pods/binding</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">get</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">list</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">watch</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">create</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">update</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">patch</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">delete</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">nodes</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">get</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">list</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">watch</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">storage.k8s.io</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">storageclasses</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">csinodes</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">csidrivers</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">csistoragecapacities</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">watch</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">list</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">get</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">apps</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">replicasets</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">statefulsets</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">watch</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">list</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">get</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">persistentvolumeclaims</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">services</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">namespaces</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">configmaps</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">replicationcontrollers</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">persistentvolumes</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">poddisruptionbudgets</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">replicasets</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">statefulsets</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">watch</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">list</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">get</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">policy</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">poddisruptionbudgets</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">watch</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">list</span>
</span></span><span style="display:flex;"><span> - <span style="color:#ae81ff">get</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceAccount</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f scheduler-sa.yaml
</span></span></code></pre></div><h3 id="create-the-custom-scheduler-deployment">Create the custom scheduler deployment</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">component</span>: <span style="color:#ae81ff">scheduler</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">tier</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>     - <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>       - <span style="color:#ae81ff">/usr/local/bin/kube-scheduler</span>
</span></span><span style="display:flex;"><span>       - --<span style="color:#ae81ff">leader-elect=false</span>
</span></span><span style="display:flex;"><span>       - --<span style="color:#ae81ff">config=/etc/kubernetes/scheduler-config.yaml</span>
</span></span><span style="display:flex;"><span>       - -<span style="color:#ae81ff">v=5</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">env</span>: []
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">image</span>: <span style="color:#ae81ff">registry.k8s.io/kube-scheduler:v1.25.12</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">200m</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">128Mi</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">128Mi</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/healthz</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">port</span>: <span style="color:#ae81ff">10259</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">scheme</span>: <span style="color:#ae81ff">HTTPS</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/healthz</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">port</span>: <span style="color:#ae81ff">10259</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">scheme</span>: <span style="color:#ae81ff">HTTPS</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>       - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/etc/kubernetes/scheduler-config.yaml</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler-config</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">subPath</span>: <span style="color:#ae81ff">scheduler-config.yaml</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">serviceAccountName</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>     - <span style="color:#f92672">configMap</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler-config</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">name</span>: <span style="color:#ae81ff">custom-scheduler-config</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f custom-scheduler-deployment.yaml
</span></span></code></pre></div><h3 id="schedule-pods-with-the-custom-kube-scheduler">Schedule Pods with the custom kube-scheduler</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">my-app</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">schedulerName</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">my-app</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">my-app-image</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="K8S" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kube-Scheduler Profile]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-kube-scheduler-profile/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-dmz-vxlan/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes with external Ingress Controller with Haproxy and VXLAN" />
                <link href="https://devopstales.github.io/kubernetes/k8s-dmz-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes with external Ingress Controller with Haproxy and BGP" />
                <link href="https://devopstales.github.io/kubernetes/cni-genie/?utm_source=atom_feed" rel="related" type="text/html" title="CNI-Genie: network separation with multiple CNI" />
                <link href="https://devopstales.github.io/kubernetes/multus-nmstate/?utm_source=atom_feed" rel="related" type="text/html" title="Configurre network wit nmstate operator" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-kube-scheduler-profile/</id>
            
            
            <published>2024-10-23T00:00:00+00:00</published>
            <updated>2024-10-23T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can create a custom Kube-Scheduler profile to chaneg scheduling options.</p>
<h3 id="what-is-kube-scheduler">What is Kube-Scheduler?</h3>
<p>Kube-Scheduler is the component that is makes decisions on where to run Pods based on various criteria such as node selectors, affinities, hardware constraints, resource limits. By default the sheduler schedules the pods to the lease used node. In this example I will change this to the <img src="https://kubernetes.io/docs/concepts/scheduling-eviction/resource-bin-packing/#enabling-bin-packing-using-mostallocated-strategy" alt="MostAllocated strategy"  class="zoomable" />. With this configuration you can save resources and mony.</p>
<blockquote>
<p>This post was tested on Kubernetes version 1.25 and later.</p></blockquote>
<h3 id="find-kube-scheduler-config">Find Kube-Scheduler config</h3>
<p>On the masternodes find the <code>/etc/kubernetes/manifests/kube-scheduler.yaml</code> file.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">component</span>: <span style="color:#ae81ff">kube-scheduler</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tier</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kube-scheduler</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">kube-scheduler</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">authentication-kubeconfig=/etc/kubernetes/scheduler.conf</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">authorization-kubeconfig=/etc/kubernetes/scheduler.conf</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">bind-address=127.0.0.1</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">kubeconfig=/etc/kubernetes/scheduler.conf</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">leader-elect=true</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">port=0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">k8s.gcr.io/kube-scheduler:v1.25.2</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">failureThreshold</span>: <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">host</span>: <span style="color:#ae81ff">127.0.0.1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/healthz</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">10259</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">scheme</span>: <span style="color:#ae81ff">HTTPS</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">initialDelaySeconds</span>: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">periodSeconds</span>: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">timeoutSeconds</span>: <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kube-scheduler</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">100m</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">startupProbe</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">failureThreshold</span>: <span style="color:#ae81ff">24</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">host</span>: <span style="color:#ae81ff">127.0.0.1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/healthz</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">10259</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">scheme</span>: <span style="color:#ae81ff">HTTPS</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">initialDelaySeconds</span>: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">periodSeconds</span>: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">timeoutSeconds</span>: <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/etc/kubernetes/scheduler.conf</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kubeconfig</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">readOnly</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hostNetwork</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">priorityClassName</span>: <span style="color:#ae81ff">system-node-critical</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">seccompProfile</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">RuntimeDefault</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hostPath</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/etc/kubernetes/scheduler.conf</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">FileOrCreate</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kubeconfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {}
</span></span></code></pre></div><h3 id="create-config-for-the-scheduler">Create Config for the scheduler</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubescheduler.config.k8s.io/v1beta2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeSchedulerConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">leaderElection</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">leaderElect</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">profiles</span>:
</span></span><span style="display:flex;"><span>   - <span style="color:#f92672">schedulerName</span>: <span style="color:#ae81ff">custom-scheduler</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">pluginConfig</span>:
</span></span><span style="display:flex;"><span>       - <span style="color:#f92672">args</span>:
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubescheduler.config.k8s.io/v1beta2</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NodeResourcesFitArgs</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">scoringStrategy</span>:
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>                   - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cpu</span>
</span></span><span style="display:flex;"><span>                     <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>                   - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">memory</span>
</span></span><span style="display:flex;"><span>                     <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">type</span>: <span style="color:#ae81ff">MostAllocated</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">name</span>: <span style="color:#ae81ff">NodeResourcesFit</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">plugins</span>:
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">score</span>:
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">enabled</span>:
</span></span><span style="display:flex;"><span>               - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">NodeResourcesFit</span>
</span></span><span style="display:flex;"><span>                 <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">1</span>
</span></span></code></pre></div><h3 id="update-scheduler-manifest">Update scheduler manifest</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo cp kube-scheduler.yaml.bak /etc/kubernetes/manifests/kube-scheduler.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">component</span>: <span style="color:#ae81ff">kube-scheduler</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tier</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kube-scheduler</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">kube-scheduler</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">config=/etc/kubernetes/myscheduler.conf</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">authorization-kubeconfig=/etc/kubernetes/scheduler.conf</span>
</span></span><span style="display:flex;"><span>    - --<span style="color:#ae81ff">authentication-kubeconfig=/etc/kubernetes/scheduler.conf</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">k8s.gcr.io/kube-scheduler:v1.25.2</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">failureThreshold</span>: <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">host</span>: <span style="color:#ae81ff">127.0.0.1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/healthz</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">10259</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">scheme</span>: <span style="color:#ae81ff">HTTPS</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">initialDelaySeconds</span>: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">periodSeconds</span>: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">timeoutSeconds</span>: <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kube-scheduler</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">100m</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">startupProbe</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">failureThreshold</span>: <span style="color:#ae81ff">24</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">host</span>: <span style="color:#ae81ff">127.0.0.1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/healthz</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">10259</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">scheme</span>: <span style="color:#ae81ff">HTTPS</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">initialDelaySeconds</span>: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">periodSeconds</span>: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">timeoutSeconds</span>: <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/etc/kubernetes/scheduler.conf</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kubeconfig</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">readOnly</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/etc/kubernetes/myscheduler.conf</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysched</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">readOnly</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hostNetwork</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">priorityClassName</span>: <span style="color:#ae81ff">system-node-critical</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">seccompProfile</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">RuntimeDefault</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hostPath</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/etc/kubernetes/scheduler.conf</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">FileOrCreate    </span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kubeconfig</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hostPath</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/etc/kubernetes/myscheduler.conf</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">FileOrCreate</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysched</span>
</span></span></code></pre></div><blockquote>
<p>Remember to xhnage the config on all master nodes.</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo cp kube-scheduler.yaml /etc/kubernetes/manifests/kube-scheduler.yaml
</span></span></code></pre></div>]]></content>
            
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="K8S" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes with external Ingress Controller with Haproxy and VXLAN]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-dmz-vxlan/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-dmz-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes with external Ingress Controller with Haproxy and BGP" />
                <link href="https://devopstales.github.io/kubernetes/cni-genie/?utm_source=atom_feed" rel="related" type="text/html" title="CNI-Genie: network separation with multiple CNI" />
                <link href="https://devopstales.github.io/kubernetes/multus-nmstate/?utm_source=atom_feed" rel="related" type="text/html" title="Configurre network wit nmstate operator" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-submariner/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Rancher Submariner Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-skupper/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Skupper Cluster Mesh" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-dmz-vxlan/</id>
            
            
            <published>2024-04-10T00:00:00+00:00</published>
            <updated>2024-04-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to nstall HAProxy Igress Controller on a separate VM instad of running it in the Kubernetes cluster as a pod. For this I  will use cilium external-workload option.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>At the company I working wor we head to create a kubernetes cluster with the DMZ network integration, but I didn&rsquo;t want to place the kubernetes cluster to the DMZ network. So I started to find a way to place only the Ingress Controller to a separate node and place only that to the DMZ. I found thet ther is an option with the HAProxy Igress Controller called external mode wher you can run the Ingress Controller not in a pod in the cluster but on a separate node.</p>
<h3 id="prerequisites">Prerequisites</h3>
<ul>
<li>recent enough kernel (&gt;= 4.19.57)</li>
<li>Docker 20.10 or newer</li>
<li>External workloads VM must have IP connectivity with the nodes on vxlan port <code>8472/udp</code></li>
<li>External workloads VM must have IP connectivity with loadbalancer IP and port</li>
<li>External workloads VM must have IP connectivity for kubernetes api</li>
<li>All external workloads must have a unique IP address assigned them</li>
<li>This guide assumes your external workload manages domain name resolution service by a stand-alone /etc/resolv.conf, or via systemd (e.g., Ubuntu, Debian).</li>
</ul>
<h3 id="ciliium-config">Ciliium config</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm upgrade cilium cilium/cilium -f cilium-helm-values.yaml -n kube-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cilium status
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cilium clustermesh enable --service-type LoadBalancer --enable-external-workloads
</span></span><span style="display:flex;"><span>cilium clustermesh vm create f101 -n ingress-system --ipv4-alloc-cidr 10.244.20.0/30
</span></span><span style="display:flex;"><span>cilium clustermesh vm status
</span></span><span style="display:flex;"><span>cilium clustermesh vm install install-external-workload.sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>scp install-external-workload.sh f101:
</span></span></code></pre></div><p>The vm object name must be the hostname of the external workload, as returned by the <code>hostname</code> command run in the external workload. In this example this is <code>f101</code>. For now you must also allocate a small IP CIDR that must be unique to each workload.  In this example this is <code>10.244.20.0/30</code>.</p>
<h3 id="install-cilium-external-workload">Install Cilium external workload</h3>
<p>On the External Ingress COntroller&rsquo;s VM we vill install cilium agent with the script:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./install-external-workload.sh
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo cilium-dbg status
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>KVStore:                 Ok         etcd: 1/1 connected, leases<span style="color:#f92672">=</span>1, lock leases<span style="color:#f92672">=</span>1, has-quorum<span style="color:#f92672">=</span>true: https://clustermesh-apiserver.cilium.io:2379 - 3.5.12 <span style="color:#f92672">(</span>Leader<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Kubernetes:              Disabled
</span></span><span style="display:flex;"><span>Host firewall:           Disabled
</span></span><span style="display:flex;"><span>SRv6:                    Disabled
</span></span><span style="display:flex;"><span>CNI Chaining:            none
</span></span><span style="display:flex;"><span>Cilium:                  Ok   1.15.3 <span style="color:#f92672">(</span>v1.15.3-22dfbc58<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>NodeMonitor:             Disabled
</span></span><span style="display:flex;"><span>Cilium health daemon:    Ok
</span></span><span style="display:flex;"><span>IPAM:                    IPv4: 1/2 allocated from 10.244.20.0/30, IPv6: 1/4294967294 allocated from f00d::a0f:0:0:0/96
</span></span><span style="display:flex;"><span>IPv4 BIG TCP:            Disabled
</span></span><span style="display:flex;"><span>IPv6 BIG TCP:            Disabled
</span></span><span style="display:flex;"><span>BandwidthManager:        Disabled
</span></span><span style="display:flex;"><span>Host Routing:            Legacy
</span></span><span style="display:flex;"><span>Masquerading:            IPTables <span style="color:#f92672">[</span>IPv4: Enabled, IPv6: Enabled<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Controller Status:       14/14 healthy
</span></span><span style="display:flex;"><span>Proxy Status:            OK, ip 10.244.20.2, <span style="color:#ae81ff">0</span> redirects active on ports 10000-20000, Envoy: embedded
</span></span><span style="display:flex;"><span>Global Identity Range:   min 256, max <span style="color:#ae81ff">65535</span>
</span></span><span style="display:flex;"><span>Hubble:                  Disabled
</span></span><span style="display:flex;"><span>Encryption:              Disabled
</span></span><span style="display:flex;"><span>Cluster health:                     Probe disabled
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nslookup -norecurse clustermesh-apiserver.kube-system.svc.cluster.local
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Server:         10.96.0.10
</span></span><span style="display:flex;"><span>Address:        10.96.0.10#53
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Name:   clustermesh-apiserver.kube-system.svc.cluster.local
</span></span><span style="display:flex;"><span>Address: 10.99.176.216
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ping <span style="color:#66d9ef">$(</span>sudo cilium-dbg service list get <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{[?(@.spec.flags.name==&#34;clustermesh-apiserver&#34;)].spec.backend-addresses[0].ip}&#39;</span><span style="color:#66d9ef">)</span> -c <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>PING 10.244.1.92 <span style="color:#f92672">(</span>10.244.1.92<span style="color:#f92672">)</span> 56<span style="color:#f92672">(</span>84<span style="color:#f92672">)</span> bytes of data.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 10.244.1.92: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">63</span> time<span style="color:#f92672">=</span>1.19 ms
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 10.244.1.92: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">63</span> time<span style="color:#f92672">=</span>0.587 ms
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 10.244.1.92: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">63</span> time<span style="color:#f92672">=</span>0.697 ms
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 10.244.1.92: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">63</span> time<span style="color:#f92672">=</span>0.634 ms
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 10.244.1.92: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">63</span> time<span style="color:#f92672">=</span>0.399 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--- 10.244.1.92 ping statistics ---
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">5</span> packets transmitted, <span style="color:#ae81ff">5</span> received, 0% packet loss, time 4076ms
</span></span><span style="display:flex;"><span>rtt min/avg/max/mdev <span style="color:#f92672">=</span> 0.399/0.702/1.193/0.264 ms
</span></span></code></pre></div><h3 id="install-the-ingress-controller-outside-of-your-cluster">Install the ingress controller outside of your cluster</h3>
<p>Copy the <code>/etc/kubernetes/admin.conf</code> kubeconfig file from the control plane server to this server and store it in the root user’s home directory. The ingress controller will use this to connect to the Kubernetes API.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo mkdir -p /root/.kube
</span></span><span style="display:flex;"><span>sudo cp admin.conf /root/.kube/config
</span></span><span style="display:flex;"><span>sudo chown -R root:root /root/.kube
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create configmap -n default haproxy-kubernetes-ingress
</span></span></code></pre></div><p>HAProxy Kubernetes Ingress Controller is compatible with a specific version of HAProxy. Install the HAProxy package on your Linux distribution based on the table below. For Ubuntu and Debian, follow the install steps at <a href="https://haproxy.debian.net/">haproxy.debian.net</a></p>
<table>
  <thead>
      <tr>
          <th>Ingress controller version</th>
          <th>Compatible HAProxy version</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1.11</td>
          <td>2.8</td>
      </tr>
      <tr>
          <td>1.10</td>
          <td>2.7</td>
      </tr>
      <tr>
          <td>1.9</td>
          <td>2.6</td>
      </tr>
      <tr>
          <td>1.8</td>
          <td>2.5</td>
      </tr>
      <tr>
          <td>1.7</td>
          <td>2.4</td>
      </tr>
  </tbody>
</table>
<p>In my case I use Ingress controller version <code>1.11</code> and HAProxy version <code>2.8</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl https://haproxy.debian.net/bernat.debian.org.gpg <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>      | gpg --dearmor &gt; /usr/share/keyrings/haproxy.debian.net.gpg
</span></span><span style="display:flex;"><span>echo deb <span style="color:#e6db74">&#34;[signed-by=/usr/share/keyrings/haproxy.debian.net.gpg]&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>      http://haproxy.debian.net bookworm-backports-2.8 main <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>      &gt; /etc/apt/sources.list.d/haproxy.list
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>apt-get update
</span></span><span style="display:flex;"><span>apt-get install haproxy<span style="color:#f92672">=</span>2.8.<span style="color:#ae81ff">\*</span>
</span></span></code></pre></div><p>Stop and disable the HAProxy service.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl stop haproxy
</span></span><span style="display:flex;"><span>sudo systemctl disable haproxy
</span></span></code></pre></div><p>Call the <code>setcap</code> command to allow HAProxy to bind to ports 80 and 443:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo setcap cap_net_bind_service<span style="color:#f92672">=</span>+ep /usr/sbin/haproxy
</span></span></code></pre></div><p>Download the ingress controller from the project’s <a href="https://github.com/haproxytech/kubernetes-ingress/releases/">GitHub Releases page</a>
Extract it and then copy it to the /usr/local/bin directory.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/haproxytech/kubernetes-ingress/releases/download/v1.11.3/haproxy-ingress-controller_1.11.3_Linux_x86_64.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar -xzvf haproxy-ingress-controller_1.11.3_Linux_x86_64.tar.gz
</span></span><span style="display:flex;"><span>sudo cp ./haproxy-ingress-controller /usr/local/bin/
</span></span></code></pre></div><p>Create the file <code>/lib/systemd/system/haproxy-ingress.service</code> and add the following to it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /lib/systemd/system/haproxy-ingress.service
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[Unit]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Description=&#34;HAProxy Kubernetes Ingress Controller&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Documentation=https://www.haproxy.com/
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Requires=network-online.target
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">After=network-online.target
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[Service]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Type=simple
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">User=root
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Group=root
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">ExecStart=/usr/local/bin/haproxy-ingress-controller --external --default-ssl-certificate=ingress-system/default-cert --configmap=default/haproxy-kubernetes-ingress --program=/usr/sbin/haproxy --disable-ipv6 --ipv4-bind-address=0.0.0.0 --http-bind-port=80 --https-bind-port=443  --ingress.class=ingress-public
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">ExecReload=/bin/kill --signal HUP $MAINPID
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KillMode=process
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KillSignal=SIGTERM
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Restart=on-failure
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">LimitNOFILE=65536
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[Install]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">WantedBy=multi-user.target
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>Enable and start the service.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl enable haproxy-ingress
</span></span><span style="display:flex;"><span>sudo systemctl start haproxy-ingress
</span></span></code></pre></div><h3 id="demo-aapp">Demo Aapp</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano demo-app.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: networking.k8s.io/v1
</span></span><span style="display:flex;"><span>kind: IngressClass
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  annotations:
</span></span><span style="display:flex;"><span>    ingressclass.kubernetes.io/is-default-class: <span style="color:#e6db74">&#34;false&#34;</span>
</span></span><span style="display:flex;"><span>  labels:
</span></span><span style="display:flex;"><span>    app.kubernetes.io/instance: ingress-public
</span></span><span style="display:flex;"><span>  name: ingress-public
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  controller: haproxy.org/ingress-controller/ingress-public
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: apps/v1
</span></span><span style="display:flex;"><span>kind: Deployment
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span> labels:
</span></span><span style="display:flex;"><span>   run: app
</span></span><span style="display:flex;"><span> name: app
</span></span><span style="display:flex;"><span> namespace: default
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span> replicas: <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span> selector:
</span></span><span style="display:flex;"><span>   matchLabels:
</span></span><span style="display:flex;"><span>     run: app
</span></span><span style="display:flex;"><span> template:
</span></span><span style="display:flex;"><span>   metadata:
</span></span><span style="display:flex;"><span>     labels:
</span></span><span style="display:flex;"><span>       run: app
</span></span><span style="display:flex;"><span>   spec:
</span></span><span style="display:flex;"><span>     containers:
</span></span><span style="display:flex;"><span>     - name: app
</span></span><span style="display:flex;"><span>       image: jmalloc/echo-server
</span></span><span style="display:flex;"><span>       ports:
</span></span><span style="display:flex;"><span>       - containerPort: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Service
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span> labels:
</span></span><span style="display:flex;"><span>   run: app
</span></span><span style="display:flex;"><span> name: app
</span></span><span style="display:flex;"><span> namespace: default
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span> selector:
</span></span><span style="display:flex;"><span>   run: app
</span></span><span style="display:flex;"><span> ports:
</span></span><span style="display:flex;"><span> - name: port-1
</span></span><span style="display:flex;"><span>   port: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>   protocol: TCP
</span></span><span style="display:flex;"><span>   targetPort: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: networking.k8s.io/v1
</span></span><span style="display:flex;"><span>kind: Ingress
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span> name: test-ingress
</span></span><span style="display:flex;"><span> namespace: default
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  ingressClassName: ingress-public
</span></span><span style="display:flex;"><span>  rules:
</span></span><span style="display:flex;"><span>  - host: <span style="color:#e6db74">&#34;example.com&#34;</span>
</span></span><span style="display:flex;"><span>    http:
</span></span><span style="display:flex;"><span>      paths:
</span></span><span style="display:flex;"><span>      - path: /
</span></span><span style="display:flex;"><span>        pathType: Prefix
</span></span><span style="display:flex;"><span>        backend:
</span></span><span style="display:flex;"><span>          service:
</span></span><span style="display:flex;"><span>            name: app
</span></span><span style="display:flex;"><span>            port:
</span></span><span style="display:flex;"><span>              number: <span style="color:#ae81ff">80</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f demo-app.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat /tmp/haproxy-ingress/etc/haproxy.cfg
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>backend default_app_port-1
</span></span><span style="display:flex;"><span>  mode http
</span></span><span style="display:flex;"><span>  balance roundrobin
</span></span><span style="display:flex;"><span>  option forwardfor
</span></span><span style="display:flex;"><span>  no option abortonclose
</span></span><span style="display:flex;"><span>  default-server check
</span></span><span style="display:flex;"><span>  server SRV_1 10.244.1.105:8080 enabled
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>egrep -r <span style="color:#e6db74">&#34;example&#34;</span> /tmp/haproxy-ingress/
</span></span><span style="display:flex;"><span>/tmp/haproxy-ingress/etc/maps/host.map:example.com                      example.com
</span></span><span style="display:flex;"><span>/tmp/haproxy-ingress/etc/maps/path-prefix.map:example.com/                      default_app_port-1
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo nano /etc/hosts
</span></span><span style="display:flex;"><span>127.0.0.1 example.com
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl http://example.com
</span></span><span style="display:flex;"><span>Request served by app-84bdb7868d-hxwb7
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>GET / HTTP/1.1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Host: example.com
</span></span><span style="display:flex;"><span>Accept: */*
</span></span><span style="display:flex;"><span>User-Agent: curl/8.1.2
</span></span><span style="display:flex;"><span>X-Forwarded-For: 192.168.56.7
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="haproxy" term="haproxy" label="haproxy" />
                             
                                <category scheme="cilium" term="cilium" label="cilium" />
                             
                                <category scheme="vxlan" term="vxlan" label="vxlan" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes with external Ingress Controller with Haproxy and BGP]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-dmz-bgp/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/rke2-ingress-loadbalancer/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 With MetalLB and NGINX Ingress Controller" />
                <link href="https://devopstales.github.io/kubernetes/cni-genie/?utm_source=atom_feed" rel="related" type="text/html" title="CNI-Genie: network separation with multiple CNI" />
                <link href="https://devopstales.github.io/kubernetes/multus-nmstate/?utm_source=atom_feed" rel="related" type="text/html" title="Configurre network wit nmstate operator" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-submariner/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Rancher Submariner Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-skupper/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Skupper Cluster Mesh" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-dmz-bgp/</id>
            
            
            <published>2024-03-03T00:00:00+00:00</published>
            <updated>2024-03-03T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to nstall HAProxy Igress Controller on a separate VM instad of running it in the Kubernetes cluster as a pod. For this I  will use cilium BGP pod CIDR export option.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>At the company I working wor we head to create a kubernetes cluster with the DMZ network integration, but I didn&rsquo;t want to place the kubernetes cluster to the DMZ network. So I started to find a way to place only the Ingress Controller to a separate node and place only that to the DMZ. I found thet ther is an option with the HAProxy Igress Controller called external mode wher you can run the Ingress Controller not in a pod in the cluster but on a separate node.</p>
<h3 id="ciliium-config">Ciliium config</h3>
<p>Enable BGP in cilium:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano cilium-helm-values.yaml</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">bgpControlPlane</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm upgrade cilium cilium/cilium -f cilium-helm-values.yaml -n kube-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># test ciliumBGP CRD</span>
</span></span><span style="display:flex;"><span>k api-resources | grep -i ciliumBGP
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># If not exists delete the operator pod</span>
</span></span><span style="display:flex;"><span>k delete pod -n kube-system cilium-operator-768959858c-zjjnc
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># now exists</span>
</span></span><span style="display:flex;"><span>k api-resources | grep -i ciliumBGP
</span></span><span style="display:flex;"><span>ciliumbgppeeringpolicies    bgpp    cilium.io/v2alpha1                     false        CiliumBGPPeeringPolicy
</span></span></code></pre></div><blockquote>
<p>I will use 3179 port as BGP port besause cilium ha no privilage for standerd 179</p></blockquote>
<p>Annotate all the nodes to use port 3179</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl annotate node m102 cilium.io/bgp-virtual-router.65002<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;local-port=3179&#34;</span>
</span></span><span style="display:flex;"><span>kubectl annotate node m102 cilium.io/bgp-virtual-router.65002<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;local-port=3179&#34;</span>
</span></span><span style="display:flex;"><span>kubectl annotate node m102 cilium.io/bgp-virtual-router.65002<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;local-port=3179&#34;</span>
</span></span></code></pre></div><p>Ceate the Cilium BGP pearing policy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano cilium-bgp-policy.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;cilium.io/v2alpha1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">CiliumBGPPeeringPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">bgp-peering-policy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">virtualRouters</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#f92672">localASN</span>: <span style="color:#ae81ff">65001</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">exportPodCIDR</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">neighbors</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">peerAddress</span>: <span style="color:#e6db74">&#39;192.168.56.13/32&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">peerASN</span>: <span style="color:#ae81ff">65001</span>
</span></span></code></pre></div><blockquote>
<p>When <code>localASN</code> and <code>peerASN</code> are the same, iBGP peering is used. When <code>localASN</code> and <code>peerASN</code> are different, eBGP peering is used.</p>
<ol>
<li>&lsquo;&lsquo;&lsquo;External Border Gateway Protocol (EBGP)&rsquo;&rsquo;&rsquo;: EBGP is used between autonomous systems. It is used and implemented at the edge or border router that provides inter-connectivity for two or more autonomous system. It functions as the protocol responsible for interconnection of networks from different organizations or the Internet.</li>
<li>&lsquo;&lsquo;&lsquo;Internal Border Gateway Protocol (IBGP)&rsquo;&rsquo;&rsquo;: IBGP is used inside the autonomous systems. It is used to provide information to your internal routers. It requires all the devices in same autonomous systems to form full mesh topology or either of Route reflectors and Confederation for prefix learning.</li>
</ol></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f cilium-bgp-policy.yaml
</span></span></code></pre></div><h3 id="install-bird">Install BIRD</h3>
<p>On the External Ingress COntroller&rsquo;s VM we vill install the BRD BGP client to estabish connection betwean the VM and the K8S INternal network:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt-get install software-properties-common
</span></span><span style="display:flex;"><span>sudo add-apt-repository -y ppa:cz.nic-labs/bird
</span></span><span style="display:flex;"><span>sudo apt update
</span></span><span style="display:flex;"><span>sudo apt install bird
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/bird/bird.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>router id 192.168.56.15;
</span></span><span style="display:flex;"><span>log syslog all;debug protocols all;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># cluster nodes (add all nodes)</span>
</span></span><span style="display:flex;"><span>protocol bgp m101 <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  local 192.168.56.15 as 65001;
</span></span><span style="display:flex;"><span>  neighbor 192.168.56.141 port <span style="color:#ae81ff">3179</span> as 65001;
</span></span><span style="display:flex;"><span>  import all;
</span></span><span style="display:flex;"><span>  export all;
</span></span><span style="display:flex;"><span>  multihop;
</span></span><span style="display:flex;"><span>  graceful restart;
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>protocol bgp m102 <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  local 192.168.56.15 as 65001;
</span></span><span style="display:flex;"><span>  neighbor 192.168.56.142 port <span style="color:#ae81ff">3179</span> as 65001;
</span></span><span style="display:flex;"><span>  import all;
</span></span><span style="display:flex;"><span>  export none;
</span></span><span style="display:flex;"><span>  multihop;
</span></span><span style="display:flex;"><span>  graceful restart;
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>protocol bgp m103 <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  local 192.168.56.15 as 65001;
</span></span><span style="display:flex;"><span>  neighbor 192.168.56.143 port <span style="color:#ae81ff">3179</span> as 65001;
</span></span><span style="display:flex;"><span>  import all;
</span></span><span style="display:flex;"><span>  export none;
</span></span><span style="display:flex;"><span>  multihop;
</span></span><span style="display:flex;"><span>  graceful restart;
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Inserts routes into the kernel routing table</span>
</span></span><span style="display:flex;"><span>protocol kernel <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>   scan time 20;
</span></span><span style="display:flex;"><span>   import all;
</span></span><span style="display:flex;"><span>   export all;
</span></span><span style="display:flex;"><span>   persist;
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Gets information about network interfaces from the kernel</span>
</span></span><span style="display:flex;"><span>protocol device <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>   scan time 56;
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl enable bird
</span></span><span style="display:flex;"><span>sudo systemctl restart bird
</span></span></code></pre></div><h3 id="test-the-bgp-resoults">Test the BGP resoults</h3>
<p>On cilium:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cilium bgp peers
</span></span><span style="display:flex;"><span>Node        Local AS   Peer AS   Peer Address     Session State   Uptime   Family         Received   Advertised
</span></span><span style="display:flex;"><span>m101        <span style="color:#ae81ff">65001</span>      <span style="color:#ae81ff">65001</span>     192.168.56.15    established     6s       ipv4/unicast   <span style="color:#ae81ff">0</span>          <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>                                                                           ipv6/unicast   <span style="color:#ae81ff">0</span>          <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>m102        <span style="color:#ae81ff">65001</span>      <span style="color:#ae81ff">65001</span>     192.168.56.15    established     2s       ipv4/unicast   <span style="color:#ae81ff">0</span>          <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>                                                                           ipv6/unicast   <span style="color:#ae81ff">0</span>          <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>m103        <span style="color:#ae81ff">65001</span>      <span style="color:#ae81ff">65001</span>     192.168.56.15    established     3s       ipv4/unicast   <span style="color:#ae81ff">0</span>          <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>                                                                           ipv6/unicast   <span style="color:#ae81ff">0</span>          <span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p>On VM:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo birdc show protocols
</span></span><span style="display:flex;"><span>BIRD 1.6.8 ready.
</span></span><span style="display:flex;"><span>name     proto    table    state  since       info
</span></span><span style="display:flex;"><span>m101     BGP      master   up     11:37:24    Established
</span></span><span style="display:flex;"><span>m102     BGP      master   up     11:37:28    Established
</span></span><span style="display:flex;"><span>m103     BGP      master   up     11:37:27    Established
</span></span><span style="display:flex;"><span>kernel1  Kernel   master   up     11:37:23
</span></span><span style="display:flex;"><span>device1  Device   master   up     11:37:23
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>birdc show route
</span></span><span style="display:flex;"><span>BIRD 1.6.8 ready.
</span></span><span style="display:flex;"><span>10.244.3.0/24      via 192.168.56.141 on enp0s8 <span style="color:#f92672">[</span>m102 11:37:29<span style="color:#f92672">]</span> * <span style="color:#f92672">(</span>100/-<span style="color:#f92672">)</span> <span style="color:#f92672">[</span>i<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>10.244.4.0/24      via 192.168.56.142 on enp0s8 <span style="color:#f92672">[</span>m101 11:37:25<span style="color:#f92672">]</span> * <span style="color:#f92672">(</span>100/-<span style="color:#f92672">)</span> <span style="color:#f92672">[</span>i<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>10.244.5.0/24      via 192.168.56.143 on enp0s8 <span style="color:#f92672">[</span>m103 11:37:28<span style="color:#f92672">]</span> * <span style="color:#f92672">(</span>100/-<span style="color:#f92672">)</span> <span style="color:#f92672">[</span>i<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>route
</span></span><span style="display:flex;"><span>Kernel IP routing table
</span></span><span style="display:flex;"><span>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span></span><span style="display:flex;"><span>default         _gateway        0.0.0.0         UG    <span style="color:#ae81ff">100</span>    <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> enp0s3
</span></span><span style="display:flex;"><span>10.0.2.0        0.0.0.0         255.255.255.0   U     <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> enp0s3
</span></span><span style="display:flex;"><span>_gateway        0.0.0.0         255.255.255.255 UH    <span style="color:#ae81ff">100</span>    <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> enp0s3
</span></span><span style="display:flex;"><span>10.244.3.0      192.168.56.141  255.255.255.0   UG    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> enp0s8
</span></span><span style="display:flex;"><span>10.244.4.0      192.168.56.142  255.255.255.0   UG    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> enp0s8
</span></span><span style="display:flex;"><span>10.244.5.0      192.168.56.143  255.255.255.0   UG    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> enp0s8
</span></span><span style="display:flex;"><span>192.168.56.0    0.0.0.0         255.255.255.0   U     <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> enp0s8
</span></span></code></pre></div><h3 id="install-the-ingress-controller-outside-of-your-cluster">Install the ingress controller outside of your cluster</h3>
<p>Copy the <code>/etc/kubernetes/admin.conf</code> kubeconfig file from the control plane server to this server and store it in the root user’s home directory. The ingress controller will use this to connect to the Kubernetes API.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo mkdir -p /root/.kube
</span></span><span style="display:flex;"><span>sudo cp admin.conf /root/.kube/config
</span></span><span style="display:flex;"><span>sudo chown -R root:root /root/.kube
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create configmap -n default haproxy-kubernetes-ingress
</span></span></code></pre></div><p>HAProxy Kubernetes Ingress Controller is compatible with a specific version of HAProxy. Install the HAProxy package on your Linux distribution based on the table below. For Ubuntu and Debian, follow the install steps at <a href="https://haproxy.debian.net/">haproxy.debian.net</a></p>
<table>
  <thead>
      <tr>
          <th>Ingress controller version</th>
          <th>Compatible HAProxy version</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1.11</td>
          <td>2.8</td>
      </tr>
      <tr>
          <td>1.10</td>
          <td>2.7</td>
      </tr>
      <tr>
          <td>1.9</td>
          <td>2.6</td>
      </tr>
      <tr>
          <td>1.8</td>
          <td>2.5</td>
      </tr>
      <tr>
          <td>1.7</td>
          <td>2.4</td>
      </tr>
  </tbody>
</table>
<p>In my case I use Ingress controller version <code>1.11</code> and HAProxy version <code>2.8</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl https://haproxy.debian.net/bernat.debian.org.gpg <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>      | gpg --dearmor &gt; /usr/share/keyrings/haproxy.debian.net.gpg
</span></span><span style="display:flex;"><span>echo deb <span style="color:#e6db74">&#34;[signed-by=/usr/share/keyrings/haproxy.debian.net.gpg]&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>      http://haproxy.debian.net bookworm-backports-2.8 main <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>      &gt; /etc/apt/sources.list.d/haproxy.list
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>apt-get update
</span></span><span style="display:flex;"><span>apt-get install haproxy<span style="color:#f92672">=</span>2.8.<span style="color:#ae81ff">\*</span>
</span></span></code></pre></div><p>Stop and disable the HAProxy service.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl stop haproxy
</span></span><span style="display:flex;"><span>sudo systemctl disable haproxy
</span></span></code></pre></div><p>Call the <code>setcap</code> command to allow HAProxy to bind to ports 80 and 443:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo setcap cap_net_bind_service<span style="color:#f92672">=</span>+ep /usr/sbin/haproxy
</span></span></code></pre></div><p>Download the ingress controller from the project’s <a href="https://github.com/haproxytech/kubernetes-ingress/releases/">GitHub Releases page</a>
Extract it and then copy it to the /usr/local/bin directory.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/haproxytech/kubernetes-ingress/releases/download/v1.11.3/haproxy-ingress-controller_1.11.3_Linux_x86_64.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar -xzvf haproxy-ingress-controller_1.11.3_Linux_x86_64.tar.gz
</span></span><span style="display:flex;"><span>sudo cp ./haproxy-ingress-controller /usr/local/bin/
</span></span></code></pre></div><p>Create the file <code>/lib/systemd/system/haproxy-ingress.service</code> and add the following to it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /lib/systemd/system/haproxy-ingress.service
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[Unit]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Description=&#34;HAProxy Kubernetes Ingress Controller&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Documentation=https://www.haproxy.com/
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Requires=network-online.target
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">After=network-online.target
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[Service]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Type=simple
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">User=root
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Group=root
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">ExecStart=/usr/local/bin/haproxy-ingress-controller --external --default-ssl-certificate=ingress-system/default-cert --configmap=default/haproxy-kubernetes-ingress --program=/usr/sbin/haproxy --disable-ipv6 --ipv4-bind-address=0.0.0.0 --http-bind-port=80 --https-bind-port=443  --ingress.class=ingress-public
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">ExecReload=/bin/kill --signal HUP $MAINPID
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KillMode=process
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KillSignal=SIGTERM
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Restart=on-failure
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">LimitNOFILE=65536
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[Install]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">WantedBy=multi-user.target
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>Enable and start the service.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl enable haproxy-ingress
</span></span><span style="display:flex;"><span>sudo systemctl start haproxy-ingress
</span></span></code></pre></div><h3 id="demo-aapp">Demo Aapp</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano demo-app.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: networking.k8s.io/v1
</span></span><span style="display:flex;"><span>kind: IngressClass
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  annotations:
</span></span><span style="display:flex;"><span>    ingressclass.kubernetes.io/is-default-class: <span style="color:#e6db74">&#34;false&#34;</span>
</span></span><span style="display:flex;"><span>  labels:
</span></span><span style="display:flex;"><span>    app.kubernetes.io/instance: ingress-public
</span></span><span style="display:flex;"><span>  name: ingress-public
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  controller: haproxy.org/ingress-controller/ingress-public
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: apps/v1
</span></span><span style="display:flex;"><span>kind: Deployment
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span> labels:
</span></span><span style="display:flex;"><span>   run: app
</span></span><span style="display:flex;"><span> name: app
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span> replicas: <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span> selector:
</span></span><span style="display:flex;"><span>   matchLabels:
</span></span><span style="display:flex;"><span>     run: app
</span></span><span style="display:flex;"><span> template:
</span></span><span style="display:flex;"><span>   metadata:
</span></span><span style="display:flex;"><span>     labels:
</span></span><span style="display:flex;"><span>       run: app
</span></span><span style="display:flex;"><span>   spec:
</span></span><span style="display:flex;"><span>     containers:
</span></span><span style="display:flex;"><span>     - name: app
</span></span><span style="display:flex;"><span>       image: jmalloc/echo-server
</span></span><span style="display:flex;"><span>       ports:
</span></span><span style="display:flex;"><span>       - containerPort: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Service
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span> labels:
</span></span><span style="display:flex;"><span>   run: app
</span></span><span style="display:flex;"><span> name: app
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span> selector:
</span></span><span style="display:flex;"><span>   run: app
</span></span><span style="display:flex;"><span> ports:
</span></span><span style="display:flex;"><span> - name: port-1
</span></span><span style="display:flex;"><span>   port: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>   protocol: TCP
</span></span><span style="display:flex;"><span>   targetPort: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: networking.k8s.io/v1
</span></span><span style="display:flex;"><span>kind: Ingress
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span> name: test-ingress
</span></span><span style="display:flex;"><span> namespace: default
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  ingressClassName: ingress-public
</span></span><span style="display:flex;"><span>  rules:
</span></span><span style="display:flex;"><span>  - host: <span style="color:#e6db74">&#34;example.com&#34;</span>
</span></span><span style="display:flex;"><span>    http:
</span></span><span style="display:flex;"><span>      paths:
</span></span><span style="display:flex;"><span>      - path: /
</span></span><span style="display:flex;"><span>        pathType: Prefix
</span></span><span style="display:flex;"><span>        backend:
</span></span><span style="display:flex;"><span>          service:
</span></span><span style="display:flex;"><span>            name: app
</span></span><span style="display:flex;"><span>            port:
</span></span><span style="display:flex;"><span>              number: <span style="color:#ae81ff">80</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="haproxy" term="haproxy" label="haproxy" />
                             
                                <category scheme="cilium" term="cilium" label="cilium" />
                             
                                <category scheme="bgp" term="bgp" label="bgp" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Integrating OpenShift 4 with External Grafana]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-monitoringw-with-external-grafana/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift4-monitoring/?utm_source=atom_feed" rel="related" type="text/html" title="OKD OpenShift 4 Monitoring" />
                <link href="https://devopstales.github.io/kubernetes/openshift-log4shell/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ceph-rbd-csi/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 Ceph Persisten Storage" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 authentication" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 ingress" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-monitoringw-with-external-grafana/</id>
            
            
            <published>2024-02-20T00:00:00+00:00</published>
            <updated>2024-02-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you how you can integrate an external Grafana with OpenShift 4 Prometheus.</p>
<p>OpenShift already has its built-in monitoring stack with Prometheus, Grafana, and Alertmanager. It’s useful for monitoring a single cluster, but in the case of multiple clusters, you may want to get a single point of view. So I will configure an external VM based installed Grafana to get graphs from all the clusters.</p>
<h3 id="configuring-openshift-prometheus">Configuring OpenShift Prometheus</h3>
<p>First we will create a a secret in Openshift for the authentication based in the name of the monitoring service account:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">oc apply -f - &lt;&lt;EOF</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">prometheus-robot-secret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-monitoring</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes.io/service-account.name</span>: <span style="color:#ae81ff">prometheus-k8s</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">type</span>: <span style="color:#ae81ff">kubernetes.io/service-account-token</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>Check the token string and Try to query the OpenShift Prometheus using that token</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>TOKEN<span style="color:#f92672">=</span><span style="color:#e6db74">`</span>oc -n openshift-monitoring extract secret/prometheus-robot-secret --to<span style="color:#f92672">=</span>- --keys<span style="color:#f92672">=</span>token<span style="color:#e6db74">`</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>PROMETHEUS_URL<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>oc get route -n openshift-monitoring prometheus-k8s -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.status.ingress[0].host}&#34;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -sk -H <span style="color:#e6db74">&#34;Authorization: Bearer </span>$TOKEN<span style="color:#e6db74">&#34;</span> https://$PROMETHEUS_URL/api/v1/alerts
</span></span></code></pre></div><p>The result will end up with something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{<span style="color:#f92672">&#34;status&#34;</span>:<span style="color:#e6db74">&#34;success&#34;</span>,<span style="color:#f92672">&#34;data&#34;</span>:{<span style="color:#f92672">&#34;alerts&#34;</span>:[{<span style="color:#f92672">&#34;labels&#34;</span>:{<span style="color:#f92672">&#34;alertname&#34;</span>:<span style="color:#e6db74">&#34;PodDisruptionBudgetAtLimit&#34;</span> <span style="color:#960050;background-color:#1e0010">…</span>
</span></span></code></pre></div><h3 id="integrate-grafana-with-openshift-prometheus">Integrate Grafana with OpenShift Prometheus</h3>
<p>Go back to the Grafana Dashboard, and add &lsquo;&lsquo;&lsquo;data source&rsquo;&rsquo;&rsquo; by go to &lsquo;&lsquo;&lsquo;menu&rsquo;&rsquo;&rsquo; → &lsquo;&lsquo;&lsquo;connection&rsquo;&rsquo;&rsquo; → &lsquo;&lsquo;&lsquo;data source&rsquo;&rsquo;&rsquo; → add &lsquo;&lsquo;&rsquo;new data source&rsquo;&rsquo;&rsquo; and choose &lsquo;&lsquo;&lsquo;Prometheus&rsquo;&rsquo;&rsquo;.</p>
<p>On Authentication:</p>
<ul>
<li>Choose Forward OAuth Identity as the authentication method</li>
<li>Skip TLS Certificate Validation when using untrusted certificate</li>
</ul>
<p><img src="/img/include/openshift-external-grafana01.webp" alt="On Authentication"  class="zoomable" /></p>
<p>On HTTP Headers, add Header:</p>
<ul>
<li>Fill in the Header with &lsquo;&lsquo;&lsquo;Authorization&rsquo;&rsquo;&rsquo;</li>
<li>Fill in the value with the output of this following command</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>TOKEN<span style="color:#f92672">=</span> <span style="color:#e6db74">`</span>oc -n openshift-monitoring extract secret/prometheus-robot-secret — to<span style="color:#f92672">=</span>- — keys<span style="color:#f92672">=</span>token<span style="color:#e6db74">`</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;Bearer </span>$TOKEN<span style="color:#e6db74">&#34;</span>
</span></span></code></pre></div><p><img src="/img/include/openshift-external-grafana02.webp" alt="On Authentication"  class="zoomable" /></p>
<p>Click Save and Test, if there is an error it will be showing the error</p>
<p><img src="/img/include/openshift-external-grafana03.webp" alt="On Authentication"  class="zoomable" /></p>
<p>If everything goes well, we can start building Grafana dashboard</p>
<p><img src="/img/include/openshift-external-grafana04.webp" alt="On Authentication"  class="zoomable" /></p>
<p>Click on building the dashboard, and choose the previous data source</p>
<p><img src="/img/include/openshift-external-grafana05.webp" alt="On Authentication"  class="zoomable" /></p>
<p><img src="/img/include/openshift-external-grafana06.webp" alt="On Authentication"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="operator" term="operator" label="Operator" />
                             
                                <category scheme="prometheus" term="prometheus" label="prometheus" />
                             
                                <category scheme="grafana" term="grafana" label="grafana" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[RKE2 With MetalLB and NGINX Ingress Controller]]></title>
            <link href="https://devopstales.github.io/kubernetes/rke2-ingress-loadbalancer/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes integration with external Vault" />
                <link href="https://devopstales.github.io/kubernetes/rke2-calico/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With Calico" />
                <link href="https://devopstales.github.io/kubernetes/rke2-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With cilium" />
            
                <id>https://devopstales.github.io/kubernetes/rke2-ingress-loadbalancer/</id>
            
            
            <published>2024-02-15T00:00:00+00:00</published>
            <updated>2024-02-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how to Configure MetalLB to provide a bare metal Load Balancer for NGINX Ingress Controller.</p>
<h3 id="metallb-config">MetalLB Config</h3>
<p>First we need to install the MetalLB in RKE2. In my <a href="/kubernetes/k8s-metallb/">previous post</a> I wrote how to install it. So please check it.</p>
<p>The following configs should be deployed to your K8s environment.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">IPAddressPool</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">addresses</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.46</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.47</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.48</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.85</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.86</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.87</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.88</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.89</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.90</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.91</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.92</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.93</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.94</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">192.168.20.95</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">autoAssign</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">L2Advertisement</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ipAddressPools</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">BGPPeer</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">myASN</span>: <span style="color:#ae81ff">64790</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">peerASN</span>: <span style="color:#ae81ff">64791</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">peerAddress</span>: <span style="color:#ae81ff">192.168.20.64</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">BGPAdvertisement</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ipAddressPools</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">default</span>
</span></span></code></pre></div><blockquote>
<p>I have both Layer 2 and BGP advertisements enabled. This is because my services and clients share the same subnet. BGP won’t work for clients on the same subnet as the services because it is layer 3, the client will ARP ping for the IP and receive no reply. The PFSense router will only route to service IP’s via the node IP’s from another subnet. Therefore you need both. I chose to have them on the same subnet because this avoids having large amounts of traffic transferring the PFSense FW which is slower and more resource hungry than dedicated switches.</p></blockquote>
<h3 id="bgp-on-pfsense">BGP on PFSense</h3>
<p>In my <a href="/kubernetes/k8s-metallb-bgp-pfsense/">previous post</a> I wrote about how to configure MetalLB in BGP mode with PFSense.</p>
<blockquote>
<p>Just make sure to change the AS number to match your metallb config.</p></blockquote>
<h3 id="nginx-ingress-controller-config">NGINX Ingress Controller Config</h3>
<p>We USE RKE2 as the kubernetes cluster. RKE2 has its own NGINX Ingress Controller already installed in host network mode. So we need to reconfigure the installed helm chart to run with LoadBalancer type service. For this we need to override the default helm values in the helm release object:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo nano /var/lib/rancher/rke2/server/manifests/rke2-ingress-nginx-config.yaml
</span></span></code></pre></div><p>Add the following contents.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.cattle.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmChartConfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rke2-ingress-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">valuesContent</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    controller:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      config:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        use-forwarded-headers: &#34;true&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        enable-real-ip: &#34;true&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      publishService:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      service:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        type: LoadBalancer
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        externalTrafficPolicy: Local
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        annotations:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          metallb.universe.tf/loadBalancerIPs: 192.168.20.45</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="rke2" term="rke2" label="rke2" />
                             
                                <category scheme="rancher" term="rancher" label="rancher" />
                             
                                <category scheme="metallb" term="metallb" label="MetalLB" />
                             
                                <category scheme="pfsense" term="pfsense" label="PFSense" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Secure Install]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-secure-install/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-cisa-install/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Hardening Guide with CISA 1.6 Benchmark" />
                <link href="https://devopstales.github.io/kubernetes/k8s-falco/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes audit logs and Falco" />
                <link href="https://devopstales.github.io/kubernetes/k8s-test-tools/?utm_source=atom_feed" rel="related" type="text/html" title="Validate Kubernetes Deployment in CI/CD" />
                <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="related" type="text/html" title="Hardening Kubernetes with seccomp" />
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-secure-install/</id>
            
            
            <published>2024-01-20T00:00:00+00:00</published>
            <updated>2024-01-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to install a Kubernetes cluster in a secure way with.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install -y epel-release
</span></span><span style="display:flex;"><span>yum install -y nano wget
</span></span></code></pre></div><h3 id="selinux-and-firewall-config">Selinux and Firewall Config</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl enable firewalld
</span></span><span style="display:flex;"><span>systemctl start firewalld
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Check selinux enabled</span>
</span></span><span style="display:flex;"><span>sestatus
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Resoult</span>
</span></span><span style="display:flex;"><span>SELinux status:                 enabled
</span></span><span style="display:flex;"><span>SELinuxfs mount:                /sys/fs/selinux
</span></span><span style="display:flex;"><span>SELinux root directory:         /etc/selinux
</span></span><span style="display:flex;"><span>Loaded policy name:             targeted
</span></span><span style="display:flex;"><span>Current mode:                   enforcing
</span></span><span style="display:flex;"><span>Mode from config file:          enforcing
</span></span><span style="display:flex;"><span>Policy MLS status:              enabled
</span></span><span style="display:flex;"><span>Policy deny_unknown status:     allowed
</span></span><span style="display:flex;"><span>Memory protection checking:     actual <span style="color:#f92672">(</span>secure<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Max kernel policy version:      <span style="color:#ae81ff">33</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9345/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>6443/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>10250/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>2379/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>2380/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>30000-32767/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Used for the Monitoring</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9796/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>19090/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>6942/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9091/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e">### CNI specific ports Cilium</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 4244/TCP is required when the Hubble Relay is enabled and therefore needs to connect to all agents to collect the flows</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>4244/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Cilium healthcheck related permits:</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>4240/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --remove-icmp-block<span style="color:#f92672">=</span>echo-request --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --remove-icmp-block<span style="color:#f92672">=</span>echo-reply --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Since we are using Cilium with GENEVE as overlay, we need the following port too:</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>6081/udp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e">### Ingress Controller specific ports</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>80/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>443/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e">### To get DNS resolution working, simply enable Masquerading.</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --zone<span style="color:#f92672">=</span>public  --add-masquerade --permanent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">### Finally apply all the firewall changes</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --reload
</span></span></code></pre></div><p>Verification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo firewall-cmd --list-all
</span></span><span style="display:flex;"><span>public <span style="color:#f92672">(</span>active<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>  target: default
</span></span><span style="display:flex;"><span>  icmp-block-inversion: no
</span></span><span style="display:flex;"><span>  interfaces: eno1
</span></span><span style="display:flex;"><span>  sources: 
</span></span><span style="display:flex;"><span>  services: cockpit dhcpv6-client ssh wireguard
</span></span><span style="display:flex;"><span>  ports: 9345/tcp 6443/tcp 10250/tcp 2379/tcp 2380/tcp 30000-32767/tcp 4240/tcp 6081/udp 80/tcp 443/tcp 4244/tcp 9796/tcp 19090/tcp 6942/tcp 9091/tcp
</span></span><span style="display:flex;"><span>  protocols: 
</span></span><span style="display:flex;"><span>  masquerade: yes
</span></span><span style="display:flex;"><span>  forward-ports: 
</span></span><span style="display:flex;"><span>  source-ports: 
</span></span><span style="display:flex;"><span>  icmp-blocks: 
</span></span><span style="display:flex;"><span>  rich rules: 
</span></span></code></pre></div><h3 id="linux-configurations">Linux Configurations</h3>
<p>Enable cgroupV2</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf install -y grubby
</span></span><span style="display:flex;"><span>sudo grubby <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --update-kernel<span style="color:#f92672">=</span>ALL <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --args<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;systemd.unified_cgroup_hierarchy=1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt;&gt; /etc/systemd/system.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultCPUAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultIOAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultIPAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultBlockIOAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>init <span style="color:#ae81ff">6</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># check for type cgroup2</span>
</span></span><span style="display:flex;"><span>$ mount -l|grep cgroup
</span></span><span style="display:flex;"><span>cgroup2 on /sys/fs/cgroup type cgroup2 <span style="color:#f92672">(</span>rw,nosuid,nodev,noexec,relatime,seclabel,nsdelegate<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># check for cpu controller</span>
</span></span><span style="display:flex;"><span>$ cat /sys/fs/cgroup/cgroup.subtree_control
</span></span><span style="display:flex;"><span>cpu io memory pids
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/crio.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">#
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># protectKernelDefaults
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">#
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kernel.keys.root_maxbytes           = 25000000
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kernel.keys.root_maxkeys            = 1000000
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kernel.panic                        = 10
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kernel.panic_on_oops                = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">vm.overcommit_memory                = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">vm.panic_on_oom                     = 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><p>Ensure the eBFP filesystem is mounted (which should already be the case on RHEL 8.3):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mount | grep /sys/fs/bpf
</span></span><span style="display:flex;"><span><span style="color:#75715e"># if present should output, e.g. &#34;none on /sys/fs/bpf type bpf&#34;...</span>
</span></span></code></pre></div><p>If that&rsquo;s not the case, mount it using the commands down here:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo mount bpffs -t bpf /sys/fs/bpf
</span></span><span style="display:flex;"><span>sudo bash -c <span style="color:#e6db74">&#39;cat &lt;&lt;EOF &gt;&gt; /etc/fstab
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">none /sys/fs/bpf bpf rw,relatime 0 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF&#39;</span>
</span></span></code></pre></div><h3 id="etcd">etcd</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>useradd -r -c <span style="color:#e6db74">&#34;etcd user&#34;</span> -s /sbin/nologin -M etcd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>head -c <span style="color:#ae81ff">32</span> /dev/urandom | base64
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano /etc/kubernetes/etcd-encription.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apiserver.config.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">EncryptionConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">secrets</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">providers</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">identity</span>: {}
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">aesgcm</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">keys</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">key1</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">secret</span>: <span style="color:#ae81ff">&lt;BASE 64 ENCODED SECRET&gt;</span>
</span></span></code></pre></div><h3 id="cri-o">CRI-O</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span>1.28
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/CentOS_8/devel:kubic:libcontainers:stable.repo
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable_cri-o_<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>/CentOS_8/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install -y cri-o
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Configure User anmespacing in CRI-O</span>
</span></span><span style="display:flex;"><span>mkdir /etc/crio/crio.conf.d/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s|^cgroup_manager|#cgroup_manager|&#39;</span> /etc/crio/crio.conf
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s|^conmon_cgroup|#conmon_cgroup|&#39;</span> /etc/crio/crio.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/crio/crio.conf.d/01-crio-base.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[crio]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">storage_driver = &#34;overlay&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">storage_option = [&#34;overlay.mount_program=/usr/bin/fuse-overlayfs&#34;]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[crio.runtime]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">cgroup_manager = &#34;cgroupfs&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">conmon_cgroup = &#39;pod&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/crio/crio.conf.d/02-userns-workload.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[crio.runtime.workloads.userns]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">activation_annotation = &#34;io.kubernetes.cri-o.userns-mode&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">allowed_annotations = [&#34;io.kubernetes.cri-o.userns-mode&#34;]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Test CRIO selinux config</span>
</span></span><span style="display:flex;"><span>egrep -r <span style="color:#e6db74">&#34;selinux&#34;</span> /etc/crio/
</span></span><span style="display:flex;"><span>/etc/crio/crio.conf:selinux <span style="color:#f92672">=</span> true
</span></span></code></pre></div><p>The <strong>CRI-O</strong> will run the containers with the <code>containers</code> user so I need to create <code>/etc/subuid</code> and <code>/etc/subgid</code> on nodes.</p>
<blockquote>
<p>SubUID/GIDs are a range of user/group IDs that a user is allowed to use.</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;containers:200000:268435456&#34;</span> &gt;&gt; /etc/subuid
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;containers:200000:268435456&#34;</span> &gt;&gt; /etc/subgid
</span></span></code></pre></div><h3 id="kubeadm-install">Kubeadm install</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://pkgs.k8s.io/core:/stable:/v${VERSION}/rpm/
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://pkgs.k8s.io/core:/stable:/v${VERSION}/rpm/repodata/repomd.xml.key
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CRIP_VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>crio --version | grep <span style="color:#e6db74">&#34;^Version&#34;</span> | awk <span style="color:#e6db74">&#39;{print $2}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>yum install kubelet-$CRIP_VERSION kubeadm-$CRIP_VERSION kubectl-$CRIP_VERSION cri-tools iproute-tc -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;exclude=kubelet, kubectl, kubeadm, cri-o&#34;</span> &gt;&gt; /etc/yum.conf
</span></span></code></pre></div><h3 id="kubeadm-init-config">Kubeadm init config</h3>
<p>Set Kubernetes version:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">clusterName</span>: <span style="color:#ae81ff">k8s-main</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kubernetesVersion</span>: <span style="color:#ae81ff">1.28.2</span>
</span></span></code></pre></div><p>Configure authentication and enable webhooks:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiServer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">authorization-mode</span>: <span style="color:#e6db74">&#34;Node,RBAC&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enable-admission-plugins</span>: <span style="color:#e6db74">&#34;NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook&#34;</span>
</span></span></code></pre></div><p>Set node ip and load-balancer ip if you use an external load-balancer for multi node infra:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">InitConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">bootstrapTokens</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">token</span>: <span style="color:#e6db74">&#34;c2t0rj.cofbfnwwrb387890&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">localAPIEndpoint</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># local ip and port</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">advertiseAddress</span>: <span style="color:#ae81ff">192.168.56.12</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">bindPort</span>: <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># load-balancer ip or node ip and port</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">controlPlaneEndpoint</span>: <span style="color:#e6db74">&#34;192.168.56.12:6443&#34;</span>
</span></span></code></pre></div><p>Configure Certificate and rotation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">InitConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodeRegistration</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kubeletExtraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rotate-server-certificates</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">certificatesDir</span>: <span style="color:#ae81ff">/etc/kubernetes/pki</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiServer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubelet-certificate-authority</span>: <span style="color:#e6db74">&#34;/etc/kubernetes/pki/ca.crt&#34;</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubelet.config.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeletConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">enableServer</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serverTLSBootstrap</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rotateCertificates</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">featureGates</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">RotateKubeletServerCertificate</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">JoinConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodeRegistration</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kubeletExtraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rotate-server-certificates</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span></code></pre></div><p>Configure kubernetes to use CRI-O:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">InitConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodeRegistration</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">criSocket</span>: <span style="color:#e6db74">&#34;unix:///var/run/crio/crio.sock&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">taints</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">JoinConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodeRegistration</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">criSocket</span>: <span style="color:#e6db74">&#34;unix:///var/run/crio/crio.sock&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">taints</span>: <span style="color:#66d9ef">null</span>
</span></span></code></pre></div><p>Set CNI Network in kubernetes config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceSubnet</span>: <span style="color:#e6db74">&#34;10.96.0.0/12&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSubnet</span>: <span style="color:#e6db74">&#34;10.244.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">dnsDomain</span>: <span style="color:#e6db74">&#34;cluster.local&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiServer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">service-node-port-range</span>: <span style="color:#e6db74">&#34;30000-50000&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">anonymous-auth</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span></code></pre></div><p>Apply Pod Security Standards at the Cluster Level:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF &gt; /etc/kubernetes/k8s-pss.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apiserver.config.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">AdmissionConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">plugins</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">PodSecurity</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">configuration</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">pod-security.admission.config.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PodSecurityConfiguration</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">defaults</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enforce</span>: <span style="color:#e6db74">&#34;restricted&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enforce-version</span>: <span style="color:#e6db74">&#34;latest&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">audit</span>: <span style="color:#e6db74">&#34;restricted&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">audit-version</span>: <span style="color:#e6db74">&#34;latest&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">warn</span>: <span style="color:#e6db74">&#34;restricted&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">warn-version</span>: <span style="color:#e6db74">&#34;latest&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">exemptions</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">usernames</span>: []
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">runtimeClasses</span>: []
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">namespaces</span>: [<span style="color:#ae81ff">kube-system, cis-operator-system, cilium-spire, ceph-storage-system]</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Add your own exemption namespaces.</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiServer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">admission-control-config-file</span>: <span style="color:#ae81ff">/etc/kubernetes/k8s-pss.yaml</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraVolumes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;kubernetes-pss&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hostPath</span>: <span style="color:#e6db74">&#34;/etc/kubernetes/k8s-pss.yaml&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">mountPath</span>: <span style="color:#e6db74">&#34;/etc/kubernetes/k8s-pss.yaml&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pathType</span>: <span style="color:#e6db74">&#34;File&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">propagation</span>: <span style="color:#ae81ff">Bidirectional</span>
</span></span></code></pre></div><p>Configure etcd folder and encryption:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">etcd</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">local</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">dataDir</span>: <span style="color:#ae81ff">/var/lib/etcd</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiServer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">encryption-provider-config</span>: <span style="color:#e6db74">&#34;/etc/kubernetes/etcd-encription.yaml&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraVolumes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;etc-kubernetes-etcd-enc&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hostPath</span>: <span style="color:#e6db74">&#34;/etc/kubernetes/etcd-encription.yaml&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">mountPath</span>: <span style="color:#e6db74">&#34;/etc/kubernetes/etcd-encription.yaml&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">readOnly</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pathType</span>: <span style="color:#e6db74">&#34;File&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">propagation</span>: <span style="color:#ae81ff">HostToContainer</span>
</span></span></code></pre></div><p>Configure default kernel option protection:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">InitConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodeRegistration</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kubeletExtraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">protect-kernel-defaults</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubelet.config.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeletConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">protectKernelDefaults</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">JoinConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodeRegistration</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kubeletExtraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">protect-kernel-defaults</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span></code></pre></div><p>Enable Profiling:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiServer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">profiling</span>: <span style="color:#e6db74">&#34;false&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">scheduler</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">profiling</span>: <span style="color:#e6db74">&#34;false&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">controllerManager</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">profiling</span>: <span style="color:#e6db74">&#34;false&#34;</span>
</span></span></code></pre></div><p>Enable secomp profiles:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubelet.config.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeletConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">featureGates</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">SeccompDefault</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">seccompDefault</span>: <span style="color:#66d9ef">true</span>
</span></span></code></pre></div><p>Enable swaping:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubelet.config.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeletConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">failSwapOn</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">featureGates</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">NodeSwap</span>: <span style="color:#66d9ef">true</span>
</span></span></code></pre></div><p>Enable KubeletInUserNamespace:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubelet.config.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeletConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">cgroupDriver</span>: <span style="color:#e6db74">&#34;cgroupfs&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">featureGates</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">KubeletInUserNamespace</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeproxy.config.k8s.io/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeProxyConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">mode</span>: <span style="color:#e6db74">&#34;iptables&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or &#34;userspace&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">conntrack</span>:
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Skip setting sysctl value &#34;net.netfilter.nf_conntrack_max&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">maxPerCore</span>: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Skip setting &#34;net.netfilter.nf_conntrack_tcp_timeout_established&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tcpEstablishedTimeout</span>: <span style="color:#ae81ff">0s</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Skip setting &#34;net.netfilter.nf_conntrack_tcp_timeout_close&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tcpCloseWaitTimeout</span>: <span style="color:#ae81ff">0s</span>
</span></span></code></pre></div><p>Enable audit logging:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># 010-kubeadm-conf-1-28-2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiServer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">audit-log-maxage</span>: <span style="color:#e6db74">&#34;30&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">audit-log-maxbackup</span>: <span style="color:#e6db74">&#34;10&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">audit-log-maxsize</span>: <span style="color:#e6db74">&#34;100&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">audit-log-path</span>: <span style="color:#e6db74">&#34;/var/log/kube-audit/audit.log&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">audit-policy-file</span>: <span style="color:#e6db74">&#34;/etc/kubernetes/audit-policy.yaml&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraVolumes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;audit-config&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hostPath</span>: <span style="color:#e6db74">&#34;/etc/kubernetes/audit-policy.yaml&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">mountPath</span>: <span style="color:#e6db74">&#34;/etc/kubernetes/audit-policy.yaml&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">readOnly</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pathType</span>: <span style="color:#e6db74">&#34;File&#34;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;audit-log&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hostPath</span>: <span style="color:#e6db74">&#34;/var/log/kube-audit&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">mountPath</span>: <span style="color:#e6db74">&#34;/var/log/kube-audit&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pathType</span>: <span style="color:#e6db74">&#34;DirectoryOrCreate&#34;</span>
</span></span></code></pre></div><p>Configure audit-log policy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt;&gt; /etc/kubernetes/audit-policy.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">audit.k8s.io/v1</span> <span style="color:#75715e"># This is required.</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Policy</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Don&#39;t generate audit events for all requests in RequestReceived stage.</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">omitStages</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#34;RequestReceived&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log pod changes at RequestResponse level</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">RequestResponse</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># Resource &#34;pods&#34; doesn&#39;t match requests to any subresource of pods,</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># which is consistent with the RBAC policy.</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;pods&#34;</span>, <span style="color:#e6db74">&#34;deployments&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">RequestResponse</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;rbac.authorization.k8s.io&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># Resource &#34;pods&#34; doesn&#39;t match requests to any subresource of pods,</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># which is consistent with the RBAC policy.</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;clusterroles&#34;</span>, <span style="color:#e6db74">&#34;clusterrolebindings&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log &#34;pods/log&#34;, &#34;pods/status&#34; at Metadata level</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Metadata</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;pods/log&#34;</span>, <span style="color:#e6db74">&#34;pods/status&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Don&#39;t log requests to a configmap called &#34;controller-leader&#34;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;configmaps&#34;</span>]
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resourceNames</span>: [<span style="color:#e6db74">&#34;controller-leader&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Don&#39;t log watch requests by the &#34;system:kube-proxy&#34; on endpoints or services</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">users</span>: [<span style="color:#e6db74">&#34;system:kube-proxy&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;watch&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#75715e"># core API group</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;endpoints&#34;</span>, <span style="color:#e6db74">&#34;services&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Don&#39;t log authenticated requests to certain non-resource URL paths.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">userGroups</span>: [<span style="color:#e6db74">&#34;system:authenticated&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nonResourceURLs</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;/api*&#34;</span> <span style="color:#75715e"># Wildcard matching.</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;/version&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log the request body of configmap changes in kube-system.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Request</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#75715e"># core API group</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;configmaps&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># This rule only applies to resources in the &#34;kube-system&#34; namespace.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># The empty string &#34;&#34; can be used to select non-namespaced resources.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">namespaces</span>: [<span style="color:#e6db74">&#34;kube-system&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log configmap changes in all other namespaces at the RequestResponse level.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">RequestResponse</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#75715e"># core API group</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;configmaps&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log secret changes in all other namespaces at the Metadata level.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Metadata</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#75715e"># core API group</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;secrets&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log all other resources in core and extensions at the Request level.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Request</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#75715e"># core API group</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;extensions&#34;</span> <span style="color:#75715e"># Version of group should NOT be included.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># A catch-all rule to log all other requests at the Metadata level.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Metadata</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Long-running requests like watches that fall under this rule will not</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># generate an audit event in RequestReceived.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">omitStages</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;RequestReceived&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><h3 id="install-kubernetes">Install Kubernetes</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl enable --now crio
</span></span><span style="display:flex;"><span>crictl info
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm config images pull --config 010-kubeadm-conf-1-28-2.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl enable kubelet.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm init --skip-phases<span style="color:#f92672">=</span>addon/kube-proxy --config 010-kubeadm-conf-1-28-2.yaml
</span></span></code></pre></div><h3 id="post-install">Post Install</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get csr --all-namespaces
</span></span><span style="display:flex;"><span>kubectl get csr -oname | xargs kubectl certificate approve
</span></span><span style="display:flex;"><span>kubectl apply -f 012-k8s-clusterrole.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install -y https://harbottle.gitlab.io/harbottle-main/7/x86_64/harbottle-main-release.rpm
</span></span><span style="display:flex;"><span>yum install -y kubectx
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;PATH=$PATH:/usr/local/bin&#39;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>export PATH<span style="color:#f92672">=</span>$PATH:/usr/local/bin
</span></span></code></pre></div><h3 id="install-cilium-as-cni">Install cilium as CNI</h3>
<p>Generate Clilium configuration:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF &gt; 031-cilium-helm-values.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Set kubeProxyReplacement to &#34;strict&#34; in order to prevent CVE-2020-8554 and fully remove kube-proxy.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># See https://cilium.io/blog/2020/12/11/kube-proxy-free-cve-mitigation for more information.</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kubeProxyReplacement</span>: <span style="color:#e6db74">&#34;strict&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">k8sServiceHost</span>: <span style="color:#ae81ff">192.168.56.12</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">k8sServicePort</span>: <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rollOutCiliumPods</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">priorityClassName</span>: <span style="color:#ae81ff">system-cluster-critical</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">ipv4</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">ipv6</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">bpf</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">masquerade</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">encryption</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">wireguard</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nodeEncryption</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># L7 policy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">loadBalancer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">l7</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">backend</span>: <span style="color:#ae81ff">envoy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">envoy</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">prometheus</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># L2 LoadBalancer service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">l2announcements</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Api gateway</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">gatewayAPI</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Ingress controller</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">ingressController</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">loadbalancerMode</span>: <span style="color:#ae81ff">shared</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># mTLS</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">authentication</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">mode</span>: <span style="color:#ae81ff">required</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">mutual</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spire</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">install</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">server</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">dataStorage</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">endpointStatus</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">status</span>: <span style="color:#ae81ff">policy</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">dashboards</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;monitoring-system&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">grafana_folder</span>: <span style="color:#e6db74">&#34;cilium&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">hubble</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">metrics</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enableOpenMetrics</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">dns:query;ignoreAAAA</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">drop</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">tcp</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">flow:sourceContext=workload-name|reserved-identity;destinationContext=workload-name|reserved-identity</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">port-distribution</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">icmp</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">kafka:labelsContext=source_namespace,source_workload,destination_namespace,destination_workload,traffic_direction;sourceContext=workload-name|reserved-identity;destinationContext=workload-name|reserved-identity</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">policy:sourceContext=app|workload-name|pod|reserved-identity;destinationContext=app|workload-name|pod|dns|reserved-identity;labelsContext=source_namespace,destination_namespace</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">httpV2:exemplars=true;labelsContext=source_ip,source_namespace,source_workload,destination_ip,destination_namespace,destination_workload,traffic_direction</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">dashboards</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;monitoring-system&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">grafana_folder</span>: <span style="color:#e6db74">&#34;cilium&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ui</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">hubble.k8s.intra</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">kubernetes.io/ingress.class</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cert-manager.io/cluster-issuer</span>: <span style="color:#ae81ff">ca-issuer</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">hubble-ingress-tls</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">hubble.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tolerations</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">key</span>: <span style="color:#e6db74">&#34;node-role.kubernetes.io/master&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">operator</span>: <span style="color:#e6db74">&#34;Exists&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">effect</span>: <span style="color:#e6db74">&#34;NoSchedule&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">key</span>: <span style="color:#e6db74">&#34;node-role.kubernetes.io/control-plane&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">operator</span>: <span style="color:#e6db74">&#34;Exists&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">effect</span>: <span style="color:#e6db74">&#34;NoSchedule&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">60m</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">300Mi</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">20m</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">64Mi</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">frontend</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">1000m</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">1024M</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">100m</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">64Mi</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">proxy</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">1000m</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">1024M</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">100m</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">64Mi</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">relay</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tolerations</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">key</span>: <span style="color:#e6db74">&#34;node-role.kubernetes.io/master&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">operator</span>: <span style="color:#e6db74">&#34;Exists&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">effect</span>: <span style="color:#e6db74">&#34;NoSchedule&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">key</span>: <span style="color:#e6db74">&#34;node-role.kubernetes.io/control-plane&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">operator</span>: <span style="color:#e6db74">&#34;Exists&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">effect</span>: <span style="color:#e6db74">&#34;NoSchedule&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">100m</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">500Mi</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">prometheus</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">operator</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">1000m</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">1Gi</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">100m</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">128Mi</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">prometheus</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">dashboards</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;monitoring-system&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">grafana_folder</span>: <span style="color:#e6db74">&#34;cilium&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">ipam</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">mode</span>: <span style="color:#e6db74">&#34;cluster-pool&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">operator</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">clusterPoolIPv4PodCIDRList</span>: <span style="color:#e6db74">&#34;10.43.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">clusterPoolIPv4MaskSize</span>: <span style="color:#ae81ff">24</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">clusterPoolIPv6PodCIDRList</span>: <span style="color:#e6db74">&#34;fd00::/104&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">clusterPoolIPv6MaskSize</span>: <span style="color:#ae81ff">120</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">4000m</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">4Gi</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">100m</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">512Mi</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">prometheus</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Default port value (9090) needs to be changed since the RHEL cockpit also listens on this port.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">port</span>: <span style="color:#ae81ff">19090</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Configure this serviceMonitor section AFTER Rancher Monitoring is enabled!</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl taint nodes --all node-role.kubernetes.io/control-plane-
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm repo add cilium https://helm.cilium.io/
</span></span><span style="display:flex;"><span>helm upgrade --install cilium cilium/cilium <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --namespace kube-system <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -f 031-cilium-helm-values.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pods -A
</span></span></code></pre></div><h3 id="harden-kubernetes">Harden Kubernetes</h3>
<p>There is an opensource tool theat tests CISA&rsquo;s best best practices on your clsuter. We vill use this to test the resoults.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># kube-bench</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># https://github.com/aquasecurity/kube-bench/releases/</span>
</span></span><span style="display:flex;"><span>yum install -y https://github.com/aquasecurity/kube-bench/releases/download/v0.6.5/kube-bench_0.6.5_linux_amd64.rpm
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>useradd -r -c <span style="color:#e6db74">&#34;etcd user&#34;</span> -s /sbin/nologin -M etcd
</span></span><span style="display:flex;"><span>chown etcd:etcd /var/lib/etcd
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">700</span> /var/lib/etcd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># kube-bench</span>
</span></span><span style="display:flex;"><span>kube-bench
</span></span><span style="display:flex;"><span>kube-bench | grep <span style="color:#e6db74">&#34;\[FAIL\]&#34;</span>
</span></span></code></pre></div><h3 id="join-nodes">join nodes</h3>
<p>Firs we need to get the join command from the master:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># on master1</span>
</span></span><span style="display:flex;"><span>kubeadm token create --print-join-command
</span></span><span style="display:flex;"><span>kubeadm join 192.168.56.12:6443 --token c2t0rj.cofbfnwwrb387890 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> --discovery-token-ca-cert-hash sha256:a52f4c16a6ce9ef72e3d6172611d17d9752dfb1c3870cf7c8ad4ce3bcb97547e
</span></span></code></pre></div><p>If the next node is a worke we can just use the command what we get. If a next node is a master we need to generate a certificate-key. You need a separate certificate-key for every new master.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># on master1</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## generate cert key</span>
</span></span><span style="display:flex;"><span>kubeadm certs certificate-key
</span></span><span style="display:flex;"><span>29ab8a6013od73s8d3g4ba3a3b24679693e98acd796356eeb47df098c47f2773
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## store cert key in secret</span>
</span></span><span style="display:flex;"><span>kubeadm init phase upload-certs --upload-certs --certificate-key<span style="color:#f92672">=</span>29ab8a6013od73s8d3g4ba3a3b24679693e98acd796356eeb47df098c47f2773
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># on master2</span>
</span></span><span style="display:flex;"><span>kubeadm join 192.168.56.12:6443 --token c2t0rj.cofbfnwwrb387890 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--discovery-token-ca-cert-hash sha256:a52f4c16a6ce9ef72e3d6172611d17d9752dfb1c3870cf7c8ad4ce3bcb97547e <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--control-plane --certificate-key 29ab8a6013od73s8d3g4ba3a3b24679693e98acd796356eeb47df098c47f2773
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># on master3</span>
</span></span><span style="display:flex;"><span>kubeadm join 192.168.56.12:6443 --token c2t0rj.cofbfnwwrb387890 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--discovery-token-ca-cert-hash sha256:a52f4c16a6ce9ef72e3d6172611d17d9752dfb1c3870cf7c8ad4ce3bcb97547e <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--control-plane --certificate-key 29ab8a6013od73s8d3g4ba3a3b24679693e98acd796356eeb47df098c47f2773
</span></span></code></pre></div><p>In the end withevery new node we need to approve the certificate requests for the node.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get csr -oname | xargs kubectl certificate approve
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>useradd -r -c <span style="color:#e6db74">&#34;etcd user&#34;</span> -s /sbin/nologin -M etcd
</span></span><span style="display:flex;"><span>chown etcd:etcd /var/lib/etcd
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">700</span> /var/lib/etcd
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="cilium" term="cilium" label="Cilium" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Container Checkpoints]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-checkpointing/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-user-namespace/?utm_source=atom_feed" rel="related" type="text/html" title="Linux user namespace management wit CRI-O in Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/container-runtimes/?utm_source=atom_feed" rel="related" type="text/html" title="Containers and Container runtimes for Beginners" />
                <link href="https://devopstales.github.io/kubernetes/k8s-falco/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes audit logs and Falco" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cisa-install/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Hardening Guide with CISA 1.6 Benchmark" />
                <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="related" type="text/html" title="Hardening Kubernetes with seccomp" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-checkpointing/</id>
            
            
            <published>2024-01-14T00:00:00+00:00</published>
            <updated>2024-01-14T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to use Container Checkpoints.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="what-is-container-checkpoints">What is Container Checkpoints?</h3>
<p>Container Checkpointing feature allows you to checkpoint a running container. This means that you can save the current container state, without losing any information about the running processes or the data stored in it. Than resume it later in the future. This Feature is only available from Kubernetes 1.25. To implement Kubernetes checkpointing, you’ll need to use a container runtime that supports CRIU (Checkpoint/Restore in Userspace).</p>
<blockquote>
<p>I will use Almalinux 8 as my OS.</p></blockquote>
<h3 id="install-kernel-513">Install Kernel &gt;5.13</h3>
<p>Linux 5.13 added <code>PTRACE_GET_RSEQ_CONFIGURATION</code> feature that is neaded for Container Checkpoints feature.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo rpm --import https://repo.almalinux.org/almalinux/RPM-GPG-KEY-AlmaLinux
</span></span><span style="display:flex;"><span>sudo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
</span></span><span style="display:flex;"><span>sudo dnf install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install epel-release
</span></span><span style="display:flex;"><span>yum list available --disablerepo<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;*&#39;</span> --enablerepo<span style="color:#f92672">=</span>elrepo-kernel
</span></span></code></pre></div><h3 id="install-cri-o">Install CRI-O</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span>1.28
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/CentOS_8/devel:kubic:libcontainers:stable.repo
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable_cri-o_<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>/CentOS_8/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install cri-o nano wget net-tools bridge-utils dnsutils
</span></span></code></pre></div><h3 id="configure">Configure</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;&#39;EOF&#39; | sudo tee /etc/modules-load.d/crio.conf &gt; /dev/null
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>modprobe overlay
</span></span><span style="display:flex;"><span>modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv6.conf.all.disable_ipv6 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv6.conf.default.disable_ipv6 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Enable CRIU support in /etc/crio/crio.conf (enable_criu_support = true)</span>
</span></span><span style="display:flex;"><span>sed -i -e <span style="color:#e6db74">&#39;s/# enable_criu_support = false/enable_criu_support = true/g&#39;</span> /etc/crio/crio.conf
</span></span><span style="display:flex;"><span>sed -i -e <span style="color:#e6db74">&#39;s/# drop_infra_ctr = true/drop_infra_ctr = false/g&#39;</span> /etc/crio/crio.conf
</span></span></code></pre></div><h3 id="install-kubernets">Install kubernets</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CRIP_VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>crio --version | grep <span style="color:#e6db74">&#34;^Version&#34;</span> | awk <span style="color:#e6db74">&#39;{print $2}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>yum install kubelet-$CRIP_VERSION kubeadm-$CRIP_VERSION kubectl-$CRIP_VERSION cri-tools iproute-tc -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;exclude=kubelet, kubectl, kubeadm&#34;</span> &gt;&gt; /etc/yum.conf
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># find the node IP</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">IP=172.17.9.10</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF &gt; kubeadm-config.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">InitConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">localAPIEndpoint</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">advertiseAddress</span>: <span style="color:#ae81ff">$IP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">bindPort</span>: <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodeRegistration</span>:  <span style="color:#75715e"># Only for CRI-O</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">criSocket</span>: <span style="color:#e6db74">&#34;unix:///var/run/crio/crio.sock&#34;</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubelet.config.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeletConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">featureGates</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ContainerCheckpoint</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kubernetesVersion</span>: <span style="color:#ae81ff">v$CRIP_VERSION</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiServer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">feature-gates</span>: <span style="color:#e6db74">&#34;ContainerCheckpoint=true&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">controllerManager</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">feature-gates</span>: <span style="color:#e6db74">&#34;ContainerCheckpoint=true&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">scheduler</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">feature-gates</span>: <span style="color:#e6db74">&#34;ContainerCheckpoint=true&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSubnet</span>: <span style="color:#ae81ff">10.244.0.0</span><span style="color:#ae81ff">/16</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl enable kubelet.service
</span></span><span style="display:flex;"><span>systemctl enable --now crio
</span></span><span style="display:flex;"><span>kubeadm config images pull --cri-socket<span style="color:#f92672">=</span>unix:///var/run/crio/crio.sock --kubernetes-version<span style="color:#f92672">=</span>$CRIP_VERSION
</span></span><span style="display:flex;"><span>kubeadm init --config<span style="color:#f92672">=</span>kubeadm-config.yaml --upload-certs | tee kubeadm-init.out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>crictl info
</span></span><span style="display:flex;"><span>kubectl get node -o wide
</span></span><span style="display:flex;"><span>kubectl get po --all-namespaces
</span></span></code></pre></div><h3 id="inincialize-network">Inincialize network</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span></span><span style="display:flex;"><span>kubectl apply -f kube-flannel.yml
</span></span></code></pre></div><h3 id="install-tools">Install tools</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install git -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubectx /usr/local/sbin/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubens /usr/local/sbin/kubens
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens kube-system
</span></span><span style="display:flex;"><span>kubectl describe po coredns-5dd5756b68-bztrx
</span></span></code></pre></div><p>If you have the fallowing error: <code>failed to delegate add: failed to set bridge addr: &quot;cni0&quot; already has an IP address different from 10.244.0.1/24</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ifconfig cni0 down    
</span></span><span style="display:flex;"><span>ifconfig flannel.1 down    
</span></span><span style="display:flex;"><span>ip link delete cni0
</span></span><span style="display:flex;"><span>ip link delete flannel.1
</span></span></code></pre></div><h3 id="demo-for-creating-checkpoint">Demo for creating checkpoint:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl taint nodes --all node-role.kubernetes.io/control-plane-
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubens default
</span></span><span style="display:flex;"><span>kubectl run nginx --image<span style="color:#f92672">=</span>nginx --restart<span style="color:#f92672">=</span>Never
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -X POST <span style="color:#e6db74">&#34;https://localhost:10250/checkpoint/&lt;namespace&gt;/&lt;podId&gt;/&lt;container&gt;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -sk -X POST  <span style="color:#e6db74">&#34;https://localhost:10250/checkpoint/default/nginx/nginx&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --key /etc/kubernetes/pki/apiserver-kubelet-client.key <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cacert /etc/kubernetes/pki/ca.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cert /etc/kubernetes/pki/apiserver-kubelet-client.crt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Response:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {&#34;items&#34;:[&#34;/var/lib/kubelet/checkpoints/checkpoint-nginx_default-nginx-2024-01-25T10:01:43Z.tar&#34;]}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Check the directory:</span>
</span></span><span style="display:flex;"><span>ls -l /var/lib/kubelet/checkpoints/
</span></span></code></pre></div><p>This request created an archive in <code>/var/lib/kubelet/checkpoints/checkpoint-&lt;pod&gt;_&lt;namespace&gt;-&lt;container&gt;-&lt;timestamp&gt;.tar</code>.</p>
<h3 id="analyzing">Analyzing</h3>
<p>We now have a checkpointed container archive, so let&rsquo;s take a look at what&rsquo;s inside:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd /var/lib/kubelet/checkpoints/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cp checkpoint-nginx_default-nginx-2024-01-25T10:01:43Z.tar nginx.tar
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar --exclude<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;*/*&#34;</span> -tf nginx.tar
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Response:</span>
</span></span><span style="display:flex;"><span>stats-dump
</span></span><span style="display:flex;"><span>dump.log
</span></span><span style="display:flex;"><span>checkpoint/
</span></span><span style="display:flex;"><span>config.dump
</span></span><span style="display:flex;"><span>spec.dump
</span></span><span style="display:flex;"><span>bind.mounts
</span></span><span style="display:flex;"><span>rootfs-diff.tar
</span></span><span style="display:flex;"><span>io.kubernetes.cri-o.LogPath
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Extract:</span>
</span></span><span style="display:flex;"><span>tar -xf nginx.tar
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ll checkpoint
</span></span><span style="display:flex;"><span>total <span style="color:#ae81ff">4816</span>
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">8305</span> Jan <span style="color:#ae81ff">25</span> 10:01 cgroup.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">1993</span> Jan <span style="color:#ae81ff">25</span> 10:01 core-1.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">2074</span> Jan <span style="color:#ae81ff">25</span> 10:01 core-28.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">2072</span> Jan <span style="color:#ae81ff">25</span> 10:01 core-29.img
</span></span><span style="display:flex;"><span>-rw-------. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">43</span> Jan <span style="color:#ae81ff">25</span> 10:01 descriptors.json
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root     <span style="color:#ae81ff">398</span> Jan <span style="color:#ae81ff">25</span> 10:01 fdinfo-2.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root     <span style="color:#ae81ff">324</span> Jan <span style="color:#ae81ff">25</span> 10:01 fdinfo-3.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root     <span style="color:#ae81ff">324</span> Jan <span style="color:#ae81ff">25</span> 10:01 fdinfo-4.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">2338</span> Jan <span style="color:#ae81ff">25</span> 10:01 files.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">18</span> Jan <span style="color:#ae81ff">25</span> 10:01 fs-1.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">18</span> Jan <span style="color:#ae81ff">25</span> 10:01 fs-28.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">18</span> Jan <span style="color:#ae81ff">25</span> 10:01 fs-29.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">36</span> Jan <span style="color:#ae81ff">25</span> 10:01 ids-1.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">36</span> Jan <span style="color:#ae81ff">25</span> 10:01 ids-28.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">36</span> Jan <span style="color:#ae81ff">25</span> 10:01 ids-29.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">46</span> Jan <span style="color:#ae81ff">25</span> 10:01 inventory.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">82</span> Jan <span style="color:#ae81ff">25</span> 10:01 ipcns-var-11.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">37</span> Jan <span style="color:#ae81ff">25</span> 10:01 memfd.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">1972</span> Jan <span style="color:#ae81ff">25</span> 10:01 mm-1.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">2083</span> Jan <span style="color:#ae81ff">25</span> 10:01 mm-28.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">2083</span> Jan <span style="color:#ae81ff">25</span> 10:01 mm-29.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">7831</span> Jan <span style="color:#ae81ff">25</span> 10:01 mountpoints-13.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">26</span> Jan <span style="color:#ae81ff">25</span> 10:01 netns-10.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root     <span style="color:#ae81ff">398</span> Jan <span style="color:#ae81ff">25</span> 10:01 pagemap-1.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root     <span style="color:#ae81ff">430</span> Jan <span style="color:#ae81ff">25</span> 10:01 pagemap-28.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root     <span style="color:#ae81ff">430</span> Jan <span style="color:#ae81ff">25</span> 10:01 pagemap-29.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">24</span> Jan <span style="color:#ae81ff">25</span> 10:01 pagemap-shmem-1024.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">4096</span> Jan <span style="color:#ae81ff">25</span> 10:01 pages-1.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">1286144</span> Jan <span style="color:#ae81ff">25</span> 10:01 pages-2.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">1740800</span> Jan <span style="color:#ae81ff">25</span> 10:01 pages-3.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">1740800</span> Jan <span style="color:#ae81ff">25</span> 10:01 pages-4.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">50</span> Jan <span style="color:#ae81ff">25</span> 10:01 pstree.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">12</span> Jan <span style="color:#ae81ff">25</span> 10:01 seccomp.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">32</span> Jan <span style="color:#ae81ff">25</span> 10:01 timens-0.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root     <span style="color:#ae81ff">408</span> Jan <span style="color:#ae81ff">25</span> 10:01 tmpfs-dev-195.tar.gz.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root     <span style="color:#ae81ff">367</span> Jan <span style="color:#ae81ff">25</span> 10:01 tmpfs-dev-197.tar.gz.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">98</span> Jan <span style="color:#ae81ff">25</span> 10:01 tmpfs-dev-198.tar.gz.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">98</span> Jan <span style="color:#ae81ff">25</span> 10:01 tmpfs-dev-199.tar.gz.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">98</span> Jan <span style="color:#ae81ff">25</span> 10:01 tmpfs-dev-200.tar.gz.img
</span></span><span style="display:flex;"><span>-rw-r--r--. <span style="color:#ae81ff">1</span> root root      <span style="color:#ae81ff">27</span> Jan <span style="color:#ae81ff">25</span> 10:01 utsns-12.img
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat config.dump
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;id&#34;</span>: <span style="color:#e6db74">&#34;0e740e048ccfb41adabad2bb4153781c5b8a65f4c50fc7eddc2148802fd994da&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;k8s_nginx_nginx_default_0ff70d03-6f65-4df7-a996-3eb313b9f63f_0&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;rootfsImage&#34;</span>: <span style="color:#e6db74">&#34;docker.io/library/nginx@sha256:161ef4b1bf7effb350a2a9625cb2b59f69d54ec6059a8a155a1438d0439c593c&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;rootfsImageRef&#34;</span>: <span style="color:#e6db74">&#34;a8758716bb6aa4d90071160d27028fe4eaee7ce8166221a97d30440c8eac2be6&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;rootfsImageName&#34;</span>: <span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;runtime&#34;</span>: <span style="color:#e6db74">&#34;runc&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;createdTime&#34;</span>: <span style="color:#e6db74">&#34;2024-01-25T10:01:26.916550745Z&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;checkpointedTime&#34;</span>: <span style="color:#e6db74">&#34;2024-01-25T10:01:43.05793532Z&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;restoredTime&#34;</span>: <span style="color:#e6db74">&#34;0001-01-01T00:00:00Z&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;restored&#34;</span>: false
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar -tf rootfs-diff.tar
</span></span><span style="display:flex;"><span>var/cache/nginx/scgi_temp/
</span></span><span style="display:flex;"><span>var/cache/nginx/uwsgi_temp/
</span></span><span style="display:flex;"><span>var/cache/nginx/client_temp/
</span></span><span style="display:flex;"><span>var/cache/nginx/fastcgi_temp/
</span></span><span style="display:flex;"><span>var/cache/nginx/proxy_temp/
</span></span><span style="display:flex;"><span>run/nginx.pid
</span></span><span style="display:flex;"><span>etc/mtab
</span></span></code></pre></div><h3 id="restoring">Restoring</h3>
<p>To restore the previously check-pointed container directly in Kubernetes it is necessary to convert the checkpoint archive into an image that can be pushed to a registry.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install buildah -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>newcontainer<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>buildah from scratch<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>buildah add $newcontainer /var/lib/kubelet/checkpoints/nginx.tar /
</span></span><span style="display:flex;"><span>buildah config --annotation<span style="color:#f92672">=</span>io.kubernetes.cri-o.annotations.checkpoint.name<span style="color:#f92672">=</span>&lt;container-name&gt; $newcontainer
</span></span><span style="display:flex;"><span>buildah commit $newcontainer checkpoint-image:latest
</span></span><span style="display:flex;"><span>buildah rm $newcontainer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>buildah push localhost/checkpoint-image:latest container-image-registry.example/user/checkpoint-image:latest
</span></span></code></pre></div><p>To restore this checkpoint image (container-image-registry.example/user/checkpoint-image:latest), the image needs to be listed in the specification for a Pod. Here&rsquo;s an example manifest:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namePrefix</span>: <span style="color:#ae81ff">example-</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">&lt;container-name&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">container-image-registry.example/user/checkpoint-image:latest</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nodeName</span>: <span style="color:#ae81ff">&lt;destination-node&gt;</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[CNI-Genie: network separation with multiple CNI]]></title>
            <link href="https://devopstales.github.io/kubernetes/cni-genie/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/multus-nmstate/?utm_source=atom_feed" rel="related" type="text/html" title="Configurre network wit nmstate operator" />
                <link href="https://devopstales.github.io/kubernetes/multus/?utm_source=atom_feed" rel="related" type="text/html" title="Use Multus CNI in Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/multus-calico/?utm_source=atom_feed" rel="related" type="text/html" title="Use multus to separate metwork trafics" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-submariner/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Rancher Submariner Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-skupper/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Skupper Cluster Mesh" />
            
                <id>https://devopstales.github.io/kubernetes/cni-genie/</id>
            
            
            <published>2023-10-27T00:00:00+00:00</published>
            <updated>2023-10-27T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use CNI-Genie for network separation with multiple CNI.</p>
<h3 id="wat-is-cni-genie">Wat is CNI-Genie?</h3>
<p>CNI-Genie CNI from Huawei is a container network interface plugin for Kubernetes that enables attaching multiple network interfaces to pods. In Kubernetes, each pod has only one network interface by default, other than local loopback. With CNI-Genie, you can create multi-homed pods that have multiple interfaces. CNI-Genie acts a as ‘meta’ plugin that can call other CNI plugins to configure additional interfaces.</p>
<h3 id="kind-for-testing">Kind for testing</h3>
<p>For this Demo  will use Kind (Kubernetes in Docker) for easy reproduction. The fallowing kind config will create a one master one worker Kubernetes cluster without a preinstalled CNI.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano kind-c1-config.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kind.x-k8s.io/v1alpha4</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodes</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">worker</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">disableDefaultCNI</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSubnet</span>: <span style="color:#e6db74">&#34;10.244.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceSubnet</span>: <span style="color:#e6db74">&#34;10.245.0.0/16&#34;</span>
</span></span></code></pre></div><p>As you can see the kind kbernetes cluster will use <code>10.244.0.0/16</code> as its pod network. Normally I whoud use the same network in the CNI configuration. In this demo I will install multiple CNIs in one cluster, so I cut this network in two. Flannel will use <code>10.244.0.0/17</code> as its network and weave-net <code>10.244.128.0/17</code>.</p>
<h2 id="install-cni-networks">Install CNI networks</h2>
<p>So frs I will start the kind network:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kind create cluster --name c1 --config kind-c1-config.yaml
</span></span><span style="display:flex;"><span>Creating cluster <span style="color:#e6db74">&#34;c1&#34;</span> ...
</span></span><span style="display:flex;"><span> ✓ Ensuring node image <span style="color:#f92672">(</span>kindest/node:v1.27.0<span style="color:#f92672">)</span> 🖼
</span></span><span style="display:flex;"><span> ✓ Preparing nodes 📦 📦
</span></span><span style="display:flex;"><span> ✓ Writing configuration 📜
</span></span><span style="display:flex;"><span> ✓ Starting control-plane 🕹️
</span></span><span style="display:flex;"><span> ✓ Installing StorageClass 💾
</span></span><span style="display:flex;"><span> ✓ Joining worker nodes 🚜
</span></span><span style="display:flex;"><span>Set kubectl context to <span style="color:#e6db74">&#34;kind-c1&#34;</span>
</span></span><span style="display:flex;"><span>You can now use your cluster with:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl cluster-info --context kind-c1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Thanks <span style="color:#66d9ef">for</span> using kind! 😊
</span></span></code></pre></div><p>Then Install flannel network. For this I downloaded the flannel yaml from its git repo and modified it to use <code>kube-system</code> as its namespace and <code>10.244.0.0/17</code> as its network.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>  <span style="color:#f92672">net-conf.json</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;Network&#34;: &#34;10.244.0.0/17&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;Backend&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;Type&#34;: &#34;vxlan&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens kube-system
</span></span><span style="display:flex;"><span>kubectl apply -f kube-flannel.yaml
</span></span></code></pre></div><p>I thought it will be enough but I get an error at the flannel pods:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe pod coredns-6d4b75cb6d-c9vr2 -n kube-system
</span></span><span style="display:flex;"><span>Name:                 coredns-6d4b75cb6d-c9vr2
</span></span><span style="display:flex;"><span>Namespace:            kube-system
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Events:
</span></span><span style="display:flex;"><span>  Type     Reason                  Age                    From               Message
</span></span><span style="display:flex;"><span>  ----     ------                  ----                   ----               -------
</span></span><span style="display:flex;"><span>  Warning  FailedScheduling        6m34s <span style="color:#f92672">(</span>x26 over 132m<span style="color:#f92672">)</span>  default-scheduler  0/3 nodes are available: <span style="color:#ae81ff">3</span> node<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span> had untolerated taint <span style="color:#f92672">{</span>node.kubernetes.io/not-ready: <span style="color:#f92672">}</span>. preemption: 0/3 nodes are available: <span style="color:#ae81ff">3</span> Preemption is not helpful <span style="color:#66d9ef">for</span> scheduling.
</span></span><span style="display:flex;"><span>  Normal   Scheduled               4m24s                  default-scheduler  Successfully assigned kube-system/coredns-6d4b75cb6d-c9vr2 to testcluster-worker
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>  Warning  FailedCreatePodSandBox  2m39s                  kubelet            Failed to create pod sandbox: rpc error: code <span style="color:#f92672">=</span> Unknown desc <span style="color:#f92672">=</span> failed to setup network <span style="color:#66d9ef">for</span> sandbox <span style="color:#e6db74">&#34;cde73425ddab3522e243e810b75fac3cda51724a8f1f3c45f4a58c6df05bb613&#34;</span>: plugin type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;flannel&#34;</span> failed <span style="color:#f92672">(</span>add<span style="color:#f92672">)</span>: failed to delegate add: failed to find plugin <span style="color:#e6db74">&#34;bridge&#34;</span> in path <span style="color:#f92672">[</span>/opt/cni/bin<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  Warning  FailedCreatePodSandBox  7s <span style="color:#f92672">(</span>x12 over 2m28s<span style="color:#f92672">)</span>    kubelet            <span style="color:#f92672">(</span>combined from similar events<span style="color:#f92672">)</span>: Failed to create pod sandbox: rpc error: code <span style="color:#f92672">=</span> Unknown desc <span style="color:#f92672">=</span> failed to setup network <span style="color:#66d9ef">for</span> sandbox <span style="color:#e6db74">&#34;fc18a7232cce32804a88edface3219f4d7dcaa6ae4cd3d2e6e268b7f4c30b801&#34;</span>: plugin type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;flannel&#34;</span> failed <span style="color:#f92672">(</span>add<span style="color:#f92672">)</span>: failed to delegate add: failed to find plugin <span style="color:#e6db74">&#34;bridge&#34;</span> in path <span style="color:#f92672">[</span>/opt/cni/bin<span style="color:#f92672">]</span>
</span></span></code></pre></div><p>At this point I realized that the kubernetes node docker image dose not contain the necessary binaries, so I built a docker image that contains this binaries and I copies this binaries from an init container:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>      <span style="color:#f92672">initContainers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">install-containernetworking-plugins</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">devopstales/containernetworking-plugins:1.0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">/bin/sh</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#e6db74">&#39;-c&#39;</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">cp -R /containernetworking-plugins/* /opt/cni/bin/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cni-plugin</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/opt/cni/bin</span>
</span></span></code></pre></div><p>Next we will install the weave-net. I downloaded its yaml from the git repo and modified it to use <code>10.244.128.0/17</code> as its network.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>          <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">weave</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>                - <span style="color:#ae81ff">/home/weave/launch.sh</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>                - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">INIT_CONTAINER</span>
</span></span><span style="display:flex;"><span>                  <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>                - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">HOSTNAME</span>
</span></span><span style="display:flex;"><span>                  <span style="color:#f92672">valueFrom</span>:
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">fieldRef</span>:
</span></span><span style="display:flex;"><span>                      <span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span>                      <span style="color:#f92672">fieldPath</span>: <span style="color:#ae81ff">spec.nodeName</span>
</span></span><span style="display:flex;"><span>                - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">IPALLOC_RANGE</span>
</span></span><span style="display:flex;"><span>                  <span style="color:#f92672">value</span>: <span style="color:#ae81ff">10.244.128.0</span><span style="color:#ae81ff">/17</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens kube-system
</span></span><span style="display:flex;"><span>kubectl apply -f weave-daemonset-k8s.yaml
</span></span></code></pre></div><p>Now all the pods are running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get pods -n kube-system
</span></span><span style="display:flex;"><span>NAME                                       READY   STATUS    RESTARTS      AGE
</span></span><span style="display:flex;"><span>coredns-5d78c9869d-mfkrx                   1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>coredns-5d78c9869d-twr8t                   1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>etcd-c1-control-plane                      1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-apiserver-c1-control-plane            1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-controller-manager-c1-control-plane   1/1     Running   <span style="color:#ae81ff">1</span> <span style="color:#f92672">(</span>20m ago<span style="color:#f92672">)</span>   1h
</span></span><span style="display:flex;"><span>kube-flannel-ds-h7f64                      1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-flannel-ds-v5w2c                      1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-proxy-46g2z                           1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-proxy-qxx29                           1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-scheduler-c1-control-plane            1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>weave-net-h8rcz                            2/2     Running   <span style="color:#ae81ff">1</span> <span style="color:#f92672">(</span>20m ago<span style="color:#f92672">)</span>   1h
</span></span><span style="display:flex;"><span>weave-net-xhcld                            2/2     Running   <span style="color:#ae81ff">1</span> <span style="color:#f92672">(</span>20m ago<span style="color:#f92672">)</span>   1h
</span></span></code></pre></div><h3 id="install-cni-genie">Install CNI-Genie</h3>
<p>Tp install the CNI-Genie I used the yaml from CNI-Genie&rsquo;s yaml with a modification. The yaml contains outdated RBAC objects so you need to switch <code>rbac.authorization.k8s.io/v1bet1</code> to <code>rbac.authorization.k8s.io/v1</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://raw.githubusercontent.com/cni-genie/CNI-Genie/master/conf/1.8/genie-plugin.yaml
</span></span><span style="display:flex;"><span>nano genie-plugin.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f genie-plugin.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get pods -n kube-system
</span></span><span style="display:flex;"><span>NAME                                       READY   STATUS    RESTARTS      AGE
</span></span><span style="display:flex;"><span>coredns-5d78c9869d-mfkrx                   1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>coredns-5d78c9869d-twr8t                   1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>etcd-c1-control-plane                      1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>genie-plugin-l65tj                         1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-apiserver-c1-control-plane            1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-controller-manager-c1-control-plane   1/1     Running   <span style="color:#ae81ff">1</span> <span style="color:#f92672">(</span>20m ago<span style="color:#f92672">)</span>   1h
</span></span><span style="display:flex;"><span>kube-flannel-ds-h7f64                      1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-flannel-ds-v5w2c                      1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-proxy-46g2z                           1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-proxy-qxx29                           1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>kube-scheduler-c1-control-plane            1/1     Running   <span style="color:#ae81ff">0</span>             1h
</span></span><span style="display:flex;"><span>weave-net-h8rcz                            2/2     Running   <span style="color:#ae81ff">1</span> <span style="color:#f92672">(</span>20m ago<span style="color:#f92672">)</span>   1h
</span></span><span style="display:flex;"><span>weave-net-xhcld                            2/2     Running   <span style="color:#ae81ff">1</span> <span style="color:#f92672">(</span>20m ago<span style="color:#f92672">)</span>   1h
</span></span></code></pre></div><p>In the node containers you can find all the tree CNI configs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker exec -it c1-worker ls -laF /etc/cni/net.d/
</span></span><span style="display:flex;"><span>total <span style="color:#ae81ff">28</span>
</span></span><span style="display:flex;"><span>drwx------ <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Oct <span style="color:#ae81ff">26</span> 14:01 ./
</span></span><span style="display:flex;"><span>drwxr-xr-x <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Jun <span style="color:#ae81ff">15</span> 00:37 ../
</span></span><span style="display:flex;"><span>-rw-r--r-- <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">1487</span> Oct <span style="color:#ae81ff">26</span> 14:01 00-genie.conf
</span></span><span style="display:flex;"><span>-rw-r--r-- <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">292</span> Oct <span style="color:#ae81ff">26</span> 13:50 10-flannel.conflist
</span></span><span style="display:flex;"><span>-rw-r--r-- <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">318</span> Oct <span style="color:#ae81ff">26</span> 13:51 10-weave.conflist
</span></span><span style="display:flex;"><span>-rw-r--r-- <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">271</span> Oct <span style="color:#ae81ff">26</span> 14:01 genie-kubeconfig
</span></span></code></pre></div><h3 id="demo">Demo</h3>
<p>I will start two pods in different networks:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano test1.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cni</span>: <span style="color:#e6db74">&#34;weave&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:latest</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano test2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cni</span>: <span style="color:#e6db74">&#34;flannel&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:latest</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span></code></pre></div><p>The <code>nginx1</code> will run in <code>weave</code> network and the <code>nginx2</code> in <code>flannel</code> network.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f nginx1.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f nginx2.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get po -o wide
</span></span><span style="display:flex;"><span>NAME     READY   STATUS    RESTARTS   AGE    IP             NODE        NOMINATED NODE   READINESS GATES
</span></span><span style="display:flex;"><span>nginx1   1/1     Running   <span style="color:#ae81ff">0</span>          101s   10.244.128.2   c1-worker   &lt;none&gt;           &lt;none&gt;
</span></span><span style="display:flex;"><span>nginx2   1/1     Running   <span style="color:#ae81ff">0</span>          4s     10.244.1.5     c1-worker   &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="flannel" term="flannel" label="flannel" />
                             
                                <category scheme="cni-genie" term="cni-genie" label="CNI-Genie" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install kubernetes with kubeadm and enable swap]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-install-with-swap/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-change-ip/?utm_source=atom_feed" rel="related" type="text/html" title="How to Change IP on Kubernetes node." />
                <link href="https://devopstales.github.io/kubernetes/migrate-kubernetes-to-dockershim/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Install cri-dockerd for docker" />
                <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Migrate from docker to containerd" />
                <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-crio/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Migrate from docker to cri-o" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-containerd-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm V2" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-install-with-swap/</id>
            
            
            <published>2023-09-22T00:00:00+00:00</published>
            <updated>2023-09-22T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Kubeadm is a tool that helps you bootstrap a simple Kubernetes cluster and simplifies the deployment process. In this post I will use kubeadm to install swap enabled kubernetes.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>In all the previous tutorials we disabled the host swap because Kubernetes dose not allowed to use it. In Kubernetes 1.28 the Linux swap usage</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>192.168.1.41  kubernetes01 <span style="color:#75715e"># master node</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># hardware requirement</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4</span> CPU
</span></span><span style="display:flex;"><span>16G RAM
</span></span></code></pre></div><h3 id="enable-cgroupv2">Enable cgroupV2</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf install -y grubby
</span></span><span style="display:flex;"><span>sudo grubby <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --update-kernel<span style="color:#f92672">=</span>ALL <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --args<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;systemd.unified_cgroup_hierarchy=1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt;&gt; /etc/systemd/system.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultCPUAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultIOAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultIPAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultBlockIOAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>init <span style="color:#ae81ff">6</span>
</span></span></code></pre></div><h3 id="configure-date-time-and-selinux">Configure date time and selinux</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>timedatectl set-timezone Europe/Budapest
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf install -y vim net-tools chrony ntpstat
</span></span><span style="display:flex;"><span>timedatectl set-ntp true
</span></span><span style="display:flex;"><span>systemctl enable chronyd --now
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl stop firewalld
</span></span><span style="display:flex;"><span>systemctl mask firewalld
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>setenforce <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/=\(enforcing\|permissive\)/=disabled/g&#39;</span> /etc/sysconfig/selinux
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/=\(enforcing\|permissive\)/=disabled/g&#39;</span> /etc/selinux/config
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;net.ipv6.conf.all.disable_ipv6 = 1&#34;</span> &gt;&gt; /etc/sysctl.conf
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;net.ipv6.conf.default.disable_ipv6 = 1&#34;</span> &gt;&gt; /etc/sysctl.conf
</span></span><span style="display:flex;"><span>sysctl -p
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;centos.mydomain.lan&#34;</span> &gt; /etc/hostname
</span></span><span style="display:flex;"><span>hostnamectl set-hostname centos.mydomain.lan
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ifconfig | grep inet | grep -v inet6 | cut -d<span style="color:#e6db74">&#34; &#34;</span> -f10 | sed <span style="color:#e6db74">&#34;s|</span>$<span style="color:#e6db74">|   `hostname -s` `hostname -f`|&#34;</span> &gt;&gt; /etc/hosts
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#34;s|::1|#::1|&#34;</span> /etc/hosts
</span></span></code></pre></div><h3 id="install-containerd">Install containerd</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>dnf install -y epel-release
</span></span><span style="display:flex;"><span>dnf install -y device-mapper-persistent-data lvm2 iproute-tc
</span></span><span style="display:flex;"><span>dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style="display:flex;"><span>dnf install -y containerd.io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Configure containerd</span>
</span></span><span style="display:flex;"><span>sudo mkdir -p /etc/containerd
</span></span><span style="display:flex;"><span>sudo containerd config default &gt; /etc/containerd/config.toml
</span></span></code></pre></div><h3 id="configuration">Configuration</h3>
<p>To use the <code>systemd</code> cgroup driver in <code>/etc/containerd/config.toml</code> with <code>runc</code>, set</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc.options<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>            SystemdCgroup <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><p>As you can see we dose n ot siabled the swap:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># show swap is on</span>
</span></span><span style="display:flex;"><span>$ swapon --show
</span></span><span style="display:flex;"><span>NAME      TYPE      SIZE USED PRIO
</span></span><span style="display:flex;"><span>/dev/sda1 partition   2G   0B   -2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># check for type cgroup2</span>
</span></span><span style="display:flex;"><span>$ mount -l|grep cgroup
</span></span><span style="display:flex;"><span>cgroup2 on /sys/fs/cgroup type cgroup2 <span style="color:#f92672">(</span>rw,nosuid,nodev,noexec,relatime,seclabel,nsdelegate<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># check for cpu controller</span>
</span></span><span style="display:flex;"><span>$ cat /sys/fs/cgroup/cgroup.subtree_control
</span></span><span style="display:flex;"><span>cpu io memory pids
</span></span></code></pre></div><h3 id="install-kubeadm">Install kubeadm</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt;&gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo dnf -y install kubelet kubeadm kubectl --disableexcludes<span style="color:#f92672">=</span>kubernetes
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Start containerd</span>
</span></span><span style="display:flex;"><span>systemctl enable --now containerd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;runtime-endpoint: unix:///run/containerd/containerd.sock&#34;</span> &gt; /etc/crictl.yaml
</span></span><span style="display:flex;"><span>crictl ps
</span></span></code></pre></div><p>Change runtime in kubeadm config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># add the following flags to KUBELET_KUBEADM_ARGS variable</span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /etc/sysconfig/kubelet
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KUBELET_EXTRA_ARGS=&#34;--node-ip=192.168.1.41 --cgroup-driver=systemd --fail-swap-on=false&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl enable --now kubelet
</span></span><span style="display:flex;"><span>sudo systemctl status kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm config images pull
</span></span></code></pre></div><h3 id="init-master">Init master</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano kubeadm-config.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;kubeadm.k8s.io/v1beta3&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">InitConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">localAPIEndpoint</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># local ip and lort</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">advertiseAddress</span>: <span style="color:#ae81ff">192.168.100.10</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">bindPort</span>: <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodeRegistration</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">criSocket</span>: <span style="color:#ae81ff">unix:///run/containerd/containerd.sock</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">taints</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kubeletExtraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">runtime-cgroups</span>: <span style="color:#e6db74">&#34;/system.slice/containerd.service&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rotate-server-certificates</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># loadbalancer ip and port</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">controlPlaneEndpoint</span>: <span style="color:#e6db74">&#34;192.168.100.10:6443&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceSubnet</span>: <span style="color:#e6db74">&#34;10.96.0.0/12&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSubnet</span>: <span style="color:#e6db74">&#34;10.244.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubelet.config.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeletConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">enableServer</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">failSwapOn</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">cgroupDriver</span>: <span style="color:#e6db74">&#34;systemd&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">featureGates</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">NodeSwap</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">memorySwap</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">swapBehavior</span>: <span style="color:#ae81ff">LimitedSwap</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">JoinConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodeRegistration</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">criSocket</span>: <span style="color:#ae81ff">unix:///run/containerd/containerd.sock</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">taints</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kubeletExtraArgs</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">runtime-cgroups</span>: <span style="color:#e6db74">&#34;/system.slice/containerd.service&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rotate-server-certificates</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm init --config kubeadm-config.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
</span></span></code></pre></div><h3 id="join-workers-to-cluster">Join workers to cluster</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm join 192.168.100.10:6443 --token XXXXXXXX <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --discovery-token-ca-cert-hash sha256:XXXXXXXX
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install -y https://harbottle.gitlab.io/harbottle-main/7/x86_64/harbottle-main-release.rpm
</span></span><span style="display:flex;"><span>yum install -y kubectx helm
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="containerd" term="containerd" label="containerd" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Configurre network wit nmstate operator]]></title>
            <link href="https://devopstales.github.io/kubernetes/multus-nmstate/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/multus/?utm_source=atom_feed" rel="related" type="text/html" title="Use Multus CNI in Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/multus-calico/?utm_source=atom_feed" rel="related" type="text/html" title="Use multus to separate metwork trafics" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-submariner/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Rancher Submariner Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-skupper/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Skupper Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-linkerd/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Linkerd Cluster Mesh" />
            
                <id>https://devopstales.github.io/kubernetes/multus-nmstate/</id>
            
            
            <published>2023-09-14T00:00:00+00:00</published>
            <updated>2023-09-14T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use nmstate operator to manage your network configurations on a Kubernetes host.</p>
<p>For this Demo I will use a VM with two separate network interface. I will use the first one for the kubernetes network and flannel and use the second one to configure a bridge on ot with nmstate operator.</p>
<h3 id="k3s">K3S</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -sLS https://get.k3sup.dev | sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir /root/.kube
</span></span><span style="display:flex;"><span>IP<span style="color:#f92672">=</span>192.168.100.10
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3sup install --ip $IP --local   --context pik3s <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --merge <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local-path $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3sup ready --context pik3s
</span></span></code></pre></div><h3 id="kubernetes-nmstate">kubernetes-nmstate</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install NetworkManager -y
</span></span><span style="display:flex;"><span>systemctl start NetworkManager
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf copr enable nmstate/nmstate
</span></span><span style="display:flex;"><span>dnf install nmstate
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://github.com/nmstate/kubernetes-nmstate/releases/download/v0.80.1/nmstate.io_nmstates.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/nmstate/kubernetes-nmstate/releases/download/v0.80.1/namespace.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/nmstate/kubernetes-nmstate/releases/download/v0.80.1/service_account.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/nmstate/kubernetes-nmstate/releases/download/v0.80.1/role.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/nmstate/kubernetes-nmstate/releases/download/v0.80.1/role_binding.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/nmstate/kubernetes-nmstate/releases/download/v0.80.1/operator.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl create -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">nmstate.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NMState</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nmstate</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl create -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">nmstate.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NodeNetworkConfigurationPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">br1-enp0s9</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">desiredState</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">interfaces</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">br1</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">linux-bridge</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">state</span>: <span style="color:#ae81ff">up</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">ipv4</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">address</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">ip</span>: <span style="color:#ae81ff">192.168.200.10</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">prefix-length</span>: <span style="color:#ae81ff">24</span>
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">dhcp</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">bridge</span>:
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">port</span>:
</span></span><span style="display:flex;"><span>	- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">enp0s9</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><h3 id="multus-k3s">multus K3S</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://raw.githubusercontent.com/k8snetworkplumbingwg/multus-cni/master/deployments/multus-daemonset.yml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano multus-daemonset.yml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>containers:
</span></span><span style="display:flex;"><span>  - name: kube-multus
</span></span><span style="display:flex;"><span>    image: nfvpe/multus:v3.4.1
</span></span><span style="display:flex;"><span>    command: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;/entrypoint.sh&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    args:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;--multus-conf-file=auto&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;--cni-version=0.3.1&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># Add the following arg</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;--multus-kubeconfig-file-host=/var/lib/rancher/k3s/agent/etc/cni/net.d/multus.d/multus.kubeconfig&#34;</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>volumes:
</span></span><span style="display:flex;"><span>  - name: cni
</span></span><span style="display:flex;"><span>    hostPath:
</span></span><span style="display:flex;"><span>      path: /var/lib/rancher/k3s/agent/etc/cni/net.d
</span></span><span style="display:flex;"><span>  - name: cnibin
</span></span><span style="display:flex;"><span>    hostPath:
</span></span><span style="display:flex;"><span>      path: /var/lib/rancher/k3s/data/current/bin
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano multus-bridge.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">k8s.cni.cncf.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkAttachmentDefinition</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">multus-br1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;cniVersion&#34;: &#34;0.3.1&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;type&#34;: &#34;bridge&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;bridge&#34;: &#34;br1&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;ipam&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;type&#34;: &#34;host-local&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;subnet&#34;: &#34;192.168.200.0/24&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">         &#34;rangeStart&#34;: &#34;192.168.200.240&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">         &#34;rangeEnd&#34;: &#34;192.168.200.250&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }</span>
</span></span></code></pre></div><h3 id="demo-app">Demo app</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano demo-app.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">net-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">k8s.v1.cni.cncf.io/networks</span>: <span style="color:#ae81ff">multus-br1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">netshoot-pod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nicolaka/netshoot</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;tail&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">args</span>: [<span style="color:#e6db74">&#34;-f&#34;</span>, <span style="color:#e6db74">&#34;/dev/null&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">terminationGracePeriodSeconds</span>: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">net-pod2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">k8s.v1.cni.cncf.io/networks</span>: <span style="color:#ae81ff">multus-br1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">netshoot-pod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nicolaka/netshoot</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;tail&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">args</span>: [<span style="color:#e6db74">&#34;-f&#34;</span>, <span style="color:#e6db74">&#34;/dev/null&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">terminationGracePeriodSeconds</span>: <span style="color:#ae81ff">0</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl exec -it net-pod -- ip addr
</span></span><span style="display:flex;"><span>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span style="display:flex;"><span>    inet 127.0.0.1/8 scope host lo
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 ::1/128 scope host
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>2: eth0@if22: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1450</span> qdisc noqueue state UP group default
</span></span><span style="display:flex;"><span>    link/ether 56:60:ac:ef:12:be brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    inet 10.42.0.14/24 brd 10.42.0.255 scope global eth0
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::5460:acff:feef:12be/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>3: net1@if24: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue state UP group default
</span></span><span style="display:flex;"><span>    link/ether a2:0a:ec:07:64:6b brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    inet 192.168.200.240/24 brd 192.168.200.255 scope global net1
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::a00a:ecff:fe07:646b/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl exec -it net-pod2 -- ip addr
</span></span><span style="display:flex;"><span>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span style="display:flex;"><span>    inet 127.0.0.1/8 scope host lo
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 ::1/128 scope host
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>2: eth0@if23: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1450</span> qdisc noqueue state UP group default
</span></span><span style="display:flex;"><span>    link/ether 2e:b3:6e:d8:cf:35 brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    inet 10.42.0.15/24 brd 10.42.0.255 scope global eth0
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::2cb3:6eff:fed8:cf35/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>3: net1@if25: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue state UP group default
</span></span><span style="display:flex;"><span>    link/ether 52:96:53:1a:58:15 brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    inet 192.168.200.241/24 brd 192.168.200.255 scope global net1
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::5096:53ff:fe1a:5815/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># ping own ip</span>
</span></span><span style="display:flex;"><span>kubectl exec -it net-pod -- ping -c <span style="color:#ae81ff">1</span> -I net1 192.168.200.241
</span></span><span style="display:flex;"><span>PING 192.168.200.241 <span style="color:#f92672">(</span>192.168.200.241<span style="color:#f92672">)</span> from 192.168.200.240 net1: 56<span style="color:#f92672">(</span>84<span style="color:#f92672">)</span> bytes of data.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 192.168.200.241: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>0.220 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--- 192.168.200.241 ping statistics ---
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span> packets transmitted, <span style="color:#ae81ff">1</span> received, 0% packet loss, time 0ms
</span></span><span style="display:flex;"><span>rtt min/avg/max/mdev <span style="color:#f92672">=</span> 0.220/0.220/0.220/0.000 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ping net-pod2&#39;s ip</span>
</span></span><span style="display:flex;"><span>kubectl exec -it net-pod2 -- ping -c <span style="color:#ae81ff">1</span> -I net1 192.168.200.240
</span></span><span style="display:flex;"><span>PING 192.168.200.240 <span style="color:#f92672">(</span>192.168.200.240<span style="color:#f92672">)</span> from 192.168.200.241 net1: 56<span style="color:#f92672">(</span>84<span style="color:#f92672">)</span> bytes of data.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 192.168.200.240: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>0.072 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--- 192.168.200.240 ping statistics ---
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span> packets transmitted, <span style="color:#ae81ff">1</span> received, 0% packet loss, time 0ms
</span></span><span style="display:flex;"><span>rtt min/avg/max/mdev <span style="color:#f92672">=</span> 0.072/0.072/0.072/0.000 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ping host</span>
</span></span><span style="display:flex;"><span>kubectl exec -it net-pod -- ping -c <span style="color:#ae81ff">1</span> -I net1 192.168.200.10
</span></span><span style="display:flex;"><span>PING 192.168.200.10 <span style="color:#f92672">(</span>192.168.200.10<span style="color:#f92672">)</span> from 192.168.200.240 net1: 56<span style="color:#f92672">(</span>84<span style="color:#f92672">)</span> bytes of data.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 192.168.200.10: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>0.082 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--- 192.168.200.10 ping statistics ---
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span> packets transmitted, <span style="color:#ae81ff">1</span> received, 0% packet loss, time 0ms
</span></span><span style="display:flex;"><span>rtt min/avg/max/mdev <span style="color:#f92672">=</span> 0.082/0.082/0.082/0.000 ms
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="multus" term="multus" label="multus" />
                             
                                <category scheme="nmstate" term="nmstate" label="nmstate" />
                             
                                <category scheme="flannel" term="flannel" label="flannel" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Multicluster Kubernetes with Rancher Submariner Cluster Mesh]]></title>
            <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-submariner/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-skupper/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Skupper Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-linkerd/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Linkerd Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
            
                <id>https://devopstales.github.io/kubernetes/cluster-mesh-with-submariner/</id>
            
            
            <published>2023-08-23T00:00:00+00:00</published>
            <updated>2023-08-23T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install Rancher Submariner on multiple Kubernetes clusters and connect those clusters with Cluster Mesh.</p>
<h3 id="bootstrap-kind-clusters">Bootstrap kind clusters</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano kind-c1-config.yaml </span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kind.x-k8s.io/v1alpha4</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodes</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">worker</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">disableDefaultCNI</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiServerAddress</span>: <span style="color:#ae81ff">192.168.0.15</span> <span style="color:#75715e"># PUT YOUR IP ADDRESSS OF YOUR MACHINE HERE!</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSubnet</span>: <span style="color:#e6db74">&#34;10.0.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceSubnet</span>: <span style="color:#e6db74">&#34;10.1.0.0/16&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano kind-c2-config.yaml </span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kind.x-k8s.io/v1alpha4</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodes</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">worker</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">disableDefaultCNI</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiServerAddress</span>: <span style="color:#ae81ff">192.168.0.15</span> <span style="color:#75715e"># PUT YOUR IP ADDRESSS OF YOUR MACHINE HERE!</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSubnet</span>: <span style="color:#e6db74">&#34;10.2.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceSubnet</span>: <span style="color:#e6db74">&#34;10.3.0.0/16&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kind create cluster --name c1 --config kind-c1-config.yaml 
</span></span><span style="display:flex;"><span>kind create cluster --name c2 --config kind-c2-config.yaml
</span></span></code></pre></div><h3 id="inctall-calico-cni">Inctall Calico CNI</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano tigera-c1.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operator.tigera.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Installation</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">calicoNetwork</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ipPools</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">blockSize</span>: <span style="color:#ae81ff">26</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cidr</span>: <span style="color:#ae81ff">10.0.0.0</span><span style="color:#ae81ff">/16</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">encapsulation</span>: <span style="color:#ae81ff">VXLANCrossSubnet</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">natOutgoing</span>: <span style="color:#ae81ff">Enabled</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">nodeSelector</span>: <span style="color:#ae81ff">all()</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operator.tigera.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">APIServer</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>: {}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano tigera-c2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operator.tigera.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Installation</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">calicoNetwork</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ipPools</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">blockSize</span>: <span style="color:#ae81ff">26</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cidr</span>: <span style="color:#ae81ff">10.2.0.0</span><span style="color:#ae81ff">/16</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">encapsulation</span>: <span style="color:#ae81ff">VXLANCrossSubnet</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">natOutgoing</span>: <span style="color:#ae81ff">Enabled</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">nodeSelector</span>: <span style="color:#ae81ff">all()</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operator.tigera.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">APIServer</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>: {}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx kind-c1
</span></span><span style="display:flex;"><span>kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f tigera-c1.yaml
</span></span><span style="display:flex;"><span>watch kubectl get pods -n calico-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectx kind-c2
</span></span><span style="display:flex;"><span>kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f tigera-c2.yaml
</span></span><span style="display:flex;"><span>watch kubectl get pods -n calico-system
</span></span></code></pre></div><h3 id="install-submariner">Install submariner</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx kind-c1
</span></span><span style="display:flex;"><span>kubectl label node c1-worker submariner.io/gateway<span style="color:#f92672">=</span>true 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectx kind-c2
</span></span><span style="display:flex;"><span>kubectl label node c2-worker submariner.io/gateway<span style="color:#f92672">=</span>true
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx kind-c1
</span></span><span style="display:flex;"><span>subctl deploy-broker
</span></span><span style="display:flex;"><span>subctl join broker-info.subm --natt<span style="color:#f92672">=</span>false --clusterid kind-c1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectx kind-c2
</span></span><span style="display:flex;"><span>subctl join broker-info.subm --natt<span style="color:#f92672">=</span>false --clusterid kind-c2
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get pod -n submariner-operator
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                                             READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>submariner-gateway-xc7ql                         1/1     Running   <span style="color:#ae81ff">0</span>          96s
</span></span><span style="display:flex;"><span>submariner-lighthouse-agent-7dd644569c-cw26l     1/1     Running   <span style="color:#ae81ff">0</span>          96s
</span></span><span style="display:flex;"><span>submariner-lighthouse-coredns-7567869b57-dhqwk   1/1     Running   <span style="color:#ae81ff">0</span>          95s
</span></span><span style="display:flex;"><span>submariner-lighthouse-coredns-7567869b57-w4njc   1/1     Running   <span style="color:#ae81ff">0</span>          95s
</span></span><span style="display:flex;"><span>submariner-metrics-proxy-7pfg2                   1/1     Running   <span style="color:#ae81ff">0</span>          96s
</span></span><span style="display:flex;"><span>submariner-operator-6bd479d489-cb8h9             1/1     Running   <span style="color:#ae81ff">0</span>          18m
</span></span><span style="display:flex;"><span>submariner-routeagent-fwbbp                      1/1     Running   <span style="color:#ae81ff">0</span>          96s
</span></span><span style="display:flex;"><span>submariner-routeagent-w8chv                      1/1     Running   <span style="color:#ae81ff">0</span>          96s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><p>From your host you can test the connections:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -Ls https://get.submariner.io | bash
</span></span><span style="display:flex;"><span>export PATH<span style="color:#f92672">=</span>$PATH:~/.local/bin
</span></span><span style="display:flex;"><span>echo export PATH<span style="color:#f92672">=</span><span style="color:#ae81ff">\$</span>PATH:~/.local/bin &gt;&gt; ~/.profile
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>subctl show gateways
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Cluster <span style="color:#e6db74">&#34;kind-c1&#34;</span>
</span></span><span style="display:flex;"><span> ✓ Showing Gateways
</span></span><span style="display:flex;"><span>NODE        HA STATUS   SUMMARY                               
</span></span><span style="display:flex;"><span>c1-worker   active      All connections <span style="color:#f92672">(</span>1<span style="color:#f92672">)</span> are established   
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Cluster <span style="color:#e6db74">&#34;kind-c2&#34;</span>
</span></span><span style="display:flex;"><span> ✓ Showing Gateways
</span></span><span style="display:flex;"><span>NODE        HA STATUS   SUMMARY                               
</span></span><span style="display:flex;"><span>c2-worker   active      All connections <span style="color:#f92672">(</span>1<span style="color:#f92672">)</span> are established  
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>subctl show connections
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Cluster <span style="color:#e6db74">&#34;kind-c2&#34;</span>
</span></span><span style="display:flex;"><span> ✓ Showing Connections
</span></span><span style="display:flex;"><span>GATEWAY     CLUSTER   REMOTE IP    NAT   CABLE DRIVER   SUBNETS                    STATUS      RTT avg.     
</span></span><span style="display:flex;"><span>c1-worker   kind-c1   172.18.0.3   no    libreswan      10.1.0.0/16, 10.0.0.0/16   connected   568.195µs    
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Cluster <span style="color:#e6db74">&#34;kind-c1&#34;</span>
</span></span><span style="display:flex;"><span> ✓ Showing Connections
</span></span><span style="display:flex;"><span>GATEWAY     CLUSTER   REMOTE IP    NAT   CABLE DRIVER   SUBNETS                    STATUS      RTT avg.     
</span></span><span style="display:flex;"><span>c2-worker   kind-c2   172.18.0.4   no    libreswan      10.3.0.0/16, 10.2.0.0/16   connected   424.481µs
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>subctl verify --context kind-c1 --tocontext kind-c2 --only service-discovery,connectivity --verbose
</span></span></code></pre></div><h3 id="run-connectivity-test">Run connectivity test:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat deployment.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">docker.io/nginx:1.15.8</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">html</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/usr/share/nginx/html/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">periodSeconds</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">html</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">configMap</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">items</span>:
</span></span><span style="display:flex;"><span>              - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">message</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">path</span>: <span style="color:#ae81ff">index.html</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing-container</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">docker.io/cilium/json-mock:1.2</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">curl</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">sS</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">o</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">/dev/null</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">localhost</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">curl</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">sS</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">o</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">/dev/null</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">localhost</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 apply -f deployment.yaml
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 apply -f deployment.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano configmap_c1.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">message</span>: <span style="color:#f92672">&#34;{\&#34;Cluster\&#34;: \&#34;c1\&#34;, \&#34;Planet\&#34;: </span><span style="color:#ae81ff">\&#34;N&#39;Zoth\&#34;}\n&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">nano configmap_c2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">message</span>: <span style="color:#f92672">&#34;{\&#34;Cluster\&#34;: \&#34;c2\&#34;, \&#34;Planet\&#34;: </span><span style="color:#ae81ff">\&#34;Foran Tutha\&#34;}\n&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 apply -f configmap_c1.yaml
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 apply -f configmap_c2.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat service1.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ClusterIP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 apply -f service1.yaml
</span></span></code></pre></div><h3 id="deploy-applications-on-kubernetes">Deploy applications on Kubernetes</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx kind-c1
</span></span><span style="display:flex;"><span>subctl export service --namespace default rebel-base
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get ServiceExport
</span></span><span style="display:flex;"><span>NAME             AGE
</span></span><span style="display:flex;"><span>rebel-base       2m22s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get svc
</span></span><span style="display:flex;"><span>NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>   AGE
</span></span><span style="display:flex;"><span>kubernetes   ClusterIP   10.1.0.1       &lt;none&gt;        443/TCP   41m
</span></span><span style="display:flex;"><span>rebel-base   ClusterIP   10.1.125.152   &lt;none&gt;        80/TCP    5s
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx kind-c2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get ServiceImport -n submariner-operator
</span></span><span style="display:flex;"><span>NAME                         TYPE           IP                AGE
</span></span><span style="display:flex;"><span>rebel-base-default-kind-c1   ClusterSetIP   <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;10.1.125.152&#34;</span><span style="color:#f92672">]</span>   12s
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                             
                                <category scheme="cluster-mesh" term="cluster-mesh" label="cluster-mesh" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="submariner" term="submariner" label="submariner" />
                             
                                <category scheme="cluster-mesh" term="cluster-mesh" label="cluster-mesh" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Multicluster Kubernetes with Skupper Cluster Mesh]]></title>
            <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-skupper/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-linkerd/?utm_source=atom_feed" rel="related" type="text/html" title="Multicluster Kubernetes with Linkerd Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
            
                <id>https://devopstales.github.io/kubernetes/cluster-mesh-with-skupper/</id>
            
            
            <published>2023-08-12T00:00:00+00:00</published>
            <updated>2023-08-12T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install skupper on multiple Kubernetes clusters and connect those clusters with Cluster Mesh.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/skupperproject/skupper/releases/download/1.4.2/skupper-cli-1.4.2-linux-amd64.tgz
</span></span><span style="display:flex;"><span>tar -xzf skupper-cli-1.4.2-linux-amd64.tgz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p $HOME/bin
</span></span><span style="display:flex;"><span>mv skupper $HOME/bin
</span></span><span style="display:flex;"><span>export PATH<span style="color:#f92672">=</span>$PATH:$HOME/bin
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kind create cluster --name c1
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.10/config/manifests/metallb-native.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker network inspect -f <span style="color:#e6db74">&#39;{{.IPAM.Config}}&#39;</span> kind
</span></span><span style="display:flex;"><span><span style="color:#f92672">[{</span>172.18.0.0/16  172.18.0.1 map<span style="color:#f92672">[]}</span> <span style="color:#f92672">{</span>fc00:f853:ccd:e793::/64  fc00:f853:ccd:e793::1 map<span style="color:#f92672">[]}]</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano c1-address-pool.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">IPAddressPool</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">example</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">addresses</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">172.18.255.150-172.18.255.199</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">L2Advertisement</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">empty</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kind create cluster --name c2
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.10/config/manifests/metallb-native.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano c2-address-pool.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">IPAddressPool</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">example</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">addresses</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">172.18.255.150-172.18.255.199</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">L2Advertisement</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">empty</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span></code></pre></div><h3 id="install-skuuper">Install Skuuper</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx kind-c1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create ns interconnect
</span></span><span style="display:flex;"><span>kubens interconnect
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>skupper init --enable-cluster-permissions --enable-console --enable-flow-collector
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx kind-c2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create ns interconnect
</span></span><span style="display:flex;"><span>kubens interconnect
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>skupper init --enable-cluster-permissions
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>skupper token create c2-token.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectx kind-c1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>skupper link create c2-token.yaml
</span></span></code></pre></div><h3 id="test-deploy">Test deploy</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano deploy.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">docker.io/nginx:1.15.8</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">html</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/usr/share/nginx/html/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">periodSeconds</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">html</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">configMap</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">items</span>:
</span></span><span style="display:flex;"><span>              - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">message</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">path</span>: <span style="color:#ae81ff">index.html</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing-container</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">docker.io/cilium/json-mock:1.2</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">curl</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">sS</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">o</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">/dev/null</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">localhost</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">curl</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">sS</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">o</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">/dev/null</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">localhost</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano configmap_c1.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">message</span>: <span style="color:#f92672">&#34;{\&#34;Cluster\&#34;: \&#34;c1\&#34;, \&#34;Planet\&#34;: </span><span style="color:#ae81ff">\&#34;N&#39;Zoth\&#34;}\n&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano configmap_c2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">message</span>: <span style="color:#f92672">&#34;{\&#34;Cluster\&#34;: \&#34;c2\&#34;, \&#34;Planet\&#34;: </span><span style="color:#ae81ff">\&#34;Foran Tutha\&#34;}\n&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx kind-c1
</span></span><span style="display:flex;"><span>kubens interconnect
</span></span><span style="display:flex;"><span>kubectl apply -f deploy.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f configmap_c1.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f service.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectx kind-c2
</span></span><span style="display:flex;"><span>kubens interconnect
</span></span><span style="display:flex;"><span>kubectl apply -f deploy.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f configmap_c2.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c1 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c2&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;Foran Tutha&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c2&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;Foran Tutha&#34;</span><span style="color:#f92672">}</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>skupper expose deployment/rebel-base <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --port <span style="color:#ae81ff">80</span> -c kind-c2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>skupper expose deployment/rebel-base <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --port <span style="color:#ae81ff">80</span> -c kind-c1
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kgs rebel-base -o yaml           </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">internal.skupper.io/originalAssignedPort</span>: <span style="color:#ae81ff">80</span>:<span style="color:#ae81ff">1024</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">internal.skupper.io/originalSelector</span>: <span style="color:#ae81ff">name=rebel-base</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">internal.skupper.io/originalTargetPort</span>: <span style="color:#ae81ff">80</span>:<span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubectl.kubernetes.io/last-applied-configuration</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      {&#34;apiVersion&#34;:&#34;v1&#34;,&#34;kind&#34;:&#34;Service&#34;,&#34;metadata&#34;:{&#34;annotations&#34;:{},&#34;name&#34;:&#34;rebel-base&#34;,&#34;namespace&#34;:&#34;interconnect&#34;},&#34;spec&#34;:{&#34;ports&#34;:[{&#34;port&#34;:80}],&#34;selector&#34;:{&#34;name&#34;:&#34;rebel-base&#34;},&#34;type&#34;:&#34;ClusterIP&#34;}}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#e6db74">&#34;2023-08-25T07:48:10Z&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">interconnect</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resourceVersion</span>: <span style="color:#e6db74">&#34;4874&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">uid</span>: <span style="color:#ae81ff">584f78e7-ca4f-4b7e-bb22-ff57df56552b</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">clusterIP</span>: <span style="color:#ae81ff">10.96.209.144</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">clusterIPs</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">10.96.209.144</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">internalTrafficPolicy</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ipFamilies</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">IPv4</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ipFamilyPolicy</span>: <span style="color:#ae81ff">SingleStack</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">1024</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">application</span>: <span style="color:#ae81ff">skupper-router</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">skupper.io/component</span>: <span style="color:#ae81ff">router</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sessionAffinity</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ClusterIP</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">loadBalancer</span>: {}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c2 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c2&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;Foran Tutha&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span>
</span></span></code></pre></div><h3 id="admin-console">Admin Console</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get service skupper                                                                        
</span></span><span style="display:flex;"><span>NAME      TYPE           CLUSTER-IP      EXTERNAL-IP      PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>                                        AGE
</span></span><span style="display:flex;"><span>skupper   LoadBalancer   10.96.135.212   172.18.255.201   8010:31238/TCP,8080:32514/TCP,8081:32366/TCP   32m
</span></span></code></pre></div><pre tabindex="0"><code>kubectl get secret skupper-console-users -o json | jq -r .data.admin | base64 -d
xfGRpW09Qu
</code></pre><p>Open <code>https://172.18.255.201:8010</code> in your browser and login with <code>admin</code> as user and <code>xfGRpW09Qu</code> as password.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                             
                                <category scheme="cluster-mesh" term="cluster-mesh" label="cluster-mesh" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="skupper" term="skupper" label="skupper" />
                             
                                <category scheme="cluster-mesh" term="cluster-mesh" label="cluster-mesh" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Multicluster Kubernetes with Linkerd Cluster Mesh]]></title>
            <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-linkerd/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
            
                <id>https://devopstales.github.io/kubernetes/cluster-mesh-with-linkerd/</id>
            
            
            <published>2023-08-06T00:00:00+00:00</published>
            <updated>2023-08-06T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install linkerd on multiple Kubernetes clusters and connect those clusters with Cluster Mesh.</p>
<h3 id="bootstrap-kind-clustes-with-loadbalancer">Bootstrap kind clustes with loadbalancer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano kind-c1-config.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kind.x-k8s.io/v1alpha4</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodes</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">worker</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiServerAddress</span>: <span style="color:#ae81ff">192.168.0.15</span> <span style="color:#75715e"># PUT YOUR IP ADDRESSS OF YOUR MACHINE HERE!</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSubnet</span>: <span style="color:#e6db74">&#34;10.0.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceSubnet</span>: <span style="color:#e6db74">&#34;10.1.0.0/16&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano kind-c2-config.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kind.x-k8s.io/v1alpha4</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodes</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">worker</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiServerAddress</span>: <span style="color:#ae81ff">192.168.0.15</span> <span style="color:#75715e"># PUT YOUR IP ADDRESSS OF YOUR MACHINE HERE!</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSubnet</span>: <span style="color:#e6db74">&#34;10.2.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceSubnet</span>: <span style="color:#e6db74">&#34;10.3.0.0/16&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker network inspect -f <span style="color:#e6db74">&#39;{{.IPAM.Config}}&#39;</span> kind
</span></span><span style="display:flex;"><span><span style="color:#f92672">[{</span>172.18.0.0/16  172.18.0.1 map<span style="color:#f92672">[]}</span> <span style="color:#f92672">{</span>fc00:f853:ccd:e793::/64  fc00:f853:ccd:e793::1 map<span style="color:#f92672">[]}]</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano c1-address-pool.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">IPAddressPool</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">example</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">addresses</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">172.18.255.150-172.18.255.199</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">L2Advertisement</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">empty</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano c2-address-pool.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">IPAddressPool</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">example</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">addresses</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">172.18.255.150-172.18.255.199</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">metallb.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">L2Advertisement</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">empty</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kind create cluster --name c1 --config kind-c1-config.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.10/config/manifests/metallb-native.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f c1-address-pool.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kind create cluster --name c2 --config kind-c2-config.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.10/config/manifests/metallb-native.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f c2-address-pool.yaml
</span></span></code></pre></div><h3 id="generate-certificates-for-linkerd">Generate Certificates for Linkerd</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install step
</span></span><span style="display:flex;"><span>brew install linkerd
</span></span><span style="display:flex;"><span>curl -sL https://linkerd.github.io/linkerd-smi/install | sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>step certificate create root.linkerd.cluster.local root.crt root.key <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --profile root-ca --no-password --insecure
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>step certificate create identity.linkerd.cluster.local issuer.crt issuer.key <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --profile intermediate-ca --not-after 8760h --no-password --insecure <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ca root.crt --ca-key root.key
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># first, install the Linkerd CRDs in both clusters</span>
</span></span><span style="display:flex;"><span>linkerd install --crds | tee <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    &gt;<span style="color:#f92672">(</span>kubectl --context<span style="color:#f92672">=</span>kind-c1 apply -f -<span style="color:#f92672">)</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    &gt;<span style="color:#f92672">(</span>kubectl --context<span style="color:#f92672">=</span>kind-c2 apply -f -<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># then install the Linkerd control plane in both clusters</span>
</span></span><span style="display:flex;"><span>linkerd install <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --identity-trust-anchors-file root.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --identity-issuer-certificate-file issuer.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --identity-issuer-key-file issuer.key <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  | tee <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    &gt;<span style="color:#f92672">(</span>kubectl --context<span style="color:#f92672">=</span>kind-c1 apply -f -<span style="color:#f92672">)</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    &gt;<span style="color:#f92672">(</span>kubectl --context<span style="color:#f92672">=</span>kind-c2 apply -f -<span style="color:#f92672">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># And then Linkerd Viz:</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ctx in kind-c1 kind-c2; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>  linkerd --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span> viz install | <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    kubectl --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span> apply -f - <span style="color:#f92672">||</span> break
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># And SMI plugin</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ctx in kind-c1 kind-c2; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>    echo <span style="color:#e6db74">&#34;install smi </span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>;        
</span></span><span style="display:flex;"><span>    linkerd smi install --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span>  | kubectl apply -f - --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span>;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ctx in kind-c1 kind-c2; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>  echo <span style="color:#e6db74">&#34;Checking cluster: </span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span><span style="color:#e6db74"> .........&#34;</span>
</span></span><span style="display:flex;"><span>  linkerd --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span> check <span style="color:#f92672">||</span> break
</span></span><span style="display:flex;"><span>  echo <span style="color:#e6db74">&#34;-------------&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span></code></pre></div><p>To install the multicluster components on both cluster, you can run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ctx in kind-c1 kind-c2; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>  echo <span style="color:#e6db74">&#34;Installing on cluster: </span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span><span style="color:#e6db74"> .........&#34;</span>
</span></span><span style="display:flex;"><span>  linkerd --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span> multicluster install | <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    kubectl --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span> apply -f - <span style="color:#f92672">||</span> break
</span></span><span style="display:flex;"><span>  echo <span style="color:#e6db74">&#34;-------------&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ctx in kind-c1 kind-c2; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>  echo <span style="color:#e6db74">&#34;Checking gateway on cluster: </span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span><span style="color:#e6db74"> .........&#34;</span>
</span></span><span style="display:flex;"><span>  kubectl --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span> -n linkerd-multicluster <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    rollout status deploy/linkerd-gateway <span style="color:#f92672">||</span> break
</span></span><span style="display:flex;"><span>  echo <span style="color:#e6db74">&#34;-------------&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ctx in kind-c1 kind-c2; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>  printf <span style="color:#e6db74">&#34;Checking cluster: </span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span><span style="color:#e6db74"> .........&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">while</span> <span style="color:#f92672">[</span> <span style="color:#e6db74">&#34;</span><span style="color:#66d9ef">$(</span>kubectl --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span> -n linkerd-multicluster get service linkerd-gateway -o <span style="color:#e6db74">&#39;custom-columns=:.status.loadBalancer.ingress[0].ip&#39;</span> --no-headers<span style="color:#66d9ef">)</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&lt;none&gt;&#34;</span> <span style="color:#f92672">]</span>; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>      printf <span style="color:#e6db74">&#39;.&#39;</span>
</span></span><span style="display:flex;"><span>      sleep <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>  echo <span style="color:#e6db74">&#34;`kubectl --context=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span><span style="color:#e6db74"> -n linkerd-multicluster get service linkerd-gateway -o &#39;custom-columns=:.status.loadBalancer.ingress[0].ip&#39; --no-headers`&#34;</span>
</span></span><span style="display:flex;"><span>  printf <span style="color:#e6db74">&#34;\n&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span></code></pre></div><h3 id="link-the-clusters">Link the clusters</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ctx in kind-c1 kind-c2; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>  linkerd --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span> multicluster check -o short
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>linkerd --context kind-c1 multicluster link --cluster-name kind-c1 | kubectl --context<span style="color:#f92672">=</span>kind-c2 apply -f -
</span></span><span style="display:flex;"><span>linkerd --context kind-c2 multicluster link --cluster-name kind-c2 | kubectl --context<span style="color:#f92672">=</span>kind-c1 apply -f -
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ctx in kind-c1 kind-c2; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>  linkerd --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span> multicluster check -o short
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Status check results are √
</span></span><span style="display:flex;"><span>Status check results are √
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ctx in kind-c1 kind-c2; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>  linkerd --context<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>ctx<span style="color:#e6db74">}</span> multicluster gateways
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CLUSTER  ALIVE    NUM_SVC      LATENCY  
</span></span><span style="display:flex;"><span>kind-c2  True           <span style="color:#ae81ff">0</span>          1ms  
</span></span><span style="display:flex;"><span>CLUSTER  ALIVE    NUM_SVC      LATENCY  
</span></span><span style="display:flex;"><span>kind-c1  True           <span style="color:#ae81ff">0</span>          4ms 
</span></span></code></pre></div><h3 id="run-connectivity-test">Run connectivity test:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat deployment.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">linkerd.io/inject</span>: <span style="color:#ae81ff">enabled</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">docker.io/nginx:1.15.8</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">html</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/usr/share/nginx/html/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">periodSeconds</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">html</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">configMap</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">items</span>:
</span></span><span style="display:flex;"><span>              - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">message</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">path</span>: <span style="color:#ae81ff">index.html</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">linkerd.io/inject</span>: <span style="color:#ae81ff">enabled</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing-container</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">docker.io/cilium/json-mock:1.2</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">curl</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">sS</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">o</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">/dev/null</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">localhost</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">curl</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">sS</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">o</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">/dev/null</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">localhost</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 apply -f deployment.yaml
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 apply -f deployment.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat configmap_c1.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">message</span>: <span style="color:#f92672">&#34;{\&#34;Cluster\&#34;: \&#34;c1\&#34;, \&#34;Planet\&#34;: </span><span style="color:#ae81ff">\&#34;N&#39;Zoth\&#34;}\n&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cat configmap_c2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">message</span>: <span style="color:#f92672">&#34;{\&#34;Cluster\&#34;: \&#34;c2\&#34;, \&#34;Planet\&#34;: </span><span style="color:#ae81ff">\&#34;Foran Tutha\&#34;}\n&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 apply -f configmap_c1.yaml
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 apply -f configmap_c2.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat service.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ClusterIP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 apply -f service.yaml
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 apply -f service.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 exec -ti deployment/x-wing -c x-wing-container -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c1 exec -ti deployment/x-wing -c x-wing-container -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 exec -ti deployment/x-wing -c x-wing-container -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c2&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;Foran Tutha&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 exec -ti deployment/x-wing -c x-wing-container -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c2&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;Foran Tutha&#34;</span><span style="color:#f92672">}</span>
</span></span></code></pre></div><h3 id="expose-the-service">Expose the service</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 label svc -n default rebel-base mirror.linkerd.io/exported<span style="color:#f92672">=</span>true
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c2 get svc -n default
</span></span><span style="display:flex;"><span>NAME                 TYPE        CLUSTER-IP    EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>   AGE
</span></span><span style="display:flex;"><span>kubernetes           ClusterIP   10.1.0.1      &lt;none&gt;        443/TCP   34m
</span></span><span style="display:flex;"><span>rebel-base           ClusterIP   10.1.52.213   &lt;none&gt;        80/TCP    2m13s
</span></span><span style="display:flex;"><span>rebel-base-kind-c1   ClusterIP   10.1.140.47   &lt;none&gt;        80/TCP    30s
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano TrafficSplit.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">split.smi-spec.io/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">TrafficSplit</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">service</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">backends</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">service</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">service</span>: <span style="color:#ae81ff">rebel-base-kind-c1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">50</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c2 apply -f TrafficSplit.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c2 exec -ti deployment/x-wing -c x-wing-container -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c2&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;Foran Tutha&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 exec -ti deployment/x-wing -c x-wing-container -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 exec -ti deployment/x-wing -c x-wing-container -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c1 exec -ti deployment/x-wing -c x-wing-container -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span><span style="color:#e6db74">```</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                             
                                <category scheme="cluster-mesh" term="cluster-mesh" label="cluster-mesh" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="linkerd" term="linkerd" label="linkerd" />
                             
                                <category scheme="cluster-mesh" term="cluster-mesh" label="cluster-mesh" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Multicluster with Cilium Cluster Mesh]]></title>
            <link href="https://devopstales.github.io/kubernetes/cluster-mesh-with-cilium/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/multus-calico/?utm_source=atom_feed" rel="related" type="text/html" title="Use multus to separate metwork trafics" />
            
                <id>https://devopstales.github.io/kubernetes/cluster-mesh-with-cilium/</id>
            
            
            <published>2023-07-15T00:00:00+00:00</published>
            <updated>2023-07-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install Cilium on multiple Kubernetes clusters and connect those clusters with Cluster Mesh.</p>
<h3 id="bootstrap-kind-clusters">Bootstrap kind clusters</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano kind-c1-config.yaml </span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kind.x-k8s.io/v1alpha4</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodes</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">worker</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">disableDefaultCNI</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSubnet</span>: <span style="color:#e6db74">&#34;10.0.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceSubnet</span>: <span style="color:#e6db74">&#34;10.1.0.0/16&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano kind-c2-config.yaml </span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kind.x-k8s.io/v1alpha4</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodes</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">worker</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">disableDefaultCNI</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSubnet</span>: <span style="color:#e6db74">&#34;10.2.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceSubnet</span>: <span style="color:#e6db74">&#34;10.3.0.0/16&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kind create cluster --name c1 --config kind-c1-config.yaml 
</span></span><span style="display:flex;"><span>kind create cluster --name c2 --config kind-c2-config.yaml
</span></span></code></pre></div><h3 id="install-cilium">Install Cilium</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add cilium https://helm.cilium.io/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectx kind-c1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm install cilium cilium/cilium <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --namespace kube-system <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set nodeinit.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set kubeProxyReplacement<span style="color:#f92672">=</span>partial <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set hostServices.enabled<span style="color:#f92672">=</span>false <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set externalIPs.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set nodePort.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set hostPort.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set cluster.name<span style="color:#f92672">=</span>c1 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set cluster.id<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cilium status
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    /¯¯<span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> /¯¯<span style="color:#ae81ff">\_</span>_/¯¯<span style="color:#ae81ff">\ </span>   Cilium:             OK
</span></span><span style="display:flex;"><span> <span style="color:#ae81ff">\_</span>_/¯¯<span style="color:#ae81ff">\_</span>_/    Operator:           OK
</span></span><span style="display:flex;"><span> /¯¯<span style="color:#ae81ff">\_</span>_/¯¯<span style="color:#ae81ff">\ </span>   Envoy DaemonSet:    disabled <span style="color:#f92672">(</span>using embedded mode<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span> <span style="color:#ae81ff">\_</span>_/¯¯<span style="color:#ae81ff">\_</span>_/    Hubble Relay:       disabled
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">\_</span>_/       ClusterMesh:        disabled
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Deployment             cilium-operator    Desired: 2, Ready: 2/2, Available: 2/2
</span></span><span style="display:flex;"><span>DaemonSet              cilium             Desired: 2, Ready: 2/2, Available: 2/2
</span></span><span style="display:flex;"><span>Containers:            cilium             Running: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>                       cilium-operator    Running: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>Cluster Pods:          4/4 managed by Cilium
</span></span><span style="display:flex;"><span>Helm chart version:    1.14.0
</span></span><span style="display:flex;"><span>Image versions         cilium             quay.io/cilium/cilium:v1.14.0@sha256:5a94b561f4651fcfd85970a50bc78b201cfbd6e2ab1a03848eab25a82832653a: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>                       cilium-operator    quay.io/cilium/operator-generic:v1.14.0@sha256:3014d4bcb8352f0ddef90fa3b5eb1bbf179b91024813a90a0066eb4517ba93c9: <span style="color:#ae81ff">2</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx kind-c2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl --context<span style="color:#f92672">=</span>kind-c1 get secret -n kube-system cilium-ca -o yaml | <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  kubectl --context kind-c2 create -f -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm install cilium cilium/cilium <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --namespace kube-system <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set nodeinit.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set kubeProxyReplacement<span style="color:#f92672">=</span>partial <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set hostServices.enabled<span style="color:#f92672">=</span>false <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set externalIPs.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set nodePort.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set hostPort.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set cluster.name<span style="color:#f92672">=</span>c2 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   --set cluster.id<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cilium status
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    /¯¯<span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> /¯¯<span style="color:#ae81ff">\_</span>_/¯¯<span style="color:#ae81ff">\ </span>   Cilium:             OK
</span></span><span style="display:flex;"><span> <span style="color:#ae81ff">\_</span>_/¯¯<span style="color:#ae81ff">\_</span>_/    Operator:           OK
</span></span><span style="display:flex;"><span> /¯¯<span style="color:#ae81ff">\_</span>_/¯¯<span style="color:#ae81ff">\ </span>   Envoy DaemonSet:    disabled <span style="color:#f92672">(</span>using embedded mode<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span> <span style="color:#ae81ff">\_</span>_/¯¯<span style="color:#ae81ff">\_</span>_/    Hubble Relay:       disabled
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">\_</span>_/       ClusterMesh:        disabled
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>DaemonSet              cilium             Desired: 2, Ready: 2/2, Available: 2/2
</span></span><span style="display:flex;"><span>Deployment             cilium-operator    Desired: 2, Ready: 2/2, Available: 2/2
</span></span><span style="display:flex;"><span>Containers:            cilium             Running: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>                       cilium-operator    Running: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>Cluster Pods:          4/4 managed by Cilium
</span></span><span style="display:flex;"><span>Helm chart version:    1.14.0
</span></span><span style="display:flex;"><span>Image versions         cilium             quay.io/cilium/cilium:v1.14.0@sha256:5a94b561f4651fcfd85970a50bc78b201cfbd6e2ab1a03848eab25a82832653a: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>                       cilium-operator    quay.io/cilium/operator-generic:v1.14.0@sha256:3014d4bcb8352f0ddef90fa3b5eb1bbf179b91024813a90a0066eb4517ba93c9: <span style="color:#ae81ff">2</span>
</span></span></code></pre></div><h3 id="enable-cilium-cluster-mesh">Enable Cilium Cluster Mesh</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cilium clustermesh enable --context kind-c1 --service-type NodePort
</span></span><span style="display:flex;"><span>cilium clustermesh enable --context kind-c2 --service-type NodePort
</span></span></code></pre></div><p>Connect the clusters:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cilium clustermesh connect --context kind-c1 --destination-context kind-c2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cilium clustermesh status --context kind-c1 --wait
</span></span><span style="display:flex;"><span>⚠️  Service type NodePort detected! Service may fail when nodes are removed from the cluster!
</span></span><span style="display:flex;"><span>✅ Service <span style="color:#e6db74">&#34;clustermesh-apiserver&#34;</span> of type <span style="color:#e6db74">&#34;NodePort&#34;</span> found
</span></span><span style="display:flex;"><span>✅ Cluster access information is available:
</span></span><span style="display:flex;"><span>  - 172.18.0.3:32379
</span></span><span style="display:flex;"><span>✅ Deployment clustermesh-apiserver is ready
</span></span><span style="display:flex;"><span>⌛ Waiting <span style="color:#f92672">(</span>0s<span style="color:#f92672">)</span> <span style="color:#66d9ef">for</span> clusters to be connected: <span style="color:#ae81ff">2</span> nodes are not ready
</span></span><span style="display:flex;"><span>⌛ Waiting <span style="color:#f92672">(</span>11s<span style="color:#f92672">)</span> <span style="color:#66d9ef">for</span> clusters to be connected: <span style="color:#ae81ff">2</span> nodes are not ready
</span></span><span style="display:flex;"><span>⌛ Waiting <span style="color:#f92672">(</span>24s<span style="color:#f92672">)</span> <span style="color:#66d9ef">for</span> clusters to be connected: <span style="color:#ae81ff">2</span> nodes are not ready
</span></span><span style="display:flex;"><span>✅ All <span style="color:#ae81ff">2</span> nodes are connected to all clusters <span style="color:#f92672">[</span>min:1 / avg:1.0 / max:1<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>🔌 Cluster Connections:
</span></span><span style="display:flex;"><span>  - c2: 2/2 configured, 2/2 connected
</span></span><span style="display:flex;"><span>🔀 Global services: <span style="color:#f92672">[</span> min:0 / avg:0.0 / max:0 <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cilium clustermesh status --context kind-c2 --wait
</span></span><span style="display:flex;"><span>⚠️  Service type NodePort detected! Service may fail when nodes are removed from the cluster!
</span></span><span style="display:flex;"><span>✅ Service <span style="color:#e6db74">&#34;clustermesh-apiserver&#34;</span> of type <span style="color:#e6db74">&#34;NodePort&#34;</span> found
</span></span><span style="display:flex;"><span>✅ Cluster access information is available:
</span></span><span style="display:flex;"><span>  - 172.18.0.4:32379
</span></span><span style="display:flex;"><span>✅ Deployment clustermesh-apiserver is ready
</span></span><span style="display:flex;"><span>✅ All <span style="color:#ae81ff">2</span> nodes are connected to all clusters <span style="color:#f92672">[</span>min:1 / avg:1.0 / max:1<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>🔌 Cluster Connections:
</span></span><span style="display:flex;"><span>  - c1: 2/2 configured, 2/2 connected
</span></span><span style="display:flex;"><span>🔀 Global services: <span style="color:#f92672">[</span> min:0 / avg:0.0 / max:0 <span style="color:#f92672">]</span>
</span></span></code></pre></div><h3 id="run-connectivity-test">Run connectivity test:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat deployment.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">docker.io/nginx:1.15.8</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">html</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/usr/share/nginx/html/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">periodSeconds</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">httpGet</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">html</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">configMap</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">items</span>:
</span></span><span style="display:flex;"><span>              - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">message</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">path</span>: <span style="color:#ae81ff">index.html</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing-container</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">docker.io/cilium/json-mock:1.2</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">livenessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">curl</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">sS</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">o</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">/dev/null</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">localhost</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">readinessProbe</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">exec</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">curl</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">sS</span>
</span></span><span style="display:flex;"><span>            - -<span style="color:#ae81ff">o</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">/dev/null</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">localhost</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 apply -f deployment.yaml
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 apply -f deployment.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat configmap_c1.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">message</span>: <span style="color:#f92672">&#34;{\&#34;Cluster\&#34;: \&#34;c1\&#34;, \&#34;Planet\&#34;: </span><span style="color:#ae81ff">\&#34;N&#39;Zoth\&#34;}\n&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cat configmap_c2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base-response</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">message</span>: <span style="color:#f92672">&#34;{\&#34;Cluster\&#34;: \&#34;c2\&#34;, \&#34;Planet\&#34;: </span><span style="color:#ae81ff">\&#34;Foran Tutha\&#34;}\n&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl --context kind-c1 apply -f configmap_c1.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl --context kind-c2 apply -f configmap_c2.yaml</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cat service1.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ClusterIP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 apply -f service1.yaml
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 apply -f service1.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c1 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c2&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;Foran Tutha&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c2&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;Foran Tutha&#34;</span><span style="color:#f92672">}</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat service2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">io.cilium/global-service</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">io.cilium/service-affinity</span>: <span style="color:#e6db74">&#34;local&#34;</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">io.cilium/shared-service</span>: <span style="color:#e6db74">&#34;false&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ClusterIP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 apply -f service2.yaml
</span></span><span style="display:flex;"><span>kubectl --context kind-c2 apply -f service2.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --context kind-c1 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c1&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;N&#39;Zoth&#34;</span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>kubectl --context kind-c1 exec -ti deployment/x-wing -- curl rebel-base
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;Cluster&#34;</span>: <span style="color:#e6db74">&#34;c2&#34;</span>, <span style="color:#e6db74">&#34;Planet&#34;</span>: <span style="color:#e6db74">&#34;Foran Tutha&#34;</span><span style="color:#f92672">}</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                             
                                <category scheme="cluster-mesh" term="cluster-mesh" label="cluster-mesh" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="cilium" term="cilium" label="Cilium" />
                             
                                <category scheme="cluster-mesh" term="cluster-mesh" label="cluster-mesh" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Troubleshooting Kubernetes: API error at resource listing]]></title>
            <link href="https://devopstales.github.io/kubernetes/debug-couldnt-get-resource-list/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-migrate-pv/?utm_source=atom_feed" rel="related" type="text/html" title="How to Migrate Persistent Volumes on Kubernetes Easily?" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cephfs-storage-with-csi-driver/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes CephFS volume with CSI driver" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph-storage-with-csi-driver/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD volume with CSI driver" />
                <link href="https://devopstales.github.io/kubernetes/kubedash-1.0/?utm_source=atom_feed" rel="related" type="text/html" title="kubedash 1.0" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
            
                <id>https://devopstales.github.io/kubernetes/debug-couldnt-get-resource-list/</id>
            
            
            <published>2023-07-10T00:00:00+00:00</published>
            <updated>2023-07-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I this post I will show you how to troubleshoot your Kubernetes cluster when you get an API error at resource listing.</p>
<p>Yesterday when I tried to use my Kubernetes cluster, I got an error:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>couldn<span style="color:#960050;background-color:#1e0010">&#39;</span>t get resource list <span style="color:#66d9ef">for</span> custom.metrics.k8s.io/v1beta1: the server is currently unable to handle the request
</span></span></code></pre></div><p>I din&rsquo;t understand first so I started debugging. T</p>
<p>The <code>custom.metrics.k8s.io/v1beta1</code> is not a standard Kubernetes api. Kubernetes API can be extended with Custom Resources that are fully managed by Kubernetes and available to Kubectl and other tools. When you get it wit <code>kubectl</code> the Kubernetes API will find it like any other API object in etcd. The other way is to use a third-party API server living in the Kubernetes cluster as a pod to serv the object. So when you get it wit <code>kubectl</code> the Kubernetes API server will forward the request to the third-party API server. For this forward to work you need an <code>APIService</code> object:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apiregistration.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">APIService</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">v1beta1.metrics.k8s.io</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">group</span>: <span style="color:#ae81ff">metrics.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">groupPriorityMinimum</span>: <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">insecureSkipTLSVerify</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">metrics-server</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">port</span>: <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">version</span>: <span style="color:#ae81ff">v1beta1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">versionPriority</span>: <span style="color:#ae81ff">100</span>
</span></span></code></pre></div><p>First I believed it is the CRD of the metrics-server, and I started debugging the metrics-server. Check its logs but I found no problem. The I find the <code>APIService</code> object and realized this is not the same object.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get apiservice
</span></span><span style="display:flex;"><span>NAME                                   SERVICE                                                          AVAILABLE                 AGE
</span></span><span style="display:flex;"><span>v1.                                    Local                                                            True                      3y362d
</span></span><span style="display:flex;"><span>v1.acme.cert-manager.io                Local                                                            True                      131d
</span></span><span style="display:flex;"><span>v1.admissionregistration.k8s.io        Local                                                            True                      3y4d
</span></span><span style="display:flex;"><span>v1.apiextensions.k8s.io                Local                                                            True                      3y4d
</span></span><span style="display:flex;"><span>v1.apps                                Local                                                            True                      3y362d
</span></span><span style="display:flex;"><span>v1.authentication.k8s.io               Local                                                            True                      3y362d
</span></span><span style="display:flex;"><span>v1.authorization.k8s.io                Local                                                            True                      3y362d
</span></span><span style="display:flex;"><span>v1.autoscaling                         Local                                                            True                      3y362d
</span></span><span style="display:flex;"><span>v1.autoscaling.k8s.io                  Local                                                            True                      79d
</span></span><span style="display:flex;"><span>v1.batch                               Local                                                            True                      3y362d
</span></span><span style="display:flex;"><span>v1.cert-manager.io                     Local                                                            True                      79d
</span></span><span style="display:flex;"><span>v1.certificates.k8s.io                 Local                                                            True                      623d
</span></span><span style="display:flex;"><span>v1.coordination.k8s.io                 Local                                                            True                      3y362d
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>v1beta1.custom.metrics.k8s.io          cattle-monitoring-system/rancher-monitoring-prometheus-adapter   False <span style="color:#f92672">(</span>ServiceNotFound<span style="color:#f92672">)</span>   679d
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>v1beta1.metrics.k8s.io                 kube-system/metrics-server                                       True                      2y36d
</span></span></code></pre></div><p>The information we&rsquo;re looking for on this table is all the <code>APIServices</code> where <strong>Available</strong> is <strong>False</strong>. So I figured out the problem is caused by the removal og rancher, that left behind som object at deletion.</p>
<h2 id="conclusion">Conclusion</h2>
<p>One of the most common cause of the &lsquo;couldn&rsquo;t get resource list for&rsquo; error is the Kubernetes Metrics object served by metrics-server or prometheus-adapter, because metrics are not stored in Etcd like other resources. They are stored in memory or in prometheus, and then exposed via an API extension. If the API is not available, you will get this error.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[OKD OpenShift 4 Monitoring]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-monitoring/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-log4shell/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ceph-rbd-csi/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 Ceph Persisten Storage" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 authentication" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 ingress" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-install/?utm_source=atom_feed" rel="related" type="text/html" title="How To Install OKD OpenShift 4 on premise" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-monitoring/</id>
            
            
            <published>2023-06-14T00:00:00+00:00</published>
            <updated>2023-06-14T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you can use the enbeddid Prometheus monitoring system in OpenShift 4 to monitor your workload applications.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<h3 id="create-demo-app-to-monitor">Create Demo app to monitor</h3>
<p>First I installed a wordpress by helmfile to use as an app to monitor.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc new-project monitoring-test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc project monitoring-test
</span></span></code></pre></div><p>Deploy test app</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano wordpress-helmfile.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">helmDefaults</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">createNamespace</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">repositories</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">bitnami</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">url</span>: <span style="color:#ae81ff">https://charts.bitnami.com/bitnami</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">releases</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">wordpress-test</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">monitoring-test</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">chart</span>: <span style="color:#ae81ff">bitnami/wordpress</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">set</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mariadb.primary.containerSecurityContext.enabled</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mariadb.primary.podSecurityContext.enabled</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mariadb.auth.rootPassword</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#ae81ff">wordpress-test</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mariadb.primary.persistence.enabled</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mariadb.primary.persistence.size</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#ae81ff">20Gi</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">wordpressPassword</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#ae81ff">wordpress-test</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">persistence.enabled</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">containerSecurityContext.enabled</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">podSecurityContext.enabled</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#66d9ef">false</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helmfile apply -f wordpress-helmfile.yaml
</span></span></code></pre></div><h3 id="enable-user-namespace-monitoring">Enable user namespace monitoring</h3>
<p>By default the enbeddid prometheus only monitor the cluster components. To monitor applications in user namespace you need to enable the user namespace monitoring.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc apply -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: ConfigMap
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: cluster-monitoring-config
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: openshift-monitoring
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">data:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  config.yaml: |
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    enableUserWorkload: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    alertmanagerMain:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      enableUserAlertmanagerConfig: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>This will create a separate prometheus stack for user namespace monitoring. List user namespace monitor status:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc get pods -n openshift-user-workload-monitoring
</span></span><span style="display:flex;"><span>NAME                                  READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>prometheus-operator-7c55995fb-zsjxk   2/2     Running   <span style="color:#ae81ff">0</span>          4m
</span></span><span style="display:flex;"><span>prometheus-user-workload-0            6/6     Running   <span style="color:#ae81ff">0</span>          4m
</span></span><span style="display:flex;"><span>prometheus-user-workload-1            6/6     Running   <span style="color:#ae81ff">0</span>          4m
</span></span><span style="display:flex;"><span>thanos-ruler-user-workload-0          3/3     Running   <span style="color:#ae81ff">0</span>          4m
</span></span><span style="display:flex;"><span>thanos-ruler-user-workload-1          3/3     Running   <span style="color:#ae81ff">0</span>          4m
</span></span></code></pre></div><p>Now we can create alert routing to send emails about the alerts.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc apply -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: monitoring.coreos.com/v1beta1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: AlertmanagerConfig
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: pod-num-alert
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: monitoring-test
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  receivers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - name: default
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - name: email_alert
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      emailConfigs:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - to: devopstales@
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        from: prometheus@mydomain.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        smarthost: mail.mydomain.intra:25
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        requireTLS: false
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        sendResolved: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  route:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    receiver: email_alert
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    groupInterval: 5m
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    groupWait: 30s
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    repeatInterval: 10m
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    groupBy:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - namespace
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    routes:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - match:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          severity: wordpress
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        receiver: email_alert
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>Create test alert:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc apply -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: monitoring.coreos.com/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: PrometheusRule
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: pod-num-alert
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: monitoring-test
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  groups:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - name: monitoring-test
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    rules:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - alert: RunningPodNumAlert
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      expr: sum(kube_pod_status_ready{namespace=&#34;monitoring-test&#34;}) != 3
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      for: 5m
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        namespace: monitoring-test
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        severity: wordpress
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">---
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: monitoring.coreos.com/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: PrometheusRule
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: pod-memory-alert
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: monitoring-test
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  groups:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - name: monitoring-test
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    rules:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - alert: RunningPodMemoryAlert
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      expr: ((( sum(container_memory_working_set_bytes{image!=&#34;&#34;,container!=&#34;POD&#34;, namespace=&#34;monitoring-test&#34;}) by (namespace,container,pod)))) / 1000000 &gt; 90
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      for: 5m
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        namespace: monitoring-test
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        severity: wordpress
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to Migrate Persistent Volumes on Kubernetes Easily?]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-migrate-pv/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-cephfs-storage-with-csi-driver/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes CephFS volume with CSI driver" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph-storage-with-csi-driver/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD volume with CSI driver" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph-csi-extand/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes volume expansion with Ceph RBD CSI driver" />
                <link href="https://devopstales.github.io/linux/ceph_backup_benji/?utm_source=atom_feed" rel="related" type="text/html" title="CEPH backup with Benji" />
                <link href="https://devopstales.github.io/kubernetes/who-mapping-rbd-device/?utm_source=atom_feed" rel="related" type="text/html" title="Ceph: who is mapping a RBD device" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-migrate-pv/</id>
            
            
            <published>2023-05-31T00:00:00+00:00</published>
            <updated>2023-05-31T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can you use migrate your data from one PV to another.</p>
<p>Have you faced a situation where you need to migrate your data from one PV to another. For example your your DB grew over time, and you need more space for it, but you cannot resize the PVC because it doesn&rsquo;t support volume expansion. Or you need to migrate data between StotageClasses or Clusters. I have, and find a tool called <a href="https://github.com/utkuozdemir/pv-migrate">pv-migrate</a> that supports this migrations.</p>
<p>For the example I will migrate data between StotageClasses. I have two StotageClasses <code>cis-rbd-sc</code> and <code>csi-cephfs-sc</code> and I will migrate data from <code>cis-rbd-sc</code> to <code>cis-cephfs-sc</code>.</p>
<h3 id="installing-pv-migrate">Installing PV-Migrate</h3>
<p>First we need to install the <code>pv-migrate</code> tool. The easiest way is installing as a kubectl plugin by <code>krew</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl krew install pv-migrate
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl pv-migrate --help
</span></span></code></pre></div><p><code>pv-migrate</code> can migrate your data by tree different methods:</p>
<ul>
<li><em>lbsvc</em>: Load Balancer Service, this will run rsync+ssh over a Kubernetes Service type LoadBalancer. This is the method you want to use if you&rsquo;re migrating PVC from different Kubernetes clusters.</li>
<li><em>mnt2</em>: Mounts both PVCs in a single pod and runs a regular rsync. This is only usable if source and destination PVCs are in the same namespace.</li>
<li><em>svc</em>: Service, Runs rsync+ssh in a Kubernetes Service (ClusteRIP). Only applicable when the source and destination PVCs are in the same Kubernetes cluster.</li>
</ul>
<p>In my sase it will use the <code>mnt2</code> method but you didn&rsquo;t need to configure this because it automatically detect the best method.</p>
<h3 id="how-to-migrate-persistent-volumes">How to Migrate Persistent Volumes</h3>
<p>First you need to scale down your application that use the pvc:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl scale deployment test-app --replicas<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p>Then we need to create a backup of the <code>pv</code> and <code>pvc</code> objects:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get pv test-app-pv -o yaml &gt; test-app-pv.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># then find the pv belong to it and backup that too:</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kg pv pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6 -o yaml &gt; pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6.yaml
</span></span></code></pre></div><p>Now we can edit the existing pvc to change the storage class:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cp test-app-pv.yaml test-app-pv_new.yaml
</span></span></code></pre></div><p>Remove the unnecessary parts and change the storage class.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano test-app-pv_new.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PersistentVolumeClaim</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">test-app-pv</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-app-pv_new</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">pv-test</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">accessModes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">ReadWriteOnce</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">2Gi</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">storageClassName</span>: <span style="color:#ae81ff">csi-cephfs-sc</span>
</span></span></code></pre></div><p>Apply the new <code>pvc</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f test-app-pv_new.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pvc test-app-pv test-app-pv_new
</span></span><span style="display:flex;"><span>NAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    AGE
</span></span><span style="display:flex;"><span>test-app-pv       Bound    pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6   2Gi        RWO            csi-rbd-sc      54m
</span></span><span style="display:flex;"><span>test-app-pv_new   Bound    pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39   2Gi        RWO            csi-cephfs-sc   34m
</span></span></code></pre></div><p>Now we can use the <code>pv-migrate</code> to copy the data:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl pv-migrate migrate <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ignore-mounted <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  test-app-pv test-app-pv_new
</span></span><span style="display:flex;"><span>🚀  Starting migration
</span></span><span style="display:flex;"><span>💡  PVC grafana-two is mounted to node minikube, ignoring...
</span></span><span style="display:flex;"><span>💡  PVC grafana is mounted to node minikube, ignoring...
</span></span><span style="display:flex;"><span>💭  Will attempt <span style="color:#ae81ff">3</span> strategies: mnt2,svc,lbsvc
</span></span><span style="display:flex;"><span>🚁  Attempting strategy: mnt2
</span></span><span style="display:flex;"><span>🔑  Generating SSH key pair
</span></span><span style="display:flex;"><span>🔑  Creating secret <span style="color:#66d9ef">for</span> the public key
</span></span><span style="display:flex;"><span>🚀  Creating sshd pod
</span></span><span style="display:flex;"><span>⏳  Waiting <span style="color:#66d9ef">for</span> the sshd pod to start running
</span></span><span style="display:flex;"><span>🚀  Sshd pod started
</span></span><span style="display:flex;"><span>🔑  Creating secret <span style="color:#66d9ef">for</span> the private key
</span></span><span style="display:flex;"><span>🔗  Connecting to the rsync server
</span></span><span style="display:flex;"><span>📂  Copying data... 100% |█████████████████████████████████████████████████████████████████████████| <span style="color:#f92672">()</span>
</span></span><span style="display:flex;"><span>🧹  Cleaning up
</span></span><span style="display:flex;"><span>✨  Cleanup successful
</span></span><span style="display:flex;"><span>✅  Migration succeeded
</span></span></code></pre></div><p>We will delete the <code>pvc</code>s so we need to change the reclaim policy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl patch pv pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6 -p <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;persistentVolumeReclaimPolicy&#34;:&#34;Retain&#34;}}&#39;</span>
</span></span><span style="display:flex;"><span>kubectl patch pv pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39 -p <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;persistentVolumeReclaimPolicy&#34;:&#34;Retain&#34;}}&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pv pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6 pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39
</span></span><span style="display:flex;"><span>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                    STORAGECLASS    REASON AGE
</span></span><span style="display:flex;"><span>pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6   2Gi        RWO            Retain           Bound       pv-test/test-app-pv       csi-rbd-sc            54m
</span></span><span style="display:flex;"><span>pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39   2Gi        RWO            Retain           Bound       pv-test/test-app-pv_new   csi-cephfs-sc         34m
</span></span></code></pre></div><p>Now we can delete the <code>pvc</code>s:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl delete -f test-app-pv.yaml
</span></span><span style="display:flex;"><span>kubectl delete -f test-app-pv_new.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pv pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6 pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39
</span></span><span style="display:flex;"><span>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS         CLAIM                 STORAGECLASS    REASON   AGE
</span></span><span style="display:flex;"><span>pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6   2Gi        RWO            Retain           Released       pv-test/test-app-pv   csi-rbd-sc            54m
</span></span><span style="display:flex;"><span>pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39   2Gi        RWO            Retain           Released       pv-test/test-app-pv_new   csi-cephfs-sc            34m
</span></span></code></pre></div><p>Now we need to patch path the <code>pv</code>s to reuse:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl patch pv pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6 -p <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;claimRef&#34;: null}}&#39;</span>
</span></span><span style="display:flex;"><span>kubectl patch pv pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39 -p <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;claimRef&#34;: null}}&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pv pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6 pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39
</span></span><span style="display:flex;"><span>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS      REASON   AGE
</span></span><span style="display:flex;"><span>pvc-4dce1b52-818e-4e3e-b968-c2fe4e9de7d6   2Gi        RWO            Retain           Available           csi-rbd-sc                 59d
</span></span><span style="display:flex;"><span>pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39   2Gi        RWO            Retain           Available           csi-cephfs-sc              39d
</span></span></code></pre></div><p>Create the new <code>test-app-pv</code> with bound to <code>pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano test-app-pv_mod.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PersistentVolumeClaim</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">test-app-pv</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-app-pv</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">pv-test</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">accessModes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">ReadWriteOnce</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">2Gi</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">storageClassName</span>: <span style="color:#ae81ff">csi-cephfs-sc</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumeMode</span>: <span style="color:#ae81ff">Filesystem</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumeName</span>: <span style="color:#ae81ff">pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f test-app-pv_mod.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pvc test-app-pv
</span></span><span style="display:flex;"><span>NAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    AGE
</span></span><span style="display:flex;"><span>test-app-pv       Bound    pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39   2Gi        RWO            csi-cephfs-sc   54m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pv pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39
</span></span><span style="display:flex;"><span>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                    STORAGECLASS    REASON AGE
</span></span><span style="display:flex;"><span>pvc-2aef0615-5e1e-4f66-a14d-cdda326bff39   2Gi        RWO            Retain           Bound       pv-test/test-app-pv   csi-cephfs-sc         34m
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes CephFS volume with CSI driver]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-cephfs-storage-with-csi-driver/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph-storage-with-csi-driver/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD volume with CSI driver" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph-csi-extand/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes volume expansion with Ceph RBD CSI driver" />
                <link href="https://devopstales.github.io/linux/ceph_backup_benji/?utm_source=atom_feed" rel="related" type="text/html" title="CEPH backup with Benji" />
                <link href="https://devopstales.github.io/kubernetes/who-mapping-rbd-device/?utm_source=atom_feed" rel="related" type="text/html" title="Ceph: who is mapping a RBD device" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD for dynamic provisioning" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-cephfs-storage-with-csi-driver/</id>
            
            
            <published>2023-05-30T00:00:00+00:00</published>
            <updated>2023-05-30T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can you use CephFS with CSI driver for persistent storage on Kubernetes.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>The Container Storage Interface (CSI) is a standard for exposing arbitrary block and file storage storage systems to Kubernetes. Using CSI third-party storage providers can write and deploy plugins exposing storage systems in Kubernetes. Before we begin lets ensure that we have the following requirements:</p>
<ul>
<li>Kubernetes cluster v1.14+</li>
<li>allow-privileged flag enabled for both kubelet and API server</li>
<li>Running Ceph cluster</li>
<li>Created CephFS</li>
</ul>
<p>First we need to create a namespace for the storage provider:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns ceph-csi-cephfs
</span></span><span style="display:flex;"><span>kubens ceph-csi-cephfs
</span></span></code></pre></div><p>Login to the CEPH cluster and get the configurations:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ceph config generate-minimal-conf &gt; ceph-minimal.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat ceph-minimal.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e"># minimal ceph.conf for e285a458-7c95-4187-8129-fbd6c370c537</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>global<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    fsid <span style="color:#f92672">=</span> e285a458-7c95-4187-8129-fbd6c370c537
</span></span><span style="display:flex;"><span>    mon_host <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>v2:192.168.10.11:3300/0,v1:192.168.10.11:6789/0<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>v2:192.168.10.12:3300/0,v1:192.168.10.12:6789/0<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>v2:192.168.10.13:3300/0,v1:192.168.10.13:6789/0<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ceph auth get-key client.admin
</span></span><span style="display:flex;"><span>QVFDWDNuVmtNV3NvSlJBQUFvazIxMCszZXFxNmF6SmpT5WJjaUE9PQ<span style="color:#f92672">==</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add ceph-csi https://ceph.github.io/csi-charts
</span></span><span style="display:flex;"><span>helm show values ceph-csi/ceph-csi-cephfs &gt; defaultValues.yaml
</span></span></code></pre></div><p>Crate helm values file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano values.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">csiConfig</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">clusterID</span>: <span style="color:#ae81ff">e285a458-7c95-4187-8129-fbd6c370c537</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">monitors</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">192.168.10.11</span>:<span style="color:#ae81ff">6789</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">192.168.10.12</span>:<span style="color:#ae81ff">6789</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">192.168.10.13</span>:<span style="color:#ae81ff">6789</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cephFS</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">subvolumeGroup</span>: <span style="color:#e6db74">&#34;csi&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">secret</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">csi-cephfs-secret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">adminID</span>: <span style="color:#ae81ff">admin</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">adminKey</span>: <span style="color:#ae81ff">QVFDWDNuVmtNV3NvSlJBQUFvazIxMCszZXFxNmF6SmpT5WJjaUE9PQ==</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">storageClass</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">k8s-cephfs</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">clusterID</span>: <span style="color:#ae81ff">e285a458-7c95-4187-8129-fbd6c370c537</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># (required) CephFS filesystem name into which the volume shall be created</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsName</span>: <span style="color:#ae81ff">k8s-etc-nvme</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">reclaimPolicy</span>: <span style="color:#ae81ff">Delete</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">allowVolumeExpansion</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumeNamePrefix</span>: <span style="color:#e6db74">&#34;poc-k8s-&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">provisionerSecret</span>: <span style="color:#ae81ff">csi-cephfs-secret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">controllerExpandSecret</span>: <span style="color:#ae81ff">csi-cephfs-secret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nodeStageSecret</span>: <span style="color:#ae81ff">csi-cephfs-secret</span>
</span></span></code></pre></div><p>Deploy helm chart:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm upgrade --install ceph-csi-cephfs ceph-csi/ceph-csi-cephfs --values ./values.yaml
</span></span></code></pre></div><h3 id="demo-time">Demo time</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano pvc.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PersistentVolumeClaim</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">csi-cephfs-pvc</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">accessModes</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">ReadWriteMany</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">1Gi</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">storageClassName</span>: <span style="color:#ae81ff">csi-cephfs-sc</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f pvc.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pvc
</span></span><span style="display:flex;"><span>NAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    AGE
</span></span><span style="display:flex;"><span>csi-cephfs-pvc   Bound    pvc-51526639-6fef-4abd-b453-c2b03c08781f   1Gi        RWX            csi-cephfs-sc   31m
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Automatic rolling of Pods due to configuration changes]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-rolling-upgrade/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-rolling-pods-config-changes/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Rolling Update Configuration" />
                <link href="https://devopstales.github.io/kubernetes/k8s-pod-locations/?utm_source=atom_feed" rel="related" type="text/html" title="Influencing Kubernetes Scheduler Decisions" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-rolling-upgrade/</id>
            
            
            <published>2023-05-29T00:00:00+00:00</published>
            <updated>2023-05-29T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can for pod upgrade at config changes in helm charts.</p>
<p>Alongside the deployment of containers, we often ship configuration via <code>ConfigMap</code> and/or <code>Secret</code> resources. A common challenge is the need to restart the <code>Pod</code> resources when there is a change in the associated configuration.</p>
<p>By default, if the <code>Pod</code> itself didn’t change, the <code>Deployment</code> or <code>StatefulSet</code> resource will not trigger a new rollout.</p>
<h3 id="roll-when-secret-or-configmap-resources-changes">Roll when Secret or ConfigMap resources changes</h3>
<p>So to rol the Pod we need to change something in the spec when the config is changing. But what? and how to realize the change of the <code>ConfigMap</code> and/or <code>Secret</code>? The solution is to store the checksum of the  <code>ConfigMap</code> and/or <code>Secret</code> in the annotation of the Deployment, so when the file is changing the checksum is changing too, and with this we gat a new version from the <code>Deployment</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span>[<span style="color:#ae81ff">...]</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">checksum/config</span>: {{ <span style="color:#ae81ff">include (print $.Template.BasePath &#34;/configmap.yaml&#34;) . | sha256sum }}</span>
</span></span><span style="display:flex;"><span>[<span style="color:#ae81ff">...]</span>
</span></span></code></pre></div><p>For resources defined as part of a <code>library</code> chart:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span>[<span style="color:#ae81ff">...]</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">checksum/config</span>: {{ <span style="color:#ae81ff">include (&#34;mylibchart.configmap&#34;) . | sha256sum }}</span>
</span></span><span style="display:flex;"><span>[<span style="color:#ae81ff">...]</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Rolling Update Configuration]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-rolling-pods-config-changes/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-pod-locations/?utm_source=atom_feed" rel="related" type="text/html" title="Influencing Kubernetes Scheduler Decisions" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-rolling-pods-config-changes/</id>
            
            
            <published>2023-05-25T00:00:00+00:00</published>
            <updated>2023-05-25T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can influence the Deployment controller to perform a rolling upgrade.</p>
<h3 id="deployment-controllers">Deployment controllers</h3>
<p>Deployment controllers are a type of Pod controller in Kubernetes. They provide fine-grained control over how its pods are configured, how updates are performed, how many pods should run, and when pods should be terminated. To understand how this controller do its job first we need to understand the Deployments.</p>
<h3 id="kubernetes-deployment-overview">Kubernetes Deployment Overview</h3>
<p>Kubernetes deployments are essentially just a wrapper around ReplicaSets. The ReplicaSet manages the number of running pods, and the Deployment implements features on top of that to allow rolling updates, health checks on pods, and easy roll-back of updates.</p>
<p>During normal operations, the Deployment will just manage a single ReplicaSet which ensures that desired number of pods are running:</p>
<p><img src="/img/include/deployment_overview01.webp" alt="Deployment Overview"  class="zoomable" /></p>
<p>Here are some example kubectl commands for commonly performed operations on a Deployment:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># List deployments:</span>
</span></span><span style="display:flex;"><span>kubectl get deploy
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Update a deployment with a manifest file:</span>
</span></span><span style="display:flex;"><span>kubectl apply -f test.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Scale a deployment “test” to 3 replicas:</span>
</span></span><span style="display:flex;"><span>kubectl scale deploy/test --replicas<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Watch update status for deployment “test”:</span>
</span></span><span style="display:flex;"><span>kubectl rollout status deploy/test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Pause deployment on “test”:</span>
</span></span><span style="display:flex;"><span>kubectl rollout pause deploy/test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Resume deployment on “test”:</span>
</span></span><span style="display:flex;"><span>kubectl rollout resume deploy/test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># View rollout history on “test”:</span>
</span></span><span style="display:flex;"><span>kubectl rollout history deploy/test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Undo most recent update on “test”:</span>
</span></span><span style="display:flex;"><span>kubectl rollout undo deploy/test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Rollback to specific revision on “test”:</span>
</span></span><span style="display:flex;"><span>kubectl rollout undo deploy/test --to-revision<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span></code></pre></div><h3 id="kubernetes-rolling-updates">Kubernetes Rolling Updates</h3>
<p>One of the primary benefits of using a Deployment to control your pods is the ability to perform rolling updates. Rolling updates allow you to update the configuration of your pods gradually, for this Deployment offers multiple options to control this process.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">3</span>  
</span></span><span style="display:flex;"><span><span style="color:#f92672">strategy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">RollingUpdate</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rollingUpdate</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">maxSurge</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">maxUnavailable</span>: <span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p>For a working rolling update the first precondition in a Deployment is the <code>replicas</code>. To seamlessly upgrade between versions you need multiple running pods.</p>
<p>The nex important configuration is the update strategy in <code>strategy.type</code>. it can be <em>RollingUpdate</em> (New pods are added gradually, and old pods are terminated gradually) or <em>Recreate</em> (All old pods are terminated before any new pods are added).</p>
<p>When using the RollingUpdate strategy, there are two more options that let you fine-tune the update process:</p>
<ul>
<li><em>maxSurge</em>: The number of pods that can be created above the desired amount of pods during an update</li>
<li><em>maxUnavailable</em>: The number of pods that can be unavailable during the update process</li>
</ul>
<p>Both maxSurge and maxUnavailable can be specified as either an integer (e.g. 2) or a percentage (e.g. 50%), and they cannot both be zero. When specified as an integer, it represents the actual number of pods; when specifying a percentage, that percentage of the desired number of pods is used, rounded down. For example, If you were using the default values of 25% for both maxSurge and maxUnavailable, and applied an update to a Deployment with 8 pods, then maxSurge would be 2 pods, and maxUnavailable would also be 2 pods.</p>
<p>This strategy says that we want to add pods one at a time, and that there must always be 3 pods ready in the deployment. The following gif will illustrate what happens in every step of the rolling update.</p>
<p><img src="/img/include/deployment_overview02.webp" alt="Rolling Upgrades"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Influencing Kubernetes Scheduler Decisions]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-pod-locations/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://devopstales.github.io/kubernetes/k8s-pod-locations/</id>
            
            
            <published>2023-04-10T00:00:00+00:00</published>
            <updated>2023-04-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can influence the Kubernetes Scheduler where to schedule a pod.</p>
<h3 id="kubernetes-scheduler">Kubernetes Scheduler</h3>
<p>When the Kubernetes Scheduler schedule a pod it examines each node for whether or not it can host the Pod. The scheduler uses the following equation to calculate the available memory on a given node: <code>Usable memory = available memory - reserved memory</code></p>
<p>The reserved memory refers to:</p>
<ul>
<li>Memory used by Kubernetes daemons like kubelet, containerd (or another container runtime).</li>
<li>Memory is used by the node’s operating system. For example, kernel daemons.</li>
</ul>
<p>If you are following the best practices you are declaring the amount of CPU and memory your Pods require through requests and limits.</p>
<h3 id="influencing-the-scheduling-process">Influencing the Scheduling Process</h3>
<p>You have multiple ways to influence the scheduler. In the simplest way is to force a Pod to run on one - and only one - node by specifying its name in the <code>.spec.nodeName</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">nodeName</span>: <span style="color:#ae81ff">app-prod01</span>
</span></span></code></pre></div><h3 id="taints-and-tolerations">Taints and Tolerations</h3>
<p>Suppose we didn’t want any pods to run on a specific node. You might need to do this for a variety of reasons. Whatever the particular reason, we need a way to ensure our pods are not placed on a certain node. That’s where a taint comes in.</p>
<p>When a node is <code>tainted</code>, no Pod can be scheduled to it unless the Pod <code>tolerates</code> the taint. You can taint a node with a command like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl taint nodes <span style="color:#f92672">[</span>node name<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>key<span style="color:#f92672">=</span>value<span style="color:#f92672">]</span>:NoSchedule
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl taint nodes worker-01 locked<span style="color:#f92672">=</span>true:NoSchedule
</span></span></code></pre></div><p>The definition for a Pod that has the necessary toleration to get scheduled on the tainted node look like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mypod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mycontainer</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">tolerations</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#f92672">key</span>: <span style="color:#e6db74">&#34;locked&#34;</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">operator</span>: <span style="color:#e6db74">&#34;Equal&#34;</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">effect</span>: <span style="color:#e6db74">&#34;NoSchedule&#34;</span>
</span></span></code></pre></div><h3 id="node-affinity">Node Affinity</h3>
<p>Node Affinity gives you more flexible way to choose a node by allowing you to define hard and soft node-requirements. The hard requirements must be matched on the node to be selected, but the soft requirements allows you to add more weight to nodes with specific labels. The mos basic example for this scenario to choose a node with ssd for your database instance:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">db</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">affinity</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">nodeAffinity</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">nodeSelectorTerms</span>:
</span></span><span style="display:flex;"><span>       - <span style="color:#f92672">matchExpressions</span>:
</span></span><span style="display:flex;"><span>         - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">disk-type</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">operator</span>: <span style="color:#ae81ff">In</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">values</span>:
</span></span><span style="display:flex;"><span>           - <span style="color:#ae81ff">ssd</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">preferredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style="display:flex;"><span>     - <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">preference</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">matchExpressions</span>:
</span></span><span style="display:flex;"><span>         - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">zone</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">operator</span>: <span style="color:#ae81ff">In</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">values</span>:
</span></span><span style="display:flex;"><span>           - <span style="color:#ae81ff">zone1</span>
</span></span><span style="display:flex;"><span>           - <span style="color:#ae81ff">zone2</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">db</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">image</span>: <span style="color:#ae81ff">mysql</span>
</span></span></code></pre></div><p>The <code>requiredDuringSchedulingIgnoredDuringExecution</code> is the hard requirement and the <code>preferredDuringSchedulingIgnoredDuringExecution</code> is the soft requirement. You can add Affinity not just for a nod but the pods themselves.</p>
<h3 id="pod-affinity">Pod Affinity</h3>
<p>You can yous hard (<code>requiredDuringSchedulingIgnoredDuringExecution</code>) and soft (<code>preferredDuringSchedulingIgnoredDuringExecution</code>) requirements for the pods too:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">name</span>: <span style="color:#ae81ff">middleware</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span> <span style="color:#f92672">affinity</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">podAffinity</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style="display:flex;"><span>     - <span style="color:#f92672">labelSelector</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">matchExpressions</span>:
</span></span><span style="display:flex;"><span>         - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">role</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">operator</span>: <span style="color:#ae81ff">In</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">values</span>:
</span></span><span style="display:flex;"><span>           - <span style="color:#ae81ff">frontend</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">topologyKey</span>: <span style="color:#ae81ff">kubernetes.io/hostname</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">podAntiAffinity</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">preferredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style="display:flex;"><span>     - <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>       <span style="color:#f92672">podAffinityTerm</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">labelSelector</span>:
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">matchExpressions</span>:
</span></span><span style="display:flex;"><span>           - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">role</span>
</span></span><span style="display:flex;"><span>             <span style="color:#f92672">operator</span>: <span style="color:#ae81ff">In</span>
</span></span><span style="display:flex;"><span>             <span style="color:#f92672">values</span>:
</span></span><span style="display:flex;"><span>             - <span style="color:#ae81ff">auth</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">topologyKey</span>: <span style="color:#ae81ff">kubernetes.io/hostname</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span> - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">middleware</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">image</span>: <span style="color:#ae81ff">redis</span>
</span></span></code></pre></div><p>You may have noticed that both the hard and soft requirements have the IgnoredDuringExecution suffix. It means that after the scheduling decision has been made, the scheduler will not attempt to change already-placed Pods even if the conditions changed.</p>
<p>For example if your application has multiple replicas and you did&rsquo;t want to schedule two pod from this app to the same host:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">extensions/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:                                            
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx                                   </span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">affinity</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">podAntiAffinity</span>:                                 
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">topologyKey</span>: <span style="color:#ae81ff">kubernetes.io/hostname</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">labelSelector</span>:                               
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">matchLabels</span>:                               
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx        </span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">container</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:latest</span>
</span></span></code></pre></div><h3 id="pod-topology-spread-constraints">Pod Topology Spread Constraints</h3>
<p>You can use topology spread constraints to control how Pods are spread across your cluster among failure-domains such as regions, zones, nodes.</p>
<p>Suppose you have a 4-node cluster with the following labels:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>NAME    STATUS   ROLES    AGE     VERSION   LABELS
</span></span><span style="display:flex;"><span>node1   Ready    &lt;none&gt;   4m26s   v1.16.0   node<span style="color:#f92672">=</span>node1,zone<span style="color:#f92672">=</span>zoneA
</span></span><span style="display:flex;"><span>node2   Ready    &lt;none&gt;   3m58s   v1.16.0   node<span style="color:#f92672">=</span>node2,zone<span style="color:#f92672">=</span>zoneA
</span></span><span style="display:flex;"><span>node3   Ready    &lt;none&gt;   3m17s   v1.16.0   node<span style="color:#f92672">=</span>node3,zone<span style="color:#f92672">=</span>zoneB
</span></span><span style="display:flex;"><span>node4   Ready    &lt;none&gt;   2m43s   v1.16.0   node<span style="color:#f92672">=</span>node4,zone<span style="color:#f92672">=</span>zoneB
</span></span></code></pre></div><p>You can define one or multiple <code>topologySpreadConstraint</code> to instruct the kube-scheduler how to place each incoming Pod in relation to the existing Pods across your cluster. If we want an incoming Pod to be evenly spread with existing Pods across zones, the spec can be something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">topologySpreadConstraints</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">maxSkew</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">topologyKey</span>: <span style="color:#ae81ff">zone</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">whenUnsatisfiable</span>: <span style="color:#ae81ff">ScheduleAnyway</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">labelSelector</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:latest</span>
</span></span></code></pre></div><p>Besides the usual deployment specification, we have additionally defined <code>TopologySpreadConstraints</code> as such:</p>
<ul>
<li><strong>maxSkew</strong>: 1 — distribute pods in an absolute even manner</li>
<li><strong>topologyKey</strong>: <code>kubernetes.io/hostname</code> —use the hostname as topology domain</li>
<li><strong>whenUnsatisfiable</strong>: ScheduleAnyway — always schedule pods even if it can’t satisfy even distribution of pods</li>
<li><strong>labelSelector</strong> —only act on Pods that match this selector</li>
</ul>
<p>You can use 2 <code>TopologySpreadConstraints</code> to control the Pods spreading on both zone and node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">topologySpreadConstraints</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">maxSkew</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">topologyKey</span>: <span style="color:#ae81ff">zone</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">whenUnsatisfiable</span>: <span style="color:#ae81ff">ScheduleAnyway</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">labelSelector</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">maxSkew</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">topologyKey</span>: <span style="color:#ae81ff">node</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">whenUnsatisfiable</span>: <span style="color:#ae81ff">ScheduleAnyway</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">labelSelector</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:latest</span>
</span></span></code></pre></div><p>Ofcourse, you can use the default <code>kubernetes.io/hostname</code> label for <code>topologyKey</code>.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[kubedash 1.0]]></title>
            <link href="https://devopstales.github.io/kubernetes/kubedash-1.0/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.5/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.5: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.4/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.4: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.3/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.3: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.2/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.2: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.1/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!" />
            
                <id>https://devopstales.github.io/kubernetes/kubedash-1.0/</id>
            
            
            <published>2023-03-20T00:00:00+00:00</published>
            <updated>2023-03-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Today I am happy to announce the release of KubeDash 1.0. This blog post focuses on the functionality provided by the KubeDash 1.0.</p>
<h2 id="what-is-kubedash">What is KubeDash?</h2>
<p>KubeDash is a general purpose, web-based UI for Kubernetes clusters. It allows users to observe applications running in the cluster and troubleshoot them, as well as manage the cluster itself. It supports <a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/#openid-connect-tokens">OpenID Connect Tokens</a> as a way to identify users who access the cluster</p>
<p><img src="/img/include/KubeDash_1.0_pic_01.png" alt="KubeDash"  class="zoomable" /></p>
<p>The Default user is admin / admin</p>
<p><img src="/img/include/KubeDash_1.0_pic_03.png" alt="KubeDash"  class="zoomable" /></p>
<p><img src="/img/include/KubeDash_1.0_pic_05.png" alt="KubeDash"  class="zoomable" /></p>
<p><img src="/img/include/KubeDash_1.0_pic_04.png" alt="KubeDash"  class="zoomable" /></p>
<p>You can watch the installed helm charts:</p>
<p><img src="/img/include/KubeDash_1.0_pic_02.png" alt="KubeDash"  class="zoomable" /></p>
<h2 id="usage">Usage</h2>
<p>To ease deployment I created a helm chart for trivy-operator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add devopstales https://devopstales.github.io/helm-charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>helm upgrade --install kubedash devopstales/kubedash
</span></span></code></pre></div><p>Create a value file for deploy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">TimeZone</span>: <span style="color:#e6db74">&#34;CET&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">logLevel</span>: <span style="color:#e6db74">&#34;INFO&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">flaskConfig</span>: <span style="color:#e6db74">&#34;production&#34;</span> <span style="color:#75715e">#or development</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceAccount</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;kubedash-admin&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">image</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repository</span>: <span style="color:#ae81ff">devopstales/kubedash</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tag</span>: <span style="color:#ae81ff">0.1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">pullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">podSecurityContext</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">runAsNonRoot</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">runAsUser</span>: <span style="color:#ae81ff">10001</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">containerSecurityContext</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">allowPrivilegeEscalation</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">capabilities</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">drop</span>: [<span style="color:#e6db74">&#34;all&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">url</span>: <span style="color:#e6db74">&#34;kubedash.mydomain.intra&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nginx.ingress.kubernetes.io/proxy-body-size</span>: <span style="color:#e6db74">&#34;10m&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes.io/ingress.class</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tlsSecret</span>: <span style="color:#e6db74">&#34;mycert-tls&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">certManager</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">clusterIssuer</span>: <span style="color:#e6db74">&#34;letsencrypt&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">whitelist</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ips</span>: []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">route</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span></code></pre></div><p>The following tables lists configurable parameters of the kubedash chart and their default values.</p>
<table>
  <thead>
      <tr>
          <th>Key</th>
          <th>Type</th>
          <th>Default</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>TimeZone</td>
          <td>string</td>
          <td><code>&quot;CET&quot;</code></td>
          <td>Time Zone in container</td>
      </tr>
      <tr>
          <td>affinity</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>Set the affinity for the pod.</td>
      </tr>
      <tr>
          <td>containerSecurityContext</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>list of the container&rsquo;s SecurityContexts</td>
      </tr>
      <tr>
          <td>flaskConfig</td>
          <td>string</td>
          <td><code>&quot;production&quot;</code></td>
          <td>flask environment: production or development</td>
      </tr>
      <tr>
          <td>image.pullPolicy</td>
          <td>string</td>
          <td><code>&quot;Always&quot;</code></td>
          <td>The docker image pull policy</td>
      </tr>
      <tr>
          <td>image.repository</td>
          <td>string</td>
          <td><code>&quot;devopstales/kubedash&quot;</code></td>
          <td>The docker image repository to use</td>
      </tr>
      <tr>
          <td>image.tag</td>
          <td>string</td>
          <td><code>&quot;0.1-devel&quot;</code></td>
          <td>The docker image tag to use</td>
      </tr>
      <tr>
          <td>ingress.annotations</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>Extra annotation to the Ingress object</td>
      </tr>
      <tr>
          <td>ingress.enabled</td>
          <td>bool</td>
          <td><code>true</code></td>
          <td>Enable Ingress object creation</td>
      </tr>
      <tr>
          <td>ingress.tls.certManager.clusterIssuer</td>
          <td>string</td>
          <td><code>&quot;letsencrypt&quot;</code></td>
          <td>Name of the certManager cluster issuer to use</td>
      </tr>
      <tr>
          <td>ingress.tls.certManager.enabled</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>Enable certManager</td>
      </tr>
      <tr>
          <td>ingress.tls.enabled</td>
          <td>bool</td>
          <td><code>true</code></td>
          <td>Enable tls on Ingress object</td>
      </tr>
      <tr>
          <td>ingress.tls.tlsSecret</td>
          <td>string</td>
          <td><code>&quot;&quot;</code></td>
          <td>Name of the secret storing tls cert</td>
      </tr>
      <tr>
          <td>ingress.url</td>
          <td>string</td>
          <td><code>&quot;kubedash.mydomain.intra&quot;</code></td>
          <td>URL of the Ingress object</td>
      </tr>
      <tr>
          <td>ingress.whitelist.enabled</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>Enable ip blocking on ingress</td>
      </tr>
      <tr>
          <td>ingress.whitelist.ips</td>
          <td>list</td>
          <td><code>[]</code></td>
          <td>List of ips to allow communication</td>
      </tr>
      <tr>
          <td>logLevel</td>
          <td>string</td>
          <td><code>&quot;INFO&quot;</code></td>
          <td>Log level</td>
      </tr>
      <tr>
          <td>nodeSelector</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>Set nodeSelector for the pod</td>
      </tr>
      <tr>
          <td>persistence.accessMode</td>
          <td>string</td>
          <td><code>&quot;ReadWriteOnce&quot;</code></td>
          <td>Volumes mode</td>
      </tr>
      <tr>
          <td>persistence.annotations</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>Volumes annotations</td>
      </tr>
      <tr>
          <td>persistence.enabled</td>
          <td>bool</td>
          <td><code>true</code></td>
          <td>Volumes for the pod</td>
      </tr>
      <tr>
          <td>persistence.size</td>
          <td>string</td>
          <td><code>&quot;1Gi&quot;</code></td>
          <td>Volumes size</td>
      </tr>
      <tr>
          <td>podSecurityContext</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>list of the pos&rsquo;s SecurityContexts</td>
      </tr>
      <tr>
          <td>route.annotations</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>Extra annotation to the OpenShift Route object</td>
      </tr>
      <tr>
          <td>route.enabled</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>Enable OpenShift Route object creation</td>
      </tr>
      <tr>
          <td>route.url</td>
          <td>string</td>
          <td><code>&quot;kubedash.mydomain.intra&quot;</code></td>
          <td>URL of the OpenShift Route object</td>
      </tr>
      <tr>
          <td>serviceAccount.create</td>
          <td>bool</td>
          <td><code>true</code></td>
          <td>Enable automatic serviceAccount creation</td>
      </tr>
      <tr>
          <td>serviceAccount.name</td>
          <td>string</td>
          <td><code>&quot;kubedash-admin&quot;</code></td>
          <td>Configure the name of the serviceAccount</td>
      </tr>
      <tr>
          <td>tolerations</td>
          <td>list</td>
          <td><code>[]</code></td>
          <td>Set tolerations for the pod</td>
      </tr>
  </tbody>
</table>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-operators" term="k8s-operators" label="k8s-operators" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="kubedash" term="kubedash" label="kubedash" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[OKD OpenShift 4: Service Serving Certificate]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-service-serving-certificate/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/devops/openshift4-buildconfig/?utm_source=atom_feed" rel="related" type="text/html" title="Understand OKD OpenShift 4 Buildconfig Configurations" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-buildconfig/?utm_source=atom_feed" rel="related" type="text/html" title="Understand OKD OpenShift 4 Buildconfig Configurations" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-registry/?utm_source=atom_feed" rel="related" type="text/html" title="Configuringure OKD OpenShift 4 registry for bare metal" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-tekton/?utm_source=atom_feed" rel="related" type="text/html" title="Deploying Tekton on OpenShift 4" />
                <link href="https://devopstales.github.io/kubernetes/openshift-log4shell/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-service-serving-certificate/</id>
            
            
            <published>2023-02-25T00:00:00+00:00</published>
            <updated>2023-02-25T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you can use Service Serving Certificate on OpenShift4.</p>
<h3 id="what-is-service-serving-certificate">What is Service Serving Certificate?</h3>
<p>Service serving certificates are intended to support complex middleware applications that require encryption. Openshift automaticle generate a <code>x509.SHA256WithRSA</code> signature CA certificate stored in <code>service-ca</code> secret. These certificates are issued as TLS web server certificates. The service CA certificate, which issues the service certificates, is valid for 26 months and is automatically rotated when there is less than 13 months validity left. The generated certificate is only valid for the internal service DNS name <code>&lt;service.name&gt;.&lt;service.namespace&gt;.svc</code>, and is only valid for internal communications.</p>
<h3 id="openshift-service-ca-operator">OpenShift Service CA Operator</h3>
<p>The openshift-service-ca-operator is an OpenShift Cluster Operator that runs in the cluster by default:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$  oc get co service-ca
</span></span><span style="display:flex;"><span>NAME         VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE
</span></span><span style="display:flex;"><span>service-ca   4.4.12    True        False         False      4d4h
</span></span></code></pre></div><p>The Service CA Operator runs the operator in the openshift-service-ca-operator namespace:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ oc get pod
</span></span><span style="display:flex;"><span>NAME                                   READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>service-ca-operator-5f596775f8-gwlpj   1/1     Running   <span style="color:#ae81ff">1</span>          2d7h
</span></span></code></pre></div><p>The OpenShift Service CA Operator runs the following OpenShift controllers:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ oc get pod -n openshift-service-ca
</span></span><span style="display:flex;"><span>NAME                                            READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>apiservice-cabundle-injector-64cfdd7645-h4dqf   1/1     Running   <span style="color:#ae81ff">3</span>          2d7h
</span></span><span style="display:flex;"><span>configmap-cabundle-injector-67ffc677d5-prn7b    1/1     Running   <span style="color:#ae81ff">3</span>          2d7h
</span></span><span style="display:flex;"><span>service-serving-cert-signer-b5665b6f5-lx7bl     1/1     Running   <span style="color:#ae81ff">3</span>          2d7h
</span></span></code></pre></div><p>For OpenShift 4.x the service ca certificates are managed by the service CA operator.</p>
<p>The key and certificate are in a secret in the namespace openshift-service-ca as signing-key secret:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ oc get secrets -n openshift-service-ca signing-key -o <span style="color:#e6db74">&#34;jsonpath={.data[&#39;tls\.crt&#39;]}&#34;</span> |  base64 -d | openssl x509 -text
</span></span><span style="display:flex;"><span>Certificate:
</span></span><span style="display:flex;"><span>    Data:
</span></span><span style="display:flex;"><span>        Version: <span style="color:#ae81ff">3</span> <span style="color:#f92672">(</span>0x2<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        Serial Number: <span style="color:#ae81ff">1181511372096086528</span> <span style="color:#f92672">(</span>0x106592553fdf2200<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        Signature Algorithm: sha256WithRSAEncryption
</span></span><span style="display:flex;"><span>        Issuer: CN <span style="color:#f92672">=</span> openshift-service-serving-signer@1596638040
</span></span><span style="display:flex;"><span>        Validity
</span></span><span style="display:flex;"><span>            Not Before: Aug  <span style="color:#ae81ff">5</span> 14:34:00 <span style="color:#ae81ff">2020</span> GMT
</span></span><span style="display:flex;"><span>            Not After : Oct  <span style="color:#ae81ff">4</span> 14:34:01 <span style="color:#ae81ff">2022</span> GMT
</span></span><span style="display:flex;"><span>        Subject: CN <span style="color:#f92672">=</span> openshift-service-serving-signer@1596638040
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><h3 id="how-to-use-service-serving-certificate">How to use Service Serving Certificate?</h3>
<p>To activate Service Serving Certificate you need to annotate the service with <code>service.beta.openshift.io/serving-cert-secret-name</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ oc annotate service service-serving-cert service.beta.openshift.io/serving-cert-secret-name<span style="color:#f92672">=</span>service-serving-cert
</span></span></code></pre></div><p>Example Service:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">service-serving-cert</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">service.alpha.openshift.io/serving-cert-secret-name</span>: <span style="color:#ae81ff">service-serving-cert</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">service-serving-cert</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">port</span>: <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">8443</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">service-serving-cert</span>
</span></span></code></pre></div><p>Check certificate:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ oc get secret service-serving-cert -o json | jq -r <span style="color:#e6db74">&#39;.data.&#34;tls.crt&#34;&#39;</span> | base64 --decode &gt; service-serving-cert.pem
</span></span><span style="display:flex;"><span>$ openssl crl2pkcs7 -nocrl -certfile service-serving-cert.pem | openssl pkcs7 -print_certs  -noout
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>subject<span style="color:#f92672">=</span>/CN<span style="color:#f92672">=</span>service-serving-cert.rbo.svc
</span></span><span style="display:flex;"><span>issuer<span style="color:#f92672">=</span>/CN<span style="color:#f92672">=</span>openshift-service-serving-signer@1545507973
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>subject<span style="color:#f92672">=</span>/CN<span style="color:#f92672">=</span>openshift-service-serving-signer@1545507973
</span></span><span style="display:flex;"><span>issuer<span style="color:#f92672">=</span>/CN<span style="color:#f92672">=</span>openshift-service-serving-signer@1545507973
</span></span></code></pre></div><p>Now the communication between the pods (truth a service as a proxy) is encrypted by a <strong>self signed certificate</strong> managed by Openshift. The applications wont see the certificate as valid because it is self signed. So we need to add the root certificate (CA) as trusted in the app.
To do this you can generate and mount as configmap.</p>
<h3 id="add-the-service-ca-bundle-to-a-config-map">Add the service CA bundle to a config map</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ oc create -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: ConfigMap
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: service-trustbundle-ca
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  annotations:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    service.beta.openshift.io/inject-cabundle: &#34;true&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">data: {}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ oc get configmap/service-trustbundle-ca -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.data.service-ca\.crt}&#34;</span>  | openssl x509 -noout -subject -issuer -dates
</span></span><span style="display:flex;"><span>subject<span style="color:#f92672">=</span> /CN<span style="color:#f92672">=</span>openshift-service-serving-signer@1593524307
</span></span><span style="display:flex;"><span>issuer<span style="color:#f92672">=</span> /CN<span style="color:#f92672">=</span>openshift-service-serving-signer@1593524307
</span></span><span style="display:flex;"><span>notBefore<span style="color:#f92672">=</span>Jun <span style="color:#ae81ff">30</span> 13:38:26 <span style="color:#ae81ff">2020</span> GMT
</span></span><span style="display:flex;"><span>notAfter<span style="color:#f92672">=</span>Aug <span style="color:#ae81ff">29</span> 13:38:27 <span style="color:#ae81ff">2022</span> GMT
</span></span></code></pre></div><h3 id="mount-the-configmap-in-your-client-container">Mount the configMap in your client container</h3>
<p>You need to map the configMap in your client container which is service-A so that service-A gets access to client certificate.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;my-service-a&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">service-a</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">service-a</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">client-certs-config</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">configMap</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;service-trustbundle-ca&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">service-a-pod</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">my-image-repo/my-image-name:my-image-tag</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/etc/servicea/client-certs</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">client-certs-config</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">readOnly</span>: <span style="color:#66d9ef">true</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Understand OKD OpenShift 4 Buildconfig Configurations]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-buildconfig/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/devops/openshift4-buildconfig/?utm_source=atom_feed" rel="related" type="text/html" title="Understand OKD OpenShift 4 Buildconfig Configurations" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-registry/?utm_source=atom_feed" rel="related" type="text/html" title="Configuringure OKD OpenShift 4 registry for bare metal" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-tekton/?utm_source=atom_feed" rel="related" type="text/html" title="Deploying Tekton on OpenShift 4" />
                <link href="https://devopstales.github.io/kubernetes/openshift-log4shell/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ceph-rbd-csi/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 Ceph Persisten Storage" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-buildconfig/</id>
            
            
            <published>2023-01-25T00:00:00+00:00</published>
            <updated>2023-01-25T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you can install rad hat openshift pipelines (Tekton) on OpenShift4.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<h3 id="what-is-buildconfig">What is Buildconfig?</h3>
<p>Openshift has introduced a new resource called <code>BuildConfig</code>, to support Build Config Openshift developed a new technology called Source-to-Image (S2I) to build pods. S2I provides Openshift capabilities equivalent to Jenkins.</p>
<h3 id="understand-buildconfig-definition">Understand Buildconfig definition</h3>
<p>In a Buildconfig definition, there a list of directives to be fill. A sample Buildconfig definition looks like below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">build.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">BuildConfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">maven-webapp-build</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">runPolicy</span>: <span style="color:#ae81ff">&lt;... list the run policy ...&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">triggers</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">&lt;... list of triggers ...&gt; </span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">&lt;... input parameters or source ...&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">strategy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">&lt;... build strategy to use ...&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">output</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">&lt;... repository details ...&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">postCommit</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">&lt;... optinal build hooks ...&gt;</span>
</span></span></code></pre></div><p>Under the <code>spec</code> section source, <code>strategy</code> and <code>output</code> must be filled in order to run the build config.</p>
<ul>
<li><code>triggers</code> - Webhooks like GitHub/GitLab webhooks can be used to trigger this build.</li>
<li><code>source</code> - Here you can define the source code repository.</li>
<li><code>strategy</code> - This can be <code>Docker Build</code>, <code>Source-to-Image</code> or <code>Custom Build</code></li>
<li><code>output</code> - This directive is used to set an image output repository. This can be either Openshift build in a repository, on-premise private registry or docker hub.</li>
</ul>
<h3 id="source-to-image-s2i-build">Source-to-Image (S2I) Build</h3>
<p>Red Hat introduced Source-to-Image technology in order to reduce workload from developers and allow them to focus on the code.  Openshift provides a list of pre-built language images.  Those images are built with S2I binary, all the essential libraries, and tools needed for the development environment.</p>
<h3 id="openshift-imagestream-configuration-example">Openshift ImageStream Configuration Example</h3>
<p>First we ned to create an <code>ImageStream</code> to store the image. This is a folder in OKD&rsquo;s local dcker registry.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano ImageStream.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">image.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ImageStream</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">maven-webapp</span>
</span></span></code></pre></div><h3 id="openshift-buildconfig-configuration-example---1">Openshift BuildConfig Configuration Example - 1</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano BuildConfig.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">build.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">BuildConfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">maven-webapp-build</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Dockerfile</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">dockerfile</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      FROM docker.io/tomcat
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      RUN wget https://tomcat.apache.org/tomcat-7.0-doc/appdev/sample/sample.war -O /usr/local/tomcat/webapps/maven-webapp.war
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      CMD [&#34;catalina.sh&#34;, &#34;run&#34;]</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">strategy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Docker</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">output</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">to</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ImageStreamTag</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#39;maven-webapp:latest&#39;</span>
</span></span></code></pre></div><p>I this <code>BuildConfig</code> I created a Docker build this is the name of the <code>strategy</code> too. For Docker build the <code>source</code> is a Dockerfile. As you can see the content of the Dockerfile is directly in the object. In the end the <code>output</code> is an <code>ImageStream</code>.</p>
<p><img src="/img/include/openshift4-buildconfig01.webp" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/openshift4-buildconfig02.webp" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/openshift4-buildconfig03.webp" alt="Example image"  class="zoomable" /></p>
<h3 id="openshift-buildconfig-configuration-example---2">Openshift BuildConfig Configuration Example - 2</h3>
<p>In this example, I will explain how to use <code>Docker Build Strategy</code> and <code>Git repositories</code>. In this, I hosted all resources on the Github repository.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano BuildConfig2.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">build.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">BuildConfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">maven-webapp-build2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Git</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">git</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">uri</span>: <span style="color:#e6db74">&#39;https://github.com/devopstales/maven-web-project.git&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">ref</span>: <span style="color:#ae81ff">main</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">contextDir</span>: <span style="color:#ae81ff">sample</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">strategy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Docker</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#With this you can set a path to the docker file</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#dockerStrategy:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># dockerfilePath: dockerfile</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">output</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">to</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ImageStreamTag</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#39;maven-webapp:latest&#39;</span>
</span></span></code></pre></div><h3 id="openshift-buildconfig-configuration-example---3">Openshift BuildConfig Configuration Example - 3</h3>
<p>In this example, I am using  the <strong>source</strong> <code>strategy</code> for Source-to-Image (S2I) Build:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano BuildConfig3.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">BuildConfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">build.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">centos-s2i</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">build-test</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">output</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">to</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ImageStreamTag</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#39;maven-webapp:latest&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">strategy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Docker</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">dockerStrategy</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">dockerfilePath</span>: <span style="color:#ae81ff">Dockerfile</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Git</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">git</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">uri</span>: <span style="color:#e6db74">&#39;https://github.com/devopstales/maven-web-project&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">ref</span>: <span style="color:#ae81ff">main</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">contextDir</span>: <span style="color:#ae81ff">/S2I</span>
</span></span></code></pre></div><h1 id="the-build-pods">The build pods</h1>
<p>Openshift Use pods to uild the images so if a bild is unsuccessfull the build pod stuck in <code>Error</code> status:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get pods
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                          READY   STATUS       RESTARTS   AGE
</span></span><span style="display:flex;"><span>maven-webapp-build-1-build    0/1     Error        <span style="color:#ae81ff">0</span>          66m
</span></span><span style="display:flex;"><span>maven-webapp-build-2-build    0/1     Error        <span style="color:#ae81ff">0</span>          44m
</span></span><span style="display:flex;"><span>maven-webapp-build-3-build    0/1     Error        <span style="color:#ae81ff">0</span>          42m
</span></span><span style="display:flex;"><span>maven-webapp-build-4-build    0/1     Completed    <span style="color:#ae81ff">0</span>          39m
</span></span><span style="display:flex;"><span>maven-webapp-build2-1-build   0/1     Init:Error   <span style="color:#ae81ff">0</span>          31m
</span></span><span style="display:flex;"><span>maven-webapp-build2-2-build   0/1     Error        <span style="color:#ae81ff">0</span>          28m
</span></span><span style="display:flex;"><span>maven-webapp-build2-3-build   0/1     Init:Error   <span style="color:#ae81ff">0</span>          5m50s
</span></span><span style="display:flex;"><span>maven-webapp-build2-4-build   0/1     Completed    <span style="color:#ae81ff">0</span>          5m14s
</span></span></code></pre></div><h3 id="how-tu-use-the-imagestream-to-automatcle-update-image-in-deployment">How tu use the ImageStream to Automatcle update image in Deployment?</h3>
<p>You can define an <code>ImageStream</code> in the <code>DeploymentConfig</code> object to trigger image update:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano DeploymentConfig.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">DeploymentConfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">maven-webapp</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">maven-webapp</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">maven-webapp</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">maven-webapp</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">triggers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ConfigChange </span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ImageChange</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">imageChangeParams</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">automatic</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containerNames</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">maven-webapp</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">from</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ImageStreamTag</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">maven-webapp:latest</span>
</span></span></code></pre></div><h3 id="set-up-a-github-webhook">Set up a GitHub webhook</h3>
<p>Add <code>GitHub</code> type trigger for your <code>BuildConfig</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano BuildConfig3.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">BuildConfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">build.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">centos-s2i</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">build-test</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">output</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">to</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ImageStreamTag</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#39;maven-webapp:latest&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">strategy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Docker</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">dockerStrategy</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">dockerfilePath</span>: <span style="color:#ae81ff">Dockerfile</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Git</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">git</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">uri</span>: <span style="color:#e6db74">&#39;https://github.com/devopstales/maven-web-project&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">ref</span>: <span style="color:#ae81ff">main</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">contextDir</span>: <span style="color:#ae81ff">/S2I</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">triggers</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Generic</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">generic</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">secretReference</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">name</span>: <span style="color:#ae81ff">centos-s2i-generic-webhook-secret</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">type</span>: <span style="color:#ae81ff">GitHub</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">github</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">secretReference</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">name</span>: <span style="color:#ae81ff">centos-s2i-github-webhook-secret</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ConfigChange</span>
</span></span></code></pre></div><p>GitHub webhooks allow external services to be notified when certain events happen. To automatically deploy a new pod when updates to the GitHub Dockerfile occur, you must configure your GitHub repo with the webhook that OpenShift provides as part of the BuildConfig.</p>
<ul>
<li>In the <code>Development</code> UI go to <code>Builds</code>, select your <code>BuildConfig</code></li>
<li>Go to the Webhooks section and click Copy URL with Secret for the Generic webhook type.</li>
</ul>
<p><img src="/img/include/openshift4-buildconfig04.webp" alt="Example image"  class="zoomable" /></p>
<ul>
<li>Open your GitHub repo and navigate to <code>Settings</code>.</li>
<li>Select <code>Webhooks</code> from the Options menu and click <code>Add Webhook</code>.</li>
</ul>
<p><img src="/img/include/openshift4-buildconfig05.webp" alt="Example image"  class="zoomable" /></p>
<ul>
<li>On the <code>Add webhook</code> page, paste the URL that you copied earlier into the <code>Payload URL</code> field.</li>
<li>In the <code>Content type</code> field, select the <code>application/json</code> option.</li>
<li>Click <code>Add webhook</code>.</li>
</ul>
<p><img src="/img/include/openshift4-buildconfig06.webp" alt="Example image"  class="zoomable" /></p>
<p>Select your newly added webhook to see its details. The Recent Deliveries section displays an entry for a ping test that is prefixed with a tick mark, which indicates that the ping test was successful.</p>
<p><img src="/img/include/openshift4-buildconfig07.webp" alt="Example image"  class="zoomable" /></p>
<p>Click the entry to view more details about the REST API call and the associated response for the ping test. A successful ping test indicates that GitHub is able to connect with your OpenShift cluster.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Use Cilium BGP integration with OPNsense]]></title>
            <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp-v2/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/multus-calico/?utm_source=atom_feed" rel="related" type="text/html" title="Use multus to separate metwork trafics" />
                <link href="https://devopstales.github.io/kubernetes/multus/?utm_source=atom_feed" rel="related" type="text/html" title="Use Multus CNI in Kubernetes" />
            
                <id>https://devopstales.github.io/kubernetes/cilium-opnsense-bgp-v2/</id>
            
            
            <published>2023-01-25T00:00:00+00:00</published>
            <updated>2023-01-25T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install Cilium with BGP integration for Kubernetes.</p>
<p>In the upcoming release, version 1.13, Cilium will include a functionality which allow to advertise routes to Service IPs via BGP, so we didn&rsquo;t need to install MetalLB.</p>
<blockquote>
<p>Cilium version 1.13 is still in pre-release phase.</p></blockquote>
<h3 id="how-does-the-full-setup-look-like">How does the full setup look like?</h3>
<p>For this Demo I will use a pfsense in virtualbox and tree vm for kubernetes in the same host-only network.</p>
<table>
  <thead>
      <tr>
          <th>vm</th>
          <th>nic</th>
          <th>ip</th>
          <th>mode</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>opnsense01</td>
          <td>em1</td>
          <td>192.168.0.200</td>
          <td>bridged</td>
      </tr>
      <tr>
          <td>opnsense01</td>
          <td>em2</td>
          <td>172.17.9.200</td>
          <td>host-only</td>
      </tr>
      <tr>
          <td>k8sm01</td>
          <td>enp0s8</td>
          <td>172.17.9.10</td>
          <td>host-only</td>
      </tr>
      <tr>
          <td>k8sm02</td>
          <td>enp0s8</td>
          <td>172.17.9.11</td>
          <td>host-only</td>
      </tr>
      <tr>
          <td>k8sm02</td>
          <td>enp0s8</td>
          <td>172.17.9.12</td>
          <td>host-only</td>
      </tr>
  </tbody>
</table>
<h3 id="install-bgp-to-opnsense">Install BGP to OPNsense</h3>
<p>Go to <code>System &gt; Firmware &gt; Plugins</code> and install <code>os-frr</code></p>
<h3 id="configure-bgp-on-opnsense">Configure BGP on OPNsense</h3>
<p>Go tp <code>Routing &gt; General</code> and enable enable the plugin. Next go to <code>Routing &gt; BGP</code> and enble, then add AS Number.</p>
<p><img src="/img/include/cilium-opnsense-bgp1.jpg" alt="Enable BGP"  class="zoomable" /></p>
<h3 id="configure-neighbor">Configure Neighbor</h3>
<p>Go to  <code>Routing &gt; BGP</code> the switch to the <code>Neighbor</code> tab and add the following three neighbors.</p>
<p><img src="/img/include/cilium-opnsense-bgp2.jpg" alt="Neighbor"  class="zoomable" /></p>
<p><img src="/img/include/cilium-opnsense-bgp3.jpg" alt="Neighbor"  class="zoomable" /></p>
<p><img src="/img/include/cilium-opnsense-bgp4.PNG" alt="Neighbor"  class="zoomable" /></p>
<h3 id="cilium-configuration">Cilium configuration</h3>
<p>BGP support is enabled by providing the BGP configuration via a ConfigMap and by setting a few Helm values. Otherwise, BGP is disabled by default.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm install cilium cilium/cilium <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set bgp.enabled<span style="color:#f92672">=</span>true
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">cilium.io/v2alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">CiliumBGPPeeringPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">opensense</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">virtualRouters</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">localASN</span>: <span style="color:#ae81ff">64513</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">neighbors</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">peerASN</span>: <span style="color:#ae81ff">64512</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">peerAddress</span>: <span style="color:#ae81ff">172.17.9.200</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">cilium.io/v2alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">CiliumLoadBalancerIPPool</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">cidrs</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">cidr</span>: <span style="color:#ae81ff">10.25.0.10-10.25.3.250</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">disabled</span>: <span style="color:#66d9ef">false</span>
</span></span></code></pre></div><h3 id="demo-time">Demo Time</h3>
<p>Let’s create a demo application for testing.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano test.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">LoadBalancer</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f bgpconfig.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f test.yaml
</span></span></code></pre></div><p>After a few moments, you can run this command to get the IP address:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl describe service test-nginx | grep <span style="color:#e6db74">&#34;LoadBalancer Ingress&#34;</span>
</span></span><span style="display:flex;"><span>LoadBalancer Ingress:     10.25.0.11
</span></span></code></pre></div><p>Let&rsquo;s check the address in a browser. If pfSense is you default gateway it will work perfectly, but in my demo enviroment I need to create a route to pfSense for this network on my host machine:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo route add -net 10.25.0.0/22 gw 172.17.9.200
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>route -n
</span></span><span style="display:flex;"><span>Kernel IP routing table
</span></span><span style="display:flex;"><span>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span></span><span style="display:flex;"><span>0.0.0.0         192.168.0.1     0.0.0.0         UG    <span style="color:#ae81ff">600</span>    <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> wlan0
</span></span><span style="display:flex;"><span>10.25.0.0       172.17.9.200    255.255.252.0   UG    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> vboxnet7
</span></span><span style="display:flex;"><span>172.17.9.0      0.0.0.0         255.255.255.0   U     <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> vboxnet7
</span></span></code></pre></div><p><img src="/img/include/pfsense-bgp-kubernetes.png" alt="Demo"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="opnsense" term="opnsense" label="OPNsense" />
                             
                                <category scheme="cilium" term="cilium" label="Cilium" />
                             
                                <category scheme="bgp" term="bgp" label="BGP" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Configuringure OKD OpenShift 4 registry for bare metal]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-registry/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift4-tekton/?utm_source=atom_feed" rel="related" type="text/html" title="Deploying Tekton on OpenShift 4" />
                <link href="https://devopstales.github.io/kubernetes/openshift-log4shell/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ceph-rbd-csi/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 Ceph Persisten Storage" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 authentication" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 ingress" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-registry/</id>
            
            
            <published>2023-01-23T00:00:00+00:00</published>
            <updated>2023-01-23T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you can configure the enbedded rad hat quay docker registry in Openshift.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<p>On platforms that do not provide shareable object storage, the OpenShift Image Registry Operator bootstraps itself as <code>Removed</code>. This allows <code>openshift-installer</code> to complete installations on these platform types.</p>
<h3 id="changing-the-image-registrys-management-state">Changing the image registry’s management state</h3>
<p>To start the image registry, you must change the Image Registry Operator configuration’s <code>managementState</code> from <code>Removed</code> to <code>Managed</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc project openshift-image-registry
</span></span><span style="display:flex;"><span>oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;managementState&#34;:&#34;Managed&#34;}}&#39;</span>
</span></span></code></pre></div><h3 id="image-registry-storage-configuration">Image registry storage configuration</h3>
<p>The Image Registry Operator is not initially available for platforms that do not provide default storage. After installation, you must configure your registry to use storage so that the Registry Operator is made available. I configured ceph storage in a <a href="">previous post</a>.</p>
<p>Edit the registry configuration and add <code>image-registry-storage</code> PVC.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;storage&#34;:{&#34;pvc&#34;:{&#34;claim&#34;:&#34;image-registry-storage&#34;}}}}&#39;</span>
</span></span></code></pre></div><p>You must configure storage for the Image Registry Operator. For non-production clusters, you can set the image registry to an empty directory. If you do so, all images are lost if you restart the registry.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;storage&#34;:{&#34;emptyDir&#34;:{}}}}&#39;</span>
</span></span></code></pre></div><h3 id="image-registry-rbd-storage-configuration">Image registry RBD storage configuration</h3>
<p>To allow the image registry to use block storage types such as RBD or vSphere Virtual Machine Disk (VMDK) during upgrades as a cluster administrator, you can use the Recreate rollout strategy.</p>
<blockquote>
<p>Block storage volumes are supported but not recommended for use with image registry on production clusters. An installation where the registry is configured on block storage is not highly available because the registry cannot have more than one replica.</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc patch config.imageregistry.operator.openshift.io/cluster --type<span style="color:#f92672">=</span>merge -p <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;rolloutStrategy&#34;:&#34;Recreate&#34;,&#34;replicas&#34;:1}}&#39;</span>
</span></span></code></pre></div><p>Provision the PV for the block storage device, and create a PVC for that volume.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano pvc.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>kind: PersistentVolumeClaim
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: image-registry-storage 
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  accessModes:
</span></span><span style="display:flex;"><span>  - ReadWriteOnce 
</span></span><span style="display:flex;"><span>  resources:
</span></span><span style="display:flex;"><span>    requests:
</span></span><span style="display:flex;"><span>      storage: 100Gi 
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc apply -f pvc.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;storage&#34;:{&#34;emptyDir&#34;:{}}}}&#39;</span>
</span></span></code></pre></div><h3 id="image-registry-s3-storage-configuration">Image registry S3 storage configuration</h3>
<p>To allow the image registry to use S3 storage you need to create a <code>image-registry-private-configuration-user</code> secret to provide credentials needed for storage access and management.</p>
<h3 id="exposing-openshift-container-registry">Exposing OpenShift Container Registry</h3>
<p>The first step in setting up an OpenShift Container Registry is to expose the registry through the default or customized route. You can do so by running the following command.</p>
<p>For S3 on AWS storage, the secret is expected to contain two keys:</p>
<ul>
<li><code>REGISTRY_STORAGE_S3_ACCESSKEY</code></li>
<li><code>REGISTRY_STORAGE_S3_SECRETKEY</code></li>
</ul>
<p>Create an OpenShift Container Platform secret that contains the required keys:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc create secret generic image-registry-private-configuration-user --from-literal<span style="color:#f92672">=</span>REGISTRY_STORAGE_S3_ACCESSKEY<span style="color:#f92672">=</span>myaccesskey --from-literal<span style="color:#f92672">=</span>REGISTRY_STORAGE_S3_SECRETKEY<span style="color:#f92672">=</span>mysecretkey --namespace openshift-image-registry
</span></span></code></pre></div><p>You must configure storage for the Image Registry Operator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc edit configs.imageregistry.operator.openshift.io/cluster
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>  storage:
</span></span><span style="display:flex;"><span>    s3:
</span></span><span style="display:flex;"><span>      bucket: &lt;bucket-name&gt;
</span></span><span style="display:flex;"><span>      region: &lt;region-name&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e"># is you use self hosted S3 like Minio or Ceph</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc patch configs.imageregistry.operator.openshift.io/cluster --type<span style="color:#f92672">=</span>merge --patch <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;defaultRoute&#34;:true}}&#39;</span>
</span></span></code></pre></div><blockquote>
<p>If you use self hosted S3 like Minio or Ceph y need to add the <code>regionEndpoint</code> option too. For example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span> storage:
</span></span><span style="display:flex;"><span>   s3:
</span></span><span style="display:flex;"><span>     bucket: &lt;bucket-name&gt;
</span></span><span style="display:flex;"><span>     region: &lt;region-name&gt;
</span></span><span style="display:flex;"><span>     regionEndpoint: http://rook-ceph-rgw-ocs-storagecluster-cephobjectstore.openshift-storage.svc.cluster.local
</span></span></code></pre></div></blockquote>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Deploying Tekton on OpenShift 4]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-tekton/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-log4shell/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ceph-rbd-csi/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 Ceph Persisten Storage" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 authentication" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 ingress" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-install/?utm_source=atom_feed" rel="related" type="text/html" title="How To Install OKD OpenShift 4 on premise" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-tekton/</id>
            
            
            <published>2023-01-20T00:00:00+00:00</published>
            <updated>2023-01-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you can install rad hat openshift pipelines (Tekton) on OpenShift4.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<h3 id="configure-redhat-registry-authentication">Configure RedHat registry Authentication</h3>
<p>The first thing we will need to do is set up authentication to the RedHat registry. To do this, we will start with a copy of your OpenShift pull-secret. Download your registry.redhat.io <a href="https://console.redhat.com/openshift/install/pull-secret">pull secret from the RedHat OpenShift Cluster Manager</a> and save it to your home directory as <code>pull-secret.json</code>.</p>
<blockquote>
<p>If you configured a valid <code>pullSecret</code> in <code>install-config.yaml</code> at install you didn&rsquo;t nead this.</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc project openshift-config
</span></span><span style="display:flex;"><span>oc delete secret pull-secret
</span></span><span style="display:flex;"><span>oc create secret generic pull-secret --from-file<span style="color:#f92672">=</span>.dockerconfigjson<span style="color:#f92672">=</span>/tmp/pull-secret.json --type<span style="color:#f92672">=</span>kubernetes.io/dockerconfigjson
</span></span></code></pre></div><h3 id="enable-all-the-operator-sources-in-openshift-4">Enable all the Operator sources in OpenShift 4</h3>
<p>The nex step is to enable all the Operator sources in OpenShift 4.</p>
<blockquote>
<p>You will need to have Cluster Admin privileges in order to run the commands in the following section.</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc patch OperatorHub cluster --type json -p <span style="color:#e6db74">&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/spec/disableAllDefaultSources&#34;, &#34;value&#34;: false}]&#39;</span>
</span></span><span style="display:flex;"><span>operatorhub.config.openshift.io/cluster patched
</span></span></code></pre></div><p>At this point, you can validate that the Operator Hub in OpenShift is empty by checking in the UI:</p>
<p><img src="/img/include/okd-tekton001.webp" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/okd-tekton002.webp" alt="Example image"  class="zoomable" /></p>
<h3 id="install-the-rad-hat-openshift-pipelines-operator">Install the rad hat openshift pipelines operator</h3>
<p>In order to use Tekton in OpenShift we will install an operator from use the user interface of the OpenShift Web Console:</p>
<p><img src="/img/include/okd-tekton003.webp" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/okd-tekton004.webp" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/okd-tekton005.webp" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/okd-tekton006.webp" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/okd-tekton007.webp" alt="Example image"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Microk8s: Unable to connect to the server: x509: certificate has expired or is not yet valid]]></title>
            <link href="https://devopstales.github.io/kubernetes/microk8s-expired-cert/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/linux/proxmox-custom-certificate/?utm_source=atom_feed" rel="related" type="text/html" title="Proxmox: Set custom certificate" />
            
                <id>https://devopstales.github.io/kubernetes/microk8s-expired-cert/</id>
            
            
            <published>2023-01-10T00:00:00+00:00</published>
            <updated>2023-01-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will shoe you how to renew the kubernetes api cert in Microk8s.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># microk8s kubectl get all --all-namespaces</span>
</span></span><span style="display:flex;"><span>Unable to connect to the server: x509: certificate has expired or is not yet valid: current time 2023-01-11T10:50:25+01:00 is after 2022-07-21T13:27:27Z
</span></span></code></pre></div><p>So the k8s api certificate probably expired. Test it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># sudo microk8s.refresh-certs -c</span>
</span></span><span style="display:flex;"><span>The CA certificate will expire in <span style="color:#ae81ff">0</span> days.
</span></span></code></pre></div><p>Ok so we renew the certificate:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># microk8s.refresh-certs</span>
</span></span><span style="display:flex;"><span>Taking a backup of the current certificates under /var/snap/microk8s/2530/var/log/ca-backup/
</span></span><span style="display:flex;"><span>Creating new certificates
</span></span><span style="display:flex;"><span>Signature ok
</span></span><span style="display:flex;"><span>subject<span style="color:#f92672">=</span>/C<span style="color:#f92672">=</span>GB/ST<span style="color:#f92672">=</span>Canonical/L<span style="color:#f92672">=</span>Canonical/O<span style="color:#f92672">=</span>Canonical/OU<span style="color:#f92672">=</span>Canonical/CN<span style="color:#f92672">=</span>127.0.0.1
</span></span><span style="display:flex;"><span>Getting CA Private Key
</span></span><span style="display:flex;"><span>Signature ok
</span></span><span style="display:flex;"><span>subject<span style="color:#f92672">=</span>/CN<span style="color:#f92672">=</span>front-proxy-client
</span></span><span style="display:flex;"><span>Getting CA Private Key
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>Creating new kubeconfig file
</span></span><span style="display:flex;"><span>2023-01-11T10:53:03+01:00 INFO Waiting <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#34;snap.microk8s.daemon-cluster-agent.service&#34;</span> to stop.
</span></span><span style="display:flex;"><span>Stopped.
</span></span><span style="display:flex;"><span>Started.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>The CA certificates have been replaced. Kubernetes will restart the pods of your workloads.
</span></span><span style="display:flex;"><span>Any worker nodes you may have in your cluster need to be removed and re-joined to become aware of the new CA.
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="container-runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="microk8s" term="microk8s" label="microk8s" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to Manage Kubernetes Resource Limits]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-limits/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.5/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.5: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-crowdsec-ids/?utm_source=atom_feed" rel="related" type="text/html" title="CrowdSec Intrusion Detection System (IDS) for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.4/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.4: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/container-build-in-kubernetes/?utm_source=atom_feed" rel="related" type="text/html" title="How to build containers in Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/kube-openid-connect-1.0/?utm_source=atom_feed" rel="related" type="text/html" title="kube-openid-connect 1.0" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-limits/</id>
            
            
            <published>2022-11-08T00:00:00+00:00</published>
            <updated>2022-11-08T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you the usage of the Kubernetes limits and requests.</p>
<p>Kubernetes schedule and orchestrate containers on the underlying shared set of physical resources. By default, a pod in Kubernetes will run with no limits on CPU and memory in a namespace. However, this can create several problems related to resources. So there is no control of how much resources each pod can use. Some a hungry container can eat the resources from other container on the node.</p>
<h3 id="resource-types">Resource types</h3>
<p>CPU and memory are each a resource type. Every resource type has a base unit. CPU represents compute processing and is specified in units of CPU cores. 1 physical CPU core, or 1 virtual core, depending on whether the node is a physical host or a virtual machine running inside a physical machine. You can use a fraction of a cpu by setting to <code>0.5</code> For CPU resource units, the quantity expression 0.1 is equivalent to the expression 100m, which can be read as &ldquo;one hundred millicpu&rdquo;.</p>
<p>The other common resource is memory. Memory is specified in units of bytes. You can express memory as a plain integer or as a fixed-point number using one of these quantity suffixes: E, P, T, G, M, k or Ei, Pi, Ti, Gi, Mi, Ki. For example, the following represent roughly the same value:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>128974848, 129e6, 129M,  128974848000m, 123Mi
</span></span></code></pre></div><h3 id="understanding-requests">Understanding Requests</h3>
<p>A request is the amount of resources that the system will guarantee for the container. Kubernetes will use this value to decide on which node to place the pod. In the case that request is not set for a container, the defaults is the same as the resource limit. The Kubelet reserves the
requested amount of system resource. That means no mather the container use the requested resource or not other containers can not use that reserved resources.</p>
<h3 id="understanding-limits">Understanding Limits</h3>
<p>A limit is the maximum amount of resources that Kubernetes will allow the container to use. For example: when a process in the container tries to consume more than the allowed amount of memory, the system kernel terminates the process that attempted the allocation, with an out of memory (OOM) error. If limit is not set, then the default is to  set 0 (unbounded).</p>
<p><img src="/img/include/container-resource-1.png" alt="Request vs Limit"  class="zoomable" /></p>
<h3 id="examples">Examples</h3>
<p>Below is an example of a pod configuration file with requests and limits set for CPU and memory of two containers in a pod.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">demo</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">demo1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;16Mi&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#e6db74">&#34;100m&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;32Mi&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#e6db74">&#34;200m&#34;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">demo2</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">mysql</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;64Mi&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#e6db74">&#34;200m&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;128Mi&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#e6db74">&#34;400m&#34;</span>
</span></span></code></pre></div><p>Run the following command to inspect the resources used by the pod:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl top pods
</span></span><span style="display:flex;"><span>NAME          CPU<span style="color:#f92672">(</span>cores<span style="color:#f92672">)</span>   MEMORY<span style="color:#f92672">(</span>bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>demo          201m         27Mi
</span></span></code></pre></div><p>You can do a similar test for nodes or namespaces:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl top node
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                         CPU<span style="color:#f92672">(</span>cores<span style="color:#f92672">)</span>   CPU%   MEMORY<span style="color:#f92672">(</span>bytes<span style="color:#f92672">)</span>   MEMORY%
</span></span><span style="display:flex;"><span>k8s-m101                     1338m        66%    3586Mi          45%
</span></span><span style="display:flex;"><span>k8s-w102                     2488m        31%    18918Mi         58%
</span></span></code></pre></div><p>Yo can use a handy tool called <a href="https://github.com/robscott/kube-capacity"><code>kube-capacity</code></a> that provides an overview of the resource requests, limits, and utilization in a Kubernetes cluster:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl krew install resource-capacity
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kube-capacity
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NODE        CPU REQUESTS    CPU LIMITS    MEMORY REQUESTS    MEMORY LIMITS
</span></span><span style="display:flex;"><span>*           560m <span style="color:#f92672">(</span>28%<span style="color:#f92672">)</span>      130m <span style="color:#f92672">(</span>7%<span style="color:#f92672">)</span>     572Mi <span style="color:#f92672">(</span>9%<span style="color:#f92672">)</span>         770Mi <span style="color:#f92672">(</span>13%<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>k8s-m101    220m <span style="color:#f92672">(</span>22%<span style="color:#f92672">)</span>      10m <span style="color:#f92672">(</span>1%<span style="color:#f92672">)</span>      192Mi <span style="color:#f92672">(</span>6%<span style="color:#f92672">)</span>         360Mi <span style="color:#f92672">(</span>12%<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>k8s-w102    340m <span style="color:#f92672">(</span>34%<span style="color:#f92672">)</span>      120m <span style="color:#f92672">(</span>12%<span style="color:#f92672">)</span>    380Mi <span style="color:#f92672">(</span>13%<span style="color:#f92672">)</span>        410Mi <span style="color:#f92672">(</span>14%<span style="color:#f92672">)</span>
</span></span></code></pre></div><h3 id="finding-the-right-requests-and-limits">Finding the right requests and limits</h3>
<p>For this demo I will use a Python app using the Flask framework. A simple cache service which has two endpoints, one to cache the data and another for retrieving it.</p>
<p>Before you start, make sure that your cluster has the metrics server installed. In my case I use minikube and I can enable it as a plugin:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ minikube addons enable metrics-server
</span></span></code></pre></div><p>You can deploy the application with the following YAML file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano deployment.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cache-service</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">image</span>: <span style="color:#ae81ff">xasag94215/flask-cache</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">5000</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rest</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">5000</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">limit-demo.mydomain.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">number</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">Prefix</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl top pods
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                           CPU<span style="color:#f92672">(</span>cores<span style="color:#f92672">)</span>   MEMORY<span style="color:#f92672">(</span>bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>flask-cache-8484fd74dd-sxpk7   188m         151Mi
</span></span></code></pre></div><p>Requests and limits depend on how much memory and CPU the application uses. An application that serves static pages might have a memory and CPU mostly static. It is common o have metrics server and prometheus database to store your metrics. The you can get max and min of the CPU and memory and extrapolate requests and limits. But there&rsquo;s a quicker way.</p>
<h3 id="vertical-pod-autoscaler">Vertical Pod Autoscaler</h3>
<p>The SIG-autoscaling group developed a tool that can do that automatically: the <a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler">Vertical Pod Autoscaler (VPA)</a>. The Vertical Pod Autoscaler is a Kubernetes Operator that estimates the correct requests and limits for Pod.</p>
<blockquote>
<p><strong>Limitations:</strong></p>
<ul>
<li>Vertical Pod autoscaling supports a maximum of 500 VerticalPodAutoscaler objects per cluster.</li>
<li>Vertical Pod autoscaling is not ready for use with JVM-based workloads due to limited visibility into actual memory usage of the workload.</li>
</ul></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add fairwinds-stable https://charts.fairwinds.com/stable
</span></span><span style="display:flex;"><span>helm upgrade --install vpa fairwinds-stable/vpa <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--namespace vpa-system --create-namespace <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set admissionController.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set updater.extraArgs.min-replicas<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span></code></pre></div><p>So if you want to the Vertical Pod Autoscaler (VPA) to estimate limits and requests for your Flask app, you should create the following YAML file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano vpa.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;autoscaling.k8s.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">VerticalPodAutoscaler</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetRef</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;apps/v1&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">updatePolicy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">updateMode</span>: <span style="color:#e6db74">&#34;Off&#34;</span>
</span></span></code></pre></div><p>You can query the vpa object with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl describe vpa flask-cache
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Status:
</span></span><span style="display:flex;"><span>  Conditions:
</span></span><span style="display:flex;"><span>    Last Transition Time:  2022-11-14T13:58:08Z
</span></span><span style="display:flex;"><span>    Status:                True
</span></span><span style="display:flex;"><span>    Type:                  RecommendationProvided
</span></span><span style="display:flex;"><span>  Recommendation:
</span></span><span style="display:flex;"><span>    Container Recommendations:
</span></span><span style="display:flex;"><span>      Container Name:  cache-service
</span></span><span style="display:flex;"><span>      Lower Bound:
</span></span><span style="display:flex;"><span>        Cpu:     25m
</span></span><span style="display:flex;"><span>        Memory:  60194k
</span></span><span style="display:flex;"><span>      Target:
</span></span><span style="display:flex;"><span>        Cpu:     410m
</span></span><span style="display:flex;"><span>        Memory:  262144k
</span></span><span style="display:flex;"><span>      Uncapped Target:
</span></span><span style="display:flex;"><span>        Cpu:     410m
</span></span><span style="display:flex;"><span>        Memory:  262144k
</span></span><span style="display:flex;"><span>      Upper Bound:
</span></span><span style="display:flex;"><span>        Cpu:     <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        Memory:  500Mi
</span></span><span style="display:flex;"><span>Events:          &lt;none&gt;
</span></span></code></pre></div><p>In the lower part of the output, the autoscaler has three sections:</p>
<ul>
<li>The <strong>lower bound</strong> is the minimum estimation for the container.</li>
<li>The <strong>upper bound</strong> is the maximum recommended resource estimation for the container.</li>
<li><strong>Target</strong> estimation is the one we will use for setting resource requests.</li>
<li>All of these estimations are capped based on min allowed and max allowed container policies.</li>
<li>The <strong>uncapped target</strong> estimation is a target estimation produced if there were no minAllowed and maxAllowed restrictions.</li>
</ul>
<p>You can start a load tester and keep inspecting the Vertical Pod Autoscaler (VPA) recommendation. Once the recommendations are stable, you can apply them back to your deployment:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cache-service</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">image</span>: <span style="color:#ae81ff">xasag94215/flask-cache</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">5000</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rest</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">25m</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">64Mi</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">410m</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">512Mi</span>
</span></span></code></pre></div><p>If <code>updateMode: &quot;Auto&quot;</code> is set then the VerticalPodAutoscaler automatically patch the pod at next creation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano vpa.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;autoscaling.k8s.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">VerticalPodAutoscaler</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetRef</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;apps/v1&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">flask-cache</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">updatePolicy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">updateMode</span>: <span style="color:#e6db74">&#34;Auto&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl delete po flask-cache-8484fd74dd-hpmhh --force
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get po -o yaml flask-cache-8484fd74dd-cdxkn | grep vpa
</span></span><span style="display:flex;"><span>    vpaObservedContainers: cache-service
</span></span><span style="display:flex;"><span>    vpaUpdates: <span style="color:#960050;background-color:#1e0010">&#39;</span>Pod resources updated by flask-cache: container 0: cpu request, memory
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl get po -o yaml flask-cache-8484fd74dd-cdxkn</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">xasag94215/flask-cache</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cache-service</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">5000</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rest</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">350m</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;248153480&#34;</span>
</span></span></code></pre></div><h3 id="visualising-limits-and-requests-recommendations">Visualising limits and requests recommendations</h3>
<p>If you prefer to use a graphical interface to inspect VPA you can use <a href="https://github.com/FairwindsOps/goldilocks">Goldilocks dashboard</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano goldilocks-values.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">dashboard</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">goldilocks.mydomain.intra</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">path</span>: <span style="color:#e6db74">&#34;/&#34;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">type</span>: <span style="color:#e6db74">&#34;ImplementationSpecific&#34;</span>
</span></span><span style="display:flex;"><span>---
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm upgrade --install goldilocks --namespace vpa-system fairwinds-stable/goldilocks -f goldilocks-values.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl label ns goldilocks goldilocks.fairwinds.com/enabled<span style="color:#f92672">=</span>true
</span></span></code></pre></div><p>If you want Goldilocks to display Vertical Pod Autoscaler (VPA) recommendations, you should tag the namespace with a particular label:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl label namespace default goldilocks.fairwinds.com/enabled<span style="color:#f92672">=</span>true
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Linux user namespace management wit CRI-O in Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-user-namespace/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/container-runtimes/?utm_source=atom_feed" rel="related" type="text/html" title="Containers and Container runtimes for Beginners" />
                <link href="https://devopstales.github.io/kubernetes/k8s-falco/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes audit logs and Falco" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cisa-install/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Hardening Guide with CISA 1.6 Benchmark" />
                <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="related" type="text/html" title="Hardening Kubernetes with seccomp" />
                <link href="https://devopstales.github.io/kubernetes/k3s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with CRI-O and kadalu" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-user-namespace/</id>
            
            
            <published>2022-11-02T00:00:00+00:00</published>
            <updated>2022-11-02T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this blog post I will introduce user namespaces, then I will show you how you can use it in Kubernetes.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h1 id="what-are-user-namespaces">What are user namespaces?</h1>
<p>As we talked about in a <a href="">prewious post</a> container engines uses the linux kernels namespaces to isolate the conatiners. For example, two containers in different network namespaces will not see each other’s network interfaces. Two containers in different PID namespaces will not see each other’s processes.</p>
<p>On Linux, all files and all processes are owned by a specific user id and group id, usually defined in <code>/etc/passwd</code> and <code>/etc/group</code>. <a href="https://man7.org/linux/man-pages/man7/user_namespaces.7.html">User namespaces</a>  are isolates user IDs and group IDs from each other. With user namespaces the container engine can let a container only see a subset of the host’s user IDs and group IDs.</p>
<h2 id="why-this-is-important">Why this is important</h2>
<p>By default the container engines share the same user namespace in the container as the host use. So If I use the root user with the 0 user ID in a container it is the same ID as he root user use on the host. So if an unprivileged user on a hos has the ability to run containers with this security loophole it can make changes on the host without sudo privilege on the host:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ docker run -v /etc/:/etc/ -ti ubuntu
</span></span><span style="display:flex;"><span>root@6803a66e58d0:/# passwd
</span></span><span style="display:flex;"><span>New password:
</span></span><span style="display:flex;"><span>Retype new password:
</span></span><span style="display:flex;"><span>passwd: password updated successfully
</span></span><span style="display:flex;"><span>root@6803a66e58d0:/# exit
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ su -
</span></span><span style="display:flex;"><span>Password:
</span></span><span style="display:flex;"><span>Hello, DevOpsTales! You are a sysadmin now
</span></span><span style="display:flex;"><span><span style="color:#75715e">#</span>
</span></span></code></pre></div><h2 id="the-solution-rootless-mode">The solution rootless mode</h2>
<p>The firs container engine that can be used in rootless mode was <strong>podman</strong> they used the <code>subuid</code> and <code>bunguid</code> to run containers in rootless mode. Normally a user or group has only one ID, but wit <code>subuid</code> and <code>bunguid</code> you can allocate an ID segment for the user or groupe.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">====================================================================</span>
</span></span><span style="display:flex;"><span>User Specification
</span></span><span style="display:flex;"><span><span style="color:#f92672">====================================================================</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># The following below commands allocates the UIDs and GIDs from 100000to 165535 to the podman user and group respectively.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ sudo touch /etc/<span style="color:#f92672">{</span>subgid,subuid<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>$ sudo usermod --add-subuids 100000-165535 --add-subgids 100000-165535 <span style="color:#e6db74">${</span>USER<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>$ grep <span style="color:#e6db74">${</span>USER<span style="color:#e6db74">}</span> /etc/subuid /etc/subgid
</span></span><span style="display:flex;"><span>/etc/subuid:<span style="color:#e6db74">${</span>USER<span style="color:#e6db74">}</span>:100000:65536
</span></span><span style="display:flex;"><span>/etc/subgid:<span style="color:#e6db74">${</span>USER<span style="color:#e6db74">}</span>:100000:65536
</span></span></code></pre></div><p>Now bot <strong>podman</strong> and <strong>docker</strong> can be installed in rootless mode. The only problem with rootless mode that Kubernets can not use it.</p>
<h2 id="kubernetes-user-namespace-management-with-cri-o">Kubernetes user namespace management with CRI-O</h2>
<p>To solve this problem <strong>CRI-O</strong> <a href="https://github.com/cri-o/cri-o/pull/3944">added support</a> for user namespace configuration through pod annotations.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span>1.25
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/CentOS_8/devel:kubic:libcontainers:stable.repo
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable_cri-o_<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>/CentOS_8/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install cri-o nano wget
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bas" data-lang="bas"><span style="display:flex;"><span>cat <span style="color:#f92672">&lt;&lt;</span><span style="color:#75715e">&#39;EOF&#39; | sudo tee /etc/modules-load.d/crio.conf &gt; /dev/null</span>
</span></span><span style="display:flex;"><span>overlay
</span></span><span style="display:flex;"><span>br_netfilter
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>modprobe overlay
</span></span><span style="display:flex;"><span>modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#f92672">&lt;&lt;</span><span style="color:#66d9ef">EOF</span> <span style="color:#f92672">&gt;</span>  <span style="color:#f92672">/</span>etc<span style="color:#f92672">/</span>sysctl<span style="color:#f92672">.</span>d<span style="color:#f92672">/</span>k8s<span style="color:#f92672">.</span>conf
</span></span><span style="display:flex;"><span>net<span style="color:#f92672">.</span>bridge<span style="color:#f92672">.</span>bridge<span style="color:#f92672">-</span>nf<span style="color:#f92672">-</span>call<span style="color:#f92672">-</span>ip6tables <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>net<span style="color:#f92672">.</span>bridge<span style="color:#f92672">.</span>bridge<span style="color:#f92672">-</span>nf<span style="color:#f92672">-</span>call<span style="color:#f92672">-</span>iptables <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>net<span style="color:#f92672">.</span>ipv6<span style="color:#f92672">.</span>conf<span style="color:#f92672">.</span>all<span style="color:#f92672">.</span>disable_ipv6 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>net<span style="color:#f92672">.</span>ipv6<span style="color:#f92672">.</span>conf<span style="color:#f92672">.</span>default<span style="color:#f92672">.</span>disable_ipv6 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>net<span style="color:#f92672">.</span>ipv4<span style="color:#f92672">.</span>ip_forward                 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>net<span style="color:#f92672">.</span>bridge<span style="color:#f92672">.</span>bridge<span style="color:#f92672">-</span>nf<span style="color:#f92672">-</span>call<span style="color:#f92672">-</span>ip6tables <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl <span style="color:#f92672">--</span>system
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Configure User anmespacing in CRI-O</span>
</span></span><span style="display:flex;"><span>mkdir /etc/crio/crio.conf.d/
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/crio/crio.conf.d/01-userns-workload.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[crio.runtime.workloads.userns]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">activation_annotation = &#34;io.kubernetes.cri-o.userns-mode&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">allowed_annotations = [&#34;io.kubernetes.cri-o.userns-mode&#34;]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano /etc/containers/registries.conf
</span></span><span style="display:flex;"><span>unqualified-search-registries <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;registry.access.redhat.com&#34;</span>, <span style="color:#e6db74">&#34;registry.redhat.io&#34;</span>, <span style="color:#e6db74">&#34;quay.io&#34;</span>, <span style="color:#e6db74">&#34;docker.io&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/network_backend = &#34;cni&#34;/#network_backend = &#34;&#34;/&#39;</span> /usr/share/containers/containers.conf
</span></span></code></pre></div><p>Change the pod-subnet <code>10.244.0.0/16</code> in the cri-o bridge config <code>/etc/cni/net.d/100-crio-bridge.conf</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">nano</span> <span style="color:#960050;background-color:#1e0010">/etc/cni/net.d/</span><span style="color:#ae81ff">100</span><span style="color:#960050;background-color:#1e0010">-crio-bridge.conf</span>
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;cniVersion&#34;</span>: <span style="color:#e6db74">&#34;0.3.1&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;crio&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;bridge&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;bridge&#34;</span>: <span style="color:#e6db74">&#34;cni0&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;isGateway&#34;</span>: <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;ipMasq&#34;</span>: <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;hairpinMode&#34;</span>: <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;ipam&#34;</span>: {
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;host-local&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;routes&#34;</span>: [
</span></span><span style="display:flex;"><span>            { <span style="color:#f92672">&#34;dst&#34;</span>: <span style="color:#e6db74">&#34;0.0.0.0/0&#34;</span> },
</span></span><span style="display:flex;"><span>            { <span style="color:#f92672">&#34;dst&#34;</span>: <span style="color:#e6db74">&#34;1100:200::1/24&#34;</span> }
</span></span><span style="display:flex;"><span>        ],
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&#34;ranges&#34;</span>: [
</span></span><span style="display:flex;"><span>            [{ <span style="color:#f92672">&#34;subnet&#34;</span>: <span style="color:#e6db74">&#34;10.244.0.0/16&#34;</span> }]
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <strong>CRI-O</strong> will run the containers with the <code>containers</code> user so I need to create <code>/etc/subuid</code> and <code>/etc/subgid</code> on nodes.</p>
<blockquote>
<p>SubUID/GIDs are a range of user/group IDs that a user is allowed to use.</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;containers:200000:268435456&#34;</span> &gt;&gt; /etc/subuid
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;containers:200000:268435456&#34;</span> &gt;&gt; /etc/subgid
</span></span></code></pre></div><blockquote>
<p>First I created the id ranges for <code>root</code> user because <strong>CRI-O</strong> runs as <code>root</code> Fu the I find the fallowing ERROR in the <strong>CRI-O</strong> log:</p>
<pre tabindex="0"><code>Cannot find mappings for user \&#34;containers\&#34;: No subuid
ranges found for user \&#34;containers\&#34; in /etc/subuid&#34;
</code></pre></blockquote>
<h3 id="install-kubernetes">Install Kubernetes</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>CRIP_VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>crio --version | egrep ^Version | awk <span style="color:#e6db74">&#39;{print $2}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>yum install kubelet-$CRIP_VERSION kubeadm-$CRIP_VERSION kubectl-$CRIP_VERSION cri-tools iproute-tc -y
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>IP<span style="color:#f92672">=</span>192.168.200.10
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir /var/lib/kubelet/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># --node-ip for multi interface configuration</span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /var/lib/kubelet/kubeadm-flags.env
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KUBELET_KUBEADM_ARGS=&#34;--node-ip=&#39;$IP&#39;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl enable kubelet.service
</span></span><span style="display:flex;"><span>systemctl enable --now crio
</span></span><span style="display:flex;"><span>kubeadm config images pull --cri-socket<span style="color:#f92672">=</span>unix:///var/run/crio/crio.sock --kubernetes-version<span style="color:#f92672">=</span>$CRIP_VERSION
</span></span><span style="display:flex;"><span>kubeadm init --pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16 --apiserver-advertise-address<span style="color:#f92672">=</span>$IP  --kubernetes-version<span style="color:#f92672">=</span>$CRIP_VERSION --cri-socket<span style="color:#f92672">=</span>unix:///var/run/crio/crio.sock
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>crictl info
</span></span><span style="display:flex;"><span>kubectl get node -o wide
</span></span><span style="display:flex;"><span>kubectl get po --all-namespaces
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl taint nodes --all node-role.kubernetes.io/master-
</span></span><span style="display:flex;"><span>kubectl taint nodes --all node-role.kubernetes.io/control-plane-
</span></span></code></pre></div><p>and <strong>docker/containerd</strong> can be install in rootless mode.  user namespaces it.</p>
<h3 id="demo-time">Demo time</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano pod.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Pod
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: not-userns-pod
</span></span><span style="display:flex;"><span>  annotations:
</span></span><span style="display:flex;"><span>    io.kubernetes.cri-o.userns-mode: <span style="color:#e6db74">&#34;auto&#34;</span> <span style="color:#75715e"># this will not work</span>
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  containers:
</span></span><span style="display:flex;"><span>  - command:
</span></span><span style="display:flex;"><span>    - sleep
</span></span><span style="display:flex;"><span>    - 2d
</span></span><span style="display:flex;"><span>    image: registry.fedoraproject.org/fedora-minimal
</span></span><span style="display:flex;"><span>    name: not-userns-ctr
</span></span><span style="display:flex;"><span>    imagePullPolicy: IfNotPresent
</span></span><span style="display:flex;"><span>status: <span style="color:#f92672">{}</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Pod
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: standard-pod
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  containers:
</span></span><span style="display:flex;"><span>  - command:
</span></span><span style="display:flex;"><span>    - sleep
</span></span><span style="display:flex;"><span>    - 3d
</span></span><span style="display:flex;"><span>    image: registry.fedoraproject.org/fedora-minimal
</span></span><span style="display:flex;"><span>    name: not-userns-ctr
</span></span><span style="display:flex;"><span>    imagePullPolicy: IfNotPresent
</span></span><span style="display:flex;"><span>status: <span style="color:#f92672">{}</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl aply -f pod.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ps -eo args,pid | grep sleep
</span></span><span style="display:flex;"><span>sleep 2d                      <span style="color:#ae81ff">57277</span>
</span></span><span style="display:flex;"><span>sleep 3d                      <span style="color:#ae81ff">58878</span>
</span></span><span style="display:flex;"><span>grep --color<span style="color:#f92672">=</span>auto sleep       <span style="color:#ae81ff">58918</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># standard container</span>
</span></span><span style="display:flex;"><span>cat /proc/58878/uid_map
</span></span><span style="display:flex;"><span>         <span style="color:#ae81ff">0</span>          <span style="color:#ae81ff">0</span> <span style="color:#ae81ff">4294967295</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># namespaced container</span>
</span></span><span style="display:flex;"><span>cat /proc/57277/uid_map
</span></span><span style="display:flex;"><span>         <span style="color:#ae81ff">0</span>     <span style="color:#ae81ff">200000</span>      <span style="color:#ae81ff">65536</span>
</span></span></code></pre></div><p>As you can see the container&rsquo;s uid range is shifted.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="container-runtimes" />
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes volume expansion with Ceph RBD CSI driver]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-ceph-csi-extand/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/linux/ceph_backup_benji/?utm_source=atom_feed" rel="related" type="text/html" title="CEPH backup with Benji" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph-storage-with-csi-driver/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD volume with CSI driver" />
                <link href="https://devopstales.github.io/kubernetes/who-mapping-rbd-device/?utm_source=atom_feed" rel="related" type="text/html" title="Ceph: who is mapping a RBD device" />
                <link href="https://devopstales.github.io/linux/install-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Install Ceph cluster" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-ceph-csi-extand/</id>
            
            
            <published>2022-10-20T00:00:00+00:00</published>
            <updated>2022-10-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can you use CEPH RBD CSI driver as persistent storage end enable volume expansion on Kubernetes.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>Firt we need to install the <a href="https://github.com/kubernetes-csi/external-resizer">csi-resizer</a>. This is a sidecar container that watches Kubernetes PersistentVolumeClaims objects and triggers controller side expansion operation against a CSI endpoint</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens ceph-csi-rbd
</span></span><span style="display:flex;"><span>wget https://raw.githubusercontent.com/kubernetes-csi/external-resizer/master/deploy/kubernetes/rbac.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># chaneg namespace to your namespace in my case ceph-csi-rbd</span>
</span></span><span style="display:flex;"><span>nano rbac.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f rbac.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-resizer/master/deploy/kubernetes/deployment.yaml
</span></span></code></pre></div><p>Create or edit a StorageClass with the peccary parameters like (<code>csi.storage.k8s.io/controller-expand-secret-namespace: default</code>,<code>csi.storage.k8s.io/controller-expand-secret-name: csi-rbd-secret</code>,<code>allowVolumeExpansion: true</code>):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">storage.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">StorageClass</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">k8s-etc</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">storageclass.kubernetes.io/is-default-class</span>: <span style="color:#e6db74">&#39;true&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">provisioner</span>: <span style="color:#ae81ff">rbd.csi.ceph.com</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">parameters</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">pool</span>: <span style="color:#ae81ff">k8s-etc</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">clusterID</span>: <span style="color:#ae81ff">e285a458-7c95-4187-8129-fbd6c370c537</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">imageFeatures</span>: <span style="color:#ae81ff">layering</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/fstype</span>: <span style="color:#ae81ff">ext4</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/provisioner-secret-namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/provisioner-secret-name</span>: <span style="color:#ae81ff">csi-rbd-secret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/node-stage-secret-namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/node-stage-secret-name</span>: <span style="color:#ae81ff">csi-rbd-secret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/controller-expand-secret-namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/controller-expand-secret-name</span>: <span style="color:#ae81ff">csi-rbd-secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">volumeBindingMode</span>: <span style="color:#ae81ff">Immediate</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">reclaimPolicy</span>: <span style="color:#ae81ff">Delete</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">allowVolumeExpansion</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">mountOptions</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">discard</span>
</span></span></code></pre></div><p>Create demo app for expansion:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano testclaim.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PersistentVolumeClaim</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-claim</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">accessModes</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">ReadWriteOnce</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">1Gi</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano testpod.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ReplicationController</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span><span style="color:#75715e">#      securityContext:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#        fsGroupChangePolicy: ReadWriteOnceWithFSType</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/var/lib/www/html</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mypvc</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mypvc</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">persistentVolumeClaim</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">claimName</span>: <span style="color:#ae81ff">test-claim</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f testclaim.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f testpod.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kgp
</span></span><span style="display:flex;"><span>NAME          READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>nginx-qsw7x   1/1     Running   <span style="color:#ae81ff">0</span>          <span style="color:#ae81ff">115</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl exec -ti nginx-qsw7x -- df -kh|grep var
</span></span><span style="display:flex;"><span>/dev/rbd7                974M   24K  958M   1% /var/lib/www/html
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kgpvc
</span></span><span style="display:flex;"><span>NAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
</span></span><span style="display:flex;"><span>test-claim   Bound    pvc-da8019f5-cf01-4ede-8e36-90dd8a79564b   1Gi        RWO            k8s-etc     11m
</span></span></code></pre></div><p>Now we can change the size of the pvc and the operator will extend teh pv fo it automatically:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl patch pvc test-claim -p <span style="color:#e6db74">&#39;{&#34;spec&#34;: {&#34;resources&#34;: {&#34;requests&#34;: {&#34;storage&#34;: &#34;5Gi&#34;}}}}&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kgpvc
</span></span><span style="display:flex;"><span>NAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
</span></span><span style="display:flex;"><span>test-claim   Bound    pvc-da8019f5-cf01-4ede-8e36-90dd8a79564b   5Gi        RWO            k8s-etc     11m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl exec -ti nginx-qsw7x -- df -kh|grep var
</span></span><span style="display:flex;"><span>/dev/rbd7                4.9G   24K  4.9G   1% /var/lib/www/html
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                             
                                <category scheme="volume-expansion" term="volume-expansion" label="volume expansion" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[trivy-operator 2.5: Patch release for Admisssion controller]]></title>
            <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.5/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.4/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.4: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.3/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.3: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.2/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.2: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.1/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-1.0/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 1.0" />
            
                <id>https://devopstales.github.io/kubernetes/trivy-operator-2.5/</id>
            
            
            <published>2022-10-15T00:00:00+00:00</published>
            <updated>2022-10-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Today I am happy to announce the release of trivy-operator 2.5. This blog post focuses on the functionality provided by the trivy-operator 2.5 release.</p>
<h3 id="what-is-trivy-operator">What is trivy-operator?</h3>
<p>Trivy-operator is a Kubernetes Operator based on the open-source container vulnerability scanner Trivy. The goal of this project is to provide a vulnerability scanner that continuously scans containers deployed in a Kubernetes cluster. <a href="https://github.com/nolar/kopf">Built with Kubernetes Operator Pythonic Framework (Kopf)</a> There are a few solution for checking the images when you deploy them to the Kubernetes cluster, but fighting against vulnerabilities is a day to day task. Check once is not enough when every day is a new das for frats. That is why I created trivy-operator so you can create scheduled image scans on your running pods.</p>
<h2 id="what-is-new">What is new?</h2>
<p>With the release of trivy-operator 2.5 ther is the fallowin new features:</p>
<ul>
<li>air-gap install</li>
<li>Kubernetes CIS Benchmark with kube-bench-scnner</li>
<li>defectdojo integration</li>
<li>use insecure registry</li>
<li>add new dashboard</li>
</ul>
<h3 id="air-gapped-install">Air-Gapped Install</h3>
<p>To run trivy-operator in an air-gapped environment you need to provide the security database for trivy. You can do that by uploading tha database to an OCI compatible registry.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oras pull ghcr.io/aquasecurity/trivy-db:2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oras push docker.mydomain.intra/trivy-db:2 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>db.tar.gz:application/vnd.aquasec.trivy.db.layer.v1.tar+gzip
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -X GET https://docker.mydomain.intra/v2/_catalog
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;repositories&#34;</span>:<span style="color:#f92672">[</span><span style="color:#e6db74">&#34;nginx&#34;</span>,<span style="color:#e6db74">&#34;trivy-db&#34;</span><span style="color:#f92672">]}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -X GET https://docker.mydomain.intra/v2/trivy-db/tags/list
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;name&#34;</span>:<span style="color:#e6db74">&#34;trivy-db&#34;</span>,<span style="color:#e6db74">&#34;tags&#34;</span>:<span style="color:#f92672">[</span><span style="color:#e6db74">&#34;2&#34;</span><span style="color:#f92672">]}</span>
</span></span></code></pre></div><p>In the helm chart you need to specify the url of your OCI registry with the <code>db_repository</code> option.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Don&#39;t try to download trivy db, run in air-gapped env:</span>
</span></span><span style="display:flex;"><span>offline:
</span></span><span style="display:flex;"><span>  enabled: true
</span></span><span style="display:flex;"><span>  db_repository: docker.mydomain.intra/trivy-db
</span></span></code></pre></div><h3 id="kubernetes-cis-benchmark">Kubernetes CIS Benchmark</h3>
<p>CIS Benchmark best practices are an important first step to securing Kubernetes in production by hardening Kubernetes environments. Trivy-operator use kube-bench to scan the kubernetes cluster and create CIS Benchmark reports. To enable the CIS Benchmark scanning function you need to create a ClusterScanner.</p>
<p>The following example object is configured to:</p>
<ul>
<li>run the vulnerability scan every hour (<code>crontab: '00 * * * *'</code>)</li>
<li>use the <code>cis-1.23</code> scan profile</li>
<li>enable integration to defectdojo</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">trivy-operator.devopstales.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterScanner</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">main-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">crontab</span>: <span style="color:#e6db74">&#34;00 * * * *&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">scanProfileName</span>: <span style="color:#e6db74">&#34;cis-1.23&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">integrations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">defectdojo</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">host</span>: <span style="color:#e6db74">&#34;http://defectdojo.rancher-desktop.intra&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">api_key</span>: <span style="color:#e6db74">&#34;3880d84590915e5c96cec075444f22285ff3659c&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">k8s-cluster-name</span>: <span style="color:#e6db74">&#34;eks-prod&#34;</span>
</span></span></code></pre></div><p>The following list show the ClusterScanner objects listed by the kubectl cli:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get cs-scan
</span></span><span style="display:flex;"><span>NAME          CLUSTERSCANPROFILE   CRONTAB
</span></span><span style="display:flex;"><span>main-config   cis-1.23             <span style="color:#ae81ff">00</span> * * * *
</span></span></code></pre></div><h3 id="enable-defectdojo-integration-for-trivy-operator">Enable DefectDojo integration for trivy-operator</h3>
<p>To enable the DefectDojo integration for trivy-operator you need to enable it in the <code>NamespaceScanner</code> object:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>  <span style="color:#f92672">integrations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">policyreport</span>: <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">defectdojo</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">host</span>: <span style="color:#e6db74">&#34;https://defectdojo.mydomain.intra&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">api_key</span>: <span style="color:#e6db74">&#34;xyz456ucdssd67sd67dsg&#34;</span>
</span></span></code></pre></div><h2 id="usage">Usage</h2>
<p>To ease deployment I created a helm chart for trivy-operator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add devopstales https://devopstales.github.io/helm-charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span></code></pre></div><p>Create a value file for deploy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;&#39;EOF&#39;&gt; values.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">image</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repository</span>: <span style="color:#ae81ff">devopstales/trivy-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">pullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tag</span>: <span style="color:#e6db74">&#34;2.3&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">imagePullSecrets</span>: []
</span></span><span style="display:flex;"><span><span style="color:#f92672">podSecurityContext</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroup</span>: <span style="color:#ae81ff">10001</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroupChangePolicy</span>: <span style="color:#e6db74">&#34;OnRootMismatch&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceAccount</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;trivy-operator&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">monitoring</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">port</span>: <span style="color:#e6db74">&#34;9115&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;kube-system&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">size</span>: <span style="color:#ae81ff">1Gi</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">NamespaceScanner</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">crontab</span>: <span style="color:#e6db74">&#34;*/5 * * * *&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespaceSelector</span>: <span style="color:#e6db74">&#34;trivy-scan&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">registryAuth</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">registry</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">docker.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">user</span>: <span style="color:#e6db74">&#34;user&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">password</span>: <span style="color:#e6db74">&#34;password&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">githubToken</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">token</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>When the trivy in the container want to scan an image first download the vulnerability database from github. If you test many images you need a  <code>githubToken</code> overcome the github rate limit and dockerhub username and password for overcome the dockerhub rate limit. If your store you images in a private repository you need to add an username and password for authentication.</p>
<p>The following tables lists configurable parameters of the trivy-operator chart and their default values.</p>
<h2 id="values">Values</h2>
<table>
  <thead>
      <tr>
          <th>Key</th>
          <th>Type</th>
          <th>Default</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>TimeZone</td>
          <td>string</td>
          <td><code>&quot;UTC&quot;</code></td>
          <td>Time Zone in container</td>
      </tr>
      <tr>
          <td>admissionController.enabled</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>enable adission controller</td>
      </tr>
      <tr>
          <td>affinity</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>Set the affinity for the pod.</td>
      </tr>
      <tr>
          <td>cache.enabled</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>enable redis cache</td>
      </tr>
      <tr>
          <td>clusterScanner.crontab</td>
          <td>string</td>
          <td><code>&quot;*/1 * * * *&quot;</code></td>
          <td>crontab for scheduled scan</td>
      </tr>
      <tr>
          <td>clusterScanner.enabled</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>enable clusterScanner cr creation</td>
      </tr>
      <tr>
          <td>clusterScanner.integrations</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>configure defectdojo integration</td>
      </tr>
      <tr>
          <td>clusterScanner.scanProfileName</td>
          <td>string</td>
          <td><code>&quot;cis-1.23&quot;</code></td>
          <td>kube-hunter scan profile</td>
      </tr>
      <tr>
          <td>githubToken.enabled</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>enable github authentiation token</td>
      </tr>
      <tr>
          <td>githubToken.token</td>
          <td>string</td>
          <td><code>&quot;&quot;</code></td>
          <td>github authentiation token value</td>
      </tr>
      <tr>
          <td>grafana.dashboards.enabled</td>
          <td>bool</td>
          <td><code>true</code></td>
          <td>Enable the deployment of grafana dashboards</td>
      </tr>
      <tr>
          <td>grafana.dashboards.label</td>
          <td>string</td>
          <td><code>&quot;grafana_dashboard&quot;</code></td>
          <td>Label to find dashboards using the k8s sidecar</td>
      </tr>
      <tr>
          <td>grafana.dashboards.value</td>
          <td>string</td>
          <td><code>&quot;1&quot;</code></td>
          <td>Label value to find dashboards using the k8s sidecar</td>
      </tr>
      <tr>
          <td>grafana.folder.annotation</td>
          <td>string</td>
          <td><code>&quot;grafana_folder&quot;</code></td>
          <td>Annotation to enable folder storage using the k8s sidecar</td>
      </tr>
      <tr>
          <td>grafana.folder.name</td>
          <td>string</td>
          <td><code>&quot;Policy Reporter&quot;</code></td>
          <td>Grafana folder in which to store the dashboards</td>
      </tr>
      <tr>
          <td>grafana.namespace</td>
          <td>string</td>
          <td><code>nil</code></td>
          <td>namespace for configMap of grafana dashboards</td>
      </tr>
      <tr>
          <td>image.pullPolicy</td>
          <td>string</td>
          <td><code>&quot;Always&quot;</code></td>
          <td>The docker image pull policy</td>
      </tr>
      <tr>
          <td>image.repository</td>
          <td>string</td>
          <td><code>&quot;devopstales/trivy-operator&quot;</code></td>
          <td>The docker image repository to use</td>
      </tr>
      <tr>
          <td>image.tag</td>
          <td>string</td>
          <td><code>&quot;2.5.0&quot;</code></td>
          <td>The docker image tag to use</td>
      </tr>
      <tr>
          <td>imagePullSecrets</td>
          <td>list</td>
          <td><code>[]</code></td>
          <td>list of secrets to use for imae pull</td>
      </tr>
      <tr>
          <td>kube_bench_scnner.image.pullPolicy</td>
          <td>string</td>
          <td><code>&quot;Always&quot;</code></td>
          <td>The docker image pull policy</td>
      </tr>
      <tr>
          <td>kube_bench_scnner.image.repository</td>
          <td>string</td>
          <td><code>&quot;devopstales/kube-bench-scnner&quot;</code></td>
          <td>The docker image repository to use</td>
      </tr>
      <tr>
          <td>kube_bench_scnner.image.tag</td>
          <td>string</td>
          <td><code>&quot;2.5&quot;</code></td>
          <td>The docker image tag to use</td>
      </tr>
      <tr>
          <td>log_level</td>
          <td>string</td>
          <td><code>&quot;INFO&quot;</code></td>
          <td>Log level</td>
      </tr>
      <tr>
          <td>monitoring.port</td>
          <td>string</td>
          <td><code>&quot;9115&quot;</code></td>
          <td>configure prometheus monitoring port</td>
      </tr>
      <tr>
          <td>namespaceScanner.clusterWide</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td></td>
      </tr>
      <tr>
          <td>namespaceScanner.crontab</td>
          <td>string</td>
          <td><code>&quot;*/5 * * * *&quot;</code></td>
          <td></td>
      </tr>
      <tr>
          <td>namespaceScanner.integrations.policyreport</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td></td>
      </tr>
      <tr>
          <td>namespaceScanner.namespaceSelector</td>
          <td>string</td>
          <td><code>&quot;trivy-scan&quot;</code></td>
          <td></td>
      </tr>
      <tr>
          <td>nodeSelector</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>Set the node selector for the pod.</td>
      </tr>
      <tr>
          <td>offline.db_repository</td>
          <td>string</td>
          <td><code>&quot;localhost:5000/trivy-db&quot;</code></td>
          <td>repository to use for download trivy vuln db</td>
      </tr>
      <tr>
          <td>offline.db_repository_insecure</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>insecure repository</td>
      </tr>
      <tr>
          <td>offline.enabled</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>enable air-gapped mode</td>
      </tr>
      <tr>
          <td>persistence.accessMode</td>
          <td>string</td>
          <td><code>&quot;ReadWriteOnce&quot;</code></td>
          <td>Volumes mode</td>
      </tr>
      <tr>
          <td>persistence.annotations</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>Volumes annotations</td>
      </tr>
      <tr>
          <td>persistence.enabled</td>
          <td>bool</td>
          <td><code>true</code></td>
          <td>Volumes for the pod</td>
      </tr>
      <tr>
          <td>persistence.size</td>
          <td>string</td>
          <td><code>&quot;1Gi&quot;</code></td>
          <td>Volumes size</td>
      </tr>
      <tr>
          <td>podSecurityContext</td>
          <td>object</td>
          <td><code>{&quot;fsGroup&quot;:10001,&quot;fsGroupChangePolicy&quot;:&quot;OnRootMismatch&quot;}</code></td>
          <td>security options for the pod</td>
      </tr>
      <tr>
          <td>registryAuth.enabled</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>enable registry authentication</td>
      </tr>
      <tr>
          <td>registryAuth.image_pull_secrets</td>
          <td>list</td>
          <td><code>[&quot;regcred&quot;]</code></td>
          <td>list of image pull secrets for authentication</td>
      </tr>
      <tr>
          <td>serviceAccount.annotations</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>serviceAccount annotations</td>
      </tr>
      <tr>
          <td>serviceAccount.create</td>
          <td>bool</td>
          <td><code>true</code></td>
          <td>Enable serviceAccount creation</td>
      </tr>
      <tr>
          <td>serviceAccount.name</td>
          <td>string</td>
          <td><code>&quot;trivy-operator&quot;</code></td>
          <td>Name of the serviceAccount</td>
      </tr>
      <tr>
          <td>serviceMonitor.enabled</td>
          <td>bool</td>
          <td><code>false</code></td>
          <td>allow to override the namespace for serviceMonitor</td>
      </tr>
      <tr>
          <td>serviceMonitor.labels.release</td>
          <td>string</td>
          <td><code>&quot;prometheus&quot;</code></td>
          <td>labels to match the serviceMonitorSelector of the Prometheus Resource</td>
      </tr>
      <tr>
          <td>serviceMonitor.metricRelabelings</td>
          <td>list</td>
          <td><code>[]</code></td>
          <td>metricRelabeling config for serviceMonitor</td>
      </tr>
      <tr>
          <td>serviceMonitor.namespace</td>
          <td>object</td>
          <td><code>{}</code></td>
          <td>Name of the namespace for serviceMonitor</td>
      </tr>
      <tr>
          <td>serviceMonitor.relabelings</td>
          <td>list</td>
          <td><code>[]</code></td>
          <td>relabel config for serviceMonitor</td>
      </tr>
      <tr>
          <td>tolerations</td>
          <td>list</td>
          <td><code>[]</code></td>
          <td>Set the tolerations for the pod.</td>
      </tr>
  </tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns trivy-operator
</span></span><span style="display:flex;"><span>kubens trivy-operator
</span></span><span style="display:flex;"><span>helm upgrade --install trivy devopstales/trivy-operator -f values.yaml
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-operators" term="k8s-operators" label="k8s-operators" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="trivy-operator" term="trivy-operator" label="trivy-operator" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Debug with Ephemeral Containers]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-ephemerald-pod/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-pomerium-ingress-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Secure your applications with Pomerium Ingress Controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-change-ip/?utm_source=atom_feed" rel="related" type="text/html" title="How to Change IP on Kubernetes node." />
                <link href="https://devopstales.github.io/kubernetes/migrate-kubernetes-to-dockershim/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Install cri-dockerd for docker" />
                <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Migrate from docker to containerd" />
                <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-crio/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Migrate from docker to cri-o" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-ephemerald-pod/</id>
            
            
            <published>2022-09-12T00:00:00+00:00</published>
            <updated>2022-09-12T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can debug your application in a pod with a new function called Ephemeral Containers released in Kubernetes 1.25.</p>
<p>In security perspective it is a best practice to create a container with only the necessary tools to run the app. This means when your application not working correctly you didn&rsquo;t have the tools to debug. You can try to copy the tools to the container on-demand with <code>kubectl cp</code> but it isn&rsquo;t always possible.</p>
<p>So what Other option we have? With the new Ephemeral Containers option we can add a new container to the existing pod and use this container to debug. This option is available in k8s versions 1.23 and become Generally Available with 1.25. In practice Kubernetes extended the Pod object specification with a new <code>ephemeralContainers</code> attribute. This attribute holds a list of <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#container-v1-core">Container v1 core</a> objects.</p>
<h3 id="demo-time">Demo time</h3>
<p>For demo purpose I will use a distroless python container. &ldquo;Distroless&rdquo; images contain only your application and its runtime dependencies. They do not contain package managers, shells or any other programs you would expect to find in a standard Linux distribution, so it is perfect for the demo.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apiVersion: apps/v1
</span></span><span style="display:flex;"><span>kind: Deployment
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: slim
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  selector:
</span></span><span style="display:flex;"><span>    matchLabels:
</span></span><span style="display:flex;"><span>      app: slim
</span></span><span style="display:flex;"><span>  template:
</span></span><span style="display:flex;"><span>    metadata:
</span></span><span style="display:flex;"><span>      labels:
</span></span><span style="display:flex;"><span>        app: slim
</span></span><span style="display:flex;"><span>    spec:
</span></span><span style="display:flex;"><span>      containers:
</span></span><span style="display:flex;"><span>      - name: app
</span></span><span style="display:flex;"><span>        image: gcr.io/distroless/python3-debian11
</span></span><span style="display:flex;"><span>        command:
</span></span><span style="display:flex;"><span>        - python
</span></span><span style="display:flex;"><span>        - -m
</span></span><span style="display:flex;"><span>        - http.server
</span></span><span style="display:flex;"><span>        - <span style="color:#e6db74">&#39;8080&#39;</span>
</span></span><span style="display:flex;"><span>EOF
</span></span></code></pre></div><p>Now I will try to login to the container:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>POD_NAME<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>kubectl get pods -l app<span style="color:#f92672">=</span>slim -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{.items[0].metadata.name}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># no bash in the container</span>
</span></span><span style="display:flex;"><span>$ kubectl exec -it -c app <span style="color:#e6db74">${</span>POD_NAME<span style="color:#e6db74">}</span> -- bash
</span></span><span style="display:flex;"><span>error: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec <span style="color:#e6db74">&#34;43d1e91f41310fb1ede9fbab741921091edfe116311f18a3881f90f68d06dc13&#34;</span>: OCI runtime exec failed: exec failed: unable to start container process: exec: <span style="color:#e6db74">&#34;bash&#34;</span>: executable file not found in $PATH: unknown
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ther is sh in the container but limited tools</span>
</span></span><span style="display:flex;"><span>$ kubectl exec -it -c app <span style="color:#e6db74">${</span>POD_NAME<span style="color:#e6db74">}</span> -- sh
</span></span><span style="display:flex;"><span>$# ps
</span></span><span style="display:flex;"><span>sh: 3: ps: not found
</span></span></code></pre></div><p>So, let&rsquo;s try inspecting Pods using an ephemeral container:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl debug -it --attach<span style="color:#f92672">=</span>false -c debugger --image<span style="color:#f92672">=</span>nicolaka/netshoot <span style="color:#e6db74">${</span>POD_NAME<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$  kubectl get pod <span style="color:#e6db74">${</span>POD_NAME<span style="color:#e6db74">}</span>   -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{.spec.ephemeralContainers}&#39;</span> | jq
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;image&#34;</span>: <span style="color:#e6db74">&#34;nicolaka/netshoot&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;imagePullPolicy&#34;</span>: <span style="color:#e6db74">&#34;Always&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;debugger&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;resources&#34;</span>: <span style="color:#f92672">{}</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;stdin&#34;</span>: true,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;terminationMessagePath&#34;</span>: <span style="color:#e6db74">&#34;/dev/termination-log&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;terminationMessagePolicy&#34;</span>: <span style="color:#e6db74">&#34;File&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;tty&#34;</span>: true
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl get pod <span style="color:#e6db74">${</span>POD_NAME<span style="color:#e6db74">}</span>   -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{.status.ephemeralContainerStatuses}&#39;</span> | jq
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;containerID&#34;</span>: <span style="color:#e6db74">&#34;containerd://c3a58d41f5b007aa1d7c2f6758c0d397428bf1d3575380a0661f34efaab4bb34&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;image&#34;</span>: <span style="color:#e6db74">&#34;docker.io/nicolaka/netshoot:latest&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;imageID&#34;</span>: <span style="color:#e6db74">&#34;docker.io/nicolaka/netshoot@sha256:aeafd567d7f7f1edb5127ec311599bb2b8a9c0fb31d7a53e9cff26af6d29fd4e&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;lastState&#34;</span>: <span style="color:#f92672">{}</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;debugger&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;ready&#34;</span>: false,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;restartCount&#34;</span>: 0,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;state&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;running&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;startedAt&#34;</span>: <span style="color:#e6db74">&#34;2022-09-07T08:30:44Z&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">]</span>
</span></span></code></pre></div><p>If the ephemeral container is running, we can try attaching to it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl attach -it -c debugger <span style="color:#e6db74">${</span>POD_NAME<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$# netstat -tulpn
</span></span><span style="display:flex;"><span>Active Internet connections <span style="color:#f92672">(</span>only servers<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
</span></span><span style="display:flex;"><span>tcp        <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span> 0.0.0.0:8080            0.0.0.0:*               LISTEN      -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$# wget -O - 127.0.0.1:8080
</span></span><span style="display:flex;"><span>Connecting to localhost:8080 <span style="color:#f92672">(</span>127.0.0.1:8080<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>writing to stdout
</span></span><span style="display:flex;"><span>&lt;!DOCTYPE HTML PUBLIC <span style="color:#e6db74">&#34;-//W3C//DTD HTML 4.01//EN&#34;</span> <span style="color:#e6db74">&#34;http://www.w3.org/TR/html4/strict.dtd&#34;</span>&gt;
</span></span><span style="display:flex;"><span>&lt;html&gt;
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>&lt;/html&gt;
</span></span></code></pre></div><h3 id="shared-namespace">Shared namespace</h3>
<p>When you try to check the processes in the container you only see the debugger container processes. So, <code>kubectl debug</code> just put the debug container in the same <code>net</code> and <code>ipc</code> linux namespace. I you want to know more about pods an how they work <a href="https://devopstales.github.io/kubernetes/containers-vs-pods/">check my other post about this topic</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$# ps auxf
</span></span><span style="display:flex;"><span>PID   USER     TIME  COMMAND
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">1</span> root      0:00 zsh
</span></span><span style="display:flex;"><span>   <span style="color:#ae81ff">14</span> root      0:00 ps auxf
</span></span></code></pre></div><p>In the <a href="https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/">official documentation</a> there is a workaround to enable shared linux namespaces for the debugger container:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl patch deployment slim --patch <span style="color:#e6db74">&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  template:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      shareProcessNamespace: true&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or just start the debug container with hare-processes in the first place</span>
</span></span><span style="display:flex;"><span>$ kubectl debug -it --attach<span style="color:#f92672">=</span>false -c debugger --image<span style="color:#f92672">=</span>nicolaka/netshoot --share-processes <span style="color:#e6db74">${</span>POD_NAME<span style="color:#e6db74">}</span>
</span></span></code></pre></div><p>Wait for pod restart then test:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get pods
</span></span><span style="display:flex;"><span>NAME                    READY   STATUS        RESTARTS   AGE
</span></span><span style="display:flex;"><span>slim-5f5ffd5958-b9sgt   1/1     Terminating   <span style="color:#ae81ff">0</span>          72m
</span></span><span style="display:flex;"><span>slim-66475779f5-5c27b   1/1     Running       <span style="color:#ae81ff">0</span>          20s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl get pods
</span></span><span style="display:flex;"><span>NAME                    READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>slim-66475779f5-5c27b   1/1     Running   <span style="color:#ae81ff">0</span>          48s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ POD_NAME<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>kubectl get pods -l app<span style="color:#f92672">=</span>slim -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{.items[0].metadata.name}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl debug -it --attach<span style="color:#f92672">=</span>false -c debugger --image<span style="color:#f92672">=</span>nicolaka/netshoot <span style="color:#e6db74">${</span>POD_NAME<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl attach -it -c debugger <span style="color:#e6db74">${</span>POD_NAME<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$# ps aux
</span></span><span style="display:flex;"><span>PID   USER     TIME  COMMAND
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">65535</span>     0:00 /pause
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">7</span> root      0:00 python -m http.server <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>   <span style="color:#ae81ff">14</span> root      0:01 zsh
</span></span><span style="display:flex;"><span>   <span style="color:#ae81ff">72</span> root      0:00 ps aux
</span></span></code></pre></div><p>Now if I want to access the filesystem of the misbehaving container, because of the shared pid linux namespace I have a trick:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># From inside the ephemeral container:</span>
</span></span><span style="display:flex;"><span>$# ls /proc/<span style="color:#66d9ef">$(</span>pgrep python<span style="color:#66d9ef">)</span>/root/usr/bin
</span></span><span style="display:flex;"><span>c_rehash   getconf    iconv      locale     openssl    python     python3.9  zdump
</span></span><span style="display:flex;"><span>catchsegv  getent     ldd        localedef  pldd       python3    tzselect
</span></span></code></pre></div><h3 id="troubleshooting-network-activity">Troubleshooting network activity</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># From inside the ephemeral container:</span>
</span></span><span style="display:flex;"><span>$# tcpdump -i lo -n port <span style="color:#ae81ff">8080</span>
</span></span></code></pre></div><p>Now try to send a request to the pos. For this I will start a port forward and curl it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl port-forward pod/<span style="color:#e6db74">${</span>POD_NAME<span style="color:#e6db74">}</span> 8080:8080 &amp;
</span></span><span style="display:flex;"><span>curl http://127.0.0.1:8080
</span></span></code></pre></div><p>You will see the fallowing:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># From inside the ephemeral container:</span>
</span></span><span style="display:flex;"><span>$# tcpdump -i lo -n port <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>tcpdump: verbose output suppressed, use -v<span style="color:#f92672">[</span>v<span style="color:#f92672">]</span>... <span style="color:#66d9ef">for</span> full protocol decode
</span></span><span style="display:flex;"><span>listening on lo, link-type EN10MB <span style="color:#f92672">(</span>Ethernet<span style="color:#f92672">)</span>, snapshot length <span style="color:#ae81ff">262144</span> bytes
</span></span><span style="display:flex;"><span>09:45:01.727624 IP 127.0.0.1.41968 &gt; 127.0.0.1.8080: Flags <span style="color:#f92672">[</span>S<span style="color:#f92672">]</span>, seq 3878283086, win 65495, options <span style="color:#f92672">[</span>mss 65495,sackOK,TS val <span style="color:#ae81ff">2031418309</span> ecr 0,nop,wscale 7<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>09:45:01.727635 IP 127.0.0.1.8080 &gt; 127.0.0.1.41968: Flags <span style="color:#f92672">[</span>S.<span style="color:#f92672">]</span>, seq 2447903554, ack 3878283087, win 65483, options <span style="color:#f92672">[</span>mss 65495,sackOK,TS val <span style="color:#ae81ff">2031418309</span> ecr 2031418309,nop,wscale 7<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>09:45:01.727643 IP 127.0.0.1.41968 &gt; 127.0.0.1.8080: Flags <span style="color:#f92672">[</span>.<span style="color:#f92672">]</span>, ack 1, win 512, options <span style="color:#f92672">[</span>nop,nop,TS val <span style="color:#ae81ff">2031418309</span> ecr 2031418309<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>09:45:01.734499 IP 127.0.0.1.41968 &gt; 127.0.0.1.8080: Flags <span style="color:#f92672">[</span>P.<span style="color:#f92672">]</span>, seq 1:79, ack 1, win 512, options <span style="color:#f92672">[</span>nop,nop,TS val <span style="color:#ae81ff">2031418316</span> ecr 2031418309<span style="color:#f92672">]</span>, length 78: HTTP: GET / HTTP/1.1
</span></span><span style="display:flex;"><span>09:45:01.734521 IP 127.0.0.1.8080 &gt; 127.0.0.1.41968: Flags <span style="color:#f92672">[</span>.<span style="color:#f92672">]</span>, ack 79, win 511, options <span style="color:#f92672">[</span>nop,nop,TS val <span style="color:#ae81ff">2031418316</span> ecr 2031418316<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>09:45:01.735712 IP 127.0.0.1.8080 &gt; 127.0.0.1.41968: Flags <span style="color:#f92672">[</span>P.<span style="color:#f92672">]</span>, seq 1:155, ack 79, win 512, options <span style="color:#f92672">[</span>nop,nop,TS val <span style="color:#ae81ff">2031418317</span> ecr 2031418316<span style="color:#f92672">]</span>, length 154: HTTP: HTTP/1.0 <span style="color:#ae81ff">200</span> OK
</span></span><span style="display:flex;"><span>09:45:01.735721 IP 127.0.0.1.41968 &gt; 127.0.0.1.8080: Flags <span style="color:#f92672">[</span>.<span style="color:#f92672">]</span>, ack 155, win 511, options <span style="color:#f92672">[</span>nop,nop,TS val <span style="color:#ae81ff">2031418317</span> ecr 2031418317<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>09:45:01.735753 IP 127.0.0.1.8080 &gt; 127.0.0.1.41968: Flags <span style="color:#f92672">[</span>P.<span style="color:#f92672">]</span>, seq 155:961, ack 79, win 512, options <span style="color:#f92672">[</span>nop,nop,TS val <span style="color:#ae81ff">2031418317</span> ecr 2031418317<span style="color:#f92672">]</span>, length 806: HTTP
</span></span><span style="display:flex;"><span>09:45:01.735757 IP 127.0.0.1.41968 &gt; 127.0.0.1.8080: Flags <span style="color:#f92672">[</span>.<span style="color:#f92672">]</span>, ack 961, win 505, options <span style="color:#f92672">[</span>nop,nop,TS val <span style="color:#ae81ff">2031418317</span> ecr 2031418317<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>09:45:01.735800 IP 127.0.0.1.8080 &gt; 127.0.0.1.41968: Flags <span style="color:#f92672">[</span>F.<span style="color:#f92672">]</span>, seq 961, ack 79, win 512, options <span style="color:#f92672">[</span>nop,nop,TS val <span style="color:#ae81ff">2031418317</span> ecr 2031418317<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>09:45:01.742812 IP 127.0.0.1.41968 &gt; 127.0.0.1.8080: Flags <span style="color:#f92672">[</span>F.<span style="color:#f92672">]</span>, seq 79, ack 962, win 512, options <span style="color:#f92672">[</span>nop,nop,TS val <span style="color:#ae81ff">2031418324</span> ecr 2031418317<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>09:45:01.742820 IP 127.0.0.1.8080 &gt; 127.0.0.1.41968: Flags <span style="color:#f92672">[</span>.<span style="color:#f92672">]</span>, ack 80, win 512, options <span style="color:#f92672">[</span>nop,nop,TS val <span style="color:#ae81ff">2031418324</span> ecr 2031418324<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
</span></span></code></pre></div><h3 id="tracingprofiling-processes-using-ephemeral-containers">Tracing/profiling processes using ephemeral containers.</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># From inside the ephemeral container:</span>
</span></span><span style="display:flex;"><span>$# ps aux
</span></span><span style="display:flex;"><span>PID   USER     TIME  COMMAND
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">65535</span>     0:00 /pause
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">7</span> root      0:00 python -m http.server <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>   <span style="color:#ae81ff">14</span> root      0:01 zsh
</span></span><span style="display:flex;"><span>   <span style="color:#ae81ff">72</span> root      0:00 ps aux
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$# strace -p <span style="color:#ae81ff">7</span>
</span></span><span style="display:flex;"><span>strace: Process <span style="color:#ae81ff">7</span> attached
</span></span><span style="display:flex;"><span>restart_syscall<span style="color:#f92672">(</span>&lt;... resuming interrupted read ...&gt;<span style="color:#f92672">)</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, revents<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}])</span>
</span></span><span style="display:flex;"><span>accept4<span style="color:#f92672">(</span>3, <span style="color:#f92672">{</span>sa_family<span style="color:#f92672">=</span>AF_INET, sin_port<span style="color:#f92672">=</span>htons<span style="color:#f92672">(</span>40652<span style="color:#f92672">)</span>, sin_addr<span style="color:#f92672">=</span>inet_addr<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;127.0.0.1&#34;</span><span style="color:#f92672">)}</span>, <span style="color:#f92672">[</span>16<span style="color:#f92672">]</span>, SOCK_CLOEXEC<span style="color:#f92672">)</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>getsockname<span style="color:#f92672">(</span>4, <span style="color:#f92672">{</span>sa_family<span style="color:#f92672">=</span>AF_INET, sin_port<span style="color:#f92672">=</span>htons<span style="color:#f92672">(</span>8080<span style="color:#f92672">)</span>, sin_addr<span style="color:#f92672">=</span>inet_addr<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;127.0.0.1&#34;</span><span style="color:#f92672">)}</span>, <span style="color:#f92672">[</span>128 <span style="color:#f92672">=</span>&gt; 16<span style="color:#f92672">])</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>clone<span style="color:#f92672">(</span>child_stack<span style="color:#f92672">=</span>0x7f57a50ccfb0, flags<span style="color:#f92672">=</span>CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tid<span style="color:#f92672">=[</span>299<span style="color:#f92672">]</span>, tls<span style="color:#f92672">=</span>0x7f57a50cd700, child_tidptr<span style="color:#f92672">=</span>0x7f57a50cd9d0<span style="color:#f92672">)</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">299</span>
</span></span><span style="display:flex;"><span>futex<span style="color:#f92672">(</span>0x93a56c, FUTEX_WAKE_PRIVATE, 1<span style="color:#f92672">)</span>  <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>futex<span style="color:#f92672">(</span>0x93a570, FUTEX_WAKE_PRIVATE, 1<span style="color:#f92672">)</span>  <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500<span style="color:#f92672">)</span>   <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>Timeout<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>poll<span style="color:#f92672">([{</span>fd<span style="color:#f92672">=</span>3, events<span style="color:#f92672">=</span>POLLIN<span style="color:#f92672">}]</span>, 1, 500^Cstrace: Process <span style="color:#ae81ff">8</span> detached
</span></span><span style="display:flex;"><span> &lt;detached ...&gt;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$# strace -f -p <span style="color:#ae81ff">7</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                             
                                <category scheme="kubernetes" term="kubernetes" label="kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-migrate-from-psp/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-ps/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Pod Security Admission" />
                <link href="https://devopstales.github.io/kubernetes/k8s-pod-security-standards-using-kyverno/?utm_source=atom_feed" rel="related" type="text/html" title="Pod Security Standards using Kyverno" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
                <link href="https://devopstales.github.io/kubernetes/k8s-change-ip/?utm_source=atom_feed" rel="related" type="text/html" title="How to Change IP on Kubernetes node." />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-migrate-from-psp/</id>
            
            
            <published>2022-08-24T00:00:00+00:00</published>
            <updated>2022-08-24T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>With the release of Kubernetes v1.25, Pod Security admission has now entered to stable and PodSecurityPolicy is removed. In this article, I will show you how you can migrate to the new Pod Security Admission.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="requirements-and-limitations">Requirements and limitations</h3>
<ul>
<li><code>PodSecurity</code> is available in k8s versions 1.23 and later.</li>
<li><code>PodSecurity</code> doesn&rsquo;t terminate Pods that are already running on your nodes, even if they violate the applied policy.</li>
<li><code>PodSecurity</code> doesn&rsquo;t mutate fields. If you use any mutating fields in your PodSecurityPolicy, modify your Pod spec to ensure that those fields are present when you deploy the workloads.</li>
</ul>
<h3 id="configure-the-podsecurity-admission-controller-in-your-cluster">Configure the PodSecurity admission controller in your cluster</h3>
<p>In a nutshell <code>PodSecurity</code> enforces Pod Security Standards at the namespace level. So you need to chose one predefined policies fo every namespaces. The following policies are available:</p>
<ul>
<li><code>Restricted</code>: Most restrictive policy. Complies with Pod hardening best practices.</li>
<li><code>Baseline</code>: Minimally restrictive policy that prevents known privilege escalations. Allows all default values for fields in Pod specifications.</li>
<li><code>Privileged</code>: Unrestricted policy that allows anything, including known privilege escalations. Apply this policy with caution.</li>
</ul>
<h3 id="eliminate-mutating-podsecuritypolicies-if-your-cluster-has-any-set-up">Eliminate mutating PodSecurityPolicies, if your cluster has any set up.</h3>
<ul>
<li>Clone all mutating PSPs into a non-mutating version.</li>
<li>Update all ClusterRoles authorizing use of those mutating PSPs to also authorize use of the non-mutating variant.</li>
<li>Watch for Pods using the mutating PSPs and work with code owners to migrate to valid, non-mutating resources.</li>
<li>Delete mutating PSPs.</li>
</ul>
<p>You can start by eliminating the fields that are purely mutating, and don&rsquo;t have any bearing on the validating policy:</p>
<ul>
<li><code>.spec.defaultAllowPrivilegeEscalation</code></li>
<li><code>.spec.runtimeClass.defaultRuntimeClassName</code></li>
<li><code>.metadata.annotations['seccomp.security.alpha.kubernetes.io/defaultProfileName']</code></li>
<li><code>.metadata.annotations['apparmor.security.beta.kubernetes.io/defaultProfileName']</code></li>
<li><code>.spec.defaultAddCapabilities</code> - Although technically a mutating &amp; validating field, these should be merged into <code>.spec.allowedCapabilities</code> which performs the same validation without mutation.</li>
</ul>
<p>There are several fields in PodSecurityPolicy that are not covered by the Pod Security Standards:</p>
<ul>
<li><code>.spec.allowedHostPaths</code></li>
<li><code>.spec.allowedFlexVolumes</code></li>
<li><code>.spec.allowedCSIDrivers</code></li>
<li><code>.spec.forbiddenSysctls</code></li>
<li><code>.spec.runtimeClass</code></li>
<li><code>.spec.requiredDropCapabilities</code> - Required to drop ALL for the Restricted profile.</li>
<li><code>.spec.seLinux</code> - (Only mutating with the MustRunAs rule) required to enforce the SELinux requirements of the Baseline &amp; Restricted profiles.</li>
<li><code>.spec.runAsUser</code> - (Non-mutating with the RunAsAny rule) required to enforce RunAsNonRoot for the Restricted profile.</li>
<li><code>.spec.allowPrivilegeEscalation</code> - (Only mutating if set to false) required for the Restricted profile</li>
</ul>
<p>Identify pods running under the original PSP. This can be done using the <code>kubernetes.io/psp</code> annotation. For example, using <code>kubectl</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>PSP_NAME<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;original&#34;</span> <span style="color:#75715e"># Set the name of the PSP you&#39;re checking for</span>
</span></span><span style="display:flex;"><span>kubectl get pods --all-namespaces -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{range .items[?(@.metadata.annotations.kubernetes\.io\/psp==&#39;</span>$PSP_NAME<span style="color:#e6db74">&#39;)]}{.metadata.namespace} {.metadata.name}{&#39;\n&#39;}{end}&#34;</span>
</span></span></code></pre></div><p>Compare these running pods against the original pod spec to determine whether <code>PodSecurityPolicy</code> has modified the pod. For pods created by a workload resource you can compare the pod with the PodTemplate in the controller resource.</p>
<p>Create the new <code>PodSecurityPolicies</code>. If any Roles or ClusterRoles are granting use on all PSPs this could cause the new PSPs to be used instead of their mutating counter-parts.</p>
<p>Update your authorization to grant access to the new PSPs. In RBAC this means updating any Roles or ClusterRoles that grant the use permision on the original PSP to also grant it to the updated PSP.</p>
<p>Verify: after some soak time, rerun the command from the begging to see if any pods are still using the original PSPs. Note that pods need to be recreated after the new policies have been rolled out before they can be fully verified.</p>
<p>Once you have verified that the original PSPs are no longer in use, you can delete them.</p>
<h3 id="apply-a-pod-security-standards-in-dry-run-mode-fo-each-namespace">Apply a Pod Security Standards in dry-run mode fo each namespace</h3>
<p>Apply the Restricted policy in dry-run mode:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl label --dry-run<span style="color:#f92672">=</span>server --overwrite ns $NAMESPACE <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    pod-security.kubernetes.io/enforce<span style="color:#f92672">=</span>restricted
</span></span></code></pre></div><p>If a Pod in the namespace violates the Restricted policy, the output is similar to the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Warning: existing pods in namespace <span style="color:#e6db74">&#34;NAMESPACE&#34;</span> violate the new PodSecurity enforce level <span style="color:#e6db74">&#34;restricted:latest&#34;</span>
</span></span><span style="display:flex;"><span>namespace/NAMESPACE labeled
</span></span></code></pre></div><p>If the Restricted policy displays a warning, modify your Pods to fix the violation and try the command again. Alternatively, try the less restrictive Baseline policy in the following step.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl label --dry-run<span style="color:#f92672">=</span>server --overwrite ns NAMESPACE <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    pod-security.kubernetes.io/enforce<span style="color:#f92672">=</span>baseline
</span></span></code></pre></div><blockquote>
<p>Caution: You can optionally use the Privileged policy, which has no restrictions. Before using the Privileged policy, ensure that you trust all workloads and users that have access to the namespace. The Privileged policy allows known privilege escalations, but may be required for certain privileged system workloads.</p></blockquote>
<h3 id="enforce-the-policy-on-a-namespace">Enforce the policy on a namespace</h3>
<p>When you identify the policy that works for a namespace, apply the policy to the namespace in <code>enforce</code> mode:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl label --overwrite ns $NAMESPACE <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    pod-security.kubernetes.io/enforce<span style="color:#f92672">=</span>restricted
</span></span></code></pre></div><h3 id="review-namespace-creation-processes">Review namespace creation processes</h3>
<p>Updating the existing namespace is one thing, but you need to create the new namespaces wit  Pod Security Admission. You can use Kyverno to automaticle add the necessary label to the namespace at creation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apiVersion: kyverno.io/v1
</span></span><span style="display:flex;"><span>kind: ClusterPolicy
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: add-psa-labels
</span></span><span style="display:flex;"><span>  annotations:
</span></span><span style="display:flex;"><span>    policies.kyverno.io/title: Add PSA Labels
</span></span><span style="display:flex;"><span>    policies.kyverno.io/category: Pod Security Admission
</span></span><span style="display:flex;"><span>    policies.kyverno.io/severity: medium
</span></span><span style="display:flex;"><span>    kyverno.io/kyverno-version: 1.7.1
</span></span><span style="display:flex;"><span>    policies.kyverno.io/minversion: 1.6.0
</span></span><span style="display:flex;"><span>    kyverno.io/kubernetes-version: <span style="color:#e6db74">&#34;1.24&#34;</span>
</span></span><span style="display:flex;"><span>    policies.kyverno.io/subject: Namespace
</span></span><span style="display:flex;"><span>    policies.kyverno.io/description: &gt;-
</span></span><span style="display:flex;"><span>      Pod Security Admission <span style="color:#f92672">(</span>PSA<span style="color:#f92672">)</span> can be controlled via the assignment of labels
</span></span><span style="display:flex;"><span>      at the Namespace level which define the Pod Security Standard <span style="color:#f92672">(</span>PSS<span style="color:#f92672">)</span> profile
</span></span><span style="display:flex;"><span>      in use and the action to take. If not using a cluster-wide configuration
</span></span><span style="display:flex;"><span>      via an AdmissionConfiguration file, Namespaces must be explicitly labeled.
</span></span><span style="display:flex;"><span>      This policy assigns the labels <span style="color:#e6db74">`</span>pod-security.kubernetes.io/enforce<span style="color:#f92672">=</span>baseline<span style="color:#e6db74">`</span>
</span></span><span style="display:flex;"><span>      and <span style="color:#e6db74">`</span>pod-security.kubernetes.io/warn<span style="color:#f92672">=</span>restricted<span style="color:#e6db74">`</span> to all new Namespaces <span style="color:#66d9ef">if</span>
</span></span><span style="display:flex;"><span>      those labels are not included.
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  rules:
</span></span><span style="display:flex;"><span>  - name: add-baseline-enforce-restricted-warn
</span></span><span style="display:flex;"><span>    match:
</span></span><span style="display:flex;"><span>      any:
</span></span><span style="display:flex;"><span>      - resources:
</span></span><span style="display:flex;"><span>          kinds:
</span></span><span style="display:flex;"><span>          - Namespace
</span></span><span style="display:flex;"><span>    mutate:
</span></span><span style="display:flex;"><span>      patchStrategicMerge:
</span></span><span style="display:flex;"><span>        metadata:
</span></span><span style="display:flex;"><span>          labels:
</span></span><span style="display:flex;"><span>            +<span style="color:#f92672">(</span>pod-security.kubernetes.io/enforce<span style="color:#f92672">)</span>: baseline
</span></span><span style="display:flex;"><span>            +<span style="color:#f92672">(</span>pod-security.kubernetes.io/warn<span style="color:#f92672">)</span>: restricted
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: kyverno.io/v1
</span></span><span style="display:flex;"><span>kind: ClusterPolicy
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: deny-privileged-profile
</span></span><span style="display:flex;"><span>  annotations:
</span></span><span style="display:flex;"><span>    policies.kyverno.io/title: Deny Privileged Profile
</span></span><span style="display:flex;"><span>    policies.kyverno.io/category: Pod Security Admission
</span></span><span style="display:flex;"><span>    policies.kyverno.io/severity: medium
</span></span><span style="display:flex;"><span>    kyverno.io/kyverno-version: 1.7.1
</span></span><span style="display:flex;"><span>    policies.kyverno.io/minversion: 1.6.0
</span></span><span style="display:flex;"><span>    kyverno.io/kubernetes-version: <span style="color:#e6db74">&#34;1.24&#34;</span>
</span></span><span style="display:flex;"><span>    policies.kyverno.io/subject: Namespace
</span></span><span style="display:flex;"><span>    policies.kyverno.io/description: &gt;-
</span></span><span style="display:flex;"><span>      When Pod Security Admission <span style="color:#f92672">(</span>PSA<span style="color:#f92672">)</span> is enforced at the cluster level
</span></span><span style="display:flex;"><span>      via an AdmissionConfiguration file which defines a default level at
</span></span><span style="display:flex;"><span>      baseline or restricted, setting of a label at the <span style="color:#e6db74">`</span>privileged<span style="color:#e6db74">`</span> profile
</span></span><span style="display:flex;"><span>      will effectively cause unrestricted workloads in that Namespace, overriding
</span></span><span style="display:flex;"><span>      the cluster default. This may effectively represent a circumvention attempt
</span></span><span style="display:flex;"><span>      and should be closely controlled. This policy ensures that only those holding
</span></span><span style="display:flex;"><span>      the cluster-admin ClusterRole may create Namespaces which assign the label
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">`</span>pod-security.kubernetes.io/enforce<span style="color:#f92672">=</span>privileged<span style="color:#e6db74">`</span>.
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  validationFailureAction: audit
</span></span><span style="display:flex;"><span>  rules:
</span></span><span style="display:flex;"><span>  - name: check-privileged
</span></span><span style="display:flex;"><span>    match:
</span></span><span style="display:flex;"><span>      any:
</span></span><span style="display:flex;"><span>      - resources:
</span></span><span style="display:flex;"><span>          kinds:
</span></span><span style="display:flex;"><span>            - Namespace
</span></span><span style="display:flex;"><span>          selector:
</span></span><span style="display:flex;"><span>            matchLabels:
</span></span><span style="display:flex;"><span>              pod-security.kubernetes.io/enforce: privileged
</span></span><span style="display:flex;"><span>    exclude:
</span></span><span style="display:flex;"><span>      any:
</span></span><span style="display:flex;"><span>      - clusterRoles:
</span></span><span style="display:flex;"><span>        - cluster-admin
</span></span><span style="display:flex;"><span>    validate:
</span></span><span style="display:flex;"><span>      message: Only cluster-admins may create Namespaces that allow setting the privileged level.
</span></span><span style="display:flex;"><span>      deny: <span style="color:#f92672">{}</span>
</span></span></code></pre></div><p><a href="/kubernetes/k8s-pod-security-standards-using-kyverno/">In a previous Post</a> I showed you how you can use Kyverno instal of Pod Security Admission.</p>
<h3 id="disable-the-podsecuritypolicy-feature-on-your-cluster">Disable the PodSecurityPolicy feature on your cluster</h3>
<p>On all master edit tha api-server config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/kubernetes/manifests/kube-apiserver.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  containers:
</span></span><span style="display:flex;"><span>  - command:
</span></span><span style="display:flex;"><span>    - kube-apiserver
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span><span style="color:#75715e">#    - --enable-admission-plugins=&#34;NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,PodSecurityPolicy&#34;</span>
</span></span><span style="display:flex;"><span>    - --enable-admission-plugins<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook&#34;</span>
</span></span></code></pre></div><p>Restart the api-server pod.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Pod Security Admission]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-ps/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-pod-security-standards-using-kyverno/?utm_source=atom_feed" rel="related" type="text/html" title="Pod Security Standards using Kyverno" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
                <link href="https://devopstales.github.io/kubernetes/k8s-change-ip/?utm_source=atom_feed" rel="related" type="text/html" title="How to Change IP on Kubernetes node." />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-ps/</id>
            
            
            <published>2022-08-23T00:00:00+00:00</published>
            <updated>2022-08-23T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>With the release of Kubernetes v1.25, Pod Security Admission has now entered to stable and PodSecurityPolicy is removed. In this article, we cover the key concepts of Pod Security Admission along with how to use it.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-a-pod-security-policy">What is a Pod Security Policy?</h3>
<p>A Pod Security Policy is a cluster-level resource that controls security sensitive aspects of the pod specification. RBAC Controlls the usable Kubernetes objects for a user but nt the conditions of a specific ofject like allow run as root or not in a container.  PSP objects define a set of conditions that a pod must run with in order to be accepted into the system, as well as defaults for their related fields. PodSecurityPolicy is an optional admission controller that is enabled by default through the API, thus policies can be deployed without the PSP admission plugin enabled.</p>
<h3 id="what-is-a-pod-security-admission">What is a Pod Security Admission</h3>
<p>Pod Security Admissionis the successor to <code>PodSecurityPolicy</code> which was deprecated in the v1.21 release, and will be removed in Kubernetes v1.25. Pod Security Admission overcomes key shortcomings of Kubernetes&rsquo; existing, PodSecurityPolicy (PSP) mechanism like: challenging to deploy with controllers and teh lack of dry-run/audit capabilities made it hard to enable PodSecurityPolicy.</p>
<h3 id="configuring-pod-security-admission">Configuring Pod Security Admission</h3>
<p>Pod Security Admission use profiles based on <a href="https://kubernetes.io/docs/concepts/security/pod-security-standards/">Pod Security Standards</a>. These standards define three different policy levels:</p>
<ul>
<li>privileged - Unrestricted policy that allows anything, including known privilege escalations. Apply this policy with caution.</li>
<li>baseline - Minimally restrictive policy that prevents known privilege escalations. Allows all default values for fields in Pod specifications.
<ul>
<li>Disables <code>HostProcess</code> for windows</li>
<li>Disables <code>Host Namespaces</code> on linux like: <code>hostNetwork</code>, <code>hostPID</code> and <code>hostIPC</code></li>
<li>Disables <code>Privileged Containers</code></li>
<li>Disallow adding of <code>Capabilities</code></li>
<li>Disallow mounting of <code>HostPath Volumes</code></li>
<li>Disallow usage of <code>Host Ports</code></li>
<li>On supported hosts, the <code>runtime/default</code> AppArmor profile is applied by default.</li>
<li>Setting the SELinux type is restricted, and setting a custom SELinux user or role option is forbidden.</li>
<li>Seccomp profile must not be explicitly set to <code>Unconfined</code>.</li>
<li>Disallow the configuration of <code>Sysctls</code></li>
</ul>
</li>
<li>restricted - Most restrictive policy. Complies with Pod hardening best practices.
<ul>
<li>Disallow <code>Privilege Escalation</code></li>
<li>Disallow running cotainer as root user, group and uid or guid as 0</li>
<li>Seccomp profile must be explicitly set to one of the allowed values.</li>
<li>Containers must drop <code>ALL</code> capabilities, and are only permitted to add back the <code>NET_BIND_SERVICE</code> capability.</li>
</ul>
</li>
</ul>
<p>Policies are applied in a specific mode. The modes are:</p>
<ul>
<li><code>enforce</code> — Any Pods that violate the policy will be rejected</li>
<li><code>audit</code> — Violations will be recorded as an annotation in the audit logs, but don&rsquo;t affect whether the pod is allowed.</li>
<li><code>warn</code> — Violations will send a warning message back to the user, but don&rsquo;t affect whether the pod is allowed.</li>
</ul>
<h3 id="demo">Demo:</h3>
<p>Start a cluster with kind for the demo:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kind create cluster --image kindest/node:v1.23.0
</span></span><span style="display:flex;"><span>kubectl cluster-info --context kind-kind
</span></span><span style="display:flex;"><span>kubectx kind-kind
</span></span></code></pre></div><p>Find the enabled admission plugins:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl -n kube-system exec kube-apiserver-kind-control-plane -it -- kube-apiserver -h | grep <span style="color:#e6db74">&#34;default enabled ones&#34;</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>      --enable-admission-plugins strings
</span></span><span style="display:flex;"><span>admission plugins that should be enabled in addition
</span></span><span style="display:flex;"><span>to default enabled ones <span style="color:#f92672">(</span>NamespaceLifecycle, LimitRanger,
</span></span><span style="display:flex;"><span>ServiceAccount, TaintNodesByCondition, PodSecurity, Priority,
</span></span><span style="display:flex;"><span>DefaultTolerationSeconds, DefaultStorageClass,
</span></span><span style="display:flex;"><span>StorageObjectInUseProtection, PersistentVolumeClaimResize,
</span></span><span style="display:flex;"><span>RuntimeClass, CertificateApproval, CertificateSigning,
</span></span><span style="display:flex;"><span>CertificateSubjectRestriction, DefaultIngressClass,
</span></span><span style="display:flex;"><span>MutatingAdmissionWebhook, ValidatingAdmissionWebhook,
</span></span><span style="display:flex;"><span>ResourceQuota<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>Policies are applied to a namespace via labels. These labels are as follows:</p>
<ul>
<li>pod-security.kubernetes.io/<MODE>: <LEVEL> (required to enable pod security Admission)</li>
<li>pod-security.kubernetes.io/<MODE>-version: <VERSION> (optional, defaults to latest)</li>
</ul>
<p>Deploy demo workload:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns verify-pod-security
</span></span><span style="display:flex;"><span>kubens verify-pod-security
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># enforces a &#34;restricted&#34; security policy and audits on restricted</span>
</span></span><span style="display:flex;"><span>kubectl label --overwrite ns verify-pod-security <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  pod-security.kubernetes.io/enforce<span style="color:#f92672">=</span>restricted <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  pod-security.kubernetes.io/audit<span style="color:#f92672">=</span>restricted
</span></span></code></pre></div><p>Next, try to deploy a privileged pod:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl -n verify-pod-security apply -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">busybox-privileged</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">busybox</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">args</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">sleep</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;1000000&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">allowPrivilegeEscalation</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>The output is similar to this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Error from server <span style="color:#f92672">(</span>Forbidden<span style="color:#f92672">)</span>: error when creating <span style="color:#e6db74">&#34;STDIN&#34;</span>: pods <span style="color:#e6db74">&#34;busybox-privileged&#34;</span> is forbidden: violates PodSecurity <span style="color:#e6db74">&#34;restricted:latest&#34;</span>: allowPrivilegeEscalation !<span style="color:#f92672">=</span> false <span style="color:#f92672">(</span>container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.allowPrivilegeEscalation<span style="color:#f92672">=</span>false<span style="color:#f92672">)</span>, unrestricted capabilities <span style="color:#f92672">(</span>container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.capabilities.drop<span style="color:#f92672">=[</span><span style="color:#e6db74">&#34;ALL&#34;</span><span style="color:#f92672">])</span>, runAsNonRoot !<span style="color:#f92672">=</span> true <span style="color:#f92672">(</span>pod or container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.runAsNonRoot<span style="color:#f92672">=</span>true<span style="color:#f92672">)</span>, seccompProfile <span style="color:#f92672">(</span>pod or container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.seccompProfile.type to <span style="color:#e6db74">&#34;RuntimeDefault&#34;</span> or <span style="color:#e6db74">&#34;Localhost&#34;</span><span style="color:#f92672">)</span>
</span></span></code></pre></div><p>Now let&rsquo;s apply the privileged Pod Security Admission level and try tp deploy again.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># enforces a &#34;privileged&#34; security policy and warns / audits on baseline</span>
</span></span><span style="display:flex;"><span>kubectl label --overwrite ns verify-pod-security <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  pod-security.kubernetes.io/enforce<span style="color:#f92672">=</span>privileged <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  pod-security.kubernetes.io/warn<span style="color:#f92672">=</span>baseline <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  pod-security.kubernetes.io/audit<span style="color:#f92672">=</span>baseline
</span></span></code></pre></div><p>Now the pod is created:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pod/busybox-privileged created
</span></span></code></pre></div><p>Let&rsquo;s apply the baseline Pod Security Admission level and try again.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># enforces a &#34;baseline&#34; security policy and warns / audits on restricted</span>
</span></span><span style="display:flex;"><span>kubectl label --overwrite ns verify-pod-security <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  pod-security.kubernetes.io/enforce<span style="color:#f92672">=</span>baseline <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  pod-security.kubernetes.io/warn<span style="color:#f92672">=</span>restricted <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  pod-security.kubernetes.io/audit<span style="color:#f92672">=</span>restricted
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl -n verify-pod-security apply -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">busybox-baseline</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">busybox</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">args</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">sleep</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;1000000&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">allowPrivilegeEscalation</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">capabilities</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">add</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">NET_BIND_SERVICE</span>
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">CHOWN</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>The output is similar to the following. Note that the warnings match the error message from the restricted policy, but the pod is still successfully created.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Warning: would violate PodSecurity <span style="color:#e6db74">&#34;restricted:latest&#34;</span>: unrestricted capabilities <span style="color:#f92672">(</span>container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.capabilities.drop<span style="color:#f92672">=[</span><span style="color:#e6db74">&#34;ALL&#34;</span><span style="color:#f92672">]</span>; container <span style="color:#e6db74">&#34;busybox&#34;</span> must not include <span style="color:#e6db74">&#34;CHOWN&#34;</span> in securityContext.capabilities.add<span style="color:#f92672">)</span>, runAsNonRoot !<span style="color:#f92672">=</span> true <span style="color:#f92672">(</span>pod or container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.runAsNonRoot<span style="color:#f92672">=</span>true<span style="color:#f92672">)</span>, seccompProfile <span style="color:#f92672">(</span>pod or container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.seccompProfile.type to <span style="color:#e6db74">&#34;RuntimeDefault&#34;</span> or <span style="color:#e6db74">&#34;Localhost&#34;</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>pod/busybox-baseline created
</span></span></code></pre></div><p>You ken use Kyverno to autamate the creation of the labels at namespace. The usage Kyverno is out of the scope of this post but if you want to know more about about this topic check <a href="https://devopstales.github.io/kubernetes/k8s-kyverno-cosign/">my other post</a>.</p>
<h3 id="applying-a-cluster-wide-policy">Applying a cluster-wide policy</h3>
<p>In addition to applying labels to namespaces to configure policy you can also configure cluster-wide policies and exemptions using the AdmissionConfiguration resource.</p>
<p>First create a new kind cluster with :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kind delete cluster
</span></span></code></pre></div><p>Create a Pod Security Admission configuration that enforce and audit baseline policies while using a restricted profile to warn the end user.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF &gt; pod-security.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apiserver.config.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">AdmissionConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">plugins</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">PodSecurity</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">configuration</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">pod-security.admission.config.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PodSecurityConfiguration</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">defaults</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enforce</span>: <span style="color:#e6db74">&#34;baseline&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enforce-version</span>: <span style="color:#e6db74">&#34;latest&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">audit</span>: <span style="color:#e6db74">&#34;baseline&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">audit-version</span>: <span style="color:#e6db74">&#34;latest&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">warn</span>: <span style="color:#e6db74">&#34;restricted&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">warn-version</span>: <span style="color:#e6db74">&#34;latest&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">audit</span>: <span style="color:#e6db74">&#34;restricted&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">audit-version</span>: <span style="color:#e6db74">&#34;latest&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">exemptions</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># Array of authenticated usernames to exempt.</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">usernames</span>: []
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># Array of runtime class names to exempt.</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">runtimeClasses</span>: []
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># Array of namespaces to exempt.</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">namespaces</span>: [<span style="color:#ae81ff">kube-system]</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF &gt; kind-config.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kind.x-k8s.io/v1alpha4</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">nodes</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">role</span>: <span style="color:#ae81ff">control-plane</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kubeadmConfigPatches</span>:
</span></span><span style="display:flex;"><span>  - |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    kind: ClusterConfiguration
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    apiServer:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        # enable admission-control-config flag on the API server
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        extraArgs:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          admission-control-config-file: /etc/kubernetes/policies/pod-security.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        # mount new file / directories on the control plane
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        extraVolumes:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          - name: policies
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            hostPath: /etc/kubernetes/policies
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            mountPath: /etc/kubernetes/policies
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            readOnly: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            pathType: &#34;DirectoryOrCreate&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># mount the local file on the control plane</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraMounts</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hostPath</span>: <span style="color:#ae81ff">./pod-security.yaml</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">containerPath</span>: <span style="color:#ae81ff">/etc/kubernetes/policies/pod-security.yaml</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">readOnly</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kind create cluster --image kindest/node:v1.23.0 --config kind-config.yaml
</span></span><span style="display:flex;"><span>kubectl cluster-info --context kind-kind
</span></span><span style="display:flex;"><span>kubectx kind-kind
</span></span></code></pre></div><p>Let&rsquo;s create a new namespace and see if the labels apply there.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl create namespace test-defaults
</span></span><span style="display:flex;"><span>namespace/test-defaults created
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl describe namespace test-defaults
</span></span><span style="display:flex;"><span>Name:         test-defaults
</span></span><span style="display:flex;"><span>Labels:       kubernetes.io/metadata.name<span style="color:#f92672">=</span>test-defaults
</span></span><span style="display:flex;"><span>Annotations:  &lt;none&gt;
</span></span><span style="display:flex;"><span>Status:       Active
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>No resource quota.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>No LimitRange resource.
</span></span></code></pre></div><p>Can a privileged workload be deployed?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl -n test-defaults apply -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">busybox-privileged</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">busybox</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">busybox</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">args</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">sleep</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;1000000&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">allowPrivilegeEscalation</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>The default warn level is working.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Warning: would violate PodSecurity <span style="color:#e6db74">&#34;restricted:latest&#34;</span>: allowPrivilegeEscalation !<span style="color:#f92672">=</span> false <span style="color:#f92672">(</span>container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.allowPrivilegeEscalation<span style="color:#f92672">=</span>false<span style="color:#f92672">)</span>, unrestricted capabilities <span style="color:#f92672">(</span>container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.capabilities.drop<span style="color:#f92672">=[</span><span style="color:#e6db74">&#34;ALL&#34;</span><span style="color:#f92672">])</span>, runAsNonRoot !<span style="color:#f92672">=</span> true <span style="color:#f92672">(</span>pod or container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.runAsNonRoot<span style="color:#f92672">=</span>true<span style="color:#f92672">)</span>, seccompProfile <span style="color:#f92672">(</span>pod or container <span style="color:#e6db74">&#34;busybox&#34;</span> must set securityContext.seccompProfile.type to <span style="color:#e6db74">&#34;RuntimeDefault&#34;</span> or <span style="color:#e6db74">&#34;Localhost&#34;</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>pod/busybox-privileged created
</span></span></code></pre></div><p>Check the API server metrics endpoint:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get --raw /metrics | grep pod_security_evaluations_total
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># HELP pod_security_evaluations_total [ALPHA] Number of policy evaluations that occurred, not counting ignored or exempt requests.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TYPE pod_security_evaluations_total counter</span>
</span></span><span style="display:flex;"><span>pod_security_evaluations_total<span style="color:#f92672">{</span>decision<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;allow&#34;</span>,mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;enforce&#34;</span>,policy_level<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;baseline&#34;</span>,policy_version<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;latest&#34;</span>,request_operation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;create&#34;</span>,resource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pod&#34;</span>,subresource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>pod_security_evaluations_total<span style="color:#f92672">{</span>decision<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;allow&#34;</span>,mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;enforce&#34;</span>,policy_level<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;privileged&#34;</span>,policy_version<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;latest&#34;</span>,request_operation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;create&#34;</span>,resource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pod&#34;</span>,subresource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>pod_security_evaluations_total<span style="color:#f92672">{</span>decision<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;allow&#34;</span>,mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;enforce&#34;</span>,policy_level<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;privileged&#34;</span>,policy_version<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;latest&#34;</span>,request_operation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;update&#34;</span>,resource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pod&#34;</span>,subresource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>pod_security_evaluations_total<span style="color:#f92672">{</span>decision<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;deny&#34;</span>,mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;audit&#34;</span>,policy_level<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;baseline&#34;</span>,policy_version<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;latest&#34;</span>,request_operation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;create&#34;</span>,resource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pod&#34;</span>,subresource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>pod_security_evaluations_total<span style="color:#f92672">{</span>decision<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;deny&#34;</span>,mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;enforce&#34;</span>,policy_level<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;baseline&#34;</span>,policy_version<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;latest&#34;</span>,request_operation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;create&#34;</span>,resource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pod&#34;</span>,subresource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>pod_security_evaluations_total<span style="color:#f92672">{</span>decision<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;deny&#34;</span>,mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;warn&#34;</span>,policy_level<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;restricted&#34;</span>,policy_version<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;latest&#34;</span>,request_operation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;create&#34;</span>,resource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;controller&#34;</span>,subresource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>pod_security_evaluations_total<span style="color:#f92672">{</span>decision<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;deny&#34;</span>,mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;warn&#34;</span>,policy_level<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;restricted&#34;</span>,policy_version<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;latest&#34;</span>,request_operation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;create&#34;</span>,resource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pod&#34;</span>,subresource<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">2</span>
</span></span></code></pre></div><h3 id="auditing">Auditing</h3>
<p>Example audit-policy.yaml configuration tuned for Pod Security Admission events:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apiVersion: audit.k8s.io/v1
</span></span><span style="display:flex;"><span>kind: Policy
</span></span><span style="display:flex;"><span>rules:
</span></span><span style="display:flex;"><span>- level: RequestResponse
</span></span><span style="display:flex;"><span>  resources:
</span></span><span style="display:flex;"><span>    - group: <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#75715e"># core API group</span>
</span></span><span style="display:flex;"><span>      resources: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;pods&#34;</span>, <span style="color:#e6db74">&#34;pods/ephemeralcontainers&#34;</span>, <span style="color:#e6db74">&#34;podtemplates&#34;</span>, <span style="color:#e6db74">&#34;replicationcontrollers&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    - group: <span style="color:#e6db74">&#34;apps&#34;</span>
</span></span><span style="display:flex;"><span>      resources: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;daemonsets&#34;</span>, <span style="color:#e6db74">&#34;deployments&#34;</span>, <span style="color:#e6db74">&#34;replicasets&#34;</span>, <span style="color:#e6db74">&#34;statefulsets&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    - group: <span style="color:#e6db74">&#34;batch&#34;</span>
</span></span><span style="display:flex;"><span>      resources: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;cronjobs&#34;</span>, <span style="color:#e6db74">&#34;jobs&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  verbs: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;create&#34;</span>, <span style="color:#e6db74">&#34;update&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  omitStages:
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;RequestReceived&#34;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;ResponseStarted&#34;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;Panic&#34;</span>
</span></span></code></pre></div><p>The enableing of the audit-policy function is out of the scope of this post but if you want to know more about about this topic check <a href="https://devopstales.github.io/kubernetes/k8s-falco/">my other post</a>.</p>
<h3 id="psp-migrations">PSP migrations</h3>
<p>If you&rsquo;re already using PSP, I created a guide and <a href="/kubernetes/k8s-migrate-from-psp/">published the steps to migrate off of PSP</a>.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Pod Security Standards using Kyverno]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-pod-security-standards-using-kyverno/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kyverno-cosign/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification with Kyverno" />
                <link href="https://devopstales.github.io/kubernetes/kyverno-image-mirror/?utm_source=atom_feed" rel="related" type="text/html" title="Automatically change registry in pod definition" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-pod-security-standards-using-kyverno/</id>
            
            
            <published>2022-08-10T00:00:00+00:00</published>
            <updated>2022-08-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use Kyverno instal of Pod Security Admission.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="why-you-need-to-use-kyverno-instead-of-the-pod-security-admission">Why you need to use Kyverno instead of the Pod Security Admission</h3>
<p>Probably your first question was why I want tho change the new built in solution to a third-party solution. There is pros and cons for bot solution but the changing of the Pod Security Policy to Pod Security Admission showed that the built in solution is not carved in stone. Previously I tested he new Pod Security Admission an I find the fallowing problems with it:</p>
<ul>
<li><strong>The tree predefined Pod Security Standards is not enough</strong>, but there is no option to create your own.</li>
<li><strong>No enforcement of Pod controllers</strong>: This one is fairly major. For a profile in enforce mode, it will only block Pods emitted from a controller but NOT the actual controller itself. This results in, for example, ability to create a Deployment yet will silently block all the Pods it spawns.</li>
<li><strong>Messages are not configurable</strong>: Whatever message it generates in any of the modes is not configurable at all. Probably not a big deal.</li>
<li><strong>Seeing audits is painful</strong>: Being able to see audits involves digging into the API audit log. Setting up that log is a multi-step process, complex, not enabled by default, is disruptive if done retroactively, requires privileged access to the control plane, and the log cannot be viewed from inside the cluster.</li>
<li><strong>Exemptions are very limited</strong>: This is one of the biggest ones. Exemptions are limited to usernames, runtimeClasses, and Namespaces. Common use cases for exemption like for Pod or container name simply aren&rsquo;t there let alone more complex ones like ClusterRole. And in order to get even that you still have to configure the AdmissionConfiguration file, so see the above bullet for the difficulties that imposes.</li>
<li><strong>Can&rsquo;t use in a pipeline</strong>: PSA is engrained into the Kubernetes control plane, which means to test against it you have to actually submit something to the control plane. There&rsquo;s no standalone utility to know if, in advance, a given resource will work or not.</li>
</ul>
<p>I know Pod Security Admission is a new thing. Just like with anything else, it takes time to mature a technology, but in production environment you cannot wait. So that is the reason I decided to use Kyverno instead of the Pod Security Admission.</p>
<h3 id="perform-node-shell-attack">Perform node shell attack</h3>
<p>I will use the node shell attack on a cluster where the Pod Security Admission is enabled for all namespaces.</p>
<p>First I need to install the kubernetes plugin:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -LO https://github.com/kvaps/kubectl-node-shell/raw/master/kubectl-node_shell
</span></span><span style="display:flex;"><span>chmod +x ./kubectl-node_shell
</span></span><span style="display:flex;"><span>sudo mv ./kubectl-node_shell /usr/local/bin/kubectl-node_shell
</span></span></code></pre></div><p>Basically, the node shell attack allows an attacker to get a shell as root on a node of the cluster by starting a privileged pod with access to host namespaces (<code>hostPID</code>, <code>hostIPC</code> and <code>hostNetwork</code>).</p>
<p>Some system component need this permissions to work so I will test in the <code>kube-system</code> namespace.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl node-shell kind-control-plane -n kube-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spawning <span style="color:#e6db74">&#34;nsenter-wwsbcz&#34;</span> on <span style="color:#e6db74">&#34;kind-control-plane&#34;</span>
</span></span><span style="display:flex;"><span>If you don<span style="color:#960050;background-color:#1e0010">&#39;</span>t see a command prompt, try pressing enter.
</span></span><span style="display:flex;"><span>root@kind-control-plane:/# ls -la
</span></span><span style="display:flex;"><span>total <span style="color:#ae81ff">60</span>
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 16:31 .
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 16:31 ..
</span></span><span style="display:flex;"><span>-rwxr-xr-x   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">0</span> Feb <span style="color:#ae81ff">24</span> 16:31 .dockerenv
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">7</span> Nov  <span style="color:#ae81ff">2</span> 20:43 bin -&gt; usr/bin
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">2</span> root root <span style="color:#ae81ff">4096</span> Oct <span style="color:#ae81ff">11</span> 08:39 boot
</span></span><span style="display:flex;"><span>drwxr-xr-x  <span style="color:#ae81ff">17</span> root root <span style="color:#ae81ff">4440</span> Feb <span style="color:#ae81ff">24</span> 16:31 dev
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 16:31 etc
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">2</span> root root <span style="color:#ae81ff">4096</span> Oct <span style="color:#ae81ff">11</span> 08:39 home
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 16:31 kind
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">7</span> Nov  <span style="color:#ae81ff">2</span> 20:43 lib -&gt; usr/lib
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">9</span> Nov  <span style="color:#ae81ff">2</span> 20:43 lib32 -&gt; usr/lib32
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">9</span> Nov  <span style="color:#ae81ff">2</span> 20:43 lib64 -&gt; usr/lib64
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root   <span style="color:#ae81ff">10</span> Nov  <span style="color:#ae81ff">2</span> 20:43 libx32 -&gt; usr/libx32
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">2</span> root root <span style="color:#ae81ff">4096</span> Nov  <span style="color:#ae81ff">2</span> 20:43 media
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">2</span> root root <span style="color:#ae81ff">4096</span> Nov  <span style="color:#ae81ff">2</span> 20:43 mnt
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Jan <span style="color:#ae81ff">26</span> 08:06 opt
</span></span><span style="display:flex;"><span>dr-xr-xr-x <span style="color:#ae81ff">516</span> root root    <span style="color:#ae81ff">0</span> Feb <span style="color:#ae81ff">24</span> 16:31 proc
</span></span><span style="display:flex;"><span>drwx------   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 17:07 root
</span></span><span style="display:flex;"><span>drwxr-xr-x  <span style="color:#ae81ff">11</span> root root  <span style="color:#ae81ff">240</span> Feb <span style="color:#ae81ff">24</span> 16:32 run
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">8</span> Nov  <span style="color:#ae81ff">2</span> 20:43 sbin -&gt; usr/sbin
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">2</span> root root <span style="color:#ae81ff">4096</span> Nov  <span style="color:#ae81ff">2</span> 20:43 srv
</span></span><span style="display:flex;"><span>dr-xr-xr-x  <span style="color:#ae81ff">13</span> root root    <span style="color:#ae81ff">0</span> Feb <span style="color:#ae81ff">24</span> 16:31 sys
</span></span><span style="display:flex;"><span>drwxrwxrwt   <span style="color:#ae81ff">2</span> root root   <span style="color:#ae81ff">40</span> Feb <span style="color:#ae81ff">24</span> 17:30 tmp
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Nov  <span style="color:#ae81ff">2</span> 20:43 usr
</span></span><span style="display:flex;"><span>drwxr-xr-x  <span style="color:#ae81ff">11</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 16:31 var
</span></span></code></pre></div><p>This is the problem wit Pod Security Admission it not flexible. Now lets try it with Kyverno.</p>
<h3 id="deploy-kyverno">Deploy Kyverno</h3>
<p>First deploy Kyverno without minimal configuration:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm upgrade --install --wait --timeout 15m --atomic <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --namespace kyverno --create-namespace <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --repo https://kyverno.github.io/kyverno kyverno-policies <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  kyverno-policies --values - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">podSecurityStandard: restricted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">validationFailureAction: enforce
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>The default kyverno policies for Pod Security Standard has the same problem. It ignore all request targeting the <code>kube-system</code>, <code>kube-public</code>, <code>kube-node-lease</code> and <code>kyverno</code> namespaces. So running the attack in <code>kube-system</code> namespace will succeed.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl node-shell kind-control-plane -n kube-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spawning <span style="color:#e6db74">&#34;nsenter-wwsbcz&#34;</span> on <span style="color:#e6db74">&#34;kind-control-plane&#34;</span>
</span></span><span style="display:flex;"><span>If you don<span style="color:#960050;background-color:#1e0010">&#39;</span>t see a command prompt, try pressing enter.
</span></span><span style="display:flex;"><span>root@kind-control-plane:/# ls -la
</span></span><span style="display:flex;"><span>total <span style="color:#ae81ff">60</span>
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 16:31 .
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 16:31 ..
</span></span><span style="display:flex;"><span>-rwxr-xr-x   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">0</span> Feb <span style="color:#ae81ff">24</span> 16:31 .dockerenv
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">7</span> Nov  <span style="color:#ae81ff">2</span> 20:43 bin -&gt; usr/bin
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">2</span> root root <span style="color:#ae81ff">4096</span> Oct <span style="color:#ae81ff">11</span> 08:39 boot
</span></span><span style="display:flex;"><span>drwxr-xr-x  <span style="color:#ae81ff">17</span> root root <span style="color:#ae81ff">4440</span> Feb <span style="color:#ae81ff">24</span> 16:31 dev
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 16:31 etc
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">2</span> root root <span style="color:#ae81ff">4096</span> Oct <span style="color:#ae81ff">11</span> 08:39 home
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 16:31 kind
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">7</span> Nov  <span style="color:#ae81ff">2</span> 20:43 lib -&gt; usr/lib
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">9</span> Nov  <span style="color:#ae81ff">2</span> 20:43 lib32 -&gt; usr/lib32
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">9</span> Nov  <span style="color:#ae81ff">2</span> 20:43 lib64 -&gt; usr/lib64
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root   <span style="color:#ae81ff">10</span> Nov  <span style="color:#ae81ff">2</span> 20:43 libx32 -&gt; usr/libx32
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">2</span> root root <span style="color:#ae81ff">4096</span> Nov  <span style="color:#ae81ff">2</span> 20:43 media
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">2</span> root root <span style="color:#ae81ff">4096</span> Nov  <span style="color:#ae81ff">2</span> 20:43 mnt
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Jan <span style="color:#ae81ff">26</span> 08:06 opt
</span></span><span style="display:flex;"><span>dr-xr-xr-x <span style="color:#ae81ff">516</span> root root    <span style="color:#ae81ff">0</span> Feb <span style="color:#ae81ff">24</span> 16:31 proc
</span></span><span style="display:flex;"><span>drwx------   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 17:07 root
</span></span><span style="display:flex;"><span>drwxr-xr-x  <span style="color:#ae81ff">11</span> root root  <span style="color:#ae81ff">240</span> Feb <span style="color:#ae81ff">24</span> 16:32 run
</span></span><span style="display:flex;"><span>lrwxrwxrwx   <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">8</span> Nov  <span style="color:#ae81ff">2</span> 20:43 sbin -&gt; usr/sbin
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">2</span> root root <span style="color:#ae81ff">4096</span> Nov  <span style="color:#ae81ff">2</span> 20:43 srv
</span></span><span style="display:flex;"><span>dr-xr-xr-x  <span style="color:#ae81ff">13</span> root root    <span style="color:#ae81ff">0</span> Feb <span style="color:#ae81ff">24</span> 16:31 sys
</span></span><span style="display:flex;"><span>drwxrwxrwt   <span style="color:#ae81ff">2</span> root root   <span style="color:#ae81ff">40</span> Feb <span style="color:#ae81ff">24</span> 17:30 tmp
</span></span><span style="display:flex;"><span>drwxr-xr-x   <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">4096</span> Nov  <span style="color:#ae81ff">2</span> 20:43 usr
</span></span><span style="display:flex;"><span>drwxr-xr-x  <span style="color:#ae81ff">11</span> root root <span style="color:#ae81ff">4096</span> Feb <span style="color:#ae81ff">24</span> 16:31 var
</span></span></code></pre></div><h3 id="with-kyverno-i-have-the-capability-to-create-a-custom-solution">With Kyverno I have the capability to create a custom solution.</h3>
<p>We can add an exclude statement in our policies to allow requests coming from a user that belongs to the <code>system:nodes</code> group.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm upgrade --install --wait --timeout 15m --atomic <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --namespace kyverno --create-namespace <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --repo https://kyverno.github.io/kyverno kyverno-policies <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  kyverno-policies --values - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">podSecurityStandard: restricted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">validationFailureAction: enforce
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">background: false
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">policyExclude:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  disallow-capabilities:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  disallow-capabilities-strict:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kyverno
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  disallow-host-namespaces:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  disallow-host-path:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  disallow-host-ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  disallow-host-process:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  disallow-privilege-escalation:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  disallow-privileged-containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  disallow-proc-mount:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  disallow-selinux:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  require-run-as-non-root-user:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  require-run-as-nonroot:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  restrict-apparmor-profiles:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  restrict-seccomp:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  restrict-seccomp-strict:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  restrict-sysctls:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  restrict-volume-types:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    any:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:nodes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - kind: Group
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        name: system:serviceaccounts:kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><h3 id="attempt-to-run-a-node-shell-attack-again">Attempt to run a node shell attack again</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl node-shell kind-control-plane -n kube-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spawning <span style="color:#e6db74">&#34;nsenter-dz6d2e&#34;</span> on <span style="color:#e6db74">&#34;kind-control-plane&#34;</span>
</span></span><span style="display:flex;"><span>Error from server: admission webhook <span style="color:#e6db74">&#34;validate.kyverno.svc-fail&#34;</span> denied the request:resource Pod/kube-system/nsenter-dz6d2e was blocked due to the following policiesdisallow-capabilities-strict:
</span></span><span style="display:flex;"><span>  require-drop-all: <span style="color:#e6db74">&#39;validation failure: Containers must drop `ALL` capabilities.&#39;</span>
</span></span><span style="display:flex;"><span>disallow-host-namespaces:
</span></span><span style="display:flex;"><span>  host-namespaces: <span style="color:#e6db74">&#39;validation error: Sharing the host namespaces is disallowed. The
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    fields spec.hostNetwork, spec.hostIPC, and spec.hostPID must be unset or set to
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    `false`. Rule host-namespaces failed at path /spec/hostNetwork/&#39;</span>
</span></span><span style="display:flex;"><span>disallow-privilege-escalation:
</span></span><span style="display:flex;"><span>  privilege-escalation: <span style="color:#e6db74">&#39;validation error: Privilege escalation is disallowed. The
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    fields spec.containers[*].securityContext.allowPrivilegeEscalation, spec.initContainers[*].securityContext.allowPrivilegeEscalation,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    and spec.ephemeralContainers[*].securityContext.allowPrivilegeEscalation must
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    be set to `false`. Rule privilege-escalation failed at path /spec/containers/0/securityContext/allowPrivilegeEscalation/&#39;</span>
</span></span><span style="display:flex;"><span>disallow-privileged-containers:
</span></span><span style="display:flex;"><span>  privileged-containers: <span style="color:#e6db74">&#39;validation error: Privileged mode is disallowed. The fields
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    spec.containers[*].securityContext.privileged and spec.initContainers[*].securityContext.privileged
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    must be unset or set to `false`. Rule privileged-containers failed at path /spec/containers/0/securityContext/privileged/&#39;</span>
</span></span><span style="display:flex;"><span>require-run-as-nonroot:
</span></span><span style="display:flex;"><span>  run-as-non-root: <span style="color:#e6db74">&#39;validation error: Running as root is not allowed. Either the field
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    spec.securityContext.runAsNonRoot must be set to `true`, or the fields spec.containers[*].securityContext.runAsNonRoot,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    spec.initContainers[*].securityContext.runAsNonRoot, and spec.ephemeralContainers[*].securityContext.runAsNonRoot
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    must be set to `true`. Rule run-as-non-root[0] failed at path /spec/securityContext/runAsNonRoot/.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Rule run-as-non-root[1] failed at path /spec/containers/0/securityContext/runAsNonRoot/.&#39;</span>
</span></span><span style="display:flex;"><span>restrict-seccomp-strict:
</span></span><span style="display:flex;"><span>  check-seccomp-strict: <span style="color:#e6db74">&#39;validation error: Use of custom Seccomp profiles is disallowed.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    The fields spec.securityContext.seccompProfile.type, spec.containers[*].securityContext.seccompProfile.type,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    spec.initContainers[*].securityContext.seccompProfile.type, and spec.ephemeralContainers[*].securityContext.seccompProfile.type
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    must be set to `RuntimeDefault` or `Localhost`. Rule check-seccomp-strict[0] failed
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    at path /spec/securityContext/seccompProfile/. Rule check-seccomp-strict[1] failed
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    at path /spec/containers/0/securityContext/seccompProfile/.&#39;</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="seccomp" term="seccomp" label="seccomp" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[CrowdSec Intrusion Detection System (IDS) for Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-crowdsec-ids/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.4/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.4: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/container-build-in-kubernetes/?utm_source=atom_feed" rel="related" type="text/html" title="How to build containers in Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/kube-openid-connect-1.0/?utm_source=atom_feed" rel="related" type="text/html" title="kube-openid-connect 1.0" />
                <link href="https://devopstales.github.io/kubernetes/k8s-user-accounts/?utm_source=atom_feed" rel="related" type="text/html" title="How to create Users in Kubernetes the right way?" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.3/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.3: Patch release for Admisssion controller" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-crowdsec-ids/</id>
            
            
            <published>2022-07-08T00:00:00+00:00</published>
            <updated>2022-07-08T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can install CrowdSec Intrusion Detection System (IDS) inside a Kubernetes cluster.</p>
<h3 id="prerequisites">Prerequisites</h3>
<ul>
<li>installes Kubernetes cluster</li>
<li>installed nginx ingress controller</li>
<li>kubectl</li>
<li>helm</li>
</ul>
<h3 id="architecture">Architecture</h3>
<p>Here’s an architecture overview of CrowdSec inside a K8s cluster.</p>
<p><img src="/img/include/crowdsec_in_k8s.png" alt="CrowdSec Architecture"  class="zoomable" /></p>
<h3 id="install-crowdsec">Install CrowdSec</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add crowdsec https://crowdsecurity.github.io/helm-charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create ns crowdsec
</span></span><span style="display:flex;"><span>kubens crowdsec
</span></span></code></pre></div><p>We can create a new file <code>crowdsec-values.yaml</code>, containing the CrowdSec chart configuration.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano crowdsec-values.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">agent</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># To specify each pod you want to process it logs (pods present in the node)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">acquisition</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># The namespace where the pod is located</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">ingress-nginx</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># The pod name</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">podName</span>: <span style="color:#ae81ff">ingress-nginx-controller-*</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># as in crowdsec configuration, we need to specify the program name so the parser will match and parse logs</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">program</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Those are ENV variables</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># As it&#39;s a test, we don&#39;t want to share signals with CrowdSec so disable the Online API.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">DISABLE_ONLINE_API</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># As we are running Nginx, we want to install the Nginx collection</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">COLLECTIONS</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;crowdsecurity/nginx&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">lapi</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># As it&#39;s a test, we don&#39;t want to share signals with CrowdSec, so disable the Online API.</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">DISABLE_ONLINE_API</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span></code></pre></div><p>Now we can install CrowdSec using our config file in the CrowdSec namespace we created previously.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm install crowdsec crowdsec/crowdsec -f crowdsec-values.yaml -n crowdsec
</span></span><span style="display:flex;"><span>kubectl get pods -n crowdsec
</span></span></code></pre></div><h3 id="demo">Demo</h3>
<p>Install HelloWorld application:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm install helloworld crowdsec/helloworld
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;192.168.200.100 helloworld.mydomain.intra&#34;</span> | sudo tee -a /etc/hosts
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -v http://helloworld.mydomain.intra
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* Trying 192.168.200.100:80...
</span></span><span style="display:flex;"><span>* TCP_NODELAY set
</span></span><span style="display:flex;"><span>* Connected to helloworld.mydomain.intra <span style="color:#f92672">(</span>192.168.200.100<span style="color:#f92672">)</span> port <span style="color:#ae81ff">80</span> <span style="color:#f92672">(</span><span style="color:#75715e">#0)</span>
</span></span><span style="display:flex;"><span>&gt; GET / HTTP/1.1
</span></span><span style="display:flex;"><span>&gt; Host: helloworld.mydomain.intra
</span></span><span style="display:flex;"><span>&gt; User-Agent: curl/7.68.0
</span></span><span style="display:flex;"><span>&gt; Accept: */*
</span></span><span style="display:flex;"><span>&gt;
</span></span><span style="display:flex;"><span>* Mark bundle as not supporting multiuse
</span></span><span style="display:flex;"><span>&lt; HTTP/1.1 <span style="color:#ae81ff">200</span> OK
</span></span><span style="display:flex;"><span>&lt; Date: Mon, <span style="color:#ae81ff">20</span> Sep <span style="color:#ae81ff">2021</span> 10:38:21 GMT
</span></span><span style="display:flex;"><span>&lt; Content-Type: text/plain; charset<span style="color:#f92672">=</span>utf-8
</span></span><span style="display:flex;"><span>&lt; Content-Length: <span style="color:#ae81ff">13</span>
</span></span><span style="display:flex;"><span>&lt; Connection: keep-alive
</span></span><span style="display:flex;"><span>&lt; X-App-Name: http-echo
</span></span><span style="display:flex;"><span>&lt; X-App-Version: 0.2.3
</span></span><span style="display:flex;"><span>&lt;
</span></span><span style="display:flex;"><span>helloworld!
</span></span><span style="display:flex;"><span>* Connection <span style="color:#75715e">#0 to host helloworld.mydomain.intra left intact</span>
</span></span></code></pre></div><p>To test whether CrowdSec detects attacks, we will simulate an attack on the HelloWorld application using Nikto and see CrowdSec metrics and alerts.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./nikto.pl -host http://helloworld.mydomain.inta
</span></span></code></pre></div><p>Now we can get a shell into the CrowdSec agent pod and see metrics and alerts:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get pods -n crowdsec
</span></span><span style="display:flex;"><span>kubectl -n crowdsec exec -it crowdsec-agent-vn4bp -- sh
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>/ <span style="color:#75715e"># cscli metrics</span>
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>21-06-2022 09:39:50 AM<span style="color:#f92672">]</span> Buckets Metrics:                             
</span></span><span style="display:flex;"><span>+-------------------------------------------+---------------+-----------+--------------+--------+---------+
</span></span><span style="display:flex;"><span>|                  BUCKET                   | CURRENT COUNT | OVERFLOWS | INSTANCIATED | POURED | EXPIRED |
</span></span><span style="display:flex;"><span>+-------------------------------------------+---------------+-----------+--------------+--------+---------+
</span></span><span style="display:flex;"><span>| crowdsecurity/http-bad-user-agent         |             <span style="color:#ae81ff">3</span> |       <span style="color:#ae81ff">183</span> |          <span style="color:#ae81ff">186</span> |    <span style="color:#ae81ff">369</span> | -       |
</span></span><span style="display:flex;"><span>| crowdsecurity/http-crawl-non_statics      | -             |         <span style="color:#ae81ff">7</span> |            <span style="color:#ae81ff">9</span> |    <span style="color:#ae81ff">351</span> |       <span style="color:#ae81ff">2</span> |
</span></span><span style="display:flex;"><span>| crowdsecurity/http-path-traversal-probing | -             | -         |            <span style="color:#ae81ff">1</span> |      <span style="color:#ae81ff">2</span> |       <span style="color:#ae81ff">1</span> |
</span></span><span style="display:flex;"><span>| crowdsecurity/http-probing                |             <span style="color:#ae81ff">1</span> | -         |            <span style="color:#ae81ff">2</span> |      <span style="color:#ae81ff">2</span> |       <span style="color:#ae81ff">1</span> |
</span></span><span style="display:flex;"><span>| crowdsecurity/http-sensitive-files        | -             |         <span style="color:#ae81ff">3</span> |            <span style="color:#ae81ff">4</span> |     <span style="color:#ae81ff">17</span> |       <span style="color:#ae81ff">1</span> |
</span></span><span style="display:flex;"><span>+-------------------------------------------+---------------+-----------+--------------+--------+---------+
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>21-06-2022 09:39:50 AM<span style="color:#f92672">]</span> Acquisition Metrics:                         
</span></span><span style="display:flex;"><span>+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------+----------------+------------------------+
</span></span><span style="display:flex;"><span>|                                                                             SOURCE                                                                              | LINES READ | LINES PARSED | LINES UNPARSED | LINES POURED TO BUCKET |
</span></span><span style="display:flex;"><span>+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------+----------------+------------------------+
</span></span><span style="display:flex;"><span>| file:/var/log/containers/ingress-nginx-controller-fd7bb8d66-llxc9_ingress-nginx_controller-c536915796f13bbf66d1a8ab7159dbd055773dbbf89ab4d9653043591dfaef1f.log |        <span style="color:#ae81ff">371</span> |          <span style="color:#ae81ff">371</span> | -              |                    <span style="color:#ae81ff">741</span> |
</span></span><span style="display:flex;"><span>+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------+----------------+------------------------+
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>21-06-2022 09:39:50 AM<span style="color:#f92672">]</span> Parser Metrics:                              
</span></span><span style="display:flex;"><span>+--------------------------------+------+--------+----------+
</span></span><span style="display:flex;"><span>|            PARSERS             | HITS | PARSED | UNPARSED |
</span></span><span style="display:flex;"><span>+--------------------------------+------+--------+----------+
</span></span><span style="display:flex;"><span>| child-crowdsecurity/http-logs  | <span style="color:#ae81ff">1113</span> |    <span style="color:#ae81ff">738</span> |      <span style="color:#ae81ff">375</span> |
</span></span><span style="display:flex;"><span>| child-crowdsecurity/nginx-logs |  <span style="color:#ae81ff">371</span> |    <span style="color:#ae81ff">371</span> | -        |
</span></span><span style="display:flex;"><span>| crowdsecurity/dateparse-enrich |  <span style="color:#ae81ff">371</span> |    <span style="color:#ae81ff">371</span> | -        |
</span></span><span style="display:flex;"><span>| crowdsecurity/docker-logs      |  <span style="color:#ae81ff">371</span> |    <span style="color:#ae81ff">371</span> | -        |
</span></span><span style="display:flex;"><span>| crowdsecurity/geoip-enrich     |  <span style="color:#ae81ff">371</span> |    <span style="color:#ae81ff">371</span> | -        |
</span></span><span style="display:flex;"><span>| crowdsecurity/http-logs        |  <span style="color:#ae81ff">371</span> |    <span style="color:#ae81ff">360</span> |       <span style="color:#ae81ff">11</span> |
</span></span><span style="display:flex;"><span>| crowdsecurity/nginx-logs       |  <span style="color:#ae81ff">371</span> |    <span style="color:#ae81ff">371</span> | -        |
</span></span><span style="display:flex;"><span>| crowdsecurity/whitelists       |  <span style="color:#ae81ff">371</span> |    <span style="color:#ae81ff">371</span> | -        |
</span></span><span style="display:flex;"><span>+--------------------------------+------+--------+----------+
</span></span></code></pre></div><h3 id="install-crowdsec-lua-bouncer-plugin">Install Crowdsec Lua bouncer plugin</h3>
<p>Naow we can integrate CrowdSec with nginx ingress controller to block atackers.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl -n crowdsec exec -it crowdsec-agent-vn4bp -- sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cscli bouncers add ingress-nginx
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Api key <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#39;ingress-nginx&#39;</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>   e00b2155a7e43dd8e8d9294305bd9741
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Please keep this key since you will not be able to retrieve it!
</span></span></code></pre></div><p>You will get an API key, you need to keep it and save it for the ingress-nginx bouncer. Now we can patch our ingress-nginx helm chart to add and enable the crowdsec lua plugin using the following configuration:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano crowdsec-ingress-bouncer.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">controller</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraVolumes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">crowdsec-bouncer-plugin</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">emptyDir</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraInitContainers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">init-clone-crowdsec-bouncer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">crowdsec-lua</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">IfNotPresent</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">API_URL</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;http://crowdsec-service.crowdsec.svc.cluster.local:8080&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">API_KEY</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;e00b2155a7e43dd8e8d9294305bd9741&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">DISABLE_RUN</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">BOUNCER_CONFIG</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;/crowdsec/crowdsec-bouncer.conf&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#39;sh&#39;</span>, <span style="color:#e6db74">&#39;-c&#39;</span>, <span style="color:#e6db74">&#34;sh /docker_start.sh; mkdir -p /lua_plugins/crowdsec/; cp /crowdsec/* /lua_plugins/crowdsec/&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">crowdsec-bouncer-plugin</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/lua_plugins</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraVolumeMounts</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">crowdsec-bouncer-plugin</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/etc/nginx/lua/plugins/crowdsec</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">subPath</span>: <span style="color:#ae81ff">crowdsec</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">plugins</span>: <span style="color:#e6db74">&#34;crowdsec&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">lua-shared-dicts</span>: <span style="color:#e6db74">&#34;crowdsec_cache: 50m&#34;</span>
</span></span></code></pre></div><p>Once we have this patch we can upgrade the ingress-nginx chart:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm -n ingress-system upgrade <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-f ingress-nginx-values.yaml <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-f crowdsec-ingress-bouncer.yaml <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>ingress-nginx ingress-nginx/ingress-nginx
</span></span></code></pre></div><h3 id="demo-2">Demo 2</h3>
<p>Now we have our ingress controller patched with CrowdSec Lua bouncer plugin. We&rsquo;ll start an attack again using Nikto</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./nikto.pl -host http://helloworld.mydomain.intra
</span></span></code></pre></div><p>Getting a shell in the CrowdSec agent pod and listing the alerts:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span> <span style="color:#75715e"># cscli decisions list</span>
</span></span><span style="display:flex;"><span>+----+----------+-------------------+--------------------------------------+--------+---------+-------------+--------+--------------------+----------+
</span></span><span style="display:flex;"><span>| ID |  SOURCE  |    SCOPE:VALUE    |                REASON                | ACTION | COUNTRY |     AS      | EVENTS |     EXPIRATION     | ALERT ID |
</span></span><span style="display:flex;"><span>+----+----------+-------------------+--------------------------------------+--------+---------+-------------+--------+--------------------+----------+
</span></span><span style="display:flex;"><span>|  <span style="color:#ae81ff">3</span> | crowdsec | Ip:192.168.200.5  | crowdsecurity/http-crawl-non_statics | ban    | FR      | <span style="color:#ae81ff">0123</span> Orange |     <span style="color:#ae81ff">43</span> | 3h59m44.053908518s |        <span style="color:#ae81ff">3</span> |
</span></span><span style="display:flex;"><span>+----+----------+-------------------+--------------------------------------+--------+---------+-------------+--------+--------------------+----------+
</span></span></code></pre></div><p>Now, if we try to access the helloworld app using CURL</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ curl -v http://helloworld.mydomain.intra
</span></span><span style="display:flex;"><span>*   Trying 192.168.200.100:80...
</span></span><span style="display:flex;"><span>* TCP_NODELAY set
</span></span><span style="display:flex;"><span>* Connected to helloworld.mydomain.intra <span style="color:#f92672">(</span>192.168.200.100<span style="color:#f92672">)</span> port <span style="color:#ae81ff">80</span> <span style="color:#f92672">(</span><span style="color:#75715e">#0)</span>
</span></span><span style="display:flex;"><span>&gt; GET / HTTP/1.1
</span></span><span style="display:flex;"><span>&gt; Host: helloworld.mydomain.intra
</span></span><span style="display:flex;"><span>&gt; User-Agent: curl/7.68.0
</span></span><span style="display:flex;"><span>&gt; Accept: */*
</span></span><span style="display:flex;"><span>&gt; 
</span></span><span style="display:flex;"><span>* Mark bundle as not supporting multiuse
</span></span><span style="display:flex;"><span>&lt; HTTP/1.1 <span style="color:#ae81ff">403</span> Forbidden
</span></span><span style="display:flex;"><span>&lt; Date: Mon, <span style="color:#ae81ff">27</span> Dec <span style="color:#ae81ff">2021</span> 16:14:26 GMT
</span></span><span style="display:flex;"><span>&lt; Content-Type: text/html
</span></span><span style="display:flex;"><span>&lt; Content-Length: <span style="color:#ae81ff">146</span>
</span></span><span style="display:flex;"><span>&lt; Connection: keep-alive
</span></span><span style="display:flex;"><span>&lt; 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">403</span> Forbidden
</span></span><span style="display:flex;"><span>nginx
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* Connection <span style="color:#75715e">#0 to host helloworld.mydomain.intra left intact</span>
</span></span></code></pre></div><p>To make the app accessible again, from the crowdsec-agent pod, we just need to delete the decision on our IP.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ cscli decisions delete --ip 192.168.200.5
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>21-06-2022 04:17:10 PM<span style="color:#f92672">]</span> <span style="color:#ae81ff">4</span> decision<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span> deleted
</span></span></code></pre></div><p>And CURL the helloworld app again.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ curl -v http://helloworld.mydomain.intra
</span></span><span style="display:flex;"><span>*   Trying 192.168.200.100:80...
</span></span><span style="display:flex;"><span>* TCP_NODELAY set
</span></span><span style="display:flex;"><span>* Connected to helloworld.mydomain.intra <span style="color:#f92672">(</span>192.168.200.100<span style="color:#f92672">)</span> port <span style="color:#ae81ff">80</span> <span style="color:#f92672">(</span><span style="color:#75715e">#0)</span>
</span></span><span style="display:flex;"><span>&gt; GET / HTTP/1.1
</span></span><span style="display:flex;"><span>&gt; Host: helloworld.mydomain.intra
</span></span><span style="display:flex;"><span>&gt; User-Agent: curl/7.68.0
</span></span><span style="display:flex;"><span>&gt; Accept: */*
</span></span><span style="display:flex;"><span>&gt; 
</span></span><span style="display:flex;"><span>* Mark bundle as not supporting multiuse
</span></span><span style="display:flex;"><span>&lt; HTTP/1.1 <span style="color:#ae81ff">200</span> OK
</span></span><span style="display:flex;"><span>&lt; Date: Mon, <span style="color:#ae81ff">27</span> Dec <span style="color:#ae81ff">2021</span> 16:18:17 GMT
</span></span><span style="display:flex;"><span>&lt; Content-Type: text/plain; charset<span style="color:#f92672">=</span>utf-8
</span></span><span style="display:flex;"><span>&lt; Content-Length: <span style="color:#ae81ff">13</span>
</span></span><span style="display:flex;"><span>&lt; Connection: keep-alive
</span></span><span style="display:flex;"><span>&lt; X-App-Name: http-echo
</span></span><span style="display:flex;"><span>&lt; X-App-Version: 0.2.3
</span></span><span style="display:flex;"><span>&lt; 
</span></span><span style="display:flex;"><span>helloworld !
</span></span><span style="display:flex;"><span>* Connection <span style="color:#75715e">#0 to host helloworld.mydomain.intra left intact</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[trivy-operator 2.4: Patch release for Admisssion controller]]></title>
            <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.4/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.3/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.3: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.2/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.2: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.1/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-1.0/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 1.0" />
                <link href="https://devopstales.github.io/kubernetes/container-build-in-kubernetes/?utm_source=atom_feed" rel="related" type="text/html" title="How to build containers in Kubernetes" />
            
                <id>https://devopstales.github.io/kubernetes/trivy-operator-2.4/</id>
            
            
            <published>2022-06-30T00:00:00+00:00</published>
            <updated>2022-06-30T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Today I am happy to announce the release of trivy-operator 2.4. This blog post focuses on the functionality provided by the trivy-operator 2.4 release.</p>
<h3 id="what-is-trivy-operator">What is trivy-operator?</h3>
<p>Trivy-operator is a Kubernetes Operator based on the open-source container vulnerability scanner Trivy. The goal of this project is to provide a vulnerability scanner that continuously scans containers deployed in a Kubernetes cluster. <a href="https://github.com/nolar/kopf">Built with Kubernetes Operator Pythonic Framework (Kopf)</a> There are a few solution for checking the images when you deploy them to the Kubernetes cluster, but fighting against vulnerabilities is a day to day task. Check once is not enough when every day is a new das for frats. That is why I created trivy-operator so you can create scheduled image scans on your running pods.</p>
<h3 id="what-is-new">What is new</h3>
<p>With the release of trivy-operator 2.4 ther is the fallowin new features:</p>
<ul>
<li>add policyreport creation and Policy Reporter UI integration</li>
<li>update vulnerabilityreports if exists</li>
<li>add ownerReferences for VulnerabilityReport</li>
<li>add redis cache</li>
<li>add <a href="https://devopstales.github.io/trivy-operator/">documentation website</a></li>
</ul>
<h3 id="policyreport">PolicyReport</h3>
<p>The <a href="https://github.com/kubernetes-sigs/wg-policy-prototypes/tree/master/policy-report">PolicyReport</a> object is a prototype object probosed by the Kubernetes policy work group. The Policy Report Custom Resource Definition (CRD) can be used as a common way to provide policy results to Kubernetes cluster administrators and users, using native tools. See the <a href="https://docs.google.com/document/d/1nICYLkYS1RE3gJzuHOfHeAC25QIkFZfgymFjgOzMDVw/edit#">proposal</a> for background and details.</p>
<p>Add the PolicyReport CRDs to your cluster (v1alpha2):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -f https://github.com/kubernetes-sigs/wg-policy-prototypes/raw/master/policy-report/crd/v1alpha2/wgpolicyk8s.io_policyreports.yaml
</span></span></code></pre></div><p>If you installed the trivy-operator by the helm chart the Policy Report Custom Resource Definition is installed automticle.</p>
<p>This objects can be visualized by the Policy Reporter UI.</p>
<h3 id="policy-reporter-ui-integration">Policy Reporter UI integration</h3>
<p>The Policy Reporter UI is a monitoring and Observability Tool for the PolicyReport CRD with an optional UI. It is created by Kyverno. The main goal was a tool to visualize the resoluts of the Kyverno policies, but because it uses the PolicyReports CRD it can visualize the resoults of the trivy-operator scans.</p>
<p>Install the Policy Reporter UI:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add policy-reporter https://kyverno.github.io/policy-reporter
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm install policy-reporter policy-reporter/policy-reporter <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set kyvernoPlugin.enabled<span style="color:#f92672">=</span>true --set ui.enabled<span style="color:#f92672">=</span>true --set ui.plugins.kyverno<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-n policy-reporter --create-namespace
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl port-forward service/policy-reporter-ui 8082:8080 -n policy-reporter
</span></span></code></pre></div><p>Open <code>http://localhost:8082/</code> in your browser.</p>
<p><img src="/img/include/policy_report.png" alt="Policy Reporter UI"  class="zoomable" /></p>
<h3 id="trivy-image-validator">Trivy Image Validator</h3>
<p>The admission controller function can be configured as a ValidatingWebhook in a k8s cluster. Kubernetes will send requests to the admission server when a Pod creation is initiated. The admission controller checks the image using trivy if it is in a namespace with the label <code>trivy-operator-validation=true</code>.</p>
<p>You can define policy to the Admission Controller, by adding annotation to the pod trough the deployment:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">...</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/medium</span>: <span style="color:#e6db74">&#34;5&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/low</span>: <span style="color:#e6db74">&#34;10&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/critical</span>: <span style="color:#e6db74">&#34;2&#34;</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><h3 id="where-you-can-find">Where you can find:</h3>
<p>With the release of trivy-operator 2.4 I published trivy-operator with OperatorFramework to OperatorHub:</p>
<p><img src="/img/include/trivy-operator-OH.png" alt="OperatorHub"  class="zoomable" /></p>
<p><img src="/img/include/trivy-operator-OH2.png" alt="OperatorHub"  class="zoomable" /></p>
<h2 id="usage">Usage</h2>
<p>To ease deployment I created a helm chart for trivy-operator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add devopstales https://devopstales.github.io/helm-charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span></code></pre></div><p>Create a value file for deploy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;&#39;EOF&#39;&gt; values.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">image</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repository</span>: <span style="color:#ae81ff">devopstales/trivy-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">pullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tag</span>: <span style="color:#e6db74">&#34;2.3&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">imagePullSecrets</span>: []
</span></span><span style="display:flex;"><span><span style="color:#f92672">podSecurityContext</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroup</span>: <span style="color:#ae81ff">10001</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroupChangePolicy</span>: <span style="color:#e6db74">&#34;OnRootMismatch&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceAccount</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;trivy-operator&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">monitoring</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">port</span>: <span style="color:#e6db74">&#34;9115&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;kube-system&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">size</span>: <span style="color:#ae81ff">1Gi</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">NamespaceScanner</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">crontab</span>: <span style="color:#e6db74">&#34;*/5 * * * *&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespaceSelector</span>: <span style="color:#e6db74">&#34;trivy-scan&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">registryAuth</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">registry</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">docker.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">user</span>: <span style="color:#e6db74">&#34;user&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">password</span>: <span style="color:#e6db74">&#34;password&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">githubToken</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">token</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>When the trivy in the container want to scan an image first download the vulnerability database from github. If you test many images you need a  <code>githubToken</code> overcome the github rate limit and dockerhub username and password for overcome the dockerhub rate limit. If your store you images in a private repository you need to add an username and password for authentication.</p>
<p>The following tables lists configurable parameters of the trivy-operator chart and their default values.</p>
<table>
  <thead>
      <tr>
          <th>Parameter</th>
          <th>Description</th>
          <th>Default</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>image.repository</td>
          <td>image</td>
          <td>devopstales/trivy-operator</td>
      </tr>
      <tr>
          <td>image.pullPolicy</td>
          <td>pullPolicy</td>
          <td>Always</td>
      </tr>
      <tr>
          <td>image.tag</td>
          <td>image tag</td>
          <td>2.1</td>
      </tr>
      <tr>
          <td>imagePullSecrets</td>
          <td>imagePullSecrets list</td>
          <td>[]</td>
      </tr>
      <tr>
          <td>podSecurityContext.fsGroup</td>
          <td>mount id</td>
          <td>10001</td>
      </tr>
      <tr>
          <td>serviceAccount.create</td>
          <td>create serviceAccount</td>
          <td>true</td>
      </tr>
      <tr>
          <td>serviceAccount.annotations</td>
          <td>add annotation to serviceAccount</td>
          <td>{}</td>
      </tr>
      <tr>
          <td>serviceAccount.name</td>
          <td>name of the serviceAccount</td>
          <td>trivy-operator</td>
      </tr>
      <tr>
          <td>monitoring.port</td>
          <td>prometheus endpoint port</td>
          <td>9115</td>
      </tr>
      <tr>
          <td>serviceMonitor.enabled</td>
          <td>enable serviceMonitor object creation</td>
          <td>false</td>
      </tr>
      <tr>
          <td>serviceMonitor.namespace</td>
          <td>where to create serviceMonitor object</td>
          <td>kube-system</td>
      </tr>
      <tr>
          <td>storage.enabled</td>
          <td>enable pv to store trivy database</td>
          <td>true</td>
      </tr>
      <tr>
          <td>storage.size</td>
          <td>pv size</td>
          <td>1Gi</td>
      </tr>
      <tr>
          <td>NamespaceScanner.crontab</td>
          <td>cronjob scheduler</td>
          <td>&ldquo;*/5 * * * *&rdquo;</td>
      </tr>
      <tr>
          <td>NamespaceScanner.namespaceSelector</td>
          <td>Namespace Selector</td>
          <td>&ldquo;trivy-scan&rdquo;</td>
      </tr>
      <tr>
          <td>registryAuth.enabled</td>
          <td>enable registry authentication in operator</td>
          <td>false</td>
      </tr>
      <tr>
          <td>registryAuth.registry</td>
          <td>registry name for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>registryAuth.user</td>
          <td>username for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>registryAuth.password</td>
          <td>password for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>githubToken.enabled</td>
          <td>Enable githubToken usage for trivy database update</td>
          <td>false</td>
      </tr>
      <tr>
          <td>githubToken.token</td>
          <td>githubToken value</td>
          <td>&quot;&quot;</td>
      </tr>
  </tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns trivy-operator
</span></span><span style="display:flex;"><span>kubens trivy-operator
</span></span><span style="display:flex;"><span>helm upgrade --install trivy devopstales/trivy-operator -f values.yaml
</span></span></code></pre></div><h3 id="monitoring">Monitoring</h3>
<p>Trivy-operatos has a prometheus endpoint op port <code>9115</code> and can be deployed wit <code>ServiceMonitor</code> for automated scrapping.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -s http://10.43.179.39:9115/metrics | grep trivy_vulnerabilities
</span></span><span style="display:flex;"><span><span style="color:#75715e"># HELP trivy_vulnerabilities_sum Container vulnerabilities</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TYPE trivy_vulnerabilities_sum gauge</span>
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/openshift/mysql-56-centos7:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;scanning_error&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;UNKNOWN&#34;</span><span style="color:#f92672">}</span> 0.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span><span style="color:#f92672">}</span> 83.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span><span style="color:#f92672">}</span> 5.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span><span style="color:#f92672">}</span> 7.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span><span style="color:#f92672">}</span> 4.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;UNKNOWN&#34;</span><span style="color:#f92672">}</span> 0.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span><span style="color:#f92672">}</span> 126.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span><span style="color:#f92672">}</span> 25.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span><span style="color:#f92672">}</span> 43.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span><span style="color:#f92672">}</span> 21.0
</span></span><span style="display:flex;"><span><span style="color:#75715e"># HELP trivy_vulnerabilities Container vulnerabilities</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TYPE trivy_vulnerabilities gauge</span>
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2.3.4&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2011-3374&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;8.32-4&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2016-2781&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;8.32-4&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2017-18018&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22945&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22946&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22947&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22898&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span></code></pre></div><p><img src="/img/include/trivy-exporter.png" alt="Grafana Dashboard"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-operators" term="k8s-operators" label="k8s-operators" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="trivy-operator" term="trivy-operator" label="trivy-operator" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Secure your applications with Pomerium Ingress Controller]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-pomerium-ingress-controller/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-change-ip/?utm_source=atom_feed" rel="related" type="text/html" title="How to Change IP on Kubernetes node." />
                <link href="https://devopstales.github.io/kubernetes/migrate-kubernetes-to-dockershim/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Install cri-dockerd for docker" />
                <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Migrate from docker to containerd" />
                <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-crio/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Migrate from docker to cri-o" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-containerd-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm V2" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-pomerium-ingress-controller/</id>
            
            
            <published>2022-06-14T00:00:00+00:00</published>
            <updated>2022-06-14T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this blog post, I will show you how you can install Pomerium Ingress Controller and use it to secure your application.</p>
<p>I a <a href="/kubernetes/k8s-central-oauth/">previous post</a> I showed how you can authenticate users for specific ingresses by oauth2-proxy and nginx ingress controller. That solution works grate, but it has a flow. If you want not just authenticate but authorize users based on groups, you need multiple oauth2-proxy. That is not ideal. But wit Pomerium Ingress Controller you can configure authentication and authorization by annotations on the ingress.</p>
<p>Pomerium use certificate-manager to generates certificates for secure connections. So first I will install that:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns cert-manager
</span></span><span style="display:flex;"><span>kubens cert-manager
</span></span><span style="display:flex;"><span>helm repo add jetstack https://charts.jetstack.io
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>helm install cert-manager jetstack/cert-manager --namespace cert-manager <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--create-namespace --set installCRDs<span style="color:#f92672">=</span>true
</span></span></code></pre></div><p>To install Pomerium Ingress Controller I will use it&rsquo;s helm chart:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns ingress-system
</span></span><span style="display:flex;"><span>kubens ingress-system
</span></span><span style="display:flex;"><span>helm repo add pomerium https://helm.pomerium.io
</span></span><span style="display:flex;"><span>helm repo update
</span></span></code></pre></div><p>Now I will create the values file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano values.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">authenticate</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">idp</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">provider</span>: <span style="color:#e6db74">&#34;oidc&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">clientID</span>: <span style="color:#e6db74">&#34;oauth2_proxy&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">clientSecret</span>: <span style="color:#e6db74">&#34;1e8ee274-513e-41c0-903f-b3cg13147dgb&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">url</span>: <span style="color:#e6db74">&#34;https://sso.k8s.intra/auth/realms/cl12&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">serviceAccount</span>: <span style="color:#e6db74">&#34;pomerium-authenticate&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cert-manager.io/cluster-issuer</span>: <span style="color:#ae81ff">ca-issuer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">authenticate.k8s.intra</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">redis</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">generateTLS</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">ingressController</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ingressClassResource</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">default</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;pomerium&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">config</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rootDomain</span>: <span style="color:#ae81ff">k8s.intra</span> <span style="color:#75715e">#Change this to your reserved domain space.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">generateTLS</span>: <span style="color:#66d9ef">true</span> <span style="color:#75715e"># On by default, disabled when cert-manager or another solution is in place.</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm upgrade --install pomerium pomerium/pomerium --values ./pomerium-values.yaml
</span></span></code></pre></div><p>To demonstrate the functionality of Pomerium Ingress Controller I will create a deo application:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano demo_app.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kuard</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">kuard</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">kuard</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">gcr.io/kuar-demo/kuard-amd64:1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kuard</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kuard</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">kuard</span>
</span></span></code></pre></div><p>Now I will show so a few Ingress examples for this app. I the firs example we wil allow the authentication for a specific user by its email.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ingress.pomerium.io/policy</span>: <span style="color:#e6db74">&#39;[{&#34;allow&#34;:{&#34;and&#34;:[{&#34;email&#34;:{&#34;is&#34;:&#34;user@mydomain.intra&#34;}}]}}]&#39;</span> <span style="color:#75715e"># This can also be a yaml block quote</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">kuard.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kuard</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">Prefix</span>
</span></span></code></pre></div><p>As you can see you can add the policy as a yaml block quote.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ingress.pomerium.io/policy</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - allow:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          and:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            - email:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                is: user@mydomain.intra</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">kuard.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kuard</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">Prefix</span>
</span></span></code></pre></div><p>In the second example I will allow the authentication for all user from a specific domain.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ingress.pomerium.io/policy</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - allow:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          and:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            - email:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                ends_with: &#34;@mydomain.intra&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">kuard.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kuard</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">Prefix</span>
</span></span></code></pre></div><p>OR:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ingress.pomerium.io/policy</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - allow:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          and:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            - domain:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                is: &#34;mydomain.intra&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">kuard.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kuard</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">Prefix</span>
</span></span></code></pre></div><p>The last example shows you how you can use regex in your ingress.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cert-manager.io/issuer</span>: <span style="color:#ae81ff">example-issuer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ingress.pomerium.io/policy</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - allow:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          and:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            - domain:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                is: &#34;mydomain.intra&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ingress.pomerium.io/path_regex</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">example</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ingressClassName</span>: <span style="color:#ae81ff">pomerium</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">example.localhost.pomerium.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">example</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">^/(admin|superuser)/.*$</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">ImplementationSpecific</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">example.localhost.pomerium.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">example-tls</span>
</span></span></code></pre></div><p>As you can see Pomerium is a very versatile Ingress controller. For more examples fo to <a href="https://www.pomerium.com/docs/k8s/ingress.html">Pomerium&rsquo;s page</a>.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-authentication" term="k8s-authentication" label="k8s-authentication" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ingress" term="ingress" label="ingress" />
                             
                                <category scheme="oidc" term="oidc" label="oidc" />
                             
                                <category scheme="sso" term="sso" label="sso" />
                             
                                <category scheme="openid" term="openid" label="OpenID" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to build containers in Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/container-build-in-kubernetes/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/kube-openid-connect-1.0/?utm_source=atom_feed" rel="related" type="text/html" title="kube-openid-connect 1.0" />
                <link href="https://devopstales.github.io/kubernetes/k8s-user-accounts/?utm_source=atom_feed" rel="related" type="text/html" title="How to create Users in Kubernetes the right way?" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.3/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.3: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/cloud/gke-gitlab-terraform/?utm_source=atom_feed" rel="related" type="text/html" title="Create K8S cluster with Terraform and GitlabCI" />
                <link href="https://devopstales.github.io/kubernetes/multus-calico/?utm_source=atom_feed" rel="related" type="text/html" title="Use multus to separate metwork trafics" />
            
                <id>https://devopstales.github.io/kubernetes/container-build-in-kubernetes/</id>
            
            
            <published>2022-06-10T00:00:00+00:00</published>
            <updated>2022-06-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this blogpost I will show you what tools you can user for privileged builds in Kubernetes.</p>
<h3 id="rancker-kim">Rancker KIM</h3>
<p><code>kim</code> is a Kubernetes-aware CLI that will install a small builder backend consisting of a <code>BuildKit</code> daemon bound to the Kubelet&rsquo;s underlying <code>containerd</code> socket (for building images) along with a small server-side agent that the CLI leverages for image management (think push, pull, etc) rather than talking to the backing containerd/CRI directly.</p>
<p>Install:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/rancher/kim/releases/download/v0.1.0-beta.7/kim-linux-amd64
</span></span><span style="display:flex;"><span>chmod +x kim-linux-amd64
</span></span><span style="display:flex;"><span>mv kim-linux-amd64 /usr/local/bin/kim
</span></span></code></pre></div><p>KIM also works as a kubectl drop-in pligin. To facilitate this, you can either copy or symlink the local kim binary to kubectl-image (and optionally kubectl-builder)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd /usr/local/bin
</span></span><span style="display:flex;"><span>ln -s kim /usr/local/bin/kubectl-image
</span></span><span style="display:flex;"><span>ln -s kim /usr/local/bin/kubectl-builder
</span></span></code></pre></div><p>Deploy kim:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl crate ns kube-image
</span></span><span style="display:flex;"><span><span style="color:#75715e"># run on local cluster</span>
</span></span><span style="display:flex;"><span>kim builder install -n kube-image --endpoint-addr 127.0.0.1
</span></span><span style="display:flex;"><span><span style="color:#75715e"># run on a multi node cluster</span>
</span></span><span style="display:flex;"><span>kim builder install -n kube-image <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--selector kubernetes.io/hostname<span style="color:#f92672">=</span>k8s-m101.k8s.intra
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get po -n kube-image
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl port-forward svc/builder 1233:1233 1234:124 --namespace kube-image
</span></span></code></pre></div><p>Usage:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kim image ls
</span></span><span style="display:flex;"><span>IMAGE               TAG                 IMAGE ID            SIZE
</span></span><span style="display:flex;"><span>moby/buildkit       v0.8.3              cf14c5e88c0eb       56.5MB
</span></span><span style="display:flex;"><span>rancher/kim         v0.1.0-beta.2       fb018f26dd6ef       13.7MB
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kim build --tag local/project:tag .
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or</span>
</span></span><span style="display:flex;"><span>kim image build --tag local/project:tag .
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or</span>
</span></span><span style="display:flex;"><span>kubectl image build --tag local/project:tag .
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kim images
</span></span><span style="display:flex;"><span>IMAGE               TAG                 IMAGE ID            SIZE
</span></span><span style="display:flex;"><span>local/project       tag                 3e7bd55385a51       13MB
</span></span><span style="display:flex;"><span>moby/buildkit       v0.8.3              cf14c5e88c0eb       56.5MB
</span></span><span style="display:flex;"><span>rancher/kim         v0.1.0-beta.2       fb018f26dd6ef       13.7MB
</span></span></code></pre></div><p>The image built by kim is on the kubernetes node so yo dint&rsquo;t need to pull it. In a local or a single node clusterit is an advantage but in a multi node cluster that means you must use a nde selector on the deployment to select tha same node as the kim server is running.</p>
<h3 id="kaniko">Kaniko</h3>
<p><code>kaniko</code> is an open-source container image-building tool created by Google. It does not require privileged access to the host for building container images.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano kaniko-git.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kaniko</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kaniko</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">gcr.io/kaniko-project/executor:debug</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">args</span>: [<span style="color:#e6db74">&#34;--context=git://github.com/devopstales/k8s-image-build-demo&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;--destination=devopstales/kaniko-git:1.0.0&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;--forcekgp&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kaniko-secret</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/kaniko/.docker</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">restartPolicy</span>: <span style="color:#ae81ff">Never</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">kaniko-secret</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">secret</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">regcred</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">items</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">.dockerconfigjson</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>: <span style="color:#ae81ff">config.json</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create secret docker-registry regcred <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --docker-username<span style="color:#f92672">=</span>$REGISTRY_USER <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --docker-password<span style="color:#f92672">=</span>$REGISTRY_PASS <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --docker-server<span style="color:#f92672">=</span>$REGISTRY_URL
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f kaniko-git.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl wait <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --for condition<span style="color:#f92672">=</span>containersready <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    pod kaniko
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl logs kaniko --follow
</span></span></code></pre></div><p>It dose not meter  where Kaniko is running you need a registry to pus the images built by Kaniko and pull when you testing.</p>
<h3 id="kpack">Kpack</h3>
<p><code>kpack</code> extends Kubernetes and utilizes unprivileged kubernetes primitives to provide builds of OCI images as a platform implementation of <a href="https://buildpacks.io/">Cloud Native Buildpacks (CNB)</a>.</p>
<p>To install <code>kpack</code> download the <a href="https://github.com/pivotal/kpack/releases">most recent github release</a>. The release.yaml is an asset on the release.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create namespace build
</span></span><span style="display:flex;"><span>kubens build
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/pivotal/kpack/releases/download/v0.6.0/release-0.6.0.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create secret for push to your registry</span>
</span></span><span style="display:flex;"><span>kubectl create secret docker-registry regcred <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --docker-username<span style="color:#f92672">=</span>$REGISTRY_USER <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --docker-password<span style="color:#f92672">=</span>$REGISTRY_PASS <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --docker-server<span style="color:#f92672">=</span>$REGISTRY_URL <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --namespace build
</span></span></code></pre></div><p>Create the configuration for your app docker build:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano  kpack-config.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceAccount</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">registry-creds</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">build</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">secrets</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">registry-creds</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">imagePullSecrets</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">registry-creds</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kpack.io/v1alpha2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterStore</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">gcr.io/paketo-buildpacks/go</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">gcr.io/paketo-buildpacks/java</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">gcr.io/paketo-buildpacks/nodejs</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kpack.io/v1alpha2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterStack</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">base</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">id</span>: <span style="color:#e6db74">&#34;io.buildpacks.stacks.bionic&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">buildImage</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#34;paketobuildpacks/build:base-cnb&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">runImage</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#34;paketobuildpacks/run:base-cnb&#34;</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kpack.io/v1alpha2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Builder</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">silly-demo</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">build</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceAccountName</span>: <span style="color:#ae81ff">regcred</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tag</span>: <span style="color:#ae81ff">devopstales/kapck-build</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">stack</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">base</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterStack</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">store</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterStore</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">order</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">group</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">id</span>: <span style="color:#ae81ff">paketo-buildpacks/go</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano kpack-image.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kpack.io/v1alpha2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Image</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">generateName</span>: <span style="color:#ae81ff">silly-demo-</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">build</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tag</span>: <span style="color:#ae81ff">devopstales/kapck-demo</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">additionalTags</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">devopstales/kapck-demo:latest</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">devopstales/kapck-demo:0.0.1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceAccountName</span>: <span style="color:#ae81ff">regcred</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">builder</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">silly-demo</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Builder</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">git</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">url</span>: <span style="color:#ae81ff">https://github.com/devopstales/k8s-image-build-demo</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">revision</span>: <span style="color:#ae81ff">ebb790f3959c05e6c196e88016a243a0053f450a</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f kpack-config.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kg builder
</span></span><span style="display:flex;"><span>NAME         LATESTIMAGE                             READY
</span></span><span style="display:flex;"><span>silly-demo   devopstales/kapck-demo@sha256:f2290a3   True
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create -f kpack-image.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pods
</span></span><span style="display:flex;"><span>kubectl get images
</span></span></code></pre></div><p>All the source files can be find in <a href="https://github.com/devopstales/k8s-image-build-demo">my github repo</a>.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to Change IP on Kubernetes node.]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-change-ip/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
                <link href="https://devopstales.github.io/kubernetes/k8s-prometheus-stack/?utm_source=atom_feed" rel="related" type="text/html" title="K8S Logging And Monitoring" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes integration with external Vault" />
                <link href="https://devopstales.github.io/kubernetes/rke2-calico/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With Calico" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-change-ip/</id>
            
            
            <published>2022-06-07T00:00:00+00:00</published>
            <updated>2022-06-07T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how you can change th IP of the Kubernetes Nodes and Workers.</p>
<p>On a Kubernetes cluster ther is a component called kube-apiserver. The kube-apiserver need to know the ip address on which to advertise the apiserver (<code>--apiserver-advertise-address</code>) to members of the cluster. At the <code>kubeadm init</code> there is a phase when the kubeadm generate self-signed certificate for the apiserver valid for the node ips and the ip of the loadbalancer if configures (<code>--control-plane-endpoint</code>). If the ip of the node or the loadbalancer (this is the external ip in a cloud environment) change the certificate is no longer valid for that and the <code>kubectl</code> won&rsquo;t connect.</p>
<p>The soulution is to reinit the kubernetes cluster with the new ip and keeping the data of the etcd. The kubernetes keep all the objects and states in the etcd database.</p>
<h3 id="backup-the-data-on-the-master">Backup the data on the master</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl stop kubelet docker
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mv /etc/kubernetes /etc/kubernetes-backup
</span></span><span style="display:flex;"><span>mv /var/lib/kubelet /var/lib/kubelet-backup
</span></span></code></pre></div><h3 id="preper-for-the-new-cluster">Preper for the new Cluster</h3>
<p>Create the new folderstructure and restore the needed certificates.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir /etc/kubernetes
</span></span><span style="display:flex;"><span>cp -r /etc/kubernetes-backup/pki /etc/kubernetes
</span></span><span style="display:flex;"><span>rm -f /etc/kubernetes/pki/<span style="color:#f92672">{</span>apiserver.*,etcd/peer.*<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>rm -f ~/.kube/config
</span></span></code></pre></div><p>Now we can reinit control plane node with data in etcd using command below.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl start docker
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;KUBELET_EXTRA_ARGS=&#34;--node-ip=172.17.8.101&#34;&#39;</span> &gt; /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># add --kubernetes-version, --pod-network-cidr and --token options if needed</span>
</span></span><span style="display:flex;"><span>kubeadm init --control-plane-endpoint <span style="color:#e6db74">&#34;172.17.8.100:16443&#34;</span> --apiserver-advertise-address <span style="color:#e6db74">&#34;172.17.8.101&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--ignore-preflight-errors<span style="color:#f92672">=</span>DirAvailable--var-lib-etcd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cp kubernetes/admin.conf ~/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Verify resutl</span>
</span></span><span style="display:flex;"><span>kubectl cluster-info
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># wait for some time and delete old node</span>
</span></span><span style="display:flex;"><span>sleep <span style="color:#ae81ff">120</span>
</span></span><span style="display:flex;"><span>kubectl get nodes --sort-by<span style="color:#f92672">=</span>.metadata.creationTimestamp
</span></span><span style="display:flex;"><span>kubectl delete node <span style="color:#66d9ef">$(</span>kubectl get nodes -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{.items[?(@.status.conditions[0].status==&#34;Unknown&#34;)].metadata.name}&#39;</span><span style="color:#66d9ef">)</span>
</span></span></code></pre></div><p>Now reset the worker to kubernete cluster and change the ip in the config.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm reset
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;KUBELET_EXTRA_ARGS=&#34;--node-ip=172.17.8.102&#34;&#39;</span> &gt; /etc/sysconfig/kubelet
</span></span></code></pre></div><p>Get the join  token from the master and use this on the workers to rejoin to the master.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm token create --print-join-command
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="kube-apiserver" term="kube-apiserver" label="kube-apiserver" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[kubernetes 1.24: Install cri-dockerd for docker]]></title>
            <link href="https://devopstales.github.io/kubernetes/migrate-kubernetes-to-dockershim/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Migrate from docker to containerd" />
                <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-crio/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Migrate from docker to cri-o" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-containerd-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm V2" />
                <link href="https://devopstales.github.io/kubernetes/k8s-test-tools/?utm_source=atom_feed" rel="related" type="text/html" title="Validate Kubernetes Deployment in CI/CD" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
            
                <id>https://devopstales.github.io/kubernetes/migrate-kubernetes-to-dockershim/</id>
            
            
            <published>2022-05-05T00:00:00+00:00</published>
            <updated>2022-05-05T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>With the new Kubernetes 1.24 and deprecation of dockershim, in this post I will show you how you can migrate your kubernetes cluster to use cri-dockerd instad of dockershim.</p>
<h3 id="what-is-dockershim">What is dockershim?</h3>
<p>Dockershim was a componeni in the kubernetes engine that translated between the docker api and the Kubernetes. With the new Kubernetes 1.24 Kubernetes removed this component from it&rsquo;s codebase. Now only the CRI (Container Runetime Interface) compatible container engines can be used. Mirantys and Docker decided to move dockershim to another repository. As part of this project, initial steps were taken to wrap Dockershim in something that can speak CRI.</p>
<h3 id="so-what-is-cri-dockerd">So, what is cri-dockerd?</h3>
<p>Well, for now, it’s a thin wrapper around Dockershim itself which allows Dockershim to be started as a separate daemon. That daemon presents the expected API for kubelet’s That daemon presents the expected API for kubelet’s.</p>
<h3 id="how-to-migrate">How to migrate</h3>
<p>You have to be careful if you are on a single master node configuration. The cluster will be unavailable under the upgrade.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes -o wide
</span></span><span style="display:flex;"><span>NAME    STATUS   ROLES                  AGE     VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION                             CONTAINER-RUNTIME
</span></span><span style="display:flex;"><span>k8s01   Ready    control-plane,master   78m     v1.20.4   10.65.79.164   &lt;none&gt;        CentOS Linux <span style="color:#ae81ff">8</span>       4.18.0-240.15.1.el8_3.centos.plus.x86_64   docker://20.10.5
</span></span><span style="display:flex;"><span>k8s02   Ready    control-plane,master   64m     v1.20.4   10.65.79.131   &lt;none&gt;        CentOS Linux <span style="color:#ae81ff">8</span>       4.18.0-240.15.1.el8_3.centos.plus.x86_64   docker://20.10.5
</span></span><span style="display:flex;"><span>k8s03   Ready    control-plane,master   4m16s   v1.20.4   10.65.79.244   &lt;none&gt;        CentOS Linux <span style="color:#ae81ff">8</span>       4.18.0-240.15.1.el8_3.centos.plus.x86_64   docker://20.10.5
</span></span></code></pre></div><p>First we will cordon and drain the node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl cordon k8s01
</span></span><span style="display:flex;"><span>kubectl drain k8s01 --ignore-daemonsets
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes
</span></span><span style="display:flex;"><span>NAME    STATUS                      ROLES                  AGE    VERSION
</span></span><span style="display:flex;"><span>k8s01   Ready,SchedulingDisabled    control-plane,master   83m    v1.20.4
</span></span><span style="display:flex;"><span>k8s02   Ready                       control-plane,master   69m    v1.20.4
</span></span><span style="display:flex;"><span>k8s03   Ready                       control-plane,master   9m30s  v1.20.4
</span></span></code></pre></div><p>Stop the kubelet sevice:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl stop kubelet
</span></span><span style="display:flex;"><span>sudo systemctl status kubelet
</span></span></code></pre></div><h3 id="install-and-configure-dockershim">Install and configure dockershim:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd /tmp
</span></span><span style="display:flex;"><span>VER<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>curl -s https://api.github.com/repos/Mirantis/cri-dockerd/releases/latest|grep tag_name | cut -d <span style="color:#e6db74">&#39;&#34;&#39;</span> -f 4<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>echo $VER
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://github.com/Mirantis/cri-dockerd/releases/download/<span style="color:#e6db74">${</span>VER<span style="color:#e6db74">}</span>/cri-dockerd-<span style="color:#e6db74">${</span>VER<span style="color:#e6db74">}</span>-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>tar xvf cri-dockerd-<span style="color:#e6db74">${</span>VER<span style="color:#e6db74">}</span>-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo mv cri-dockerd /usr/local/bin/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cri-dockerd --version
</span></span><span style="display:flex;"><span>cri-dockerd 0.2.0 <span style="color:#f92672">(</span>HEAD<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://raw.githubusercontent.com/Mirantis/cri-dockerd/master/packaging/systemd/cri-docker.service
</span></span><span style="display:flex;"><span>wget https://raw.githubusercontent.com/Mirantis/cri-dockerd/master/packaging/systemd/cri-docker.socket
</span></span><span style="display:flex;"><span>sudo mv cri-docker.socket cri-docker.service /etc/systemd/system/
</span></span><span style="display:flex;"><span>sudo sed -i -e <span style="color:#e6db74">&#39;s,/usr/bin/cri-dockerd,/usr/local/bin/cri-dockerd,&#39;</span> /etc/systemd/system/cri-docker.service
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl daemon-reload
</span></span><span style="display:flex;"><span>sudo systemctl enable cri-docker.service
</span></span><span style="display:flex;"><span>sudo systemctl enable --now cri-docker.socket
</span></span></code></pre></div><h3 id="configure-the-kubelet-to-use-cri-dockerd">Configure the kubelet to use cri-dockerd</h3>
<p>test the socket connection:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo kubeadm config images pull --cri-socket /run/cri-dockerd.sock 
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled k8s.gcr.io/kube-apiserver:v1.23.5
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled k8s.gcr.io/kube-controller-manager:v1.23.5
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled k8s.gcr.io/kube-scheduler:v1.23.5
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled k8s.gcr.io/kube-proxy:v1.23.5
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled k8s.gcr.io/pause:3.6
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled k8s.gcr.io/etcd:3.5.1-0
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled k8s.gcr.io/coredns/coredns:v1.8.6
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span><span style="color:#75715e"># add the following flags to KUBELET_KUBEADM_ARGS variable</span>
</span></span><span style="display:flex;"><span>KUBELET_KUBEADM_ARGS<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;... --container-runtime=remote --container-runtime-endpoint=/run/cri-dockerd.sock&#34;</span>
</span></span></code></pre></div><p>Start kubelet:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl start kubelet
</span></span></code></pre></div><p>Check if the new runtime on the node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe node k8s01
</span></span></code></pre></div><p>Uncordon the node to mark it schedulable agen:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl uncordon k8s01
</span></span></code></pre></div><p>Once you changed the runetime on all the nodes you are done.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="containerd" term="containerd" label="Containerd" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[kubernetes 1.24: Migrate from docker to containerd]]></title>
            <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-containerd/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/migrate-kubernetes-to-dockershim/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Install cri-dockerd for docker" />
                <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-crio/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Migrate from docker to cri-o" />
                <link href="https://devopstales.github.io/kubernetes/k8s-falco/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes audit logs and Falco" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cisa-install/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Hardening Guide with CISA 1.6 Benchmark" />
                <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="related" type="text/html" title="Hardening Kubernetes with seccomp" />
            
                <id>https://devopstales.github.io/kubernetes/migrate-docker-to-containerd/</id>
            
            
            <published>2022-05-05T00:00:00+00:00</published>
            <updated>2022-05-05T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>With the new Kubernetes 1.24 and deprecation of dockershim, in this post I will show you how you can migrate your kubernetes cluster from docker to containerd.</p>
<h3 id="how-to-migrate">How to migrate</h3>
<p>You have to be careful if you are on a single master node configuration. The cluster will be unavailable under the upgrade.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes -o wide
</span></span><span style="display:flex;"><span>NAME    STATUS   ROLES                  AGE     VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION                             CONTAINER-RUNTIME
</span></span><span style="display:flex;"><span>k8s01   Ready    control-plane,master   78m     v1.20.4   10.65.79.164   &lt;none&gt;        CentOS Linux <span style="color:#ae81ff">8</span>       4.18.0-240.15.1.el8_3.centos.plus.x86_64   docker://20.10.5
</span></span><span style="display:flex;"><span>k8s02   Ready    control-plane,master   64m     v1.20.4   10.65.79.131   &lt;none&gt;        CentOS Linux <span style="color:#ae81ff">8</span>       4.18.0-240.15.1.el8_3.centos.plus.x86_64   docker://20.10.5
</span></span><span style="display:flex;"><span>k8s03   Ready    control-plane,master   4m16s   v1.20.4   10.65.79.244   &lt;none&gt;        CentOS Linux <span style="color:#ae81ff">8</span>       4.18.0-240.15.1.el8_3.centos.plus.x86_64   docker://20.10.5
</span></span></code></pre></div><p>First we will cordon and drain the node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl cordon k8s01
</span></span><span style="display:flex;"><span>kubectl drain k8s01 --ignore-daemonsets
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes
</span></span><span style="display:flex;"><span>NAME    STATUS                      ROLES                  AGE    VERSION
</span></span><span style="display:flex;"><span>k8s01   Ready,SchedulingDisabled    control-plane,master   83m    v1.20.4
</span></span><span style="display:flex;"><span>k8s02   Ready                       control-plane,master   69m    v1.20.4
</span></span><span style="display:flex;"><span>k8s03   Ready                       control-plane,master   9m30s  v1.20.4
</span></span></code></pre></div><p>Stop the kubelet sevice and remove docker:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl stop kubelet
</span></span><span style="display:flex;"><span>sudo systemctl status kubelet
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apt purge docker-ce docker-ce-cli
</span></span><span style="display:flex;"><span>OR
</span></span><span style="display:flex;"><span>yum remove docker-ce docker-ce-cli
</span></span></code></pre></div><h3 id="install-and-configure-containerd">Install and configure containerd:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">## Install containerd</span>
</span></span><span style="display:flex;"><span>sudo yum update -y <span style="color:#f92672">&amp;&amp;</span> sudo yum install -y containerd.io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Configure containerd</span>
</span></span><span style="display:flex;"><span>sudo mkdir -p /etc/containerd
</span></span><span style="display:flex;"><span>sudo containerd config default &gt; /etc/containerd/config.toml
</span></span></code></pre></div><p>To use the <code>systemd</code> cgroup driver in <code>/etc/containerd/config.toml</code> with <code>runc</code>, set</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc.options<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>            SystemdCgroup <span style="color:#f92672">=</span> true
</span></span></code></pre></div><p>Prepare the system for containerd:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kvm-intel
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;runtime-endpoint: unix:///run/containerd/containerd.sock&#34;</span> &gt; /etc/crictl.yaml
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Start containerd</span>
</span></span><span style="display:flex;"><span>systemctl enable --now containerd
</span></span></code></pre></div><p>Change runtime in kubeadm config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span><span style="color:#75715e"># add the following flags to KUBELET_KUBEADM_ARGS variable</span>
</span></span><span style="display:flex;"><span>KUBELET_KUBEADM_ARGS<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;... --container-runtime=remote --container-runtime-endpoint=/run/containerd/containerd.sock&#34;</span>
</span></span></code></pre></div><p>Start kubelet:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl start kubelet
</span></span></code></pre></div><p>Check if the new runtime on the node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe node k8s01
</span></span><span style="display:flex;"><span>System Info:
</span></span><span style="display:flex;"><span>  Machine ID:                 21a5dd31f86c4
</span></span><span style="display:flex;"><span>  System UUID:                4227EF55-BA3BCCB57BCE
</span></span><span style="display:flex;"><span>  Boot ID:                    77229747-9ea581ec6773
</span></span><span style="display:flex;"><span>  Kernel Version:             4.18.0-240.15.1.el8_3.centos.plus.x86_64
</span></span><span style="display:flex;"><span>  OS Image:                   CentOS Linux <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>  Operating System:           linux
</span></span><span style="display:flex;"><span>  Architecture:               amd64
</span></span><span style="display:flex;"><span>  Container Runtime Version:  containerd://1.4.3
</span></span><span style="display:flex;"><span>  Kubelet Version:            v1.20.4
</span></span><span style="display:flex;"><span>  Kube-Proxy Version:         v1.20.4
</span></span></code></pre></div><p>Uncordon the node to mark it schedulable agen:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl uncordon k8s01
</span></span></code></pre></div><p>Once you changed the runetime on all the nodes you are done.</p>
<h3 id="debugging-tipps">Debugging tipps</h3>
<p>Here are some usefull conmmands to debug:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>journalctl -u kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>journalctl -u containerd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>crictl --runtime-endpoint /run/containerd/containerd.sock ps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl describe node &lt;master_node_name&gt;
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="containerd" term="containerd" label="Containerd" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="containerd" term="containerd" label="Containerd" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[kubernetes 1.24: Migrate from docker to cri-o]]></title>
            <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-crio/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/migrate-kubernetes-to-dockershim/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Install cri-dockerd for docker" />
                <link href="https://devopstales.github.io/kubernetes/migrate-docker-to-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="kubernetes 1.24: Migrate from docker to containerd" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-containerd-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm V2" />
                <link href="https://devopstales.github.io/kubernetes/k8s-test-tools/?utm_source=atom_feed" rel="related" type="text/html" title="Validate Kubernetes Deployment in CI/CD" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
            
                <id>https://devopstales.github.io/kubernetes/migrate-docker-to-crio/</id>
            
            
            <published>2022-05-05T00:00:00+00:00</published>
            <updated>2022-05-05T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>With the new Kubernetes 1.24 and deprecation of dockershim, in this post I will show you how you can migrate your kubernetes cluster from docker to cri-o.</p>
<h3 id="how-to-migrate">How to migrate</h3>
<p>You have to be careful if you are on a single master node configuration. The cluster will be unavailable under the upgrade.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes -o wide
</span></span><span style="display:flex;"><span>NAME    STATUS   ROLES                  AGE     VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION                             CONTAINER-RUNTIME
</span></span><span style="display:flex;"><span>k8s01   Ready    control-plane,master   78m     v1.20.4   10.65.79.164   &lt;none&gt;        CentOS Linux <span style="color:#ae81ff">8</span>       4.18.0-240.15.1.el8_3.centos.plus.x86_64   docker://20.10.5
</span></span><span style="display:flex;"><span>k8s02   Ready    control-plane,master   64m     v1.20.4   10.65.79.131   &lt;none&gt;        CentOS Linux <span style="color:#ae81ff">8</span>       4.18.0-240.15.1.el8_3.centos.plus.x86_64   docker://20.10.5
</span></span><span style="display:flex;"><span>k8s03   Ready    control-plane,master   4m16s   v1.20.4   10.65.79.244   &lt;none&gt;        CentOS Linux <span style="color:#ae81ff">8</span>       4.18.0-240.15.1.el8_3.centos.plus.x86_64   docker://20.10.5
</span></span></code></pre></div><p>First we will cordon and drain the node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl cordon k8s01
</span></span><span style="display:flex;"><span>kubectl drain k8s01 --ignore-daemonsets
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes
</span></span><span style="display:flex;"><span>NAME    STATUS                      ROLES                  AGE    VERSION
</span></span><span style="display:flex;"><span>k8s01   Ready,SchedulingDisabled    control-plane,master   83m    v1.20.4
</span></span><span style="display:flex;"><span>k8s02   Ready                       control-plane,master   69m    v1.20.4
</span></span><span style="display:flex;"><span>k8s03   Ready                       control-plane,master   9m30s  v1.20.4
</span></span></code></pre></div><p>Stop the kubelet sevice and remove docker:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl stop kubelet
</span></span><span style="display:flex;"><span>sudo systemctl status kubelet
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apt purge docker-ce docker-ce-cli
</span></span><span style="display:flex;"><span>OR
</span></span><span style="display:flex;"><span>yum remove docker-ce docker-ce-cli
</span></span></code></pre></div><h3 id="install-and-configure-cri-o">Install and configure cri-o:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">## Install cri-o to centos/alma linux/rocky linux</span>
</span></span><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span>1.24
</span></span><span style="display:flex;"><span>OS<span style="color:#f92672">=</span>CentOS_7
</span></span><span style="display:flex;"><span><span style="color:#75715e"># OR</span>
</span></span><span style="display:flex;"><span>OS<span style="color:#f92672">=</span>CentOS_8
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/$OS/devel:kubic:libcontainers:stable.repo
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable_cri-o_<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>/$OS/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install cri-o
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Install cri-o to ubuntu/debian</span>
</span></span><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span>1.24
</span></span><span style="display:flex;"><span>OS<span style="color:#f92672">=</span>Debian_Unstable
</span></span><span style="display:flex;"><span><span style="color:#75715e"># OR</span>
</span></span><span style="display:flex;"><span>OS<span style="color:#f92672">=</span>xUbuntu_20.04
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/</span>$OS<span style="color:#e6db74">/ /&#34;</span> &gt; /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/</span>$VERSION<span style="color:#e6db74">/</span>$OS<span style="color:#e6db74">/ /&#34;</span> &gt; /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:$VERSION.list
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -L https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:$VERSION/$OS/Release.key | apt-key add -
</span></span><span style="display:flex;"><span>curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/Release.key | apt-key add -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>apt-get update
</span></span><span style="display:flex;"><span>apt-get install cri-o cri-o-runc
</span></span></code></pre></div><p>You nee the same cgroup manager in cri-o and kubeadm. The default for <code>kubeadm</code> is <code>cgroupfs</code> and for <code>cri-o</code> the default is <code>systemd</code>. In this example I configured cri-o for cgroupfs.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/crio/crio.conf
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>crio.runtime<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>conmon_cgroup <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;pod&#34;</span>
</span></span><span style="display:flex;"><span>cgroup_manager <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;cgroupfs&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano /etc/containers/registries.conf
</span></span><span style="display:flex;"><span>registries <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;quay.io&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;docker.io&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">]</span>
</span></span></code></pre></div><p>If you want to use systemd:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;KUBELET_EXTRA_ARGS=--cgroup-driver=systemd&#34;</span> | tee /etc/sysconfig/kubelet
</span></span></code></pre></div><p>Prepare the system for cri-o:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv6.conf.all.disable_ipv6 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv6.conf.default.disable_ipv6 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;runtime-endpoint: unix:///var/run/crio/crio.sock&#34;</span> &gt; /etc/crictl.yaml
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Start cri-o</span>
</span></span><span style="display:flex;"><span>systemctl enable --now crio
</span></span><span style="display:flex;"><span>systemctl status crio
</span></span></code></pre></div><p>Change runtime in kubeadm config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span><span style="color:#75715e"># add the following flags to KUBELET_KUBEADM_ARGS variable</span>
</span></span><span style="display:flex;"><span>KUBELET_KUBEADM_ARGS<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;... --container-runtime=remote --container-runtime-endpoint=/var/run/crio/crio.sock --runtime-request-timeout=5m --cgroup-driver=systemd &#34;</span>
</span></span></code></pre></div><p>Start kubelet:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl start kubelet
</span></span></code></pre></div><p>Check if the new runtime on the node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe node k8s01
</span></span></code></pre></div><p>Uncordon the node to mark it schedulable agen:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl uncordon k8s01
</span></span></code></pre></div><p>Once you changed the runetime on all the nodes you are done.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install kubernetes with kubeadm V2]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-install-containerd-v2/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-test-tools/?utm_source=atom_feed" rel="related" type="text/html" title="Validate Kubernetes Deployment in CI/CD" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kyverno-cosign/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification with Kyverno" />
                <link href="https://devopstales.github.io/kubernetes/kyverno-image-mirror/?utm_source=atom_feed" rel="related" type="text/html" title="Automatically change registry in pod definition" />
                <link href="https://devopstales.github.io/kubernetes/k8s-connaisseur-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification Admission Controller V2" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-install-containerd-v2/</id>
            
            
            <published>2022-05-02T00:00:00+00:00</published>
            <updated>2022-05-02T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Kubeadm is a tool that helps you bootstrap a simple Kubernetes cluster and simplifies the deployment process.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>192.168.1.41  kubernetes01 <span style="color:#75715e"># master node</span>
</span></span><span style="display:flex;"><span>192.168.1.42  kubernetes02 <span style="color:#75715e"># frontend node</span>
</span></span><span style="display:flex;"><span>192.168.1.43  kubernetes03 <span style="color:#75715e"># worker node</span>
</span></span><span style="display:flex;"><span>192.168.1.44  kubernetes04 <span style="color:#75715e"># worker node</span>
</span></span><span style="display:flex;"><span>192.168.1.45  kubernetes05 <span style="color:#75715e"># worker node</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># hardware requirement</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4</span> CPU
</span></span><span style="display:flex;"><span>16G RAM
</span></span></code></pre></div><h3 id="enable-cgroupv2">Enable cgroupV2</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf install -y grubby
</span></span><span style="display:flex;"><span>sudo grubby <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --update-kernel<span style="color:#f92672">=</span>ALL <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --args<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;systemd.unified_cgroup_hierarchy=1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt;&gt; /etc/systemd/system.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultCPUAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultIOAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultIPAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">DefaultBlockIOAccounting=yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>init <span style="color:#ae81ff">6</span>
</span></span></code></pre></div><h3 id="configure-date-time-and-selinux">Configure date time and selinux</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>timedatectl set-timezone Europe/Budapest
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf install -y vim net-tools chrony ntpstat
</span></span><span style="display:flex;"><span>timedatectl set-ntp true
</span></span><span style="display:flex;"><span>systemctl enable chronyd --now
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl stop firewalld
</span></span><span style="display:flex;"><span>systemctl mask firewalld
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>setenforce <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/=\(enforcing\|permissive\)/=disabled/g&#39;</span> /etc/sysconfig/selinux
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/=\(enforcing\|permissive\)/=disabled/g&#39;</span> /etc/selinux/config
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;net.ipv6.conf.all.disable_ipv6 = 1&#34;</span> &gt;&gt; /etc/sysctl.conf
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;net.ipv6.conf.default.disable_ipv6 = 1&#34;</span> &gt;&gt; /etc/sysctl.conf
</span></span><span style="display:flex;"><span>sysctl -p
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;centos.mydomain.lan&#34;</span> &gt; /etc/hostname
</span></span><span style="display:flex;"><span>hostnamectl set-hostname centos.mydomain.lan
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ifconfig | grep inet | grep -v inet6 | cut -d<span style="color:#e6db74">&#34; &#34;</span> -f10 | sed <span style="color:#e6db74">&#34;s|</span>$<span style="color:#e6db74">|   `hostname -s` `hostname -f`|&#34;</span> &gt;&gt; /etc/hosts
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#34;s|::1|#::1|&#34;</span> /etc/hosts
</span></span></code></pre></div><h3 id="install-containerd">Install containerd</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>dnf install -y epel-release
</span></span><span style="display:flex;"><span>dnf install -y device-mapper-persistent-data lvm2 iproute-tc
</span></span><span style="display:flex;"><span>dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style="display:flex;"><span>dnf install -y containerd.io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Configure containerd</span>
</span></span><span style="display:flex;"><span>sudo mkdir -p /etc/containerd
</span></span><span style="display:flex;"><span>sudo containerd config default &gt; /etc/containerd/config.toml
</span></span></code></pre></div><h3 id="configuuration">Configuuration</h3>
<p>To use the <code>systemd</code> cgroup driver in <code>/etc/containerd/config.toml</code> with <code>runc</code>, set</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc.options<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>            SystemdCgroup <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><p>As you can see we dose n ot siabled the swap:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bas" data-lang="bas"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">#</span> show swap is on
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">$</span> swapon <span style="color:#f92672">--</span>show
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">NAME</span>      <span style="color:#66d9ef">TYPE</span>      SIZE USED PRIO
</span></span><span style="display:flex;"><span><span style="color:#f92672">/</span>dev<span style="color:#f92672">/</span>sda1 partition   <span style="color:#ae81ff">2</span>G   <span style="color:#ae81ff">0</span>B   <span style="color:#ae81ff">-2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">#</span> check for type cgroup2
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">$</span> mount <span style="color:#f92672">-</span>l<span style="color:#f92672">|</span>grep cgroup
</span></span><span style="display:flex;"><span>cgroup2 on <span style="color:#f92672">/</span>sys<span style="color:#f92672">/</span>fs<span style="color:#f92672">/</span>cgroup type cgroup2 (rw,nosuid,nodev,noexec,relatime,seclabel,nsdelegate)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">#</span> check for cpu controller
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">$</span> cat <span style="color:#f92672">/</span>sys<span style="color:#f92672">/</span>fs<span style="color:#f92672">/</span>cgroup<span style="color:#f92672">/</span>cgroup<span style="color:#f92672">.</span>subtree_control
</span></span><span style="display:flex;"><span>cpu io memory pids
</span></span></code></pre></div><h3 id="install-kubeadm">Install kubeadm</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt;&gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo dnf -y install kubelet kubeadm kubectl --disableexcludes<span style="color:#f92672">=</span>kubernetes
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Start containerd</span>
</span></span><span style="display:flex;"><span>systemctl enable --now containerd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;runtime-endpoint: unix:///run/containerd/containerd.sock&#34;</span> &gt; /etc/crictl.yaml
</span></span><span style="display:flex;"><span>crictl ps
</span></span></code></pre></div><p>Change runtime in kubeadm config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># add the following flags to KUBELET_KUBEADM_ARGS variable</span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /etc/sysconfig/kubelet
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KUBELET_EXTRA_ARGS=&#34;--node-ip=192.168.1.41 --container-runtime=remote --container-runtime-endpoint=/run/containerd/containerd.sock --cgroup-driver=systemd --fail-swap-on=false&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl enable --now kubelet
</span></span><span style="display:flex;"><span>sudo systemctl status kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm config images pull
</span></span></code></pre></div><h3 id="init-master">Init master</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo kubeadm init <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--apiserver-advertise-address<span style="color:#f92672">=</span>192.168.1.41 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--cri-socket<span style="color:#f92672">=</span>unix:///run/containerd/containerd.sock <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--ignore-preflight-errors<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Swap&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
</span></span></code></pre></div><h3 id="join-workers-to-cluster">Join workers to cluster</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm join 192.168.100.10:6443 --token XXXXXXXX <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --discovery-token-ca-cert-hash sha256:XXXXXXXX
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install -y https://harbottle.gitlab.io/harbottle-main/7/x86_64/harbottle-main-release.rpm
</span></span><span style="display:flex;"><span>yum install -y kubectx helm
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="containerd" term="containerd" label="containerd" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Containers vs. Pods - Deepdyve]]></title>
            <link href="https://devopstales.github.io/kubernetes/containers-vs-pods/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/container-runtimes/?utm_source=atom_feed" rel="related" type="text/html" title="Containers and Container runtimes for Beginners" />
                <link href="https://devopstales.github.io/kubernetes/flagger-nginx-canary-deployments/?utm_source=atom_feed" rel="related" type="text/html" title="Flagger NGINX Canary Deployments" />
                <link href="https://devopstales.github.io/kubernetes/k8s-test-tools/?utm_source=atom_feed" rel="related" type="text/html" title="Validate Kubernetes Deployment in CI/CD" />
                <link href="https://devopstales.github.io/cloud/aws-eks-ecr/?utm_source=atom_feed" rel="related" type="text/html" title="Elastic Container Registry Integration with EKS" />
                <link href="https://devopstales.github.io/cloud/aws-eks-amp-monitoring/?utm_source=atom_feed" rel="related" type="text/html" title="Using AWS Prometheus (AMP) for monitoring AWS EKS cluster." />
            
                <id>https://devopstales.github.io/kubernetes/containers-vs-pods/</id>
            
            
            <published>2022-04-29T00:00:00+00:00</published>
            <updated>2022-04-29T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post we will take a look at the difference between containers and pods.</p>
<p>With the wide usage of Docker/OICD Containers, they become a replacement for vm-s. This solution is based on Micro services best prentices that means  you are using one service per container.
This can be a problem some situation and blocks moving from vm to container. While thar is a few workaround for running multiple service, Kubernetes hes a solution in a for of &lsquo;Pods&rsquo;. Pods are the smallest deployable units of Kubernetes. It is a group of one or more containers, with shared resources.
Every pod gets a unique IP. More from this in the <a href="/kubernetes/kubernetes-networking-1/">networking post</a>. This means you cannot run the same ports on different container in the same namespace. Every container in a pod gets an isolated filesystem and that from inside one container, you don&rsquo;t see processes running in other containers of the same pod. But containers in one pod can communicate via shared memory!</p>
<p>Containers dose not necessary means Docker. There are more container technologies lik LXC, OpenVZ, and more. The difference in this technologies are the different type of isolation for processes running in the container. As we talked about <a href="/kubernetes/kubernetes-deprecated-docker-containderd-docker/">in a prewious post</a> Docker/OICD Containers standards are based on the OCI Runtime Spec.</p>
<h3 id="namespace-isolation">Namespace Isolation</h3>
<p>Let&rsquo;s see what isolation primitives were created when I started the container:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Look up the container in the process tree.</span>
</span></span><span style="display:flex;"><span>$ ps auxf
</span></span><span style="display:flex;"><span>USER       PID  ...  COMMAND
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>root      <span style="color:#ae81ff">4707</span>       /usr/bin/containerd-shim-runc-v2 -namespace moby -id cc9466b3e...
</span></span><span style="display:flex;"><span>root      <span style="color:#ae81ff">4727</span>        <span style="color:#ae81ff">\_</span> nginx: master process nginx -g daemon off;
</span></span><span style="display:flex;"><span>systemd+  <span style="color:#ae81ff">4781</span>            <span style="color:#ae81ff">\_</span> nginx: worker process
</span></span><span style="display:flex;"><span>systemd+  <span style="color:#ae81ff">4782</span>            <span style="color:#ae81ff">\_</span> nginx: worker process
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Find the namespaces used by 4727 process.</span>
</span></span><span style="display:flex;"><span>$ sudo lsns
</span></span><span style="display:flex;"><span>        NS TYPE   NPROCS   PID USER    COMMAND
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532157</span> mnt         <span style="color:#ae81ff">3</span>  <span style="color:#ae81ff">4727</span> root    nginx: master process nginx -g daemon off;
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532158</span> uts         <span style="color:#ae81ff">3</span>  <span style="color:#ae81ff">4727</span> root    nginx: master process nginx -g daemon off;
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532159</span> ipc         <span style="color:#ae81ff">3</span>  <span style="color:#ae81ff">4727</span> root    nginx: master process nginx -g daemon off;
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532160</span> pid         <span style="color:#ae81ff">3</span>  <span style="color:#ae81ff">4727</span> root    nginx: master process nginx -g daemon off;
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532162</span> net         <span style="color:#ae81ff">3</span>  <span style="color:#ae81ff">4727</span> root    nginx: master process nginx -g daemon off;
</span></span></code></pre></div><p>As you can see Docker user multiple namespaces to isolate the conatiners:</p>
<ul>
<li>mnt - isolated mount table</li>
<li>uts - the container has its own hostname and domain name</li>
<li>ipc, pid - only to processes inside the same container can communicate with eache other</li>
<li>net - the container gets its own network stack</li>
</ul>
<p>User ID namespace is not used by default but you can run docker with <a href="https://docs.docker.com/engine/security/rootless/">rootless</a> and use <a href="https://docs.docker.com/engine/security/userns-remap/">user isolation</a>.</p>
<p>There is one other major namespace and that is <code>Cgroup</code>. Cgroup can be use to limits hungry processes to accidentally consume all the host&rsquo;s resources.</p>
<h3 id="check-cgroup-limits">Check Cgroup limits</h3>
<p>We can examining he corresponding subtree in the cgroup virtual filesystem. <code>cgroupfs</code> is mounted as <code>/sys/fs/cgroup</code> and for processes <code>/proc/&lt;PID&gt;/cgroup</code>.</p>
<p>Lets run a container for testing:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker run --name foo --rm -d --memory<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;512MB&#39;</span> --cpus<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;0.5&#39;</span> nginx
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># et pid for container</span>
</span></span><span style="display:flex;"><span>PID<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>docker inspect --format <span style="color:#e6db74">&#39;{{.State.Pid}}&#39;</span> foo<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Check cgroupfs node for the container main process (4727).</span>
</span></span><span style="display:flex;"><span>$ cat /proc/<span style="color:#e6db74">${</span>PID<span style="color:#e6db74">}</span>/cgroup
</span></span><span style="display:flex;"><span>11:freezer:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0
</span></span><span style="display:flex;"><span>10:blkio:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0
</span></span><span style="display:flex;"><span>9:rdma:/
</span></span><span style="display:flex;"><span>8:pids:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0
</span></span><span style="display:flex;"><span>7:devices:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0
</span></span><span style="display:flex;"><span>6:cpuset:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0
</span></span><span style="display:flex;"><span>5:cpu,cpuacct:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0
</span></span><span style="display:flex;"><span>4:memory:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0
</span></span><span style="display:flex;"><span>3:net_cls,net_prio:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0
</span></span><span style="display:flex;"><span>2:perf_event:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0
</span></span><span style="display:flex;"><span>1:name<span style="color:#f92672">=</span>systemd:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0
</span></span><span style="display:flex;"><span>0::/system.slice/containerd.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Check the memory limit.</span>
</span></span><span style="display:flex;"><span>$ cat /sys/fs/cgroup/memory/docker/<span style="color:#e6db74">${</span>ID<span style="color:#e6db74">}</span>/memory.limit_in_bytes
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">536870912</span>  <span style="color:#75715e"># Yay! It&#39;s the 512MB we requested!</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># See the CPU limits.</span>
</span></span><span style="display:flex;"><span>ls /sys/fs/cgroup/cpu/docker/<span style="color:#e6db74">${</span>ID<span style="color:#e6db74">}</span>
</span></span></code></pre></div><h3 id="examining-a-kubernetes-pod">Examining a Kubernetes pod</h3>
<p>To keep the Docker Containers and Kubernetes Pods fair comparison I use a Docker as the engine in Kubernetes. Now I start a pod for testing:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: foo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - name: app
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      image: docker.io/kennethreitz/httpbin
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      resources:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        limits:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          memory: &#34;256Mi&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - name: sidecar
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      image: curlimages/curl
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      command: [&#34;/bin/sleep&#34;, &#34;3650d&#34;]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      resources:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        limits:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          memory: &#34;128Mi&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>The actual pod inspection should be done on the Kubernetes cluster node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ ps auxf
</span></span><span style="display:flex;"><span>USER       PID  ...  COMMAND
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>root      <span style="color:#ae81ff">4947</span>         <span style="color:#ae81ff">\_</span> containerd-shim -namespace k8s.io -workdir /mnt/sda1/var/lib/containerd/...
</span></span><span style="display:flex;"><span>root      <span style="color:#ae81ff">4966</span>             <span style="color:#ae81ff">\_</span> /pause
</span></span><span style="display:flex;"><span>root      <span style="color:#ae81ff">4981</span>         <span style="color:#ae81ff">\_</span> containerd-shim -namespace k8s.io -workdir /mnt/sda1/var/lib/containerd/...
</span></span><span style="display:flex;"><span>root      <span style="color:#ae81ff">5001</span>             <span style="color:#ae81ff">\_</span> /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span>root      <span style="color:#ae81ff">5016</span>                 <span style="color:#ae81ff">\_</span> /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span>root      <span style="color:#ae81ff">5018</span>         <span style="color:#ae81ff">\_</span> containerd-shim -namespace k8s.io -workdir /mnt/sda1/var/lib/containerd/...
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">100</span>       <span style="color:#ae81ff">5035</span>             <span style="color:#ae81ff">\_</span> /bin/sleep 3650d
</span></span></code></pre></div><p>The above three process groups were created during the pod startup. That&rsquo;s interesting because in the manifest, only two containers, <code>httpbin</code> and <code>sleep</code>, were requested.</p>
<p>Every Kubernetes Pod includes an empty pause container, which bootstraps the Pod to establish all of the cgroups, reservations, and namespaces before its individual containers are created. The pause container image is always present, so the pod resource allocation happens instantaneously as containers are created.</p>
<p>Display pause containers:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker ps | grep -I pause
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>80282e0baa43   mirantis/ucp-pause:3.4.9   <span style="color:#e6db74">&#34;/pause&#34;</span>   <span style="color:#ae81ff">3</span> minutes ago   Up <span style="color:#ae81ff">3</span> minutes   k8s_POD_foo-wxk5l_default_030fc501-ec75-4675-a742-d19929818065_0
</span></span></code></pre></div><p>Here is how the namespaces look like on the cluster node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo lsns
</span></span><span style="display:flex;"><span>        NS TYPE   NPROCS   PID USER            COMMAND
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532614</span> net         <span style="color:#ae81ff">4</span>  <span style="color:#ae81ff">4966</span> root            /pause
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532715</span> mnt         <span style="color:#ae81ff">1</span>  <span style="color:#ae81ff">4966</span> root            /pause
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532716</span> uts         <span style="color:#ae81ff">4</span>  <span style="color:#ae81ff">4966</span> root            /pause
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532717</span> ipc         <span style="color:#ae81ff">4</span>  <span style="color:#ae81ff">4966</span> root            /pause
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532718</span> pid         <span style="color:#ae81ff">1</span>  <span style="color:#ae81ff">4966</span> root            /pause
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532719</span> mnt         <span style="color:#ae81ff">2</span>  <span style="color:#ae81ff">5001</span> root            /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532720</span> pid         <span style="color:#ae81ff">2</span>  <span style="color:#ae81ff">5001</span> root            /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532721</span> mnt         <span style="color:#ae81ff">1</span>  <span style="color:#ae81ff">5035</span> <span style="color:#ae81ff">100</span>             /bin/sleep 3650d
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532722</span> pid         <span style="color:#ae81ff">1</span>  <span style="color:#ae81ff">5035</span> <span style="color:#ae81ff">100</span>             /bin/sleep 3650d
</span></span></code></pre></div><p>So, much like the Docker container in the first section, the pause container gets all five namespaces - net, mnt, uts, ipc, and pid. But apparently, httpbin and sleep containers get just by two namespaces mnt and pid.</p>
<p>With the proc we can get tha semo for all the pods:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># httpbin container</span>
</span></span><span style="display:flex;"><span>sudo ls -l /proc/5001/ns
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> Apr <span style="color:#ae81ff">24</span> 14:05 ipc -&gt; <span style="color:#e6db74">&#39;ipc:[4026532717]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> Apr <span style="color:#ae81ff">24</span> 14:05 mnt -&gt; <span style="color:#e6db74">&#39;mnt:[4026532719]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> Apr <span style="color:#ae81ff">24</span> 14:05 net -&gt; <span style="color:#e6db74">&#39;net:[4026532614]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> Apr <span style="color:#ae81ff">24</span> 14:05 pid -&gt; <span style="color:#e6db74">&#39;pid:[4026532720]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> Apr <span style="color:#ae81ff">24</span> 14:05 uts -&gt; <span style="color:#e6db74">&#39;uts:[4026532716]&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># sleep container</span>
</span></span><span style="display:flex;"><span>sudo ls -l /proc/5035/ns
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">100</span> <span style="color:#ae81ff">101</span> <span style="color:#ae81ff">0</span> Apr <span style="color:#ae81ff">24</span> 14:05 ipc -&gt; <span style="color:#e6db74">&#39;ipc:[4026532717]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">100</span> <span style="color:#ae81ff">101</span> <span style="color:#ae81ff">0</span> Apr <span style="color:#ae81ff">24</span> 14:05 mnt -&gt; <span style="color:#e6db74">&#39;mnt:[4026532721]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">100</span> <span style="color:#ae81ff">101</span> <span style="color:#ae81ff">0</span> Apr <span style="color:#ae81ff">24</span> 14:05 net -&gt; <span style="color:#e6db74">&#39;net:[4026532614]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">100</span> <span style="color:#ae81ff">101</span> <span style="color:#ae81ff">0</span> Apr <span style="color:#ae81ff">24</span> 14:05 pid -&gt; <span style="color:#e6db74">&#39;pid:[4026532722]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">100</span> <span style="color:#ae81ff">101</span> <span style="color:#ae81ff">0</span> Apr <span style="color:#ae81ff">24</span> 14:05 uts -&gt; <span style="color:#e6db74">&#39;uts:[4026532716]&#39;</span>
</span></span></code></pre></div><p>While it might be tricky to notice, the httpbin and sleep containers actually reuse the net, uts, and ipc namespaces of the pause container!</p>
<p>With kubernetes config the <code>hostIPC</code>, <code>hostNetwork</code>, and <code>hostPID</code> flags can make the containers use the corresponding host&rsquo;s namespaces.</p>
<h3 id="inspecting-pods-cgroups">Inspecting pod&rsquo;s cgroups</h3>
<p>Check the cgroups for pods:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ sudo systemd-cgls
</span></span><span style="display:flex;"><span>Control group /:
</span></span><span style="display:flex;"><span>-.slice
</span></span><span style="display:flex;"><span>├─kubepods
</span></span><span style="display:flex;"><span>│ ├─burstable
</span></span><span style="display:flex;"><span>│ │ ├─pod4a8d5c3e-3821-4727-9d20-965febbccfbb
</span></span><span style="display:flex;"><span>│ │ │ ├─f0e87a93304666766ab139d52f10ff2b8d4a1e6060fc18f74f28e2cb000da8b2
</span></span><span style="display:flex;"><span>│ │ │ │ └─4966 /pause
</span></span><span style="display:flex;"><span>│ │ │ ├─dfb1cd29ab750064ae89613cb28963353c3360c2df913995af582aebcc4e85d8
</span></span><span style="display:flex;"><span>│ │ │ │ ├─5001 /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span>│ │ │ │ └─5016 /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span>│ │ │ └─097d4fe8a7002d69d6c78899dcf6731d313ce8067ae3f736f252f387582e55ad
</span></span><span style="display:flex;"><span>│ │ │   └─5035 /bin/sleep 3650d
</span></span></code></pre></div><p>So, the pod itself gets a parent node, and every container can be tweaked separately as well.</p>
<h3 id="implementing-pods-with-docker">Implementing Pods with Docker</h3>
<p>Because Pod under the hood is implemented as a bunch of shared namespaced containers with a common cgroup parent, I will try to reproduce this with Docker because Docker cannot manage pods.</p>
<p>Docker allows creating a container that reuses an existing network namespace. I&rsquo;ll use an extra package to simplify dealing with cgroups:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt-get install cgroup-tools
</span></span></code></pre></div><p>Firstly, a parent cgroup entry needs to be configured. For the sake of simplecity, I&rsquo;ll use only cpu and memory controllers:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo cgcreate -g cpu,memory:/pod-foo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Check if the corresponding folders were created:</span>
</span></span><span style="display:flex;"><span>ls -l /sys/fs/cgroup/cpu/pod-foo/
</span></span><span style="display:flex;"><span>ls -l /sys/fs/cgroup/memory/pod-foo/
</span></span></code></pre></div><p>Secondly, a sandbox (paus) container should be created:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ docker run -d --rm <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --name foo_sandbox <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cgroup-parent /pod-foo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ipc <span style="color:#e6db74">&#39;shareable&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  alpine sleep infinity
</span></span></code></pre></div><p>Lastly, starting the actual containers reusing the namespaces of the sandbox container:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># app (httpbin)</span>
</span></span><span style="display:flex;"><span>$ docker run -d --rm <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --name app <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cgroup-parent /pod-foo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --network container:foo_sandbox <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ipc container:foo_sandbox <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  kennethreitz/httpbin
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># sidecar (sleep)</span>
</span></span><span style="display:flex;"><span>$ docker run -d --rm <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --name sidecar <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cgroup-parent /pod-foo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --network container:foo_sandbox <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ipc container:foo_sandbox <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  curlimages/curl sleep 365d
</span></span></code></pre></div><p>I couldn&rsquo;t share the uts namespace between containers, because Docker not allow to configure that. You can use only just the host&rsquo;s uts namespace. But apart from the uts namespace, it&rsquo;s a success!</p>
<p>The cgroups look much like the ones created by Kubernetes itself:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ sudo systemd-cgls memory
</span></span><span style="display:flex;"><span>Controller memory; Control group /:
</span></span><span style="display:flex;"><span>├─pod-foo
</span></span><span style="display:flex;"><span>│ ├─488d76cade5422b57ab59116f422d8483d435a8449ceda0c9a1888ea774acac7
</span></span><span style="display:flex;"><span>│ │ ├─27865 /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span>│ │ └─27880 /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span>│ ├─9166a87f9a96a954b10ec012104366da9f1f6680387ef423ee197c61d37f39d7
</span></span><span style="display:flex;"><span>│ │ └─27977 sleep 365d
</span></span><span style="display:flex;"><span>│ └─c7b0ec46b16b52c5e1c447b77d67d44d16d78f9a3f93eaeb3a86aa95e08e28b6
</span></span><span style="display:flex;"><span>│   └─27743 sleep infinity
</span></span></code></pre></div><p>The global list of namespaces also looks familiar:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ sudo lsns
</span></span><span style="display:flex;"><span>        NS TYPE   NPROCS   PID USER    COMMAND
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532157</span> mnt         <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">27743</span> root    sleep infinity
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532158</span> uts         <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">27743</span> root    sleep infinity
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532159</span> ipc         <span style="color:#ae81ff">4</span> <span style="color:#ae81ff">27743</span> root    sleep infinity
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532160</span> pid         <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">27743</span> root    sleep infinity
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532162</span> net         <span style="color:#ae81ff">4</span> <span style="color:#ae81ff">27743</span> root    sleep infinity
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532218</span> mnt         <span style="color:#ae81ff">2</span> <span style="color:#ae81ff">27865</span> root    /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532219</span> uts         <span style="color:#ae81ff">2</span> <span style="color:#ae81ff">27865</span> root    /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532220</span> pid         <span style="color:#ae81ff">2</span> <span style="color:#ae81ff">27865</span> root    /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532221</span> mnt         <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">27977</span> _apt    sleep 365d
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532222</span> uts         <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">27977</span> _apt    sleep 365d
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026532223</span> pid         <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">27977</span> _apt    sleep 365d
</span></span></code></pre></div><p>And the <code>httpbin</code> and <code>sidecar</code> containers seems to share the &lsquo;ipc&rsquo; and &rsquo;net&rsquo; namespaces:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># app container</span>
</span></span><span style="display:flex;"><span>$ sudo ls -l /proc/27865/ns
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> Oct <span style="color:#ae81ff">28</span> 07:56 ipc -&gt; <span style="color:#e6db74">&#39;ipc:[4026532159]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> Oct <span style="color:#ae81ff">28</span> 07:56 mnt -&gt; <span style="color:#e6db74">&#39;mnt:[4026532218]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> Oct <span style="color:#ae81ff">28</span> 07:56 net -&gt; <span style="color:#e6db74">&#39;net:[4026532162]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> Oct <span style="color:#ae81ff">28</span> 07:56 pid -&gt; <span style="color:#e6db74">&#39;pid:[4026532220]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> Oct <span style="color:#ae81ff">28</span> 07:56 uts -&gt; <span style="color:#e6db74">&#39;uts:[4026532219]&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># sidecar container</span>
</span></span><span style="display:flex;"><span>$ sudo ls -l /proc/27977/ns
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> _apt systemd-journal <span style="color:#ae81ff">0</span> Oct <span style="color:#ae81ff">28</span> 07:56 ipc -&gt; <span style="color:#e6db74">&#39;ipc:[4026532159]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> _apt systemd-journal <span style="color:#ae81ff">0</span> Oct <span style="color:#ae81ff">28</span> 07:56 mnt -&gt; <span style="color:#e6db74">&#39;mnt:[4026532221]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> _apt systemd-journal <span style="color:#ae81ff">0</span> Oct <span style="color:#ae81ff">28</span> 07:56 net -&gt; <span style="color:#e6db74">&#39;net:[4026532162]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> _apt systemd-journal <span style="color:#ae81ff">0</span> Oct <span style="color:#ae81ff">28</span> 07:56 pid -&gt; <span style="color:#e6db74">&#39;pid:[4026532223]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> _apt systemd-journal <span style="color:#ae81ff">0</span> Oct <span style="color:#ae81ff">28</span> 07:56 uts -&gt; <span style="color:#e6db74">&#39;uts:[4026532222]&#39;</span>
</span></span></code></pre></div><h3 id="podman-pods">podman Pods</h3>
<p>There is a Docker alternative OICD compatible Container engine called podman that can be managed pods of containers like Kubernetes.</p>
<p>First I start a pod wit some containers to test:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ sudo podman pod create --name my_pod
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ sudo podman pod list
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>POD ID        NAME    STATUS   CREATED        INFRA ID      <span style="color:#75715e"># OF CONTAINERS</span>
</span></span><span style="display:flex;"><span>0e0862e977e1  my_pod     Created  <span style="color:#ae81ff">9</span> seconds ago  19e248401b83  <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ sudo podman ps -a --pod
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CONTAINER ID  IMAGE                 COMMAND  CREATED         STATUS   PORTS   NAMES               POD ID        PODNAME
</span></span><span style="display:flex;"><span>19e248401b83  k8s.gcr.io/pause:3.5           <span style="color:#ae81ff">13</span> seconds ago  Created          0e0862e977e1-infra  0e0862e977e1  my_pod
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ sudo podman run -dt --pod my_pod docker.io/curlimages/curl sleep 365d
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ sudo podman run -dt --pod my_pod docker.io/kennethreitz/httpbin
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ sudo podman ps -a --pod
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CONTAINER ID  IMAGE                                  COMMAND               CREATED             STATUS                 PORTS   NAMES               POD ID        PODNAME
</span></span><span style="display:flex;"><span>b4f923a0af26  k8s.gcr.io/pause:3.5                                         About a minute ago  Up About a minute ago          b49582203b1a-infra  b49582203b1a  my_pod
</span></span><span style="display:flex;"><span>51f3c3ea6959  docker.io/curlimages/curl:latest       sleep 365d            About a minute ago  Up About a minute ago          gracious_hellman    b49582203b1a  my_pod
</span></span><span style="display:flex;"><span>2a5b513a3089  docker.io/kennethreitz/httpbin:latest  gunicorn -b 0.0.0...  <span style="color:#ae81ff">3</span> seconds ago       Up <span style="color:#ae81ff">3</span> seconds ago               laughing_villani    b49582203b1a  my_pod
</span></span></code></pre></div><p>Ten we can list the used namespaces:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ sudo lsns
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534263</span> net         <span style="color:#ae81ff">4</span> <span style="color:#ae81ff">25012</span> root             /pause
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534335</span> mnt         <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">25012</span> root             /pause
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534336</span> uts         <span style="color:#ae81ff">4</span> <span style="color:#ae81ff">25012</span> root             /pause
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534337</span> ipc         <span style="color:#ae81ff">4</span> <span style="color:#ae81ff">25012</span> root             /pause
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534338</span> pid         <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">25012</span> root             /pause
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534340</span> mnt         <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">25023</span> systemd-network  sleep 365d
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534341</span> pid         <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">25023</span> systemd-network  sleep 365d
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534342</span> cgroup      <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">25023</span> systemd-network  sleep 365d
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534344</span> mnt         <span style="color:#ae81ff">2</span> <span style="color:#ae81ff">30514</span> root             /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534345</span> pid         <span style="color:#ae81ff">2</span> <span style="color:#ae81ff">30514</span> root             /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4026534346</span> cgroup      <span style="color:#ae81ff">2</span> <span style="color:#ae81ff">30514</span> root             /usr/bin/python3 /usr/local/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent
</span></span></code></pre></div><p>The containers shar the &lsquo;ipc&rsquo;, &rsquo;net&rsquo;, &rsquo;time&rsquo;, &lsquo;user&rsquo; and &lsquo;uts&rsquo; namespaces.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># httpbin container</span>
</span></span><span style="display:flex;"><span>sudo ls -l /proc/30514/ns
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 cgroup -&gt; <span style="color:#e6db74">&#39;cgroup:[4026534346]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 ipc -&gt; <span style="color:#e6db74">&#39;ipc:[4026534337]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 mnt -&gt; <span style="color:#e6db74">&#39;mnt:[4026534344]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 net -&gt; <span style="color:#e6db74">&#39;net:[4026534263]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 pid -&gt; <span style="color:#e6db74">&#39;pid:[4026534345]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 time -&gt; <span style="color:#e6db74">&#39;time:[4026531834]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 user -&gt; <span style="color:#e6db74">&#39;user:[4026531837]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 uts -&gt; <span style="color:#e6db74">&#39;uts:[4026534336]&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># curl container</span>
</span></span><span style="display:flex;"><span>sudo ls -l /proc/25023/ns
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> systemd-network systemd-journal <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 cgroup -&gt; <span style="color:#e6db74">&#39;cgroup:[4026534342]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> systemd-network systemd-journal <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 ipc -&gt; <span style="color:#e6db74">&#39;ipc:[4026534337]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> systemd-network systemd-journal <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 mnt -&gt; <span style="color:#e6db74">&#39;mnt:[4026534340]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> systemd-network systemd-journal <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 net -&gt; <span style="color:#e6db74">&#39;net:[4026534263]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> systemd-network systemd-journal <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 pid -&gt; <span style="color:#e6db74">&#39;pid:[4026534341]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> systemd-network systemd-journal <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 time -&gt; <span style="color:#e6db74">&#39;time:[4026531834]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> systemd-network systemd-journal <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 user -&gt; <span style="color:#e6db74">&#39;user:[4026531837]&#39;</span>
</span></span><span style="display:flex;"><span>lrwxrwxrwx <span style="color:#ae81ff">1</span> systemd-network systemd-journal <span style="color:#ae81ff">0</span> ápr   <span style="color:#ae81ff">28</span> 18:54 uts -&gt; <span style="color:#e6db74">&#39;uts:[4026534336]&#39;</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Containers and Container runtimes for Beginners]]></title>
            <link href="https://devopstales.github.io/kubernetes/container-runtimes/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-falco/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes audit logs and Falco" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cisa-install/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Hardening Guide with CISA 1.6 Benchmark" />
                <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="related" type="text/html" title="Hardening Kubernetes with seccomp" />
                <link href="https://devopstales.github.io/kubernetes/kubernetes-deprecated-docker-containderd-docker/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes deprecated Docker? Containderd is the new Docker!!" />
                <link href="https://devopstales.github.io/kubernetes/k3s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with CRI-O and kadalu" />
            
                <id>https://devopstales.github.io/kubernetes/container-runtimes/</id>
            
            
            <published>2022-04-22T00:00:00+00:00</published>
            <updated>2022-04-22T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Most people who start with containers believe it is just lightweight virtual machines with fast startup time, but it is a oversimplification that can be misleading. In this post we will try to understand the real natures of containers.</p>
<p>It is easy to follow tutorials from the Internet on how to put a Python or a Node.js application into a container. But Docker is a behemoth doing a wide variety of things, and the apparent simplicity of docker run nginx can be deceptive.</p>
<h3 id="containers-are-not-virtual-machines">Containers Are Not Virtual Machines</h3>
<p>Virtualization engines are creating a paravirtualized hardware that from the perspective of the VirtualMachine is looks like a real hardware. So the virtual machine has its own kernel hat communicate with the virtual hardware. Then the virtualization engine communicate with tha real hardware truth the host&rsquo;s kernel. This solution requires more hardware resource for an app then a direct communication with the kernel.</p>
<p><img src="/img/include/VM-container.png" alt="vm vs cotainer"  class="zoomable" /></p>
<p>A container is just an isolated (namespaces) and restricted (cgroups, capabilities, seccomp) process on the host. It dose not have two kernel layer so requires less resources. To start a containerized process, you need to create namespaces, than run a process in it. A low-level Container Runtime knows how to prepare such namespaces and then how to start a containerized process in it.</p>
<h3 id="what-is-a-low-level-container-runtime">What is a Low-Level Container Runtime?</h3>
<p>Containers are implemented using Linux namespaces and cgroups. Namespaces let you virtualize system resources, like the file system or networking, for each container. Cgroups provide a way to limit the amount of resources like CPU and memory that each container can use. At the lowest level, container runtimes are responsible for setting up these namespaces and cgroups for containers, and then running commands inside those namespaces and cgroups. Low-level runtimes support using these operating system features.</p>
<h4 id="runc">runc</h4>
<p><code>runc</code> is a CLI tool for spawning and running containers according to the OCI specification. Docker donated this library to OCI as a reference implementation of the OCI runtime specification.</p>
<h4 id="crun">crun</h4>
<p><code>crun</code> is a lightweight fully featured OCI runtime and C library for running containers.</p>
<p>&ldquo;While most of the tools used in the Linux containers ecosystem are written in Go, I believe C is a better fit for a lower level tool like a container runtime. runc, the most used implementation of the OCI runtime specs written in Go, re-execs itself and use a module written in C for setting up the environment before the container process starts.&rdquo; (Source: <a href="https://github.com/containers/crun#why-another-implementation">crun GitHub page</a> )</p>
<p><code>crun</code> is faster than runc and has a much lower memory footprint.</p>
<table>
  <thead>
      <tr>
          <th></th>
          <th>crun</th>
          <th>runc</th>
          <th>%</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>100 /bin/true</td>
          <td>0:01.69</td>
          <td>0:3.34</td>
          <td>-49.4%</td>
      </tr>
  </tbody>
</table>
<h3 id="images-arent-needed-to-run-containers">Images Aren&rsquo;t Needed To Run Containers</h3>
<p>For folks familiar with how runc starts containers, it&rsquo;s clear that images aren&rsquo;t really a part of the equation. Instead, to run a container, a runtime needs a so-called bundle that consists of:</p>
<ul>
<li>a config.json file holding container parameters (path to an executable, env vars, etc.)</li>
<li>a folder with the said executable and supporting files (if any).</li>
</ul>
<p>Oftentimes, a bundle folder contains a file structure resembling a typical Linux distribution (/var, /usr, /lib, /etc, &hellip;). When runc launches a container with such a bundle, the process inside gets a root filesystem that looks pretty much like your favorite Linux flavor, be it Debian, CentOS, or Alpine.</p>
<p>But such a file structure is not mandatory! So-called scratch or distroless containers are getting more and more popular nowadays</p>
<h4 id="some-containers-are-virtual-machines">Some Containers are Virtual Machines</h4>
<p><code>runv</code> is a hypervisor-based runtime for OCI. <code>runV</code> supports the following hypervisors:</p>
<ul>
<li>KVM (QEMU 2.1 or later)</li>
<li>KVM (Kvmtool)</li>
<li>Xen (4.5 or later)</li>
<li>QEMU without KVM (NOT RECOMMENDED. QEMU 2.1 or later)</li>
</ul>
<h3 id="what-is-a-shim">What is a shim?</h3>
<p>A container runtime shim is a piece of software that resides in between a container manager (containerd, cri-o, podman) and a low-level container runtime (runc, crun) solving the integration problem of these counterparts.</p>
<p><img src="/img/include/containerd-shim.png" alt="container-d shim"  class="zoomable" /></p>
<h3 id="oci">OCI</h3>
<p>Docker, Google, CoreOS, and other vendors created the <a href="https://opencontainers.org/">Open Container Initiative (OCI)</a>. The OCI currently contains two specifications: the Runtime Specification (runtime-spec) as a standerd of CRI (Container runtime Interface) and the Image Specification (image-spec). This led to other standards like CNI (Container Network Interface), a Cloud Native Computing Foundation project, or Container Storage Interface (CSI).</p>
<h3 id="what-is-a-container-runtime">What is a container runtime?</h3>
<p>Container runtime is the engine that runs and manages the components required to run containers. Communicating with the kernel to start containerized processes, setting up cgroups, configure mount points and do many things to make your container work.</p>
<h3 id="docker">Docker</h3>
<p>Docker was released in 2013 and solved many of the problems that developers had running containers like LXC or OpenVZ. Before version 1.11, the implementation of Docker was a monolithic daemon. The monolith did everything as one package such as downloading container images, launching container processes, exposing a remote API, and acting as a log collection daemon, all in a centralized process running as root. (Source: <a href="https://coreos.com/rkt/docs/latest/rkt-vs-other-projects.html#rkt-vs-docker">Coreos</a> )</p>
<p>At this time docker was the only runtime that Kubernetes supported, but wit the release of Coreos&rsquo;s rkt Kubernetes needed a standard interface to ease the integration of other container runtimes. This led to the splitting of Docker into different parts.</p>
<p><img src="/img/include/conatinerd.png" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/docker_engine.png" alt="Example image"  class="zoomable" /></p>
<h3 id="cri-o">CRI-O</h3>
<p>CRI-O is an implementation of the Kubernetes CRI (Container Runtime Interface) to enable using OCI (Open Container Initiative) compatible runtimes. It is a lightweight alternative to using Docker as the runtime for kubernetes. It allows Kubernetes to use any OCI-compliant runtime as the container runtime for running pods. Today it supports runc and Kata Containers as the container runtimes but any OCI-conformant runtime can be plugged in principle.</p>
<p>CRI-O supports OCI container images and can pull from any container registry. It is a lightweight alternative to using Docker, Moby or rkt as the runtime for Kubernetes. (Source: <a href="https://cri-o.io/">CRI-O Website</a> )</p>
<pre tabindex="0"><code>crictl ps - list containers
crictl pods - list pods
</code></pre><h3 id="pouchcontainer">PouchContainer</h3>
<p>PouchContainer is an open-source project created by Alibaba Group. It provides applications with a lightweight runtime environment with strong isolation and minimal overhead. PouchContainer isolates applications from varying runtime environment, and minimizes operational workload. t includes lots of security features, like hypervisor-based container technology, lxcfs, directory disk quota, patched Linux kernel.  PouchContainer utilizes Dragonfly, a P2P-base distribution system, to achieve lightning-fast container image distribution at enterprise&rsquo;s large scale.</p>
<p><img src="/img/include/pouchcontainer-arch.png" alt="PouchContainer"  class="zoomable" /></p>
<h3 id="kata-containers">Kata Containers</h3>
<p>Kata Containers is an open source community working to build a secure container runtime with lightweight virtual machines that feel and perform like containers, but provide stronger workload isolation using hardware virtualization technology as a second layer of defense. (Source: <a href="https://katacontainers.io/">Kata Containers Website</a> )</p>
<p><img src="/img/include/katacontainers.jpg" alt="Kata container engine"  class="zoomable" /></p>
<h3 id="podman">Podman</h3>
<p>Podman is a daemonless, open source, Linux-native tool designed to develop, manage, and run Open Container Initiative (OCI) containers and pods. It has a similar directory structure to Buildah, Skopeo, and CRI-O. Podman doesn’t admin privileges for its commands to work.</p>
<p><img src="/img/include/porownanie.png" alt="Podman"  class="zoomable" /></p>
<h4 id="containerd">Containerd</h4>
<p><code>containerd</code> is a daemon that controls runC. From containerd website, &ldquo;containerd manages the complete container lifecycle of its host system, from image transfer and storage to container execution and supervision to low-level storage to network attachments and beyond&rdquo;.</p>
<p><img src="/img/include/docker_oci.png" alt="Containerd"  class="zoomable" /></p>
<h3 id="what-is-gvisor">What is gvisor</h3>
<p>gVisor is an application kernel, written in Go, that implements a substantial portion of the Linux system call interface. It provides an additional layer of isolation between running applications and the host operating system.</p>
<p>gVisor includes an Open Container Initiative (OCI) compatible Low-Level Container Runtime called <code>runsc</code> that makes it easy to work with existing container tooling. The <code>runsc</code> runtime integrates with Docker, containerd and Kubernetes, making it simple to run sandboxed containers.</p>
<p><img src="/img/include/gvisor2.png" alt="gvisor"  class="zoomable" />
<img src="/img/include/gvisor.png" alt="gvisor"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="containerd" term="containerd" label="Containerd" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                             
                                <category scheme="podman" term="podman" label="Podman" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="containerd" term="containerd" label="Containerd" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install an OpenShift 4 cluster with Cilium]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-cilium/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift4-calico/?utm_source=atom_feed" rel="related" type="text/html" title="Install an OpenShift 4 cluster with Calico" />
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/k3s-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with k3sup and Cilium" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-cilium/</id>
            
            
            <published>2022-04-06T00:00:00+00:00</published>
            <updated>2022-04-06T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you How you can Install  OpenShift 4 cluster with Cilium.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<h3 id="infrastructure">Infrastructure</h3>
<table>
  <thead>
      <tr>
          <th style="text-align: center">Host</th>
          <th style="text-align: center">ROLES</th>
          <th style="text-align: center">OS</th>
          <th style="text-align: center">IP</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">pfsense</td>
          <td style="text-align: center">Load Balancer, dhcp, dns</td>
          <td style="text-align: center">pfsense</td>
          <td style="text-align: center">192.168.1.1</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-services</td>
          <td style="text-align: center">pxeboot</td>
          <td style="text-align: center">CentOS 7</td>
          <td style="text-align: center">192.168.1.200</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-bootstrap</td>
          <td style="text-align: center">bootstrap</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.210</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-mastr-1</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.201</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-mastr-2</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.202</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-mastr-3</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.203</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-1</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.204</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-2</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.205</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-4</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.206</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-5</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.207</td>
      </tr>
  </tbody>
</table>
<h3 id="dns-config">DNS Config</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>; OpenShift Container Platform Cluster - A records
</span></span><span style="display:flex;"><span>pfsense.okd.mydomain.intra.          IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>okd4-bootstrap.okd.mydomain.intra.   IN      A      192.168.1.210
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>okd4-mastr-1.okd.mydomain.intra.        IN      A      192.168.1.201
</span></span><span style="display:flex;"><span>okd4-mastr-2.okd.mydomain.intra.        IN      A      192.168.1.202
</span></span><span style="display:flex;"><span>okd4-mastr-3.okd.mydomain.intra.        IN      A      192.168.1.203
</span></span><span style="display:flex;"><span>okd4-worker-1.okd.mydomain.intra.        IN      A      192.168.1.204
</span></span><span style="display:flex;"><span>okd4-worker-2.okd.mydomain.intra.        IN      A      192.168.1.205
</span></span><span style="display:flex;"><span>okd4-worker-3.okd.mydomain.intra.        IN      A      192.168.1.206
</span></span><span style="display:flex;"><span>okd4-worker-4.okd.mydomain.intra.        IN      A      192.168.1.207
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>; OpenShift internal cluster IPs - A records
</span></span><span style="display:flex;"><span>api.okd.mydomain.intra.            IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>api-int.okd.mydomain.intra.        IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>etcd-0.okd.mydomain.intra.         IN      A     192.168.1.201
</span></span><span style="display:flex;"><span>etcd-1.okd.mydomain.intra.         IN      A     192.168.1.202
</span></span><span style="display:flex;"><span>etcd-2.okd.mydomain.intra.         IN      A     192.168.1.203
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>okd.mydomain.intra.                IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>*.okd.mydomain.intra.              IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>; OpenShift internal cluster IPs - SRV records
</span></span><span style="display:flex;"><span>_etcd-server-ssl._tcp.okd.mydomain.intra.    <span style="color:#ae81ff">86400</span>     IN    SRV     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">10</span>    <span style="color:#ae81ff">2380</span>    etcd-0.okd.mydomain.intra.
</span></span><span style="display:flex;"><span>_etcd-server-ssl._tcp.okd.mydomain.intra.    <span style="color:#ae81ff">86400</span>     IN    SRV     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">10</span>    <span style="color:#ae81ff">2380</span>    etcd-1.okd.mydomain.intra.
</span></span><span style="display:flex;"><span>_etcd-server-ssl._tcp.okd.mydomain.intra.    <span style="color:#ae81ff">86400</span>     IN    SRV     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">10</span>    <span style="color:#ae81ff">2380</span>    etcd-2.okd.mydomain.intra.
</span></span></code></pre></div><h3 id="dhcp-config">DHCP Config:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>32:89:07:57:27:00  192.168.1.200 	okd4-services
</span></span><span style="display:flex;"><span>32:89:07:57:27:10  192.168.1.210 	okd4-bootstrap
</span></span><span style="display:flex;"><span>32:89:07:57:27:01  192.168.1.201 	okd4-mastr-1
</span></span><span style="display:flex;"><span>32:89:07:57:27:02  192.168.1.202 	okd4-mastr-2
</span></span><span style="display:flex;"><span>32:89:07:57:27:03  192.168.1.203 	okd4-mastr-3
</span></span><span style="display:flex;"><span>32:89:07:57:27:04  192.168.1.204 	okd4-worker-1
</span></span><span style="display:flex;"><span>32:89:07:57:27:05  192.168.1.205 	okd4-worker-2
</span></span><span style="display:flex;"><span>32:89:07:57:27:06  192.168.1.206 	okd4-worker-3
</span></span><span style="display:flex;"><span>32:89:07:57:27:07  192.168.1.207 	okd4-worker-4
</span></span></code></pre></div><p>PXE bootserver config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Next Server: 192.168.1.200
</span></span><span style="display:flex;"><span>Default BIOS file name: pxelinux.0
</span></span></code></pre></div><h2 id="haproxy-config">HAPROXY Config:</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.210   <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.201  <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.202  <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.202  <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.210   <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.201  <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.202  <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.202  <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.204  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.205  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.204  <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.205  <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.206  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.207  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.206  <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.207  <span style="color:#ae81ff">443</span>
</span></span></code></pre></div><h3 id="install-and-configure-pxeboot">Install and configure pxeboot</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh okd4-services
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install epel-release -y
</span></span><span style="display:flex;"><span>yum install httpd nano jq -y
</span></span><span style="display:flex;"><span>dnf install -y tftp-server syslinux-tftpboot
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p /var/lib/tftpboot
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/menu.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/mboot.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/chain.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/ldlinux.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/libutil.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p /var/lib/tftpboot/fcsos33
</span></span><span style="display:flex;"><span>cd /var/lib/tftpboot/fcsos33
</span></span><span style="display:flex;"><span>RHCOS_BASEURL<span style="color:#f92672">=</span>https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/
</span></span><span style="display:flex;"><span>wget <span style="color:#e6db74">${</span>RHCOS_BASEURL<span style="color:#e6db74">}</span>33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span><span style="display:flex;"><span>wget <span style="color:#e6db74">${</span>RHCOS_BASEURL<span style="color:#e6db74">}</span>33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img
</span></span><span style="display:flex;"><span>wget <span style="color:#e6db74">${</span>RHCOS_BASEURL<span style="color:#e6db74">}</span>33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img
</span></span><span style="display:flex;"><span>cd ~
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir /var/lib/tftpboot/pxelinux.cfg
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat &gt; /var/lib/tftpboot/pxelinux.cfg/default <span style="color:#e6db74">&lt;&lt; EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">default menu.c32
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">prompt 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">timeout 30
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu title PXE Menu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^1) Boot from local drive
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">localboot 0x00
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 2
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^2) Install OKD Bootstrap
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KERNEL /fcsos33/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">APPEND initrd=/fcsos33/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img,/fcsos33/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img coreos.inst.install_dev=/dev/vda coreos.inst.image_url=http://192.168.201.4/fcos.raw.xz coreos.inst.ignition_url=http://192.168.201.4/bootstrap.ign
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 3
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^3) Install OKD Master
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KERNEL /fcsos33/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">APPEND initrd=/fcsos33/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img,/fcsos33/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img coreos.inst.install_dev=/dev/vda coreos.inst.image_url=http://192.168.201.4/fcos.raw.xz coreos.inst.ignition_url=http://192.168.201.4/master.ign
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 4
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^4) Install OKD Worker
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KERNEL /fcsos33/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">APPEND initrd=/fcsos33/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img,/fcsos33/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img coreos.inst.install_dev=/dev/vda coreos.inst.image_url=http://192.168.201.4/fcos.raw.xz coreos.inst.ignition_url=http://192.168.201.4/worker.ign
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>Then run: <code>systemctl enable --now tftp.service</code></p>
<h3 id="create-okd-config">Create okd config</h3>
<blockquote>
<p>find the raw image:
<a href="https://getfedora.org/en/coreos/download?tab=metal_virtualized&amp;stream=stable">https://getfedora.org/en/coreos/download?tab=metal_virtualized&amp;stream=stable</a>
4K vs non 4K</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz
</span></span><span style="display:flex;"><span>wget https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz.sig
</span></span><span style="display:flex;"><span>cp fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz /var/www/html/fcos.raw.xz
</span></span><span style="display:flex;"><span>cp fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz.sig /var/www/html/fcos.raw.xz.sig
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># find installer</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># https://github.com/openshift/okd/releases</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://github.com/openshift/okd/releases/download/4.6.0-0.okd-2021-02-14-205305/openshift-client-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz
</span></span><span style="display:flex;"><span>wget https://github.com/openshift/okd/releases/download/4.6.0-0.okd-2021-02-14-205305/openshift-install-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar -xzf openshift-client-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz
</span></span><span style="display:flex;"><span>tar -xzf openshift-install-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo mv kubectl oc openshift-install /usr/local/bin/
</span></span><span style="display:flex;"><span>oc version
</span></span><span style="display:flex;"><span>openshift-install version
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir install_dir
</span></span></code></pre></div><p>Use Calico for <code>networkType</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat &gt; install_dir/install-config.yaml <span style="color:#e6db74">&lt;&lt; EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseDomain: mydomain.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: okd
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">compute:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">- hyperthreading: Enabled
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: worker
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  replicas: 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">controlPlane:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  hyperthreading: Enabled
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: master
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  replicas: 3
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">networking:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  clusterNetwork:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - cidr: 10.128.0.0/14
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    hostPrefix: 23
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  networkType: Cilium
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  serviceNetwork:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - 172.30.0.0/16
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">platform:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  none: {}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">fips: false
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">pullSecret: &#39;{&#34;auths&#34;:{&#34;fake&#34;:{&#34;auth&#34;: &#34;bar&#34;}}}&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">sshKey: &#39;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDK7lDozs9WLJD14H+nz...&#39; 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>openshift-install create manifests --dir<span style="color:#f92672">=</span>install_dir/
</span></span></code></pre></div><p>Add Operator Lifecycle Manager (OLM).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/cilium/cilium-olm.git /opt/cilium-olm
</span></span><span style="display:flex;"><span>cp /opt/cilium-olm/manifests/cilium.v1.10.4/* manifests/
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/mastersSchedulable: true/mastersSchedulable: False/&#39;</span> install_dir/manifests/cluster-scheduler-02-config.yml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>openshift-install create ignition-configs --dir<span style="color:#f92672">=</span>install_dir/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo cp -R install_dir/*.ign /var/www/html/
</span></span><span style="display:flex;"><span>sudo cp -R install_dir/metadata.json /var/www/html/
</span></span><span style="display:flex;"><span>sudo chown -R apache: /var/www/html/
</span></span><span style="display:flex;"><span>sudo chmod -R <span style="color:#ae81ff">755</span> /var/www/html/
</span></span></code></pre></div><blockquote>
<p>The config contains certificates that is walid for 24 hours.</p></blockquote>
<h3 id="starting-the-vms">Starting the VMs</h3>
<p>It&rsquo;s time to start the VMs. Select the okd4-bootstrap VM and navigate to Console. Start the VM. Then one by one the masters and the workers too.</p>
<h3 id="bootstrap-okd-cluster">Bootstrap OKD Cluster</h3>
<p>You can monitor the installation progress by running the following command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>openshift-install --dir<span style="color:#f92672">=</span>install_dir/ wait-for bootstrap-complete --log-level<span style="color:#f92672">=</span>info
</span></span></code></pre></div><blockquote>
<p>The certificates in the cluster is not authomaticle approved so I use the abow <code>tmux</code> command to approve</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>tmux
</span></span><span style="display:flex;"><span>export KUBECONFIG<span style="color:#f92672">=</span>~/install_dir/auth/kubeconfig
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> true; <span style="color:#66d9ef">do</span> echo <span style="color:#e6db74">`</span>oc get csr -o go-template<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{{range .items}}{{if not .status}}{{.metadata.name}}{{&#34;\n&#34;}}{{end}}{{end}}&#39;</span> | xargs -r oc adm certificate approve<span style="color:#e6db74">`</span>; sleep 60; <span style="color:#66d9ef">done</span>
</span></span></code></pre></div><p>Once the bootstrap process completes, you should see the following messages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>INFO It is now safe to remove the bootstrap resources
</span></span></code></pre></div><p>Then stop the bootstrap node.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># debug command to check the health of the cluster.</span>
</span></span><span style="display:flex;"><span>watch oc get csr
</span></span><span style="display:flex;"><span>watch oc get node
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc get clusteroperator
</span></span><span style="display:flex;"><span>oc get clusterversion
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>watch <span style="color:#e6db74">&#34;oc get clusteroperator&#34;</span>
</span></span><span style="display:flex;"><span>watch <span style="color:#e6db74">&#34;oc get po -A | grep -v Running | grep -v Completed&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -X GET https://api.okd.mydomain.intra:6443/healthz -k
</span></span></code></pre></div><p>You should have the OCP running with the cilium as the CNI network plugin. Log on to the web console, you should see the Cilium operator is installed in the cilium namespace.</p>
<p><img src="img/include/okd-cilium.png" alt="Cilium CNI"  class="zoomable" /></p>
<p>We will update the CiliumConfig CRD resource to enable hubble UI</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">cilium.io/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">CiliumConfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>: 
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cilium</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">cilium</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">debug</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">cni</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">binPath</span>: <span style="color:#ae81ff">/var/lib/cni/bin</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">confPath</span>: <span style="color:#ae81ff">/var/run/multus/cni/net.d</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">endpointRoutes</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hubble</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metrics</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">dns:query;ignoreAAAA</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">drop</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">tcp</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">flow</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">icmp</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">relay</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ui</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">hubble.apps.dev-cilium.ibmcloud.io.cpak</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ipam</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">mode</span>: <span style="color:#ae81ff">cluster-pool</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">operator</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">clusterPoolIPv4MaskSize</span>: <span style="color:#e6db74">&#34;23&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">clusterPoolIPv4PodCIDR</span>: <span style="color:#ae81ff">10.128.0.0</span><span style="color:#ae81ff">/14</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kubeProxyReplacement</span>: <span style="color:#ae81ff">probe</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nativeRoutingCIDR</span>: <span style="color:#ae81ff">10.128.0.0</span><span style="color:#ae81ff">/14</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">prometheus</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">operator</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">prometheus</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span></code></pre></div><p>Apply the yaml file. The we need to fix the rbac of the oml-role:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cilium-olm</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">cilium</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#39;*&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">monitoring.coreos.com</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">servicemonitors</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#39;*&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">networking.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">ingresses</span>
</span></span></code></pre></div><p>Now if you logon to the hubble-ui, you will see no data received, and you cannot see any service map. The problem is SELinux disable the access of the UNIX socket file created by hubble, so we need to create our own SELinux policy.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ nano cilium.te
</span></span><span style="display:flex;"><span>module cilium 1.0;
</span></span><span style="display:flex;"><span>require <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span> type container_var_run_t;
</span></span><span style="display:flex;"><span> type container_t;
</span></span><span style="display:flex;"><span> class dir read;
</span></span><span style="display:flex;"><span> class sock_file write;
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#============= container_t ==============</span>
</span></span><span style="display:flex;"><span>allow container_t container_var_run_t:dir read;
</span></span><span style="display:flex;"><span>allow container_t container_var_run_t:sock_file write;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo checkmodule -M -m -o cilium.mod cilium.te
</span></span><span style="display:flex;"><span>sudo semodule_package -o cilium.pp -m cilium.mod
</span></span><span style="display:flex;"><span>sudo semodule -i cilium.pp
</span></span></code></pre></div><p>Now you should be able the see data in the hubble-ui.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="cloud" term="cloud" label="Cloud" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="OpenShift" />
                             
                                <category scheme="openshift-4" term="openshift-4" label="OpenShift 4" />
                             
                                <category scheme="cilium" term="cilium" label="Cilium" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[kube-openid-connect 1.0]]></title>
            <link href="https://devopstales.github.io/kubernetes/kube-openid-connect-1.0/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-central-oauth/?utm_source=atom_feed" rel="related" type="text/html" title="Central authentication with oauth2-proxy" />
                <link href="https://devopstales.github.io/sso/k8s-gangway/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes authentication with Keycloak and gangway" />
                <link href="https://devopstales.github.io/sso/k8s-dasboard-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Dashboard authentication with Keycloak and gatekeeper" />
                <link href="https://devopstales.github.io/kubernetes/k8s-user-accounts/?utm_source=atom_feed" rel="related" type="text/html" title="How to create Users in Kubernetes the right way?" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.3/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.3: Patch release for Admisssion controller" />
            
                <id>https://devopstales.github.io/kubernetes/kube-openid-connect-1.0/</id>
            
            
            <published>2022-03-25T00:00:00+00:00</published>
            <updated>2022-03-25T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Today I am happy to announce the release of kube-openid-connect 1.0 and assign the first ever stable release number. This blog post focuses on the functionality provided by the kube-openid-connect 1.0 release.</p>
<h3 id="what-is-kube-openid-connect">What is kube-openid-connect?</h3>
<p>Kube OpenID Connect is an application that can be used to easily enable authentication flows via OIDC for a kubernetes cluster. Kubernetes supports <a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/#openid-connect-tokens">OpenID Connect Tokens</a> as a way to identify users who access the cluster. Kube OpenID Connect helps users with it&rsquo;s <code>kubectl</code> plugin to authenticate and get <code>kubectl</code> config.</p>
<h3 id="how-it-works">How It Works</h3>
<p>Kube OpenID Connect has two main component the server an the <code>kubectl plugin</code>. The server is written in python and the <code>kubectl plugin</code> in go for easier multi architecture build. When you want to login to a Kubernetes cluster you just simply use the <code>kubectl login</code> command to connect to the server component. It will open the OpenID authentication page in you browser. After you successfully logged in the server based on yout <code>JWT token</code> generates a <code>kubectl config</code> and push back to your <code>kubectl plugin</code>, that writes it to your config.</p>
<h3 id="oidc-provider-setup">OIDC (Provider) Setup</h3>
<p>You will need to obtain the OIDC details of the provider you need to use. This will contain the Issuer URL, Client ID and the Client Secret.
In the case of Google (The provider which was used when initially creating this) go to the <a href="https://console.developers.google.com/apis/credentials">Developer / Credentials</a> console. You will need to add the ingress url to both</p>
<ul>
<li><em>Authorised JavaScript origins</em> - <a href="https://kubeauth.k8s.intra">https://kubeauth.k8s.intra</a></li>
<li><em>Authorised redirect URIs</em> - <a href="https://kubeauth.k8s.intra/callback">https://kubeauth.k8s.intra/callback</a></li>
</ul>
<p>If you used kops the credentials you&rsquo;re after are</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kops/v1alpha2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Cluster</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">authorization</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rbac</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kubeAPIServer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">authorizationRbacSuperUser</span>: <span style="color:#ae81ff">admin</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">oidcClientID</span>: <span style="color:#ae81ff">UNIQUE_ID_REDACTED.apps.googleusercontent.com</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">oidcIssuerURL</span>: <span style="color:#ae81ff">https://accounts.google.com</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">oidcUsernameClaim</span>: <span style="color:#ae81ff">email</span>
</span></span></code></pre></div><p>For G Suite :
The redacted part of a ClientID is about 45 alphanumeric characters long (may also contain a hyphen or two)
The client secret will be about 25 alphanumeric chacters (may also contain a hyphen or two)</p>
<p>For manually configure the Kubernetes ApiServer integration with OpeniD provider:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano /etc/kubernetes/manifests/kube-apiserver.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#ae81ff">/hyperkube</span>
</span></span><span style="display:flex;"><span>- <span style="color:#ae81ff">apiserver</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>- --<span style="color:#ae81ff">oidc-issuer-url={{ .Values.server.oidcServerURL }}</span>
</span></span><span style="display:flex;"><span>- --<span style="color:#ae81ff">oidc-client-id={{ .Values.server.oidcClientID }}</span>
</span></span><span style="display:flex;"><span>- --<span style="color:#ae81ff">oidc-username-claim=email</span>
</span></span><span style="display:flex;"><span>- --<span style="color:#ae81ff">oidc-groups-claim=groups</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># for self sign cert or custom ca</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#- --oidc-ca-file=/etc/kubernetes/pki/rootca.pem</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl restart kubelet
</span></span></code></pre></div><h2 id="install-the-server">Install the server</h2>
<p>To ease deployment I created a helm chart for kube-openid-connect.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add devopstales https://devopstales.github.io/helm-charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span></code></pre></div><p>Create a value file for deploy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;&#39;EOF&#39;&gt; values.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Default values for kube-openid-connect.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># This is a YAML-formatted file.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Declare variables to be passed into your templates.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">TimeZone</span>: <span style="color:#ae81ff">Europe/Budapest</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">server</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">debug</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">oidcRedirectUrlHttpScema</span>: <span style="color:#ae81ff">https</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># redirect after logout</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">oidcOutURL</span>: <span style="color:#ae81ff">https://devopstales.github.io/tags/kube-openid-connect/</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># http or https</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">oidcRedirectUrlHost</span>: <span style="color:#ae81ff">kubeauth.k8s.intra</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># same es ingres host</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">oidcServerURL</span>: <span style="color:#ae81ff">https://sso.k8s.intra/auth/realms/homelab</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">oidcClientID</span>: <span style="color:#ae81ff">k8s-auth</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">oidcSecret</span>: <span style="color:#ae81ff">ashdkhsadhasdhakjshdakshdash</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">k8sContext</span>: <span style="color:#ae81ff">k8s-cl01</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">k8sApiServer</span>: <span style="color:#ae81ff">https://192.168.0.10:6443</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># `k8sApiServer` is the url for kubectl</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#   This is typically  https://api.fqdn</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">k8sCaCrt</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    -----BEGIN CERTIFICATE-----
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    CA
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    -----END CERTIFICATE-----</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># `caCrt` is the public / CA cert for the cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># cat /etc/kubernetes/pki/apiserver.crt</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">className</span>: <span style="color:#e6db74">&#34;nginx&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cert-manager.io/cluster-issuer</span>: <span style="color:#ae81ff">ca-issuer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nginx.ingress.kubernetes.io/proxy-buffer-size</span>: <span style="color:#e6db74">&#34;64k&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ingress.kubernetes.io/force-ssl-redirect</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">kubeauth.k8s.intra</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">ImplementationSpecific</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">kubeauth-tls</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">kubeauth.k8s.intra</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>The following tables lists configurable parameters of the trivy-operator chart and their default values.</p>
<table>
  <thead>
      <tr>
          <th>Parameter</th>
          <th>Description</th>
          <th>Default</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>TimeZone</td>
          <td>Tomezone for container time</td>
          <td>Europe/Budapest</td>
      </tr>
      <tr>
          <td>server.debug</td>
          <td>enable debug logging</td>
          <td>false</td>
      </tr>
      <tr>
          <td>server.oidcOutURL</td>
          <td>Where to redirect after logout?</td>
          <td><a href="https://devopstales.github.io/tags/kube-openid-connect/">https://devopstales.github.io/tags/kube-openid-connect/</a></td>
      </tr>
      <tr>
          <td>server.oidcRedirectUrlHttpScema</td>
          <td>Ingress schema (http or https)</td>
          <td>http</td>
      </tr>
      <tr>
          <td>server.oidcRedirectUrlHost</td>
          <td>Ingress hostname</td>
          <td>chart-example.local</td>
      </tr>
      <tr>
          <td>server.oidcServerURL</td>
          <td>URL of OIDC provider endpoint</td>
          <td>Not set</td>
      </tr>
      <tr>
          <td>server.oidcClientID</td>
          <td>Your unique client ID</td>
          <td>Not set</td>
      </tr>
      <tr>
          <td>server.oidcSecret</td>
          <td>The password for the Client ID</td>
          <td>Not set</td>
      </tr>
      <tr>
          <td>server.k8sContext</td>
          <td>Context of the cluster in generated config</td>
          <td>Not set</td>
      </tr>
      <tr>
          <td>server.k8sApiServer</td>
          <td>The endpoint for kubectl to use</td>
          <td>Not set</td>
      </tr>
      <tr>
          <td>server.k8sCaCrt</td>
          <td>The Public CA cert for the cluster</td>
          <td>Not set</td>
      </tr>
      <tr>
          <td>image.repository</td>
          <td>image</td>
          <td>devopstales/trivy-operator</td>
      </tr>
      <tr>
          <td>image.pullPolicy</td>
          <td>pullPolicy</td>
          <td>Always</td>
      </tr>
      <tr>
          <td>image.tag</td>
          <td>image tag</td>
          <td>1.0</td>
      </tr>
      <tr>
          <td>imagePullSecrets</td>
          <td>imagePullSecrets list</td>
          <td><code>[]</code></td>
      </tr>
      <tr>
          <td>nameOverride</td>
          <td>Override the name part</td>
          <td>Not set</td>
      </tr>
      <tr>
          <td>fullnameOverride</td>
          <td>Override the full name</td>
          <td>Not set</td>
      </tr>
      <tr>
          <td>serviceAccount.create</td>
          <td>create serviceAccount</td>
          <td>true</td>
      </tr>
      <tr>
          <td>serviceAccount.annotations</td>
          <td>add annotation to serviceAccount</td>
          <td><code>{}</code></td>
      </tr>
      <tr>
          <td>serviceAccount.name</td>
          <td>name of the serviceAccount</td>
          <td>Not set</td>
      </tr>
      <tr>
          <td>podAnnotations</td>
          <td>add extra annotations for the pod</td>
          <td><code>{}</code></td>
      </tr>
      <tr>
          <td>podSecurityContext.fsGroup</td>
          <td>mount id</td>
          <td>10001</td>
      </tr>
      <tr>
          <td>securityContext</td>
          <td>add extra securityContext for the pod</td>
          <td><code>{}</code></td>
      </tr>
      <tr>
          <td>service.port</td>
          <td>port number</td>
          <td>5000</td>
      </tr>
      <tr>
          <td>service.type</td>
          <td>type of the service</td>
          <td>ClusterIP</td>
      </tr>
      <tr>
          <td>ingress.enabled</td>
          <td>enable ingress</td>
          <td>true</td>
      </tr>
      <tr>
          <td>ingress.className</td>
          <td>ingress calss</td>
          <td>Not Set</td>
      </tr>
      <tr>
          <td>ingress.annotations</td>
          <td>extra annotation to ingress</td>
          <td>Not set</td>
      </tr>
      <tr>
          <td>ingress.hosts.host</td>
          <td>hostname for ingress</td>
          <td>chart-example.local</td>
      </tr>
      <tr>
          <td>ingress.hosts.paths[0].path</td>
          <td>subpath on ingress</td>
          <td><code>\</code></td>
      </tr>
      <tr>
          <td>ingress.hosts.paths[0].pathType</td>
          <td>ingress path type</td>
          <td>ImplementationSpecific</td>
      </tr>
      <tr>
          <td>ingress.tls</td>
          <td>tls config for ingress</td>
          <td><code>[]</code></td>
      </tr>
  </tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns kubeauth
</span></span><span style="display:flex;"><span>kubens kubeauth
</span></span><span style="display:flex;"><span>helm upgrade --install kubelogin devopstales/kube-openid-connect -f values.yaml
</span></span></code></pre></div><h3 id="install-the-kubectl-plugin">Install the Kubectl plugin</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Homebrew (macOS and Linux)</span>
</span></span><span style="display:flex;"><span>brew tap devopstales/devopstales
</span></span><span style="display:flex;"><span>brew install kubectl-login
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Krew (macOS, Linux, Windows and ARM)</span>
</span></span><span style="display:flex;"><span>kubectl krew install openid-connect
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Chocolatey (Windows)</span>
</span></span><span style="display:flex;"><span>choco install kubectl-login
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Binary release (Windows, macOS and Linux)</span>
</span></span><span style="display:flex;"><span>https://github.com/devopstales/kube-openid-connect/releases
</span></span></code></pre></div><h3 id="use-the-plugin-to-login">Use the plugin to login:</h3>
<p>Point the url to the ingress of the server component:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl login https://kubeauth.k8s.intra
</span></span><span style="display:flex;"><span>Configfile created with config <span style="color:#66d9ef">for</span> productioncluster to ~/.kube/config
</span></span><span style="display:flex;"><span>Happy Kubernetes interaction!
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-authentication" term="k8s-authentication" label="k8s-authentication" />
                             
                                <category scheme="k8s-operators" term="k8s-operators" label="k8s-operators" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="kube-openid-connect" term="kube-openid-connect" label="kube-openid-connect" />
                             
                                <category scheme="oauth2" term="oauth2" label="oauth2" />
                             
                                <category scheme="oidc" term="oidc" label="oidc" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to create Users in Kubernetes the right way?]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-user-accounts/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-rbac-gen/?utm_source=atom_feed" rel="related" type="text/html" title="How to create kubeconfig?" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.3/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.3: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/cloud/gke-gitlab-terraform/?utm_source=atom_feed" rel="related" type="text/html" title="Create K8S cluster with Terraform and GitlabCI" />
                <link href="https://devopstales.github.io/kubernetes/multus-calico/?utm_source=atom_feed" rel="related" type="text/html" title="Use multus to separate metwork trafics" />
                <link href="https://devopstales.github.io/kubernetes/multus/?utm_source=atom_feed" rel="related" type="text/html" title="Use Multus CNI in Kubernetes" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-user-accounts/</id>
            
            
            <published>2022-03-22T00:00:00+00:00</published>
            <updated>2022-03-22T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I this post I will show you how you can create Users in Kubernetes the right way.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="users-in-kubernetes">Users in Kubernetes</h3>
<p>All Kubernetes clusters have two categories of users: service accounts managed by Kubernetes, and normal users. Kubernetes does not have objects which represent normal user accounts. Normal users cannot be added to a cluster through an API call.</p>
<h3 id="so-how-we-choud-create-an-user-account">So how we choud create an user account?</h3>
<p>Any user that presents a valid certificate signed by the cluster&rsquo;s certificate authority (CA) is considered authenticated. So you need to create a certificate for you username.</p>
<h3 id="why-i-need-a-user-account-insted-of-service-account">Why I need a user account insted of service account?</h3>
<p>A service account is wisible and its token can be mounted in to a pod so theat pod has the same privileges as you.</p>
<h3 id="generate-new-certificate">Generate new certificate</h3>
<p>First, we have to generate a private key and a certificate signing request:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>openssl genrsa -out devopstales.pem
</span></span><span style="display:flex;"><span>openssl req -new -key devopstales.pem -out devopstales.csr -subj <span style="color:#e6db74">&#34;/CN=devopstales&#34;</span>
</span></span></code></pre></div><p><code>devopstales</code> well be my username. You can add your user to specific groups by addin them as groups like <code>devops-groupe</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>openssl req -new -key ivnilv.pem -out ivnilv.csr -subj <span style="color:#e6db74">&#34;/CN=devopstales/O=devops-groupe&#34;</span>
</span></span></code></pre></div><h3 id="signing-the-certificate">Signing the certificate</h3>
<p>Use the csr file for generating a <code>CertificateSigningRequest</code> object n Kubernetes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat devopstales.csr | base64 | tr -d <span style="color:#e6db74">&#39;\n&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;&#39;EOF&#39;&gt; devopstales-csr.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: certificates.k8s.io/v1beta1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: CertificateSigningRequest
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: user-request-devopstales
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  groups:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - system:authenticated
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  request: LS0tLS1CRUdJTi...
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  usages:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - digital signature
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - key encipherment
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - client auth
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>OR from Kubernetes v1.22 (in this example it will expire after 10 years):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat devopstales.csr | base64 | tr -d <span style="color:#e6db74">&#39;\n&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;&#39;EOF&#39;&gt; devopstales-csr.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: certificates.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: CertificateSigningRequest
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: user-request-devopstales
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  groups:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - system:authenticated
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  request: LS0tLS1CRUdJTi...
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  signerName: kubernetes.io/kube-apiserver-client
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  expirationSeconds: 315569260
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  usages:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - digital signature
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - key encipherment
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - client auth
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>Create the <code>CertificateSigningRequest</code> and approve it. Then the Kubernetes api server will generate the certificate theat you can use to authentication.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -f devopstales-csr.yaml
</span></span><span style="display:flex;"><span>kubectl certificate approve user-request-devopstales
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get csr
</span></span><span style="display:flex;"><span>NAME                       AGE       REQUESTOR   CONDITION
</span></span><span style="display:flex;"><span>user-request-devopstales   1m        admin       Approved,Issued
</span></span></code></pre></div><p>Now the certificate should be signed. You can download the new signed public key from the csr resource:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get csr user-request-devopstales -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{.status.certificate}&#39;</span> | base64 -d &gt; devopstales-user.crt
</span></span></code></pre></div><h3 id="create-new-user-config-file">Create new user config file</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --kubeconfig ~/.kube/config-devopstales config set-cluster preprod --insecure-skip-tls-verify<span style="color:#f92672">=</span>true --server<span style="color:#f92672">=</span>https://KUBERNETES-API-ADDRESS
</span></span><span style="display:flex;"><span>kubectl --kubeconfig ~/.kube/config-devopstales config set-credentials devopstales --client-certificate<span style="color:#f92672">=</span>devopstales-user.crt --client-key<span style="color:#f92672">=</span>devopstales.pem --embed-certs<span style="color:#f92672">=</span>true
</span></span><span style="display:flex;"><span>kubectl --kubeconfig ~/.kube/config-devopstales config set-context default --cluster<span style="color:#f92672">=</span>preprod --user<span style="color:#f92672">=</span>devopstales
</span></span><span style="display:flex;"><span>kubectl --kubeconfig ~/.kube/config-devopstales config use-context default
</span></span></code></pre></div><p>Ofcourse you need rbac for this user:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;&#39;EOF&#39;&gt; devopstales-rbac.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">devopstales-ns</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>: {}
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>: {}
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">devopstales</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">devopstales-ns</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;&#34;</span>, <span style="color:#e6db74">&#34;extensions&#34;</span>, <span style="color:#e6db74">&#34;apps&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;*&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;*&#34;</span>]
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;batch&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">jobs</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">cronjobs</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;*&#34;</span>]
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">devopstales</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">devopstales-ns</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">User</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">devopstales</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">devopstales</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl apply -f devopstales-rbac.yaml</span>
</span></span></code></pre></div><p>Let’s test if the new kubeconfig we generated worked fine:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --kubeconfig ~/.kube/config-devopstales get pods
</span></span></code></pre></div><h3 id="conclusion">Conclusion</h3>
<p>As we can see creating certificate for all the users is a hard task for the administratos if we hawe many users. A better solution to use an sso based authentication proxy like my <a href="/kubernetes/kube-openid-connect-1.0/">Kubectl OpenID Connect</a>.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-authentication" term="k8s-authentication" label="k8s-authentication" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="docker" term="docker" label="docker" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flagger NGINX Canary Deployments]]></title>
            <link href="https://devopstales.github.io/kubernetes/flagger-nginx-canary-deployments/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/gitops-flux2-sops/?utm_source=atom_feed" rel="related" type="text/html" title="Flux2 and Mozilla SOPS to encrypt secrets" />
                <link href="https://devopstales.github.io/kubernetes/gitops-flux2/?utm_source=atom_feed" rel="related" type="text/html" title="Flux2 Install and Usage" />
                <link href="https://devopstales.github.io/kubernetes/gitops-flux2-kubeseal/?utm_source=atom_feed" rel="related" type="text/html" title="Flux2 and kubeseal to encrypt secrets" />
                <link href="https://devopstales.github.io/kubernetes/argocd-image-updater/?utm_source=atom_feed" rel="related" type="text/html" title="Argo CD Image Updater for automate image update" />
                <link href="https://devopstales.github.io/kubernetes/argocd-kubeseal/?utm_source=atom_feed" rel="related" type="text/html" title="ArgoCD and kubeseal to encrypt secrets" />
            
                <id>https://devopstales.github.io/kubernetes/flagger-nginx-canary-deployments/</id>
            
            
            <published>2022-03-15T00:00:00+00:00</published>
            <updated>2022-03-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this blog post, I will show you how you can install Flagger and use it to set up progressive delivery for the <code>podinfo</code> app to your Kubernetes cluster.</p>


<H3>Parts of the K8S Gitops series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-gitops/">GitOps solutions for Kubernetes</a></li>
     <li>Part2: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-image-updater/">Argo CD Image Updater for automate image update</a></li>
<!-- ArgoCD notify
https://blog.argoproj.io/notifications-for-argo-bb7338231604
-->
<!----------------------------------------------->
     <li>Part4: <a href="../../kubernetes/gitops-flux2/">Flux2 Install and Usage</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part6: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>
<!-- Flux CD auto image update
https://particule.io/en/blog/flux-auto-image-update/
-->
<!----------------------------------------------->
<!-- Fleet 
Rancher fleet + helm-controller
-->
<!----------------------------------------------->
<!-- Canary Deployment:
Canary Basics - https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments
Canary with helm:
  https://itnext.io/safe-and-automation-friendly-canary-deployments-with-helm-669394d2c48a
  https://github.com/stoehdoi/canary-demo/tree/master/deploy
ArgoCD + Argo Rollouts for canary deploy:
-->
     <li>Part7: <a href="../../kubernetes/flagger-nginx-canary-deployments/">Flagger NGINX Canary Deployments</a></li>
</ul>



<h3 id="what-is-flagger">What is Flagger</h3>
<p>Flagger is a progressive delivery operator for Kubernetes that resolves the outlined problem by gradually shifting traffic to the new release while monitoring configured metrics. It can perform automated analysis and testing on the new release, deciding whether to propagate it to the whole cluster or stop if issues are found. Flagger slowly increases the load on the new release while keeping the old one available, ensuring minimal downtime. It can send notifications to Slack, Microsoft Teams, and other platforms to notify you and your team of transpired events.</p>
<h3 id="prerequisites">Prerequisites</h3>
<ul>
<li>nginx ingress controller</li>
<li>flagger</li>
<li>flagger-loadtester</li>
<li>prometheus</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add flagger https://flagger.app
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm upgrade -i flagger flagger/flagger <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--namespace ingress-nginx <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set prometheus.install<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set meshProvider<span style="color:#f92672">=</span>nginx
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
</span></span><span style="display:flex;"><span>kubectl create ns ingress-nginx
</span></span><span style="display:flex;"><span>helm upgrade -i ingress-nginx ingress-nginx/ingress-nginx <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--namespace ingress-nginx <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set controller.metrics.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set controller.podAnnotations.<span style="color:#e6db74">&#34;prometheus\.io/scrape&#34;</span><span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set controller.podAnnotations.<span style="color:#e6db74">&#34;prometheus\.io/port&#34;</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10254</span>
</span></span></code></pre></div><h3 id="deploying-an-app">Deploying an App</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -k https://github.com/fluxcd/flagger//kustomize/podinfo?ref<span style="color:#f92672">=</span>main
</span></span></code></pre></div><pre tabindex="0"><code>kubectl get pods -n test
#Output
NAME                       READY   STATUS    RESTARTS   AGE
podinfo-78fd6c49bf-jsjm5   1/1     Running   0          18s
podinfo-78fd6c49bf-k2nh4   0/1     Running   0          3s
</code></pre><p>Now that the pods are running, you’ll create an Ingress to expose the app at your domain. Open a file called <code>podinfo-ingress.yaml</code> for editing:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano podinfo-ingress.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: networking.k8s.io/v1
</span></span><span style="display:flex;"><span>kind: Ingress
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: podinfo
</span></span><span style="display:flex;"><span>  namespace: test
</span></span><span style="display:flex;"><span>  labels:
</span></span><span style="display:flex;"><span>    app: podinfo
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  ingressClassName: nginx
</span></span><span style="display:flex;"><span>  rules:
</span></span><span style="display:flex;"><span>    - host: <span style="color:#e6db74">&#34;app.k8s.mydomain.intra&#34;</span>
</span></span><span style="display:flex;"><span>      http:
</span></span><span style="display:flex;"><span>        paths:
</span></span><span style="display:flex;"><span>          - pathType: Prefix
</span></span><span style="display:flex;"><span>            path: <span style="color:#e6db74">&#34;/&#34;</span>
</span></span><span style="display:flex;"><span>            backend:
</span></span><span style="display:flex;"><span>              service:
</span></span><span style="display:flex;"><span>                name: podinfo
</span></span><span style="display:flex;"><span>                port:
</span></span><span style="display:flex;"><span>                  number: <span style="color:#ae81ff">80</span>
</span></span></code></pre></div><p>Before you create the canary, you’ll need to deploy Flagger’s load tester, which allows canary resources to test releases by sending HTTP requests.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f podinfo-ingress.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm install flagger-loadtester flagger/loadtester -n test
</span></span></code></pre></div><p>Note that the <code>podinfo</code> service does not yet exist in your cluster. It will be created later by Flagger automatically as part of the canary.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano podinfo-canary.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: flagger.app/v1beta1
</span></span><span style="display:flex;"><span>kind: Canary
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: podinfo
</span></span><span style="display:flex;"><span>  namespace: test
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  provider: nginx
</span></span><span style="display:flex;"><span>  targetRef:
</span></span><span style="display:flex;"><span>    apiVersion: apps/v1
</span></span><span style="display:flex;"><span>    kind: Deployment
</span></span><span style="display:flex;"><span>    name: podinfo
</span></span><span style="display:flex;"><span>  ingressRef:
</span></span><span style="display:flex;"><span>    apiVersion: networking.k8s.io/v1
</span></span><span style="display:flex;"><span>    kind: Ingress
</span></span><span style="display:flex;"><span>    name: podinfo
</span></span><span style="display:flex;"><span>  progressDeadlineSeconds: <span style="color:#ae81ff">60</span>
</span></span><span style="display:flex;"><span>  service:
</span></span><span style="display:flex;"><span>    port: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    targetPort: <span style="color:#ae81ff">9898</span>
</span></span><span style="display:flex;"><span>  analysis:
</span></span><span style="display:flex;"><span>    interval: 10s
</span></span><span style="display:flex;"><span>    threshold: <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>    maxWeight: <span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span>    stepWeight: <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>    metrics:
</span></span><span style="display:flex;"><span>    - name: request-success-rate
</span></span><span style="display:flex;"><span>      thresholdRange:
</span></span><span style="display:flex;"><span>        min: <span style="color:#ae81ff">99</span>
</span></span><span style="display:flex;"><span>      interval: 1m
</span></span><span style="display:flex;"><span>    webhooks:
</span></span><span style="display:flex;"><span>      - name: acceptance-test
</span></span><span style="display:flex;"><span>        type: pre-rollout
</span></span><span style="display:flex;"><span>        url: http://flagger-loadtester.test/
</span></span><span style="display:flex;"><span>        timeout: 30s
</span></span><span style="display:flex;"><span>        metadata:
</span></span><span style="display:flex;"><span>          type: bash
</span></span><span style="display:flex;"><span>          cmd: <span style="color:#e6db74">&#34;curl -sd &#39;test&#39; http://podinfo-canary/token | grep token&#34;</span>
</span></span><span style="display:flex;"><span>      - name: load-test
</span></span><span style="display:flex;"><span>        url: http://flagger-loadtester.test/
</span></span><span style="display:flex;"><span>        timeout: 5s
</span></span><span style="display:flex;"><span>        metadata:
</span></span><span style="display:flex;"><span>          cmd: <span style="color:#e6db74">&#34;hey -z 1m -q 10 -c 2 http://app.k8s.mydomain.intra/&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f podinfo-canary.yaml
</span></span></code></pre></div><p>You can now navigate to <code>app.k8s.mydomain.intra</code>. You’ll see the <code>podinfo</code> app:</p>
<p><img src="/img/include/flagger-nginx01.png" alt="appinfo"  class="zoomable" /></p>
<p>You can press the <code>Ping</code> button to refresh version numbers of other pods. Run the following command to set a different version of podinfo:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl set image deployment/podinfo podinfod<span style="color:#f92672">=</span>stefanprodan/podinfo:6.0.3 -n test
</span></span></code></pre></div><p>Flagger will detect that the deployment revision number changed, which you can check by listing the events associated with the <code>podinfo</code> canary:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe canary/podinfo -n test
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Output</span>
</span></span><span style="display:flex;"><span>Events:
</span></span><span style="display:flex;"><span>  Type     Reason  Age                From     Message
</span></span><span style="display:flex;"><span>  ----     ------  ----               ----     -------
</span></span><span style="display:flex;"><span>  Normal   Synced  117s               flagger  New revision detected! Scaling up podinfo.test
</span></span><span style="display:flex;"><span>  Warning  Synced  107s               flagger  canary deployment podinfo.test not ready: waiting <span style="color:#66d9ef">for</span> rollout to finish: <span style="color:#ae81ff">0</span> of <span style="color:#ae81ff">2</span> <span style="color:#f92672">(</span>readyThreshold 100%<span style="color:#f92672">)</span> updated replicas are available
</span></span><span style="display:flex;"><span>  Warning  Synced  97s                flagger  canary deployment podinfo.test not ready: waiting <span style="color:#66d9ef">for</span> rollout to finish: <span style="color:#ae81ff">1</span> of <span style="color:#ae81ff">2</span> <span style="color:#f92672">(</span>readyThreshold 100%<span style="color:#f92672">)</span> updated replicas are available
</span></span><span style="display:flex;"><span>  Normal   Synced  87s                flagger  Starting canary analysis <span style="color:#66d9ef">for</span> podinfo.test
</span></span><span style="display:flex;"><span>  Normal   Synced  87s                flagger  Pre-rollout check acceptance-test passed
</span></span><span style="display:flex;"><span>  Normal   Synced  87s                flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>  Warning  Synced  67s <span style="color:#f92672">(</span>x2 over 77s<span style="color:#f92672">)</span>  flagger  Halt advancement no values found <span style="color:#66d9ef">for</span> nginx metric request-success-rate probably podinfo.test is not receiving traffic: running query failed: no values found
</span></span><span style="display:flex;"><span>  Normal   Synced  57s                flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>  Normal   Synced  47s                flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>  Normal   Synced  37s                flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">20</span>
</span></span><span style="display:flex;"><span>  Normal   Synced  27s                flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">25</span>
</span></span></code></pre></div><p>Return to your browser and watch the version numbers flicker as the app continually refreshes itself.</p>
<p><img src="/img/include/flagger-nginx02.png" alt="appinfo"  class="zoomable" /></p>
<p>Flagger denotes the traffic shifts with events starting with Advance podinfo.test canary weight, followed by the percentage of traffic being diverted:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe canary/podinfo -n test
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Output</span>
</span></span><span style="display:flex;"><span>Output
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>  Normal   Synced  116s                  flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>  Normal   Synced  106s                  flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>After some time, the canary deployment should succeed and the version numbers will stabilize:</p>
<p><img src="/img/include/flagger-nginx03.png" alt="appinfo"  class="zoomable" /></p>
<p>The final event log of the canary will look similar to this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe canary/podinfo -n test
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Output</span>
</span></span><span style="display:flex;"><span>Events:
</span></span><span style="display:flex;"><span>  Type     Reason  Age                   From     Message
</span></span><span style="display:flex;"><span>  ----     ------  ----                  ----     -------
</span></span><span style="display:flex;"><span>  Normal   Synced  2m56s                 flagger  New revision detected! Scaling up podinfo.test
</span></span><span style="display:flex;"><span>  Warning  Synced  2m46s                 flagger  canary deployment podinfo.test not ready: waiting <span style="color:#66d9ef">for</span> rollout to finish: <span style="color:#ae81ff">0</span> of <span style="color:#ae81ff">2</span> <span style="color:#f92672">(</span>readyThreshold 100%<span style="color:#f92672">)</span> updated replicas are available
</span></span><span style="display:flex;"><span>  Warning  Synced  2m36s                 flagger  canary deployment podinfo.test not ready: waiting <span style="color:#66d9ef">for</span> rollout to finish: <span style="color:#ae81ff">1</span> of <span style="color:#ae81ff">2</span> <span style="color:#f92672">(</span>readyThreshold 100%<span style="color:#f92672">)</span> updated replicas are available
</span></span><span style="display:flex;"><span>  Normal   Synced  2m26s                 flagger  Starting canary analysis <span style="color:#66d9ef">for</span> podinfo.test
</span></span><span style="display:flex;"><span>  Normal   Synced  2m26s                 flagger  Pre-rollout check acceptance-test passed
</span></span><span style="display:flex;"><span>  Normal   Synced  2m26s                 flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>  Warning  Synced  2m6s <span style="color:#f92672">(</span>x2 over 2m16s<span style="color:#f92672">)</span>  flagger  Halt advancement no values found <span style="color:#66d9ef">for</span> nginx metric request-success-rate probably podinfo.test is not receiving traffic: running query failed: no values found
</span></span><span style="display:flex;"><span>  Normal   Synced  116s                  flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>  Normal   Synced  106s                  flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>  Normal   Synced  96s                   flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">20</span>
</span></span><span style="display:flex;"><span>  Normal   Synced  86s                   flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">25</span>
</span></span><span style="display:flex;"><span>  Normal   Synced  76s                   flagger  Advance podinfo.test canary weight <span style="color:#ae81ff">30</span>
</span></span><span style="display:flex;"><span>  Warning  Synced  16s                   flagger  podinfo-primary.test not ready: waiting <span style="color:#66d9ef">for</span> rollout to finish: <span style="color:#ae81ff">1</span> old replicas are pending termination
</span></span><span style="display:flex;"><span>  Normal   Synced  6s <span style="color:#f92672">(</span>x6 over 66s<span style="color:#f92672">)</span>      flagger  <span style="color:#f92672">(</span>combined from similar events<span style="color:#f92672">)</span>: Routing all traffic to primary
</span></span></code></pre></div><h3 id="reporting-to-slack">Reporting to Slack</h3>
<p>You can configure Flagger to send its logs to your Slack workspace. To use Slack integration, you’ll need to have an <a href="https://api.slack.com/messaging/webhooks">incoming webhook</a> on Slack for your workspace.</p>
<p>To do so, first log in to Slack and navigate to the <a href="https://api.slack.com/apps?new_app=1">app creation</a> page. Pick a name that you’ll recognize, select the desired workspace, and click <code>Create App</code>.</p>
<p>You’ll be redirected to the settings page for the new app. Click on <code>Incoming Webhooks</code> on the left navigation bar.</p>
<p><img src="/img/include/flagger-nginx04.png" alt="slack webhook"  class="zoomable" /></p>
<p>Enable webhooks by flipping the switch button next to the title <code>Activate Incoming Webhooks</code>.</p>
<p><img src="/img/include/flagger-nginx05.png" alt="slack webhook"  class="zoomable" /></p>
<p>To configure Flagger to send logs to Slack, you’ll need to update its Helm release by running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm upgrade flagger flagger/flagger <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--reuse-values <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set slack.url<span style="color:#f92672">=</span>&lt;your_hook_URL&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set slack.channel<span style="color:#f92672">=</span>&lt;your_channel_name&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set slack.user<span style="color:#f92672">=</span>&lt;username&gt;
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl set image deployment/podinfo podinfod<span style="color:#f92672">=</span>stefanprodan/podinfo:3.1.1 -n test
</span></span></code></pre></div><p>You’ll soon see messages appearing in Slack:</p>
<p><img src="/img/include/flagger-nginx06.png" alt="slack messages"  class="zoomable" /></p>
<p>When this release deploys, you’ll see a success message:</p>
<p><img src="/img/include/flagger-nginx07.png" alt="slack messages"  class="zoomable" /></p>
<p>For the new release, deploy the <code>6.0.3</code> version again by running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl set image deployment/podinfo podinfod<span style="color:#f92672">=</span>stefanprodan/podinfo:6.0.3 -n test
</span></span></code></pre></div><p>Run the following command to create a large number of HTTP 500 statuses:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>watch curl http://app.your_domain/status/500
</span></span></code></pre></div><p>After some time, you’ll see that Flagger decided not to apply the new release.</p>
<p><img src="/img/include/flagger-nginx08.png" alt="slack messages"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-gitops" term="k8s-gitops" label="k8s-gitops" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="gitops" term="gitops" label="gitops" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install an OpenShift 4 cluster with Calico]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-calico/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/cloud/aws-eks-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Deploy Ingress Controller to EKS cluster with WAF" />
                <link href="https://devopstales.github.io/cloud/aws-eks-install/?utm_source=atom_feed" rel="related" type="text/html" title="Create EKS Cluster with eksctl" />
                <link href="https://devopstales.github.io/cloud/aws-eks-networking/?utm_source=atom_feed" rel="related" type="text/html" title="AWS EKS Network Solutions" />
                <link href="https://devopstales.github.io/kubernetes/multus-calico/?utm_source=atom_feed" rel="related" type="text/html" title="Use multus to separate metwork trafics" />
                <link href="https://devopstales.github.io/kubernetes/kubernetes-networking-2/?utm_source=atom_feed" rel="related" type="text/html" title="Understanding kubernetes networking: owerlay networks" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-calico/</id>
            
            
            <published>2022-03-12T00:00:00+00:00</published>
            <updated>2022-03-12T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you How you can Install  OpenShift 4 cluster with Calico.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<h3 id="infrastructure">Infrastructure</h3>
<table>
  <thead>
      <tr>
          <th style="text-align: center">Host</th>
          <th style="text-align: center">ROLES</th>
          <th style="text-align: center">OS</th>
          <th style="text-align: center">IP</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">pfsense</td>
          <td style="text-align: center">Load Balancer, dhcp, dns</td>
          <td style="text-align: center">pfsense</td>
          <td style="text-align: center">192.168.1.1</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-services</td>
          <td style="text-align: center">pxeboot</td>
          <td style="text-align: center">CentOS 7</td>
          <td style="text-align: center">192.168.1.200</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-bootstrap</td>
          <td style="text-align: center">bootstrap</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.210</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-mastr-1</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.201</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-mastr-2</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.202</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-mastr-3</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.203</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-1</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.204</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-2</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.205</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-4</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.206</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-5</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.207</td>
      </tr>
  </tbody>
</table>
<h3 id="dns-config">DNS Config</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>; OpenShift Container Platform Cluster - A records
</span></span><span style="display:flex;"><span>pfsense.okd.mydomain.intra.          IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>okd4-bootstrap.okd.mydomain.intra.   IN      A      192.168.1.210
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>okd4-mastr-1.okd.mydomain.intra.        IN      A      192.168.1.201
</span></span><span style="display:flex;"><span>okd4-mastr-2.okd.mydomain.intra.        IN      A      192.168.1.202
</span></span><span style="display:flex;"><span>okd4-mastr-3.okd.mydomain.intra.        IN      A      192.168.1.203
</span></span><span style="display:flex;"><span>okd4-worker-1.okd.mydomain.intra.        IN      A      192.168.1.204
</span></span><span style="display:flex;"><span>okd4-worker-2.okd.mydomain.intra.        IN      A      192.168.1.205
</span></span><span style="display:flex;"><span>okd4-worker-3.okd.mydomain.intra.        IN      A      192.168.1.206
</span></span><span style="display:flex;"><span>okd4-worker-4.okd.mydomain.intra.        IN      A      192.168.1.207
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>; OpenShift internal cluster IPs - A records
</span></span><span style="display:flex;"><span>api.okd.mydomain.intra.            IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>api-int.okd.mydomain.intra.        IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>etcd-0.okd.mydomain.intra.         IN      A     192.168.1.201
</span></span><span style="display:flex;"><span>etcd-1.okd.mydomain.intra.         IN      A     192.168.1.202
</span></span><span style="display:flex;"><span>etcd-2.okd.mydomain.intra.         IN      A     192.168.1.203
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>okd.mydomain.intra.                IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>*.okd.mydomain.intra.              IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>; OpenShift internal cluster IPs - SRV records
</span></span><span style="display:flex;"><span>_etcd-server-ssl._tcp.okd.mydomain.intra.    <span style="color:#ae81ff">86400</span>     IN    SRV     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">10</span>    <span style="color:#ae81ff">2380</span>    etcd-0.okd.mydomain.intra.
</span></span><span style="display:flex;"><span>_etcd-server-ssl._tcp.okd.mydomain.intra.    <span style="color:#ae81ff">86400</span>     IN    SRV     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">10</span>    <span style="color:#ae81ff">2380</span>    etcd-1.okd.mydomain.intra.
</span></span><span style="display:flex;"><span>_etcd-server-ssl._tcp.okd.mydomain.intra.    <span style="color:#ae81ff">86400</span>     IN    SRV     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">10</span>    <span style="color:#ae81ff">2380</span>    etcd-2.okd.mydomain.intra.
</span></span></code></pre></div><h3 id="dhcp-config">DHCP Config:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>32:89:07:57:27:00  192.168.1.200 	okd4-services
</span></span><span style="display:flex;"><span>32:89:07:57:27:10  192.168.1.210 	okd4-bootstrap
</span></span><span style="display:flex;"><span>32:89:07:57:27:01  192.168.1.201 	okd4-mastr-1
</span></span><span style="display:flex;"><span>32:89:07:57:27:02  192.168.1.202 	okd4-mastr-2
</span></span><span style="display:flex;"><span>32:89:07:57:27:03  192.168.1.203 	okd4-mastr-3
</span></span><span style="display:flex;"><span>32:89:07:57:27:04  192.168.1.204 	okd4-worker-1
</span></span><span style="display:flex;"><span>32:89:07:57:27:05  192.168.1.205 	okd4-worker-2
</span></span><span style="display:flex;"><span>32:89:07:57:27:06  192.168.1.206 	okd4-worker-3
</span></span><span style="display:flex;"><span>32:89:07:57:27:07  192.168.1.207 	okd4-worker-4
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Next Server: 192.168.1.200
</span></span><span style="display:flex;"><span>Default BIOS file name: pxelinux.0
</span></span></code></pre></div><h2 id="haproxy-config">HAPROXY Config:</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.210   <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.201  <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.202  <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.202  <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.210   <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.201  <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.202  <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.202  <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.204  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.205  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.204  <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.205  <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.206  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.207  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.206  <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.207  <span style="color:#ae81ff">443</span>
</span></span></code></pre></div><h3 id="install-and-configure-pxeboot">Install and configure pxeboot</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh okd4-services
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install epel-release -y
</span></span><span style="display:flex;"><span>yum install httpd nano jq -y
</span></span><span style="display:flex;"><span>dnf install -y tftp-server syslinux-tftpboot
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p /var/lib/tftpboot
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/menu.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/mboot.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/chain.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/ldlinux.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/libutil.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p /var/lib/tftpboot/fcsos33
</span></span><span style="display:flex;"><span>cd /var/lib/tftpboot/fcsos33
</span></span><span style="display:flex;"><span>RHCOS_BASEURL<span style="color:#f92672">=</span>https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/
</span></span><span style="display:flex;"><span>wget <span style="color:#e6db74">${</span>RHCOS_BASEURL<span style="color:#e6db74">}</span>33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span><span style="display:flex;"><span>wget <span style="color:#e6db74">${</span>RHCOS_BASEURL<span style="color:#e6db74">}</span>33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img
</span></span><span style="display:flex;"><span>wget <span style="color:#e6db74">${</span>RHCOS_BASEURL<span style="color:#e6db74">}</span>33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img
</span></span><span style="display:flex;"><span>cd ~
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir /var/lib/tftpboot/pxelinux.cfg
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat &gt; /var/lib/tftpboot/pxelinux.cfg/default <span style="color:#e6db74">&lt;&lt; EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">default menu.c32
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">prompt 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">timeout 30
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu title PXE Menu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^1) Boot from local drive
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">localboot 0x00
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 2
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^2) Install OKD Bootstrap
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KERNEL /fcsos33/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">APPEND initrd=/fcsos33/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img,/fcsos33/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img coreos.inst.install_dev=/dev/vda coreos.inst.image_url=http://192.168.201.4/fcos.raw.xz coreos.inst.ignition_url=http://192.168.201.4/bootstrap.ign
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 3
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^3) Install OKD Master
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KERNEL /fcsos33/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">APPEND initrd=/fcsos33/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img,/fcsos33/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img coreos.inst.install_dev=/dev/vda coreos.inst.image_url=http://192.168.201.4/fcos.raw.xz coreos.inst.ignition_url=http://192.168.201.4/master.ign
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 4
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^4) Install OKD Worker
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KERNEL /fcsos33/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">APPEND initrd=/fcsos33/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img,/fcsos33/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img coreos.inst.install_dev=/dev/vda coreos.inst.image_url=http://192.168.201.4/fcos.raw.xz coreos.inst.ignition_url=http://192.168.201.4/worker.ign
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>Then run: <code>systemctl enable --now tftp.service</code></p>
<h3 id="create-okd-config">Create okd config</h3>
<blockquote>
<p>find the raw image:
<a href="https://getfedora.org/en/coreos/download?tab=metal_virtualized&amp;stream=stable">https://getfedora.org/en/coreos/download?tab=metal_virtualized&amp;stream=stable</a>
4K vs non 4K</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz
</span></span><span style="display:flex;"><span>wget https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz.sig
</span></span><span style="display:flex;"><span>cp fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz /var/www/html/fcos.raw.xz
</span></span><span style="display:flex;"><span>cp fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz.sig /var/www/html/fcos.raw.xz.sig
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># find installer</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># https://github.com/openshift/okd/releases</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://github.com/openshift/okd/releases/download/4.6.0-0.okd-2021-02-14-205305/openshift-client-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz
</span></span><span style="display:flex;"><span>wget https://github.com/openshift/okd/releases/download/4.6.0-0.okd-2021-02-14-205305/openshift-install-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar -xzf openshift-client-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz
</span></span><span style="display:flex;"><span>tar -xzf openshift-install-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo mv kubectl oc openshift-install /usr/local/bin/
</span></span><span style="display:flex;"><span>oc version
</span></span><span style="display:flex;"><span>openshift-install version
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir install_dir
</span></span></code></pre></div><p>Use Calico for <code>networkType</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat &gt; install_dir/install-config.yaml <span style="color:#e6db74">&lt;&lt; EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseDomain: mydomain.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: okd
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">compute:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">- hyperthreading: Enabled
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: worker
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  replicas: 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">controlPlane:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  hyperthreading: Enabled
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: master
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  replicas: 3
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">networking:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  clusterNetwork:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - cidr: 10.128.0.0/14
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    hostPrefix: 23
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  networkType: Calico
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  serviceNetwork:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - 172.30.0.0/16
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">platform:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  none: {}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">fips: false
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">pullSecret: &#39;{&#34;auths&#34;:{&#34;fake&#34;:{&#34;auth&#34;: &#34;bar&#34;}}}&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">sshKey: &#39;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDK7lDozs9WLJD14H+nz...&#39; 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>openshift-install create manifests --dir<span style="color:#f92672">=</span>install_dir/
</span></span></code></pre></div><p>You may want to provide Calico with additional configuration at install-time. For example, BGP configuration or peers. You can use a Kubernetes ConfigMap with your desired Calico resources in order to set configuration as part of the installation.</p>
<p>To include <a href="https://projectcalico.docs.tigera.io/reference/resources/">Calico resources</a> during installation, edit <code>install_dir/manifests/02-configmap-calico-resources.yaml</code> in order to add your own configuration.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc create configmap -n tigera-operator calico-resources <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --from-file<span style="color:#f92672">=</span>&lt;resource-directory&gt; --dry-run -o yaml <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  &gt; install_dir/manifests/02-configmap-calico-resources.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/mastersSchedulable: true/mastersSchedulable: False/&#39;</span> install_dir/manifests/cluster-scheduler-02-config.yml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>openshift-install create ignition-configs --dir<span style="color:#f92672">=</span>install_dir/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo cp -R install_dir/*.ign /var/www/html/
</span></span><span style="display:flex;"><span>sudo cp -R install_dir/metadata.json /var/www/html/
</span></span><span style="display:flex;"><span>sudo chown -R apache: /var/www/html/
</span></span><span style="display:flex;"><span>sudo chmod -R <span style="color:#ae81ff">755</span> /var/www/html/
</span></span></code></pre></div><blockquote>
<p>The config contains certificates that is walid for 24 hours.</p></blockquote>
<h3 id="starting-the-vms">Starting the VMs</h3>
<p>It&rsquo;s time to start the VMs. Select the okd4-bootstrap VM and navigate to Console. Start the VM. Then one by one the masters and the workers too.</p>
<h3 id="bootstrap-okd-cluster">Bootstrap OKD Cluster</h3>
<p>You can monitor the installation progress by running the following command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>openshift-install --dir<span style="color:#f92672">=</span>install_dir/ wait-for bootstrap-complete --log-level<span style="color:#f92672">=</span>info
</span></span></code></pre></div><blockquote>
<p>The certificates in the cluster is not authomaticle approved so I use the abow <code>tmux</code> command to approve</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>tmux
</span></span><span style="display:flex;"><span>export KUBECONFIG<span style="color:#f92672">=</span>~/install_dir/auth/kubeconfig
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> true; <span style="color:#66d9ef">do</span> echo <span style="color:#e6db74">`</span>oc get csr -o go-template<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{{range .items}}{{if not .status}}{{.metadata.name}}{{&#34;\n&#34;}}{{end}}{{end}}&#39;</span> | xargs -r oc adm certificate approve<span style="color:#e6db74">`</span>; sleep 60; <span style="color:#66d9ef">done</span>
</span></span></code></pre></div><p>Once the bootstrap process completes, you should see the following messages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>INFO It is now safe to remove the bootstrap resources
</span></span></code></pre></div><p>Then stop the bootstrap node.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># debug command to check the health of the cluster.</span>
</span></span><span style="display:flex;"><span>watch oc get csr
</span></span><span style="display:flex;"><span>watch oc get node
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc get clusteroperator
</span></span><span style="display:flex;"><span>oc get clusterversion
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>watch <span style="color:#e6db74">&#34;oc get clusteroperator&#34;</span>
</span></span><span style="display:flex;"><span>watch <span style="color:#e6db74">&#34;oc get po -A | grep -v Running | grep -v Completed&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -X GET https://api.okd.mydomain.intra:6443/healthz -k
</span></span></code></pre></div><p>Verify Calico is installed by verifying the components are available with the following command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc get tigerastatus
</span></span></code></pre></div><p>Wait for the console to be available. Once it is available, we can point a browser to <a href="https://console-openshift-console.okd.mydomain.intra">https://console-openshift-console.okd.mydomain.intra</a></p>
<p>You will get an SSL error because the certificate is not valid for this domain. That&rsquo;s normal. Just bypass the SSL error.</p>
<p>Login with user &ldquo;kubeadmin&rdquo;.You can find the kubeadmin password in a file generated during the installation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat install_dir/auth/kubeadmin-password
</span></span></code></pre></div><p>Optionally you can integrate with Operator Lifecycle Manager (OLM). First you will need to create an OperatorGroup for the operator:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">oc apply -f - &lt;&lt;EOF</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">OperatorGroup</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">tigera-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">tigera-operator</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetNamespaces</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">tigera-operator</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>Next, you will create a Subscription to the operator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">oc apply -f - &lt;&lt;EOF</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Subscription</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">tigera-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">tigera-operator</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">channel</span>: <span style="color:#ae81ff">release-v1.25</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">installPlanApproval</span>: <span style="color:#ae81ff">Manual</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">tigera-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>: <span style="color:#ae81ff">certified-operators</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sourceNamespace</span>: <span style="color:#ae81ff">openshift-marketplace</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">startingCSV</span>: <span style="color:#ae81ff">tigera-operator.v1.25.3</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>Finally, log in to the OpenShift console, navigate to the Installed Operators section and approve the Install Plan for the operator.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="cloud" term="cloud" label="Cloud" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="OpenShift" />
                             
                                <category scheme="openshift-4" term="openshift-4" label="OpenShift 4" />
                             
                                <category scheme="calico" term="calico" label="calico" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Validate Kubernetes Deployment in CI/CD]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-test-tools/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
                <link href="https://devopstales.github.io/kubernetes/k8s-prometheus-stack/?utm_source=atom_feed" rel="related" type="text/html" title="K8S Logging And Monitoring" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes integration with external Vault" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-test-tools/</id>
            
            
            <published>2022-03-02T00:00:00+00:00</published>
            <updated>2022-03-02T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I this blog post I will show you how you can validate your kubernetes objects, helm charts, images at CI/CD.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="the-yaml">The yaml</h3>
<p>First this is the example yaml that we will use for validation tests.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano base-valid.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http-echo</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">http-echo</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">http-echo</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http-echo</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">jxlwqq/http-echo:latest</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">args</span>: [<span style="color:#e6db74">&#34;-text&#34;</span>, <span style="color:#e6db74">&#34;hello-world&#34;</span>]
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">5678</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http-echo</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">5678</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">5678</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">http-echo</span>
</span></span></code></pre></div><h3 id="kubeval">kubeval</h3>
<p><code>kubeval</code> is a tool for validating a Kubernetes YAML or JSON configuration file. It does so using schemas generated from the Kubernetes OpenAPI specification, and therefore can validate schemas for multiple versions of Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install kubeval
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeval base-valid.yaml
</span></span><span style="display:flex;"><span>PASS - base-valid.yaml contains a valid Deployment <span style="color:#f92672">(</span>http-echo<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>PASS - base-valid.yaml contains a valid Service <span style="color:#f92672">(</span>http-echo<span style="color:#f92672">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeval --kubernetes-version 1.16.1 base-valid.yaml
</span></span></code></pre></div><blockquote>
<p>One limitation of kubeval is that it is currently not able to validate against Custom Resource Definitions (CRDs)</p></blockquote>
<h3 id="kube-score">kube-score</h3>
<p><code>Kube-score</code> analyses YAML manifests and scores them against security recommendations and best practices.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install kube-score
</span></span><span style="display:flex;"><span><span style="color:#e6db74">``</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">```</span>bash
</span></span><span style="display:flex;"><span>kube-score score base-valid.yaml
</span></span><span style="display:flex;"><span>apps/v1/Deployment http-echo
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> Container Resources
</span></span><span style="display:flex;"><span>        · http-echo -&gt; CPU limit is not set
</span></span><span style="display:flex;"><span>            Resource limits are recommended to avoid resource DDOS. Set resources.limits.cpu
</span></span><span style="display:flex;"><span>        · http-echo -&gt; Memory limit is not set
</span></span><span style="display:flex;"><span>            Resource limits are recommended to avoid resource DDOS. Set resources.limits.memory
</span></span><span style="display:flex;"><span>        · http-echo -&gt; CPU request is not set
</span></span><span style="display:flex;"><span>            Resource requests are recommended to make sure that the application can start and run without crashing. Set resources.requests.cpu
</span></span><span style="display:flex;"><span>        · http-echo -&gt; Memory request is not set
</span></span><span style="display:flex;"><span>            Resource requests are recommended to make sure that the application can start and run without crashing. Set
</span></span><span style="display:flex;"><span>            resources.requests.memory
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> Pod NetworkPolicy
</span></span><span style="display:flex;"><span>        · The pod does not have a matching NetworkPolicy
</span></span><span style="display:flex;"><span>            Create a NetworkPolicy that targets this pod to control who/what can communicate with this pod. Note, this feature needs to be
</span></span><span style="display:flex;"><span>            supported by the CNI implementation used in the Kubernetes cluster to have an effect.
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> Pod Probes
</span></span><span style="display:flex;"><span>        · Container is missing a readinessProbe
</span></span><span style="display:flex;"><span>            A readinessProbe should be used to indicate when the service is ready to receive traffic. Without it, the Pod is risking to
</span></span><span style="display:flex;"><span>            receive traffic before it has booted. It<span style="color:#e6db74">&#39;s also used during rollouts, and can prevent downtime if a new version of the application
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            is failing.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            More information: https://github.com/zegl/kube-score/blob/master/README_PROBES.md
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    [CRITICAL] Container Security Context User Group ID
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        · http-echo -&gt; Container has no configured security context
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            Set securityContext to run the container in a more secure context.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    [CRITICAL] Container Image Tag
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        · http-echo -&gt; Image with latest tag
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            Using a fixed tag is recommended to avoid accidental upgrades
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    [CRITICAL] Container Ephemeral Storage Request and Limit
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        · http-echo -&gt; Ephemeral Storage limit is not set
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            Resource limits are recommended to avoid resource DDOS. Set resources.limits.ephemeral-storage
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    [CRITICAL] Container Security Context ReadOnlyRootFilesystem
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        · http-echo -&gt; Container has no configured security context
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            Set securityContext to run the container in a more secure context.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    [WARNING] Deployment has host PodAntiAffinity
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        · Deployment does not have a host podAntiAffinity set
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            It&#39;</span>s recommended to set a podAntiAffinity that stops multiple pods from a deployment from being scheduled on the same node. This
</span></span><span style="display:flex;"><span>            increases availability in <span style="color:#66d9ef">case</span> the node becomes unavailable.
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> Deployment has PodDisruptionBudget
</span></span><span style="display:flex;"><span>        · No matching PodDisruptionBudget was found
</span></span><span style="display:flex;"><span>            It<span style="color:#960050;background-color:#1e0010">&#39;</span>s recommended to define a PodDisruptionBudget to avoid unexpected downtime during Kubernetes maintenance operations, such as
</span></span><span style="display:flex;"><span>            when draining a node.
</span></span><span style="display:flex;"><span>v1/Service http-echo
</span></span></code></pre></div><p>If you plan to use it as part of your Continuous Integration pipeline, you can use a more concise output with the flag <code>--output-format ci</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kube-score score base-valid.yaml --output-format ci
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>OK<span style="color:#f92672">]</span> http-echo apps/v1/Deployment
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>OK<span style="color:#f92672">]</span> http-echo apps/v1/Deployment
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: <span style="color:#f92672">(</span>http-echo<span style="color:#f92672">)</span> CPU limit is not set
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: <span style="color:#f92672">(</span>http-echo<span style="color:#f92672">)</span> Memory limit is not set
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: <span style="color:#f92672">(</span>http-echo<span style="color:#f92672">)</span> CPU request is not set
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: <span style="color:#f92672">(</span>http-echo<span style="color:#f92672">)</span> Memory request is not set
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: <span style="color:#f92672">(</span>http-echo<span style="color:#f92672">)</span> Image with latest tag
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: <span style="color:#f92672">(</span>http-echo<span style="color:#f92672">)</span> Ephemeral Storage limit is not set
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: Container is missing a readinessProbe
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>OK<span style="color:#f92672">]</span> http-echo apps/v1/Deployment
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: The pod does not have a matching NetworkPolicy
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: <span style="color:#f92672">(</span>http-echo<span style="color:#f92672">)</span> Container has no configured security context
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>OK<span style="color:#f92672">]</span> http-echo apps/v1/Deployment
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: <span style="color:#f92672">(</span>http-echo<span style="color:#f92672">)</span> Container has no configured security context
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>CRITICAL<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: No matching PodDisruptionBudget was found
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>WARNING<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: Deployment does not have a host podAntiAffinity set
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>SKIPPED<span style="color:#f92672">]</span> http-echo apps/v1/Deployment: Skipped because the deployment is not targeted by a HorizontalPodAutoscaler
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>OK<span style="color:#f92672">]</span> http-echo apps/v1/Deployment
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>OK<span style="color:#f92672">]</span> http-echo v1/Service
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>OK<span style="color:#f92672">]</span> http-echo v1/Service
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>OK<span style="color:#f92672">]</span> http-echo v1/Service
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>OK<span style="color:#f92672">]</span> http-echo v1/Service
</span></span></code></pre></div><h3 id="trivy">trivy</h3>
<p><code>Trivy</code> (<code>tri</code> pronounced like trigger, <code>vy</code> pronounced like envy) is a simple and comprehensive scanner for vulnerabilities in container images.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>trivy image jxlwqq/http-echo:latest
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>jxlwqq/http-echo:latest <span style="color:#f92672">(</span>debian 11.1<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">=====================================</span>
</span></span><span style="display:flex;"><span>Total: <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>http-echo <span style="color:#f92672">(</span>gobinary<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">====================</span>
</span></span><span style="display:flex;"><span>Total: <span style="color:#ae81ff">0</span> <span style="color:#f92672">(</span>UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 0<span style="color:#f92672">)</span>
</span></span></code></pre></div><p>It also provides built-in policies to detect configuration issues in Docker, Kubernetes and Terraform. Also, you can write your own policies in <code>Rego</code> to scan JSON, YAML, HCL, etc, like Conftest.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>trivy config base-valid.yaml
</span></span><span style="display:flex;"><span>2022-03-09T18:38:49.725+0100	INFO	Detected config files: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>base-valid.yaml <span style="color:#f92672">(</span>kubernetes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">============================</span>
</span></span><span style="display:flex;"><span>Tests: <span style="color:#ae81ff">39</span> <span style="color:#f92672">(</span>SUCCESSES: 28, FAILURES: 11, EXCEPTIONS: 0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Failures: <span style="color:#ae81ff">11</span> <span style="color:#f92672">(</span>UNKNOWN: 0, LOW: 7, MEDIUM: 4, HIGH: 0, CRITICAL: 0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>+---------------------------+------------+----------------------------------------+----------+--------------------------------------------+
</span></span><span style="display:flex;"><span>|           TYPE            | MISCONF ID |                 CHECK                  | SEVERITY |                  MESSAGE                   |
</span></span><span style="display:flex;"><span>+---------------------------+------------+----------------------------------------+----------+--------------------------------------------+
</span></span><span style="display:flex;"><span>| Kubernetes Security Check |   KSV001   | Process can elevate its own privileges |  MEDIUM  | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of                   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | Deployment <span style="color:#e6db74">&#39;http-echo&#39;</span> should set          |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | <span style="color:#e6db74">&#39;securityContext.allowPrivilegeEscalation&#39;</span> |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | to false                                   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv001        |
</span></span><span style="display:flex;"><span>+                           +------------+----------------------------------------+----------+--------------------------------------------+
</span></span><span style="display:flex;"><span>|                           |   KSV003   | Default capabilities not dropped       |   LOW    | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of Deployment        |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | <span style="color:#e6db74">&#39;http-echo&#39;</span> should add <span style="color:#e6db74">&#39;ALL&#39;</span> to            |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | <span style="color:#e6db74">&#39;securityContext.capabilities.drop&#39;</span>        |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv003        |
</span></span><span style="display:flex;"><span>+                           +------------+----------------------------------------+          +--------------------------------------------+
</span></span><span style="display:flex;"><span>|                           |   KSV011   | CPU not limited                        |          | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of                   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | Deployment <span style="color:#e6db74">&#39;http-echo&#39;</span> should              |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | set <span style="color:#e6db74">&#39;resources.limits.cpu&#39;</span>                 |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv011        |
</span></span><span style="display:flex;"><span>+                           +------------+----------------------------------------+----------+--------------------------------------------+
</span></span><span style="display:flex;"><span>|                           |   KSV012   | Runs as root user                      |  MEDIUM  | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of                   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | Deployment <span style="color:#e6db74">&#39;http-echo&#39;</span> should set          |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | <span style="color:#e6db74">&#39;securityContext.runAsNonRoot&#39;</span> to true     |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv012        |
</span></span><span style="display:flex;"><span>+                           +------------+----------------------------------------+----------+--------------------------------------------+
</span></span><span style="display:flex;"><span>|                           |   KSV013   | Image tag <span style="color:#e6db74">&#39;:latest&#39;</span> used               |   LOW    | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of Deployment        |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | <span style="color:#e6db74">&#39;http-echo&#39;</span> should specify an image tag    |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv013        |
</span></span><span style="display:flex;"><span>+                           +------------+----------------------------------------+          +--------------------------------------------+
</span></span><span style="display:flex;"><span>|                           |   KSV014   | Root file system is not read-only      |          | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of                   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | Deployment <span style="color:#e6db74">&#39;http-echo&#39;</span> should set          |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | <span style="color:#e6db74">&#39;securityContext.readOnlyRootFilesystem&#39;</span>   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | to true                                    |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv014        |
</span></span><span style="display:flex;"><span>+                           +------------+----------------------------------------+          +--------------------------------------------+
</span></span><span style="display:flex;"><span>|                           |   KSV015   | CPU requests not specified             |          | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of                   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | Deployment <span style="color:#e6db74">&#39;http-echo&#39;</span> should              |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | set <span style="color:#e6db74">&#39;resources.requests.cpu&#39;</span>               |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv015        |
</span></span><span style="display:flex;"><span>+                           +------------+----------------------------------------+          +--------------------------------------------+
</span></span><span style="display:flex;"><span>|                           |   KSV016   | Memory requests not specified          |          | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of                   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | Deployment <span style="color:#e6db74">&#39;http-echo&#39;</span> should              |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | set <span style="color:#e6db74">&#39;resources.requests.memory&#39;</span>            |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv016        |
</span></span><span style="display:flex;"><span>+                           +------------+----------------------------------------+          +--------------------------------------------+
</span></span><span style="display:flex;"><span>|                           |   KSV018   | Memory not limited                     |          | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of                   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | Deployment <span style="color:#e6db74">&#39;http-echo&#39;</span> should              |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | set <span style="color:#e6db74">&#39;resources.limits.memory&#39;</span>              |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv018        |
</span></span><span style="display:flex;"><span>+                           +------------+----------------------------------------+----------+--------------------------------------------+
</span></span><span style="display:flex;"><span>|                           |   KSV020   | Runs with low user ID                  |  MEDIUM  | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of                   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | Deployment <span style="color:#e6db74">&#39;http-echo&#39;</span> should set          |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | <span style="color:#e6db74">&#39;securityContext.runAsUser&#39;</span> &gt; <span style="color:#ae81ff">10000</span>        |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv020        |
</span></span><span style="display:flex;"><span>+                           +------------+----------------------------------------+          +--------------------------------------------+
</span></span><span style="display:flex;"><span>|                           |   KSV021   | Runs with low group ID                 |          | Container <span style="color:#e6db74">&#39;http-echo&#39;</span> of                   |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | Deployment <span style="color:#e6db74">&#39;http-echo&#39;</span> should set          |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | <span style="color:#e6db74">&#39;securityContext.runAsGroup&#39;</span> &gt; <span style="color:#ae81ff">10000</span>       |
</span></span><span style="display:flex;"><span>|                           |            |                                        |          | --&gt;avd.aquasec.com/appshield/ksv021        |
</span></span><span style="display:flex;"><span>+---------------------------+------------+----------------------------------------+----------+--------------------------------------------+
</span></span></code></pre></div><p>You can integrate trivy to your ci/cd pipeline by using ine of the output template:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export TRIVY_VERSION<span style="color:#f92672">=</span>0.24.2
</span></span><span style="display:flex;"><span>wget --no-verbose https://github.com/aquasecurity/trivy/releases/download/v<span style="color:#e6db74">${</span>TRIVY_VERSION<span style="color:#e6db74">}</span>/trivy_<span style="color:#e6db74">${</span>TRIVY_VERSION<span style="color:#e6db74">}</span>_Linux-64bit.tar.gz -O - | tar -zxvf -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trivy image --exit-code <span style="color:#ae81ff">0</span> --no-progress --format template --template <span style="color:#e6db74">&#34;@contrib/gitlab.tpl&#34;</span> -o gl-container-scanning-report.json golang:1.12-alpine
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trivy image --exit-code <span style="color:#ae81ff">0</span> --no-progress --format template --template <span style="color:#e6db74">&#34;@contrib/junit.tpl&#34;</span> -o junit-report.xml  golang:1.12-alpine
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="gitlab" term="gitlab" label="Gitlab" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[trivy-operator 2.3: Patch release for Admisssion controller]]></title>
            <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.3/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.2/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.2: Patch release for Admisssion controller" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.1/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-1.0/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 1.0" />
                <link href="https://devopstales.github.io/cloud/gke-gitlab-terraform/?utm_source=atom_feed" rel="related" type="text/html" title="Create K8S cluster with Terraform and GitlabCI" />
                <link href="https://devopstales.github.io/kubernetes/multus-calico/?utm_source=atom_feed" rel="related" type="text/html" title="Use multus to separate metwork trafics" />
            
                <id>https://devopstales.github.io/kubernetes/trivy-operator-2.3/</id>
            
            
            <published>2022-02-04T00:00:00+00:00</published>
            <updated>2022-02-04T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Today I am happy to announce the release of trivy-operator 2.3. This blog post focuses on the functionality provided by the trivy-operator 2.3 release.</p>
<h3 id="what-is-trivy-operator">What is trivy-operator?</h3>
<p>Trivy-operator is a Kubernetes Operator based on the open-source container vulnerability scanner Trivy. The goal of this project is to provide a vulnerability scanner that continuously scans containers deployed in a Kubernetes cluster. <a href="https://github.com/nolar/kopf">Built with Kubernetes Operator Pythonic Framework (Kopf)</a> There are a few solution for checking the images when you deploy them to the Kubernetes cluster, but fighting against vulnerabilities is a day to day task. Check once is not enough when every day is a new das for frats. That is why I created trivy-operator so you can create scheduled image scans on your running pods.</p>
<h3 id="bugfixes">Bugfixes</h3>
<p>With the release of trivy-operator 2.3 I fixed a few minor problems:</p>
<h3 id="bugfix">Bugfix</h3>
<ul>
<li>Add ability to Clusterwide Admission Controller</li>
<li>Logging improvements</li>
<li>Remove duplication on scanning, cronejob</li>
</ul>
<h3 id="trivy-image-validator">Trivy Image Validator</h3>
<p>The admission controller function can be configured as a ValidatingWebhook in a k8s cluster. Kubernetes will send requests to the admission server when a Pod creation is initiated. The admission controller checks the image using trivy if it is in a namespace with the label <code>trivy-operator-validation=true</code>.</p>
<p>You can define policy to the Admission Controller, by adding annotation to the pod trough the deployment:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">...</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/medium</span>: <span style="color:#e6db74">&#34;5&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/low</span>: <span style="color:#e6db74">&#34;10&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/critical</span>: <span style="color:#e6db74">&#34;2&#34;</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><h3 id="where-you-can-find">Where you can find:</h3>
<p>With the release of trivy-operator 2.3 I published trivy-operator with OperatorFramework to OperatorHub:</p>
<p><img src="/img/include/trivy-operator-OH.png" alt="OperatorHub"  class="zoomable" /></p>
<p><img src="/img/include/trivy-operator-OH2.png" alt="OperatorHub"  class="zoomable" /></p>
<h2 id="usage">Usage</h2>
<p>To ease deployment I created a helm chart for trivy-operator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add devopstales https://devopstales.github.io/helm-charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span></code></pre></div><p>Create a value file for deploy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;&#39;EOF&#39;&gt; values.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">image</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repository</span>: <span style="color:#ae81ff">devopstales/trivy-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">pullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tag</span>: <span style="color:#e6db74">&#34;2.3&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">imagePullSecrets</span>: []
</span></span><span style="display:flex;"><span><span style="color:#f92672">podSecurityContext</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroup</span>: <span style="color:#ae81ff">10001</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroupChangePolicy</span>: <span style="color:#e6db74">&#34;OnRootMismatch&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceAccount</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;trivy-operator&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">monitoring</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">port</span>: <span style="color:#e6db74">&#34;9115&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;kube-system&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">size</span>: <span style="color:#ae81ff">1Gi</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">NamespaceScanner</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">crontab</span>: <span style="color:#e6db74">&#34;*/5 * * * *&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespaceSelector</span>: <span style="color:#e6db74">&#34;trivy-scan&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">registryAuth</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">registry</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">docker.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">user</span>: <span style="color:#e6db74">&#34;user&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">password</span>: <span style="color:#e6db74">&#34;password&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">githubToken</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">token</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>When the trivy in the container want to scan an image first download the vulnerability database from github. If you test many images you need a  <code>githubToken</code> overcome the github rate limit and dockerhub username and password for overcome the dockerhub rate limit. If your store you images in a private repository you need to add an username and password for authentication.</p>
<p>The following tables lists configurable parameters of the trivy-operator chart and their default values.</p>
<table>
  <thead>
      <tr>
          <th>Parameter</th>
          <th>Description</th>
          <th>Default</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>image.repository</td>
          <td>image</td>
          <td>devopstales/trivy-operator</td>
      </tr>
      <tr>
          <td>image.pullPolicy</td>
          <td>pullPolicy</td>
          <td>Always</td>
      </tr>
      <tr>
          <td>image.tag</td>
          <td>image tag</td>
          <td>2.1</td>
      </tr>
      <tr>
          <td>imagePullSecrets</td>
          <td>imagePullSecrets list</td>
          <td>[]</td>
      </tr>
      <tr>
          <td>podSecurityContext.fsGroup</td>
          <td>mount id</td>
          <td>10001</td>
      </tr>
      <tr>
          <td>serviceAccount.create</td>
          <td>create serviceAccount</td>
          <td>true</td>
      </tr>
      <tr>
          <td>serviceAccount.annotations</td>
          <td>add annotation to serviceAccount</td>
          <td>{}</td>
      </tr>
      <tr>
          <td>serviceAccount.name</td>
          <td>name of the serviceAccount</td>
          <td>trivy-operator</td>
      </tr>
      <tr>
          <td>monitoring.port</td>
          <td>prometheus endpoint port</td>
          <td>9115</td>
      </tr>
      <tr>
          <td>serviceMonitor.enabled</td>
          <td>enable serviceMonitor object creation</td>
          <td>false</td>
      </tr>
      <tr>
          <td>serviceMonitor.namespace</td>
          <td>where to create serviceMonitor object</td>
          <td>kube-system</td>
      </tr>
      <tr>
          <td>storage.enabled</td>
          <td>enable pv to store trivy database</td>
          <td>true</td>
      </tr>
      <tr>
          <td>storage.size</td>
          <td>pv size</td>
          <td>1Gi</td>
      </tr>
      <tr>
          <td>NamespaceScanner.crontab</td>
          <td>cronjob scheduler</td>
          <td>&ldquo;*/5 * * * *&rdquo;</td>
      </tr>
      <tr>
          <td>NamespaceScanner.namespaceSelector</td>
          <td>Namespace Selector</td>
          <td>&ldquo;trivy-scan&rdquo;</td>
      </tr>
      <tr>
          <td>registryAuth.enabled</td>
          <td>enable registry authentication in operator</td>
          <td>false</td>
      </tr>
      <tr>
          <td>registryAuth.registry</td>
          <td>registry name for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>registryAuth.user</td>
          <td>username for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>registryAuth.password</td>
          <td>password for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>githubToken.enabled</td>
          <td>Enable githubToken usage for trivy database update</td>
          <td>false</td>
      </tr>
      <tr>
          <td>githubToken.token</td>
          <td>githubToken value</td>
          <td>&quot;&quot;</td>
      </tr>
  </tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns trivy-operator
</span></span><span style="display:flex;"><span>kubens trivy-operator
</span></span><span style="display:flex;"><span>helm upgrade --install trivy devopstales/trivy-operator -f values.yaml
</span></span></code></pre></div><h3 id="monitoring">Monitoring</h3>
<p>Trivy-operatos has a prometheus endpoint op port <code>9115</code> and can be deployed wit <code>ServiceMonitor</code> for automated scrapping.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -s http://10.43.179.39:9115/metrics | grep trivy_vulnerabilities
</span></span><span style="display:flex;"><span><span style="color:#75715e"># HELP trivy_vulnerabilities_sum Container vulnerabilities</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TYPE trivy_vulnerabilities_sum gauge</span>
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/openshift/mysql-56-centos7:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;scanning_error&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;UNKNOWN&#34;</span><span style="color:#f92672">}</span> 0.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span><span style="color:#f92672">}</span> 83.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span><span style="color:#f92672">}</span> 5.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span><span style="color:#f92672">}</span> 7.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span><span style="color:#f92672">}</span> 4.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;UNKNOWN&#34;</span><span style="color:#f92672">}</span> 0.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span><span style="color:#f92672">}</span> 126.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span><span style="color:#f92672">}</span> 25.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span><span style="color:#f92672">}</span> 43.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span><span style="color:#f92672">}</span> 21.0
</span></span><span style="display:flex;"><span><span style="color:#75715e"># HELP trivy_vulnerabilities Container vulnerabilities</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TYPE trivy_vulnerabilities gauge</span>
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2.3.4&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2011-3374&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;8.32-4&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2016-2781&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;8.32-4&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2017-18018&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22945&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22946&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22947&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22898&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span></code></pre></div><p><img src="/img/include/trivy-exporter.png" alt="Grafana Dashboard"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-operators" term="k8s-operators" label="k8s-operators" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="trivy-operator" term="trivy-operator" label="trivy-operator" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Use multus to separate metwork trafics]]></title>
            <link href="https://devopstales.github.io/kubernetes/multus-calico/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/multus/?utm_source=atom_feed" rel="related" type="text/html" title="Use Multus CNI in Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
            
                <id>https://devopstales.github.io/kubernetes/multus-calico/</id>
            
            
            <published>2022-01-15T00:00:00+00:00</published>
            <updated>2022-01-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use Multus CNI and Calico to create Kubernetes pods in different networks.</p>
<h3 id="install-default-network">Install default network</h3>
<blockquote>
<p>The kubernetes cluster is installed with <code>kubeadm</code> and <code>--pod-network-cidr=10.244.0.0/16</code> option</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano custom-resources.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: operator.tigera.io/v1
</span></span><span style="display:flex;"><span>kind: Installation
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: default
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Configures Calico networking.</span>
</span></span><span style="display:flex;"><span>  calicoNetwork:
</span></span><span style="display:flex;"><span>    bgp: Disabled
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># linuxDataplane: BPF</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Note: The ipPools section cannot be modified post-install.</span>
</span></span><span style="display:flex;"><span>    ipPools:
</span></span><span style="display:flex;"><span>    - blockSize: <span style="color:#ae81ff">26</span>
</span></span><span style="display:flex;"><span>      cidr: 10.244.0.0/16
</span></span><span style="display:flex;"><span>      encapsulation: VXLANCrossSubnet
</span></span><span style="display:flex;"><span>      natOutgoing: Enabled
</span></span><span style="display:flex;"><span>      nodeSelector: all<span style="color:#f92672">()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f custom-resources.yaml
</span></span></code></pre></div><h3 id="install-secondary-network">Install Secondary network</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ip -d link show vxlan.calico
</span></span><span style="display:flex;"><span>9: vxlan.calico: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1450</span> qdisc noqueue state UNKNOWN mode DEFAULT group default
</span></span><span style="display:flex;"><span>    link/ether 66:2f:69:dc:0c:cc brd ff:ff:ff:ff:ff:ff promiscuity <span style="color:#ae81ff">0</span> minmtu <span style="color:#ae81ff">68</span> maxmtu <span style="color:#ae81ff">65535</span>
</span></span><span style="display:flex;"><span>    vxlan id <span style="color:#ae81ff">4096</span> local 192.168.200.10 dev enp0s9 srcport <span style="color:#ae81ff">0</span> <span style="color:#ae81ff">0</span> dstport <span style="color:#ae81ff">4789</span> nolearning ttl auto ageing <span style="color:#ae81ff">300</span> udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues <span style="color:#ae81ff">1</span> numrxqueues <span style="color:#ae81ff">1</span> gso_max_size <span style="color:#ae81ff">65536</span> gso_max_segs <span style="color:#ae81ff">65535</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ip a show vxlan.calico
</span></span><span style="display:flex;"><span>9: vxlan.calico: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1450</span> qdisc noqueue state UNKNOWN group default
</span></span><span style="display:flex;"><span>    link/ether 66:2f:69:dc:0c:cc brd ff:ff:ff:ff:ff:ff
</span></span><span style="display:flex;"><span>    inet 10.250.58.192/32 scope global vxlan.calico
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::642f:69ff:fedc:ccc/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span></code></pre></div><h3 id="deploy-multus">Deploy multus</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/k8snetworkplumbingwg/multus-cni/master/deployments/multus-daemonset.yml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pods --all-namespaces | grep -i multus
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ls -laF /opt/cni/bin
</span></span><span style="display:flex;"><span>total <span style="color:#ae81ff">291839</span>
</span></span><span style="display:flex;"><span>drwxr-xr-x <span style="color:#ae81ff">1</span> root root       <span style="color:#ae81ff">13</span> Jul <span style="color:#ae81ff">22</span> 13:39 ./
</span></span><span style="display:flex;"><span>drwxr-xr-x <span style="color:#ae81ff">1</span> root root        <span style="color:#ae81ff">3</span> May <span style="color:#ae81ff">25</span> 23:22 ../
</span></span><span style="display:flex;"><span>-rwxr-xr-x <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3954360</span> Jul <span style="color:#ae81ff">22</span> 12:57 bandwidth*
</span></span><span style="display:flex;"><span>-rwsr-xr-x <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">62013206</span> Jul <span style="color:#ae81ff">22</span> 12:57 calico*
</span></span><span style="display:flex;"><span>-rwsr-xr-x <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">62013206</span> Jul <span style="color:#ae81ff">22</span> 12:57 calico-ipam*
</span></span><span style="display:flex;"><span>-rwxr-xr-x <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">2342446</span> Jul <span style="color:#ae81ff">22</span> 12:57 flannel*
</span></span><span style="display:flex;"><span>-rwxr-xr-x <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3421269</span> Jul <span style="color:#ae81ff">22</span> 12:57 host-local*
</span></span><span style="display:flex;"><span>-rwsr-xr-x <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">62013206</span> Jul <span style="color:#ae81ff">22</span> 12:57 install*
</span></span><span style="display:flex;"><span>-rwxr-xr-x <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3484706</span> Jul <span style="color:#ae81ff">22</span> 12:57 loopback*
</span></span><span style="display:flex;"><span>-rwxr-xr-x <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">46926142</span> Jul <span style="color:#ae81ff">22</span> 13:39 multus*
</span></span><span style="display:flex;"><span>-rwxr-xr-x <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">39561855</span> Jul <span style="color:#ae81ff">22</span> 13:05 multus-shim*
</span></span><span style="display:flex;"><span>-rwxr-xr-x <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3913894</span> Jul <span style="color:#ae81ff">22</span> 12:57 portmap*
</span></span><span style="display:flex;"><span>-rwxr-xr-x <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">4372265</span> May <span style="color:#ae81ff">25</span> 23:21 ptp*
</span></span><span style="display:flex;"><span>-rwxr-xr-x <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3641046</span> Jul <span style="color:#ae81ff">22</span> 12:57 tuning*
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat /etc/cni/net.d/00-multus.conf | jq
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/containernetworking/plugins/releases/download/v1.2.0/cni-plugins-linux-amd64-v1.2.0.tgz
</span></span><span style="display:flex;"><span>tar -xzf cni-plugins-linux-amd64-v1.2.0.tgz -C /opt/cni/bin ./host-local ./ipvlan ./macvlan
</span></span></code></pre></div><p>check multus config find calico as the default config.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl apply -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;k8s.cni.cncf.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkAttachmentDefinition</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">22</span>-<span style="color:#ae81ff">calico</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>: 
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;cniVersion&#34;: &#34;0.3.1&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;type&#34;: &#34;calico&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;log_level&#34;: &#34;info&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;datastore_type&#34;: &#34;kubernetes&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;ipam&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;type&#34;: &#34;host-local&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;subnet&#34;: &#34;172.22.0.0/16&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;policy&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;type&#34;: &#34;k8s&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;kubernetes&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;kubeconfig&#34;: &#34;/etc/cni/net.d/calico-kubeconfig&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  }&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl apply -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;k8s.cni.cncf.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkAttachmentDefinition</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">26</span>-<span style="color:#ae81ff">calico</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>: 
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;cniVersion&#34;: &#34;0.3.1&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;type&#34;: &#34;calico&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;log_level&#34;: &#34;info&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;datastore_type&#34;: &#34;kubernetes&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;ipam&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;type&#34;: &#34;host-local&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;subnet&#34;: &#34;172.26.0.0/16&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;policy&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;type&#34;: &#34;k8s&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;kubernetes&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;kubeconfig&#34;: &#34;/etc/cni/net.d/calico-kubeconfig&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  }&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl apply -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">net-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">k8s.v1.cni.cncf.io/networks</span>: <span style="color:#ae81ff">default/26-calico</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">netshoot-pod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nicolaka/netshoot</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;tail&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">args</span>: [<span style="color:#e6db74">&#34;-f&#34;</span>, <span style="color:#e6db74">&#34;/dev/null&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">terminationGracePeriodSeconds</span>: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">net-pod2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">k8s.v1.cni.cncf.io/networks</span>: <span style="color:#ae81ff">default/22-calico</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">netshoot-pod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nicolaka/netshoot</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;tail&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">args</span>: [<span style="color:#e6db74">&#34;-f&#34;</span>, <span style="color:#e6db74">&#34;/dev/null&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">terminationGracePeriodSeconds</span>: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>The <code>default/22-calico</code> means that the <code>22-calico</code> NetworkAttachmentDefinition from the <code>default</code> namespace.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl describe pods net-pod</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">Annotations:      cni.projectcalico.org/containerID</span>: <span style="color:#ae81ff">3e73ddecf916a31d93685bbd6bbc0663ffebfcbb6417bbc71717e1512e83c315</span>
</span></span><span style="display:flex;"><span>                  <span style="color:#f92672">cni.projectcalico.org/podIP</span>: <span style="color:#ae81ff">172.26.0.2</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>                  <span style="color:#f92672">cni.projectcalico.org/podIPs</span>: <span style="color:#ae81ff">172.26.0.2</span><span style="color:#ae81ff">/32</span>
</span></span><span style="display:flex;"><span>                  <span style="color:#f92672">k8s.v1.cni.cncf.io/network-status</span>:
</span></span><span style="display:flex;"><span>                    [{
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;name&#34;: </span><span style="color:#e6db74">&#34;k8s-pod-network&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;ips&#34;: </span>[
</span></span><span style="display:flex;"><span>                            <span style="color:#e6db74">&#34;10.244.39.202&#34;</span>
</span></span><span style="display:flex;"><span>                        ],
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;default&#34;: </span><span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;dns&#34;: </span>{}
</span></span><span style="display:flex;"><span>                    },{
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;name&#34;: </span><span style="color:#e6db74">&#34;default/26-calico&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;ips&#34;: </span>[
</span></span><span style="display:flex;"><span>                            <span style="color:#e6db74">&#34;172.26.0.2&#34;</span>
</span></span><span style="display:flex;"><span>                        ],
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;dns&#34;: </span>{}
</span></span><span style="display:flex;"><span>                    }]
</span></span><span style="display:flex;"><span>                  <span style="color:#f92672">k8s.v1.cni.cncf.io/networks</span>: <span style="color:#ae81ff">default/26-calico</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">Status</span>:           <span style="color:#ae81ff">Running</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">IP</span>:               <span style="color:#ae81ff">10.244.39.202</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">IPs</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">IP</span>:  <span style="color:#ae81ff">10.244.39.202</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">Events</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">Type    Reason          Age   From               Message</span>
</span></span><span style="display:flex;"><span>  ----    ------          ----  ----               -------
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">Normal  Scheduled       11m   default-scheduler  Successfully assigned default/net-pod to test-worker2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">Normal  AddedInterface  11m   multus             Add eth0 [10.244.39.202/32] from k8s-pod-network</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">Normal  AddedInterface  11m   multus             Add net1 [172.26.0.2/32] from default/26-calico</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">Normal  Pulling         11m   kubelet            Pulling image &#34;nicolaka/netshoot&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">Normal  Pulled          11m   kubelet            Successfully pulled image &#34;nicolaka/netshoot&#34; in 2.123400585s (2.12353655s including waiting)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">Normal  Created         11m   kubelet            Created container netshoot-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">Normal  Started         11m   kubelet            Started container netshoot-pod</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl exec -it net-pod -- ip addr
</span></span><span style="display:flex;"><span>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span style="display:flex;"><span>    inet 127.0.0.1/8 scope host lo
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 ::1/128 scope host
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>3: eth0@if66: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1450</span> qdisc noqueue state UP group default
</span></span><span style="display:flex;"><span>    link/ether fa:26:21:4b:3c:94 brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    inet 172.26.0.4/32 scope global eth0
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::f826:21ff:fe4b:3c94/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl exec -it net-pod2 -- ip addr
</span></span><span style="display:flex;"><span>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span style="display:flex;"><span>    inet 127.0.0.1/8 scope host lo
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 ::1/128 scope host
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>3: eth0@if67: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1450</span> qdisc noqueue state UP group default
</span></span><span style="display:flex;"><span>    link/ether fe:16:f1:9d:5e:40 brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    inet 172.22.0.6/32 scope global eth0
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::fc16:f1ff:fe9d:5e40/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl exec -it net-pod -- ping -c <span style="color:#ae81ff">1</span> 172.22.0.6
</span></span><span style="display:flex;"><span>PING 172.22.0.6 <span style="color:#f92672">(</span>172.22.0.6<span style="color:#f92672">)</span> 56<span style="color:#f92672">(</span>84<span style="color:#f92672">)</span> bytes of data.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 172.22.0.6: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">63</span> time<span style="color:#f92672">=</span>0.099 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--- 172.22.0.6 ping statistics ---
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span> packets transmitted, <span style="color:#ae81ff">1</span> received, 0% packet loss, time 0ms
</span></span><span style="display:flex;"><span>rtt min/avg/max/mdev <span style="color:#f92672">=</span> 0.099/0.099/0.099/0.000 ms
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="multus" term="multus" label="multus" />
                             
                                <category scheme="calico" term="calico" label="calico" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Use Multus CNI in Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/multus/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-falco/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes audit logs and Falco" />
            
                <id>https://devopstales.github.io/kubernetes/multus/</id>
            
            
            <published>2022-01-14T00:00:00+00:00</published>
            <updated>2022-01-14T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use Multus CNI to create Kubernetes pods with multiple interfaces.</p>
<h3 id="what-is-multus">What is Multus?</h3>
<p>Multus CNI is a container network interface plugin for Kubernetes that enables attaching multiple network interfaces to pods. In Kubernetes, each pod has only one network interface by default, other than local loopback. With Multus, you can create multi-homed pods that have multiple interfaces. Multus acts a as ‘meta’ plugin that can call other CNI plugins to configure additional interfaces.</p>
<h3 id="install-a-default-network">Install a default network</h3>
<p>Our installation method requires that you first have installed Kubernetes and have configured a default network &ndash; that is, a CNI plugin that&rsquo;s used for your pod-to-pod connectivity. After installing Kubernetes, you must install a default network CNI plugin. In this demo I will use Flannel for the sake of simplicity.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># install flanel:</span>
</span></span><span style="display:flex;"><span>wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
</span></span><span style="display:flex;"><span>nano kube-flannel.yml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>        args:
</span></span><span style="display:flex;"><span>        - --ip-masq
</span></span><span style="display:flex;"><span>        - --kube-subnet-mgr
</span></span><span style="display:flex;"><span>        - --iface<span style="color:#f92672">=</span>enp0s8
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f kube-flannel.yml
</span></span></code></pre></div><h3 id="install-multus">Install Multus</h3>
<p>Now we can install Multus. The recommended method to deploy Multus is to deploy using a Daemonset, this spins up pods which install a Multus binary and configure Multus for usage.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/k8snetworkplumbingwg/multus-cni/master/deployments/multus-daemonset-thick-plugin.yml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pods --all-namespaces | grep -i multus
</span></span></code></pre></div><p>You may further validate that it has ran by looking at the <code>/etc/cni/net.d/</code> directory and ensure that the auto-generated <code>/etc/cni/net.d/00-multus.conf</code> exists. Check the <code>multus</code> binary is exists under <code>/opt/cni/bin</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ll /opt/cni/bin/
</span></span><span style="display:flex;"><span>total <span style="color:#ae81ff">98044</span>
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3254624</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> bandwidth
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3581192</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> bridge
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">9837552</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> dhcp
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">4699824</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> firewall
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">2650368</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> flannel
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3274160</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> host-device
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">2847152</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> host-local
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3377272</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> ipvlan
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">2715600</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> loopback
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3440168</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> macvlan
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">42554869</span> Jan <span style="color:#ae81ff">15</span> 10:44 multus
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3048528</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> portmap
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3528800</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> ptp
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">2849328</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> sbr
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">2503512</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> static
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">2820128</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> tuning
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3377120</span> Sep  <span style="color:#ae81ff">9</span>  <span style="color:#ae81ff">2020</span> vlan
</span></span></code></pre></div><h3 id="create-networkattachmentdefinition">Create NetworkAttachmentDefinition</h3>
<p>The first thing we&rsquo;ll do is create configurations for each of the additional interfaces that we attach to pods. We&rsquo;ll do this by creating Custom Resources. Each configuration we well add is a CNI configuration. If you&rsquo;re not familiar with them, let&rsquo;s break them down quickly.Here&rsquo;s an example CNI configuration:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl create -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;k8s.cni.cncf.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkAttachmentDefinition</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">macvlan-conf</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;cniVersion&#34;: &#34;0.3.0&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;type&#34;: &#34;macvlan&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;master&#34;: &#34;enp0s9&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;mode&#34;: &#34;bridge&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;ipam&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;type&#34;: &#34;host-local&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;subnet&#34;: &#34;172.17.9.0/24&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;rangeStart&#34;: &#34;172.17.9.240&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;rangeEnd&#34;: &#34;172.17.9.250&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;routes&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          { &#34;dst&#34;: &#34;0.0.0.0/0&#34; }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;gateway&#34;: &#34;172.17.9.1&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><ul>
<li><code>cniVersion</code>: Tells each CNI plugin which version is being used and can give the plugin information if it&rsquo;s using a too late (or too early) version.</li>
<li><code>master</code>: this parameter should match the interface name on the hosts in your cluster. Can not be the same interface used by the default network!!!</li>
<li><code>type</code>: This tells CNI which binary to call on disk. Each CNI plugin is a binary that&rsquo;s called. Typically, these binaries are stored in <code>/opt/cni/bin</code> on each node, and CNI executes this binary. In this case we&rsquo;ve specified the <code>macvlan</code> binary. If this is your first time installing Multus, you might want to verify that the plugins that are in the &ldquo;type&rdquo; field are actually on disk in the <code>/opt/cni/bin</code> directory.</li>
<li><code>ipam</code>: IP address allocation configuration. The <code>type</code> can an be the following:
<ul>
<li><code>dhcp</code>: Runs a daemon on the host to make DHCP requests on behalf of a container</li>
<li><code>host-local</code>: Maintains a local database of allocated IPs</li>
<li><code>static</code>: Allocates static IPv4/IPv6 addresses to containers</li>
<li><a href="https://github.com/k8snetworkplumbingwg/whereabouts">whereabouts</a>: A CNI IPAM plugin that assigns IP addresses cluster-wide</li>
</ul>
</li>
</ul>
<h3 id="networkattachmentdefinition-cni-types">NetworkAttachmentDefinition CNI Types</h3>
<h5 id="bridge">Bridge:</h5>
<p>This acts as a network switch between multiple pods on the same node host. In its current form, a bridge interface is created that does not link any physical host interface. As a result, connections are not made to any external networks including other pods on the other host nodes:</p>
<p><img src="/img/include/multus01.png" alt="Brudge"  class="zoomable" /></p>
<p>Configure the bridge plug-in with host-local IPAM. The default bridge name is cni0 by default if the name is not specified using bridge parameter:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;k8s.cni.cncf.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkAttachmentDefinition</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">bridge-conf</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;cniVersion&#34;: &#34;0.3.1&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;type&#34;: &#34;bridge&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;bridge&#34;: &#34;mybr0&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;ipam&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;type&#34;: &#34;host-local&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;subnet&#34;: &#34;192.168.12.0/24&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;rangeStart&#34;: &#34;192.168.12.10&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;rangeEnd&#34;: &#34;192.168.12.200&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }&#39;</span>
</span></span></code></pre></div><h5 id="host-device">Host-device:</h5>
<p>This plug-in makes a physical host interface move to a pod network namespace. When enabled, the specified host interface disappears in the root network namespace (default host network namespace). This behavior might affect re-creating the pod in place on the same host as the host interface may not be found as it is specified by host-device plug-in configuration.</p>
<p><img src="/img/include/multus02.png" alt="Brudge"  class="zoomable" /></p>
<p>This time, dhcp IPAM is configured, and it would trigger the creation of the dhcp-daemon daemonset pods. The pod in daemon mode listens for an address from a DHCP server on Kubernetes, whereas the DHCP server itself is not provided. In other words, it requires an existing DHCP server in the same network. This demonstration shows you the MAC address of the parent is kept in the pod network namespace. Additionally, the source IP and MAC address can be identified by using an external web server access test.</p>
<p>Add the following configurations:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;k8s.cni.cncf.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkAttachmentDefinition</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">host-device</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;cniVersion&#34;: &#34;0.3.1&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;name&#34;: &#34;host-device-main&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;type&#34;: &#34;host-device&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;device&#34;: &#34;enp0s9&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;ipam&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;type&#34;: &#34;dhcp&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }&#39;</span>
</span></span></code></pre></div><h5 id="ipvlan">ipvlan:</h5>
<p>The ipvlan plug-in may be used in the event that there are limited MAC addresses that can be used. This issue is common on some switch devices that restrict the maximum number of MAC addresses per physical port due to port security configurations. When operating in most cloud providers, you should  consider using ipvlan instead of macvlan as unknown MAC addresses are forbidden in VPC networks:</p>
<p><img src="/img/include/multus03.png" alt="Brudge"  class="zoomable" /></p>
<p>The sub-interface of the ipvlan can use distinct IP addresses with the same MAC address of the parent host interface. So, it would not work well with a DHCP server which depends on the MAC addresses. Parent host interface acts as a bridge (switch) with L2 mode, and it acts as a router with L3 mode of the ipvlan plug-in.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;k8s.cni.cncf.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkAttachmentDefinition</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ipvlan</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">   &#34;cniVersion&#34;: &#34;0.3.1&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">   &#34;name&#34;: &#34;ipvlan-main&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">   &#34;type&#34;: &#34;ipvlan&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">   &#34;mode&#34;: &#34;l2&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">   &#34;master&#34;: &#34;enp0s9&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">     &#34;ipam&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;type&#34;: &#34;host-local&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;subnet&#34;: &#34;172.17.9.0/24&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;rangeStart&#34;: &#34;172.17.9.201&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;rangeEnd&#34;: &#34;172.17.9.205&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;gateway&#34;: &#34;172.17.9.1&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">     }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">   }&#39;</span>
</span></span></code></pre></div><h5 id="macvlan">Macvlan:</h5>
<p>With macvlan, it&rsquo;s simple to use as it aligns to traditional network connectivity. Since the connectivity is directly bound with the underlying network using sub-interfaces each having MAC address.</p>
<p><img src="/img/include/multus04.png" alt="Brudge"  class="zoomable" /></p>
<p>macvlan generates MAC addresses per the sub-interfaces, and in most cases, Public Cloud Platforms are not allowed due to their security policy and Hypervisors have limited capabilities. For the <code>RHV</code> (Red Hat Virtualization) use case, you will need to change <code>No network filter</code> on your network profile before executing the test. For <code>vSwitch</code> in vSphere environments, similar relaxed policies need to be applied. The test procedure is almost the same as ipvlan, so it is easy to compare both plug-ins.</p>
<p>Macvlan has multiple modes. In this example, bridge mode will be configured. Refer to MACVLAN documentation for more information on the other mode which will not be demonstrated.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;k8s.cni.cncf.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkAttachmentDefinition</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">macvlan</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;cniVersion&#34;: &#34;0.3.1&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;name&#34;: &#34;macvlan-main&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;type&#34;: &#34;macvlan&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;mode&#34;: &#34;bridge&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;master&#34;: &#34;enp0s9&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;ipam&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            &#34;type&#34;: &#34;static&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }&#39;</span>
</span></span></code></pre></div><h3 id="creating-a-pod-that-attaches-an-additional-interface">Creating a pod that attaches an additional interface</h3>
<p><img src="/img/include/multus00.png" alt="Infra"  class="zoomable" /></p>
<p>Deploy a IPVLAN Type NetworkAttachmentDefinition:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl create -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;k8s.cni.cncf.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkAttachmentDefinition</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ipvlan-def</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;cniVersion&#34;: &#34;0.3.1&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;type&#34;: &#34;ipvlan&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;master&#34;: &#34;enp0s9&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;mode&#34;: &#34;l2&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;ipam&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;type&#34;: &#34;host-local&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;subnet&#34;: &#34;192.168.200.0/24&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;rangeStart&#34;: &#34;192.168.200.201&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;rangeEnd&#34;: &#34;192.168.200.205&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;gateway&#34;: &#34;192.168.200.1&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>Let&rsquo;s go ahead and create a pod (that just sleeps for a really long time) with this command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl create -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">net-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">k8s.v1.cni.cncf.io/networks</span>: <span style="color:#ae81ff">ipvlan-def</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">netshoot-pod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nicolaka/netshoot</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;tail&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">args</span>: [<span style="color:#e6db74">&#34;-f&#34;</span>, <span style="color:#e6db74">&#34;/dev/null&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">terminationGracePeriodSeconds</span>: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">net-pod2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">k8s.v1.cni.cncf.io/networks</span>: <span style="color:#ae81ff">ipvlan-def</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">netshoot-pod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nicolaka/netshoot</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;tail&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">args</span>: [<span style="color:#e6db74">&#34;-f&#34;</span>, <span style="color:#e6db74">&#34;/dev/null&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">terminationGracePeriodSeconds</span>: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>Check the ips in the pod:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl exec -it net-pod -- ip addr
</span></span><span style="display:flex;"><span>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span style="display:flex;"><span>    inet 127.0.0.1/8 scope host lo
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 ::1/128 scope host 
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>3: eth0@if10: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1450</span> qdisc noqueue state UP group default 
</span></span><span style="display:flex;"><span>    link/ether 06:56:cf:cb:3e:75 brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    inet 10.244.0.5/24 brd 10.244.0.255 scope global eth0
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::456:cfff:fecb:3e75/64 scope link 
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>4: net1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue state UNKNOWN group default 
</span></span><span style="display:flex;"><span>    link/ether 08:00:27:a0:41:35 brd ff:ff:ff:ff:ff:ff
</span></span><span style="display:flex;"><span>    inet 192.168.200.201/24 brd 192.168.200.255 scope global net1
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::800:2700:1a0:4135/64 scope link 
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl exec -it net-pod2 -- ip addr
</span></span><span style="display:flex;"><span>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span style="display:flex;"><span>    inet 127.0.0.1/8 scope host lo
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 ::1/128 scope host 
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>3: eth0@if9: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1450</span> qdisc noqueue state UP group default 
</span></span><span style="display:flex;"><span>    link/ether 8e:8f:68:f8:80:2c brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    inet 10.244.0.4/24 brd 10.244.0.255 scope global eth0
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::8c8f:68ff:fef8:802c/64 scope link 
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>4: net1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue state UNKNOWN group default 
</span></span><span style="display:flex;"><span>    link/ether 08:00:27:a0:41:35 brd ff:ff:ff:ff:ff:ff
</span></span><span style="display:flex;"><span>    inet 192.168.200.202/24 brd 192.168.200.255 scope global net1
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::800:2700:2a0:4135/64 scope link 
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span></code></pre></div><p>Ping test:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># ping own ip</span>
</span></span><span style="display:flex;"><span>kubectl exec -it net-pod -- ping -c <span style="color:#ae81ff">1</span> -I net1 192.168.200.201
</span></span><span style="display:flex;"><span>PING 192.168.200.201 <span style="color:#f92672">(</span>192.168.200.201<span style="color:#f92672">)</span> from 192.168.200.201 net1: 56<span style="color:#f92672">(</span>84<span style="color:#f92672">)</span> bytes of data.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 192.168.200.201: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>0.024 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--- 192.168.200.201 ping statistics ---
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span> packets transmitted, <span style="color:#ae81ff">1</span> received, 0% packet loss, time 0ms
</span></span><span style="display:flex;"><span>rtt min/avg/max/mdev <span style="color:#f92672">=</span> 0.024/0.024/0.024/0.000 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ping net-pod2&#39;s ip</span>
</span></span><span style="display:flex;"><span>kubectl exec -it net-pod -- ping -c <span style="color:#ae81ff">1</span> -I net1 192.168.200.201
</span></span><span style="display:flex;"><span>PING 192.168.200.202 <span style="color:#f92672">(</span>192.168.200.202<span style="color:#f92672">)</span> from 192.168.200.201 net1: 56<span style="color:#f92672">(</span>84<span style="color:#f92672">)</span> bytes of data.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 192.168.200.202: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>0.040 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--- 192.168.200.202 ping statistics ---
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span> packets transmitted, <span style="color:#ae81ff">1</span> received, 0% packet loss, time 0ms
</span></span><span style="display:flex;"><span>rtt min/avg/max/mdev <span style="color:#f92672">=</span> 0.040/0.040/0.040/0.000 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ping dw</span>
</span></span><span style="display:flex;"><span>kubectl exec -it net-pod -- ping -c <span style="color:#ae81ff">1</span> -I net1 192.168.200.10
</span></span><span style="display:flex;"><span>PING 192.168.200.1 <span style="color:#f92672">(</span>192.168.200.1<span style="color:#f92672">)</span> from 192.168.200.201 net1: 56<span style="color:#f92672">(</span>84<span style="color:#f92672">)</span> bytes of data.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 192.168.200.1: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>0.217 ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--- 192.168.200.1 ping statistics ---
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span> packets transmitted, <span style="color:#ae81ff">1</span> received, 0% packet loss, time 4ms
</span></span><span style="display:flex;"><span>rtt min/avg/max/mdev <span style="color:#f92672">=</span> 0.217/0.217/0.217/0.000 ms
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="multus" term="multus" label="multus" />
                             
                                <category scheme="flannel" term="flannel" label="flannel" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Single Sign-on with Pinniped OpenID Connect]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-pinniped/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/linux/pfsense-ad-join/?utm_source=atom_feed" rel="related" type="text/html" title="Firewall Ports for AD Domain Join" />
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/k8s-git-backup/?utm_source=atom_feed" rel="related" type="text/html" title="How to Backup Kubernetes to git?" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-pinniped/</id>
            
            
            <published>2021-12-29T00:00:00+00:00</published>
            <updated>2021-12-29T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will setup Pinniped, a Single Sign-on solution from the VMware Tanzu project.</p>
<h3 id="wtah-is-pinniped">Wtah is Pinniped</h3>
<p>Pinniped gives you a unified login experience across all your clusters, including on-premises and managed cloud environments.</p>
<p>Pinniped consists of two components, Supervisor and Concierge:</p>
<ul>
<li>
<p>The Pinniped Supervisor is an OIDC server which allows users to authenticate with an external identity provider (IDP), and then issues its own federation ID tokens to be passed on to clusters based on the user information from the IDP.</p>
</li>
<li>
<p>The Pinniped Concierge is a credential exchange API which takes as input a credential from an identity source (e.g., Pinniped Supervisor, proprietary IDP), authenticates the user via that credential, and returns another credential which is understood by the host Kubernetes cluster or by an impersonation proxy which acts on behalf of the user.</p>
</li>
</ul>
<p><img src="/img/include/pinniped01.svg" alt="Pinniped Architecture"  class="zoomable" /></p>
<h3 id="install-the-pinniped-supervisor">Install the Pinniped Supervisor</h3>
<p>Run below command to install Supervisor, this will install everything to the pinniped-supervisor namespace.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://get.pinniped.dev/latest/install-pinniped-supervisor.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubens pinniped-supervisor
</span></span><span style="display:flex;"><span>kubectl get po
</span></span></code></pre></div><p>After installing Pinniped, create a secret with the client ID and secret from your identity provider. In below command I have named the secret <code>oidc-client</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create secret generic oidc-client <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --namespace pinniped-supervisor <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --type secrets.pinniped.dev/oidc-client <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --from-literal<span style="color:#f92672">=</span>clientID<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;client-id-goes-here&gt;&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --from-literal<span style="color:#f92672">=</span>clientSecret<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;secret-goes-here&gt;&#34;</span>
</span></span></code></pre></div><p>The supervisor needs to be reachable from other clusters, we need to create a service and an ingress resource.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano pinniped-supervisor-ingress.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">pinniped-supervisor</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">pinniped-supervisor</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">pinniped-supervisor</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">pinniped-supervisor</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">pinniped-supervisor</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes.io/ingress.class</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cert-manager.io/cluster-issuer</span>: <span style="color:#ae81ff">ca-issuer</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">supervisor.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">supervisor-cert</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">supervisor.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">Prefix</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">pinniped-supervisor</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">number</span>: <span style="color:#ae81ff">80</span>
</span></span></code></pre></div><p>Create and apply a <code>FederationDomain</code> resource. Give it a name and set the issuer to the URL you will be using for Supervisor.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano FederationDomain.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">config.supervisor.pinniped.dev/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">FederationDomain</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">keycloak</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">pinniped-supervisor</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">issuer</span>: <span style="color:#ae81ff">https://supervisor.k8s.intra</span>
</span></span></code></pre></div><p>Create and apply a <code>OIDCIdentityProvider</code> resource.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano OIDCIdentityProvider.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">idp.supervisor.pinniped.dev/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">OIDCIdentityProvider</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">keycloak-idp</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">pinniped-supervisor</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">issuer</span>: <span style="color:#ae81ff">https://sso.k8s.intra/auth/realms/k8s</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">claims</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">username</span>: <span style="color:#ae81ff">email</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">groups</span>: <span style="color:#ae81ff">groups</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">authorizationConfig</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">additionalScopes</span>: [<span style="color:#e6db74">&#39;email&#39;</span>, <span style="color:#e6db74">&#39;profile&#39;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">client</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">oidc-client</span>
</span></span></code></pre></div><h3 id="install-the-pinniped-concierge">Install the Pinniped Concierge</h3>
<p>Install Concierge on any managed or unmanaged cluster you would like to use OIDC login on. This can include the cluster where Supervisor is running.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://get.pinniped.dev/latest/install-pinniped-concierge-crds.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://get.pinniped.dev/latest/install-pinniped-concierge.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubens pinniped-concierge
</span></span><span style="display:flex;"><span>kubectl get po
</span></span></code></pre></div><p>Create and apply a <code>JWTAuthenticator</code> resource, it is cluster scoped so no need for namespaces. Create a random string for the audience property using <code>openssl rand -base64 24</code> command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>openssl rand -base64 <span style="color:#ae81ff">24</span>
</span></span><span style="display:flex;"><span>jCIGaxMT5Yw9NvafTTVoXxGLkviPPyg6
</span></span></code></pre></div><blockquote>
<p>If you ise a self signed certificate for the ingress you need o add the base64 encoded CA pem to the JWTAuthenticator.</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat k8s.pem | base64
</span></span><span style="display:flex;"><span>LS0tLS1CR...
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano JWTAuthenticator.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">authentication.concierge.pinniped.dev/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">JWTAuthenticator</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">name</span>: <span style="color:#ae81ff">supervisor-jwt-authenticator</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">pinniped-concierge</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">issuer</span>: <span style="color:#ae81ff">https://supervisor.k8s.intra</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">audience</span>: <span style="color:#ae81ff">jCIGaxMT5Yw9NvafTTVoXxGLkviPPyg6</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">claims</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">username</span>: <span style="color:#ae81ff">username</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">groups</span>: <span style="color:#ae81ff">groups</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># tls:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#   certificateAuthorityData: LS0tLS1CR... # optional base64 CA data if using a self-signed certificate</span>
</span></span></code></pre></div><blockquote>
<p>The <code>supervisor.k8s.intra</code> domain must be resolwable from the pinniped-concierge.
You can add <code>supervisor.k8s.intra</code> as like hists file to the coredns <a href="https://devopstales.github.io/home/k8s-custom-host/">like this</a>.</p></blockquote>
<p>Below is an example of a <code>ClusterRoleBinding</code> that binds the role <code>cluster-admin</code> to the Keycloak group <code>devops-team</code>. (In my case it came from ldap) Create your own role bindings to fit your needs and apply them to the cluster.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano devops-team_ClusterRoleBinding.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-admin-it-afdeling</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-admin</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">devops-team</span>
</span></span></code></pre></div><h3 id="install-the-pinniped-command-line-tool">Install the Pinniped command-line tool</h3>
<p>For osx you can use <code>brew</code> to install the command-line tool:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install vmware-tanzu/pinniped/pinniped-cli
</span></span></code></pre></div><p>Or find the appropriate binary for your platform from the <a href="https://github.com/vmware-tanzu/pinniped/releases">latest release</a> the put the command-line tool somewhere on your <code>$PATH</code>.</p>
<p>Generate the <code>kubeconfig</code> file wigh the default admin <code>kubeconfig</code> on the cluster&rsquo;s master node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pinniped get kubeconfig <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--oidc-ca-bundle /opt/k8s_sec_lab/cert/k8s.pem <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--output pinniped-kubeconfig
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl --kubeconfig pinniped-kubeconfig get pods -n pinniped-concierge
</span></span><span style="display:flex;"><span>NAME                                                  READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>pinniped-concierge-9bc8bbdc5-qg75p                    1/1     Running   <span style="color:#ae81ff">0</span>          16m
</span></span><span style="display:flex;"><span>pinniped-concierge-9bc8bbdc5-zxsjj                    1/1     Running   <span style="color:#ae81ff">0</span>          16m
</span></span><span style="display:flex;"><span>pinniped-concierge-kube-cert-agent-5dcccbbb4b-56jbj   1/1     Running   <span style="color:#ae81ff">0</span>          79m
</span></span></code></pre></div><p>The <code>k8s.pem</code> file is containes the  CA certificate from <code>ca-issuer</code>.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-authentication" term="k8s-authentication" label="k8s-authentication" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="oidc" term="oidc" label="oidc" />
                             
                                <category scheme="kubernetes" term="kubernetes" label="kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[trivy-operator 2.2: Patch release for Admisssion controller]]></title>
            <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.2/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.1/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-1.0/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 1.0" />
                <link href="https://devopstales.github.io/kubernetes/k8s-central-oauth/?utm_source=atom_feed" rel="related" type="text/html" title="Central authentication with oauth2-proxy" />
                <link href="https://devopstales.github.io/kubernetes/k8s-rbac-gen/?utm_source=atom_feed" rel="related" type="text/html" title="How to create kubeconfig?" />
                <link href="https://devopstales.github.io/kubernetes/k8s-falco/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes audit logs and Falco" />
            
                <id>https://devopstales.github.io/kubernetes/trivy-operator-2.2/</id>
            
            
            <published>2021-12-27T00:00:00+00:00</published>
            <updated>2021-12-27T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Today I am happy to announce the release of trivy-operator 2.2. This blog post focuses on the functionality provided by the trivy-operator 2.2 release.</p>
<h3 id="what-is-trivy-operator">What is trivy-operator?</h3>
<p>Trivy-operator is a Kubernetes Operator based on the open-source container vulnerability scanner Trivy. The goal of this project is to provide a vulnerability scanner that continuously scans containers deployed in a Kubernetes cluster. <a href="https://github.com/nolar/kopf">Built with Kubernetes Operator Pythonic Framework (Kopf)</a> There are a few solution for checking the images when you deploy them to the Kubernetes cluster, but fighting against vulnerabilities is a day to day task. Check once is not enough when every day is a new das for frats. That is why I created trivy-operator so you can create scheduled image scans on your running pods.</p>
<h3 id="bugfixes">Bugfixes</h3>
<p>With the release of trivy-operator 2.2 I fixed a few minor problems:</p>
<ul>
<li>Add Advanced Grafana Dashboard and Change Prometheus Endpoint</li>
<li>Now the Admission Controller Function generates it&rsquo;s own self signed certificate for the <code>ValidatingWebhook</code></li>
</ul>
<p><img src="/img/include/trivy-exporter.png" alt="Grafana Dashboard"  class="zoomable" /></p>
<h3 id="trivy-image-validator">Trivy Image Validator</h3>
<p>The admission controller function can be configured as a ValidatingWebhook in a k8s cluster. Kubernetes will send requests to the admission server when a Pod creation is initiated. The admission controller checks the image using trivy if it is in a namespace with the label <code>trivy-operator-validation=true</code>.</p>
<p>You can define policy to the Admission Controller, by adding annotation to the pod trough the deployment:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">...</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/medium</span>: <span style="color:#e6db74">&#34;5&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/low</span>: <span style="color:#e6db74">&#34;10&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/critical</span>: <span style="color:#e6db74">&#34;2&#34;</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><h3 id="where-you-can-find">Where you can find:</h3>
<p>With the release of trivy-operator 2.2 I published trivy-operator with OperatorFramework to OperatorHub:</p>
<p><img src="/img/include/trivy-operator-OH.png" alt="OperatorHub"  class="zoomable" /></p>
<p><img src="/img/include/trivy-operator-OH2.png" alt="OperatorHub"  class="zoomable" /></p>
<h2 id="usage">Usage</h2>
<p>To ease deployment I created a helm chart for trivy-operator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add devopstales https://devopstales.github.io/helm-charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span></code></pre></div><p>Create a value file for deploy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;&#39;EOF&#39;&gt; values.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">image</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repository</span>: <span style="color:#ae81ff">devopstales/trivy-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">pullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tag</span>: <span style="color:#e6db74">&#34;2.2&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">imagePullSecrets</span>: []
</span></span><span style="display:flex;"><span><span style="color:#f92672">podSecurityContext</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroup</span>: <span style="color:#ae81ff">10001</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroupChangePolicy</span>: <span style="color:#e6db74">&#34;OnRootMismatch&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceAccount</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;trivy-operator&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">monitoring</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">port</span>: <span style="color:#e6db74">&#34;9115&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;kube-system&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">size</span>: <span style="color:#ae81ff">1Gi</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">NamespaceScanner</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">crontab</span>: <span style="color:#e6db74">&#34;*/5 * * * *&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespaceSelector</span>: <span style="color:#e6db74">&#34;trivy-scan&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">registryAuth</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">registry</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">docker.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">user</span>: <span style="color:#e6db74">&#34;user&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">password</span>: <span style="color:#e6db74">&#34;password&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">githubToken</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">token</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>When the trivy in the container want to scan an image first download the vulnerability database from github. If you test many images you need a  <code>githubToken</code> overcome the github rate limit and dockerhub username and password for overcome the dockerhub rate limit. If your store you images in a private repository you need to add an username and password for authentication.</p>
<p>The following tables lists configurable parameters of the trivy-operator chart and their default values.</p>
<table>
  <thead>
      <tr>
          <th>Parameter</th>
          <th>Description</th>
          <th>Default</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>image.repository</td>
          <td>image</td>
          <td>devopstales/trivy-operator</td>
      </tr>
      <tr>
          <td>image.pullPolicy</td>
          <td>pullPolicy</td>
          <td>Always</td>
      </tr>
      <tr>
          <td>image.tag</td>
          <td>image tag</td>
          <td>2.1</td>
      </tr>
      <tr>
          <td>imagePullSecrets</td>
          <td>imagePullSecrets list</td>
          <td>[]</td>
      </tr>
      <tr>
          <td>podSecurityContext.fsGroup</td>
          <td>mount id</td>
          <td>10001</td>
      </tr>
      <tr>
          <td>serviceAccount.create</td>
          <td>create serviceAccount</td>
          <td>true</td>
      </tr>
      <tr>
          <td>serviceAccount.annotations</td>
          <td>add annotation to serviceAccount</td>
          <td>{}</td>
      </tr>
      <tr>
          <td>serviceAccount.name</td>
          <td>name of the serviceAccount</td>
          <td>trivy-operator</td>
      </tr>
      <tr>
          <td>monitoring.port</td>
          <td>prometheus endpoint port</td>
          <td>9115</td>
      </tr>
      <tr>
          <td>serviceMonitor.enabled</td>
          <td>enable serviceMonitor object creation</td>
          <td>false</td>
      </tr>
      <tr>
          <td>serviceMonitor.namespace</td>
          <td>where to create serviceMonitor object</td>
          <td>kube-system</td>
      </tr>
      <tr>
          <td>storage.enabled</td>
          <td>enable pv to store trivy database</td>
          <td>true</td>
      </tr>
      <tr>
          <td>storage.size</td>
          <td>pv size</td>
          <td>1Gi</td>
      </tr>
      <tr>
          <td>NamespaceScanner.crontab</td>
          <td>cronjob scheduler</td>
          <td>&ldquo;*/5 * * * *&rdquo;</td>
      </tr>
      <tr>
          <td>NamespaceScanner.namespaceSelector</td>
          <td>Namespace Selector</td>
          <td>&ldquo;trivy-scan&rdquo;</td>
      </tr>
      <tr>
          <td>registryAuth.enabled</td>
          <td>enable registry authentication in operator</td>
          <td>false</td>
      </tr>
      <tr>
          <td>registryAuth.registry</td>
          <td>registry name for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>registryAuth.user</td>
          <td>username for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>registryAuth.password</td>
          <td>password for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>githubToken.enabled</td>
          <td>Enable githubToken usage for trivy database update</td>
          <td>false</td>
      </tr>
      <tr>
          <td>githubToken.token</td>
          <td>githubToken value</td>
          <td>&quot;&quot;</td>
      </tr>
  </tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns trivy-operator
</span></span><span style="display:flex;"><span>kubens trivy-operator
</span></span><span style="display:flex;"><span>helm upgrade --install trivy devopstales/trivy-operator -f values.yaml
</span></span></code></pre></div><h3 id="monitoring">Monitoring</h3>
<p>Trivy-operatos has a prometheus endpoint op port <code>9115</code> and can be deployed wit <code>ServiceMonitor</code> for automated scrapping.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -s http://10.43.179.39:9115/metrics | grep trivy_vulnerabilities
</span></span><span style="display:flex;"><span><span style="color:#75715e"># HELP trivy_vulnerabilities_sum Container vulnerabilities</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TYPE trivy_vulnerabilities_sum gauge</span>
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/openshift/mysql-56-centos7:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;scanning_error&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;UNKNOWN&#34;</span><span style="color:#f92672">}</span> 0.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span><span style="color:#f92672">}</span> 83.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span><span style="color:#f92672">}</span> 5.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span><span style="color:#f92672">}</span> 7.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span><span style="color:#f92672">}</span> 4.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;UNKNOWN&#34;</span><span style="color:#f92672">}</span> 0.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span><span style="color:#f92672">}</span> 126.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span><span style="color:#f92672">}</span> 25.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span><span style="color:#f92672">}</span> 43.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities_sum<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span><span style="color:#f92672">}</span> 21.0
</span></span><span style="display:flex;"><span><span style="color:#75715e"># HELP trivy_vulnerabilities Container vulnerabilities</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TYPE trivy_vulnerabilities gauge</span>
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2.2.4&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2011-3374&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;8.32-4&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2016-2781&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;8.32-4&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2017-18018&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22945&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22946&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22947&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span><span style="display:flex;"><span>trivy_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/nginxinc/nginx-unprivileged:latest&#34;</span>,installedVersion<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;7.74.0-1.3&#34;</span>,pkgName<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pkgName&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span>,vulnerabilityId<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CVE-2021-22898&#34;</span><span style="color:#f92672">}</span> 1.0
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-operators" term="k8s-operators" label="k8s-operators" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="trivy-operator" term="trivy-operator" label="trivy-operator" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Publish Kubernetes Operator to OperatorHub]]></title>
            <link href="https://devopstales.github.io/kubernetes/oml/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/ansible-operator-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Ansible Operator Overview" />
                <link href="https://devopstales.github.io/kubernetes/ansible-openshift-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-log4shell/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)" />
                <link href="https://devopstales.github.io/kubernetes/openshift-elasticsearch-error/?utm_source=atom_feed" rel="related" type="text/html" title="Opeshift elasticsearch search-guard error" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-ansible-service-broker-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix Ansible Service Broker in OpenShift 3.11" />
            
                <id>https://devopstales.github.io/kubernetes/oml/</id>
            
            
            <published>2021-12-21T00:00:00+00:00</published>
            <updated>2021-12-21T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can publish your operator to OperatorHub.</p>
<p>I assume you have a pre built and publised docker image with the operator in it.</p>
<h3 id="install-requirement">Install requirement</h3>
<ul>
<li><a href="https://github.com/operator-framework/operator-registry/releases">operator-registry-tools</a></li>
<li><a href="https://github.com/operator-framework/operator-sdk/releases">operator-sdk</a></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install opm
</span></span><span style="display:flex;"><span>brew install operator-sdk
</span></span></code></pre></div><h3 id="stucture">Stucture</h3>
<p>Your Operator submission can be formatted following the <code>bundle</code> or <code>packagemanifest</code> format. he <code>packagemanifest</code> format is a legacy format which is kept for backwards compatibility only so I will use <code>bundle</code> format.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>tree OLM
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>OLM
</span></span><span style="display:flex;"><span>└── 0.0.1
</span></span><span style="display:flex;"><span>    ├── manifests
</span></span><span style="display:flex;"><span>    │   ├── trivy-operator.v0.0.1.clusterserviceversion.yaml
</span></span><span style="display:flex;"><span>    │   └── crds.yaml
</span></span><span style="display:flex;"><span>    └── metadata
</span></span><span style="display:flex;"><span>        └── annotations.yaml
</span></span></code></pre></div><h3 id="create-clusterserviceversion">Create clusterserviceversion</h3>
<p>To add your operator to any of the supported platforms, you will need to submit metadata for your Operator to be used by the <code>Operator Lifecycle Manager</code> (OLM). This is YAML file called <code>ClusterServiceVersion</code> which contains references to all of the CRDs, RBAC rules, Deployment and container image needed to install and securely run your Operator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano OLM/0.0.1/manifests/trivy-operator.v0.0.1.clusterserviceversion.yaml</span>
</span></span></code></pre></div><p>First start with a CSV that only contains some descriptive metadata:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterServiceVersion</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">capabilities</span>: <span style="color:#ae81ff">Basic Install</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">categories</span>: <span style="color:#e6db74">&#34;Security&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">description</span>: <span style="color:#ae81ff">Trivy Operator for scheduled imagescans and an Admission Control.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">certified</span>: <span style="color:#e6db74">&#34;false&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">containerImage</span>: <span style="color:#ae81ff">devopstales/trivy-operator:0.0.1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-operator.v0.0.1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">description</span>: <span style="color:#ae81ff">Trivy Operator for scheduled imagescans and an Admission Control.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">displayName</span>: <span style="color:#ae81ff">Trivy Operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">keywords</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">trivy</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">security</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">maintainers</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">email</span>: <span style="color:#ae81ff">devopstales@mydomain.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">devopstales</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">maturity</span>: <span style="color:#ae81ff">alpha</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">provider</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">Blog</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">url</span>: <span style="color:#ae81ff">devopstales.hithub.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">version</span>: <span style="color:#ae81ff">0.10.0</span>
</span></span></code></pre></div><p>The next section to add to the CSV is the Install Strategy - this tells OLM about the runtime components of your operator and their requirements.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterServiceVersion</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># ... </span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-operator.v0.0.1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">install</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># ... </span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># strategy indicates what type of deployment artifacts are used</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">strategy</span>: <span style="color:#ae81ff">deployment</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># spec for the deployment strategy is a list of deployment specs and required permissions - similar to a pod template used in a deployment</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">permissions</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">serviceAccountName</span>: <span style="color:#ae81ff">trivy-operator </span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">pods</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#e6db74">&#39;*&#39;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#75715e"># the rest of the rules</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># permissions required at the cluster scope</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">clusterPermissions</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">serviceAccountName</span>: <span style="color:#ae81ff">trivy-operator </span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">serviceaccounts</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#e6db74">&#39;*&#39;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#75715e"># the rest of the rules</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">deployments</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-operator</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>          <span style="color:#75715e"># the rest of a deployment spec</span>
</span></span></code></pre></div><blockquote>
<p>For Openshift you can append SCC to the serviceaccount in the rules section</p></blockquote>
<p>It’s also important to tell OLM the ways in which your operator can be deployed:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterServiceVersion</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># ... </span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-operator.v0.0.1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># ... </span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">installModes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">supported</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">OwnNamespace</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">supported</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">SingleNamespace</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">supported</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">MultiNamespace</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">supported</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">AllNamespaces</span>
</span></span></code></pre></div><p>By definition, operators are programs that can talk to the Kubernetes API and they are also extend the Kubernetes API, by <code>CustomResourceDefinitions</code>. Which APIs are watched or owned is important metadata for OLM so we need to define thease too.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterServiceVersion</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># ... </span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">alm-examples</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;apiVersion&#34;: &#34;trivy-operator.devopstales.io/v1&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;kind&#34;: &#34;NamespaceScanner&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;metadata&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            &#34;name&#34;: &#34;trivy-operator-main-config&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          &#34;spec&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            &#34;crontab&#34;: &#34;*/5 * * * *&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            &#34;namespace_selector&#34;: &#34;trivy-scan&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            &#34;registry&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;name&#34;: &#34;docker.io&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;user&#34;: &#34;&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;password&#34;: &#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            ]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      ]</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-operator.v0.0.1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># ... </span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">customresourcedefinitions</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">owned</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># a list of CRDs that this operator owns </span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># name is the metadata.name of the CRD</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">namespace-scanners.trivy-operator.devopstales.io</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># version is the version of the CRD (one per entry)</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">version</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># spec.names.kind from the CRD</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NamespaceScanner</span>
</span></span></code></pre></div><p>You must place the <code>CustomResourceDefinitions</code> to the <code>manifests</code> folder andy any other object like <code>service</code> what you want to deploy by the <code>Operator Framework</code>. If you created your `` you can test with OperatorHub&rsquo;s <a href="https://operatorhub.io/preview">Operator Preview</a> page.</p>
<h1 id="test-operator">Test operator</h1>
<p>You can test your files with <code>operator-sdk</code> locally:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>operator-sdk bundle validate ./OLM/0.0.1 --select-optional suite<span style="color:#f92672">=</span>operatorframework
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>0000<span style="color:#f92672">]</span> All validation tests have completed successfully
</span></span></code></pre></div><h3 id="generate-bundle">Generate bundle</h3>
<p>To test the functions all working correctly you need first to install the operator with Operato framework. To do so you need a build the <code>bundle</code> image the the catalog index:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd OML
</span></span><span style="display:flex;"><span>opm alpha bundle build -c stable -d 0.0.1/manifests -t devopstales/trivy-operator-bundle:0.0.1 -p trivy-operator
</span></span><span style="display:flex;"><span>docker push docker.io/devopstales/trivy-operator-bundle:0.0.1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>opm index add -b docker.io/devopstales/trivy-operator-bundle:0.0.1 -t docker.io/devopstales/trivy-operator-index:0.0.1 -c docker
</span></span><span style="display:flex;"><span>docker push docker.io/devopstales/trivy-operator-index:0.0.1
</span></span></code></pre></div><h3 id="install-oml">Install OML</h3>
<p>To install the operator from your catalog index first you need to install the <code>operator-lifecycle-manager</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -sL https://github.com/operator-framework/operator-lifecycle-manager/releases/download/v0.19.1/install.sh | bash -s v0.19.1
</span></span></code></pre></div><h3 id="add-your-index-as-catalogsource">Add your index as CatalogSource</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano cs-trivy-operator.yaml</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">CatalogSource</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">devopstales-catalog</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">olm</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">displayName</span>: <span style="color:#ae81ff">devopstales</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">publisher</span>: <span style="color:#ae81ff">devopstales</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sourceType</span>: <span style="color:#ae81ff">grpc</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">image</span>: <span style="color:#ae81ff">docker.io/devopstales/trivy-operator-index:0.0.1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">updateStrategy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">registryPoll</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">interval</span>: <span style="color:#ae81ff">1m</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f cs-trivy-operator.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get catalogsource --all-namespaces
</span></span><span style="display:flex;"><span>NAMESPACE   NAME                    DISPLAY               TYPE      PUBLISHER        AGE
</span></span><span style="display:flex;"><span>olm         devopstales-catalog     devopstales           grpc      devopstales      13m
</span></span><span style="display:flex;"><span>olm         operatorhubio-catalog   Community Operators   grpc      OperatorHub.io   7h20m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get packagemanifest | grep trivy
</span></span><span style="display:flex;"><span>trivy-operator                             devopstales           6h54m
</span></span></code></pre></div><p>Subscribe to this operator:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">$ cat og.yaml </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">OperatorGroup</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-og</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetNamespaces</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">$ cat sub_devopstales-catalog.yaml </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Subscription</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">channel</span>: <span style="color:#ae81ff">alpha</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">installPlanApproval</span>: <span style="color:#ae81ff">Automatic</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>: <span style="color:#ae81ff">devopstales-catalog</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sourceNamespace</span>: <span style="color:#ae81ff">olm</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">startingCSV</span>: <span style="color:#ae81ff">trivy-operator.v0.0.1</span>
</span></span></code></pre></div><p>After create them, you will get the below objects:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">$ oc get sub -n default</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">NAME             PACKAGE          SOURCE                CHANNEL</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">trivy-operator   trivy-operator   devopstales-catalog   alpha</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">$ oc get ip -n default</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">NAME            CSV                     APPROVAL    APPROVED</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">install-tvpq4   trivy-operator.v0.0.1   Automatic   true</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">$ oc get csv -n default</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">NAME                    DISPLAY          VERSION   REPLACES   PHASE</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">trivy-operator.v0.0.1   Trivy Operator   0.0.1                Succeeded</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"></code></pre></div><p>The you can create the Custo Resource to test the functionality.</p>
<h3 id="publicate-operato-on-operatohub">Publicate operato on OperatoHub</h3>
<p>To publish your bundled operator you need to create a pull requuest to the <a href="https://github.com/k8s-operatorhub/community-operators">operatorhub  community-operators</a> repo or <a href="https://github.com/redhat-openshift-ecosystem/community-operators-prod">RedHat Opeshift community-operators</a> repo.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-operators" term="k8s-operators" label="k8s Operators" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="operator" term="operator" label="Operator" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!]]></title>
            <link href="https://devopstales.github.io/kubernetes/trivy-operator-2.1/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-1.0/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 1.0" />
                <link href="https://devopstales.github.io/kubernetes/k8s-central-oauth/?utm_source=atom_feed" rel="related" type="text/html" title="Central authentication with oauth2-proxy" />
                <link href="https://devopstales.github.io/kubernetes/k8s-rbac-gen/?utm_source=atom_feed" rel="related" type="text/html" title="How to create kubeconfig?" />
                <link href="https://devopstales.github.io/kubernetes/k8s-falco/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes audit logs and Falco" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cisa-install/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Hardening Guide with CISA 1.6 Benchmark" />
            
                <id>https://devopstales.github.io/kubernetes/trivy-operator-2.1/</id>
            
            
            <published>2021-12-17T00:00:00+00:00</published>
            <updated>2021-12-17T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Today I am happy to announce the release of trivy-operator 2.1. This blog post focuses on the functionality provided by the trivy-operator 2.1 release.</p>
<h3 id="what-is-trivy-operator">What is trivy-operator?</h3>
<p>Trivy-operator is a Kubernetes Operator based on the open-source container vulnerability scanner Trivy. The goal of this project is to provide a vulnerability scanner that continuously scans containers deployed in a Kubernetes cluster. <a href="https://github.com/nolar/kopf">Built with Kubernetes Operator Pythonic Framework (Kopf)</a> There are a few solution for checking the images when you deploy them to the Kubernetes cluster, but fighting against vulnerabilities is a day to day task. Check once is not enough when every day is a new das for frats. That is why I created trivy-operator so you can create scheduled image scans on your running pods.</p>
<h3 id="new-functions">New Functions</h3>
<p>With the release of trivy-operator 2.1 It is not just an operator but an Admisssion controller too!!! Now you can check the Images at deploy time with the same tool. You didn&rsquo;t need to deploy multiple applications for image scanning.</p>
<h3 id="trivy-image-validator">Trivy Image Validator</h3>
<p>The admission controller function can be configured as a <code>ValidatingWebhook</code> in a k8s cluster. Kubernetes will send requests to the admission server when a Pod creation is initiated. The admission controller checks the image using trivy.</p>
<p>You can define policy to the Admission Controller, by adding annotation to the pod trough the deployment:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">...</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/medium</span>: <span style="color:#e6db74">&#34;5&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/low</span>: <span style="color:#e6db74">&#34;10&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/critical</span>: <span style="color:#e6db74">&#34;2&#34;</span>
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><h3 id="where-you-can-find">Where you can find:</h3>
<p>With the release of trivy-operator 2.1 I published trivy-operator with OperatorFramework to OperatorHub:</p>
<p><img src="/img/include/trivy-operator-OH.png" alt="OperatorHub"  class="zoomable" /></p>
<h2 id="usage">Usage</h2>
<p>To ease deployment I created a helm chart for trivy-operator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add devopstales https://devopstales.github.io/helm-charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span></code></pre></div><p>Create a value file for deploy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;&#39;EOF&#39;&gt; values.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">image</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repository</span>: <span style="color:#ae81ff">devopstales/trivy-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">pullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tag</span>: <span style="color:#e6db74">&#34;2.1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">imagePullSecrets</span>: []
</span></span><span style="display:flex;"><span><span style="color:#f92672">podSecurityContext</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroup</span>: <span style="color:#ae81ff">10001</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroupChangePolicy</span>: <span style="color:#e6db74">&#34;OnRootMismatch&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceAccount</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;trivy-operator&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">monitoring</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">port</span>: <span style="color:#e6db74">&#34;9115&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;kube-system&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">size</span>: <span style="color:#ae81ff">1Gi</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">NamespaceScanner</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">crontab</span>: <span style="color:#e6db74">&#34;*/5 * * * *&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespaceSelector</span>: <span style="color:#e6db74">&#34;trivy-scan&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">registryAuth</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">registry</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">docker.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">user</span>: <span style="color:#e6db74">&#34;user&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">password</span>: <span style="color:#e6db74">&#34;password&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">githubToken</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">token</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>When the trivy in the container want to scan an image first download the vulnerability database from github. If you test many images you need a  <code>githubToken</code> overcome the github rate limit and dockerhub username and password for overcome the dockerhub rate limit. If your store you images in a private repository you need to add an username and password for authentication.</p>
<p>The following tables lists configurable parameters of the trivy-operator chart and their default values.</p>
<table>
  <thead>
      <tr>
          <th>Parameter</th>
          <th>Description</th>
          <th>Default</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>image.repository</td>
          <td>image</td>
          <td>devopstales/trivy-operator</td>
      </tr>
      <tr>
          <td>image.pullPolicy</td>
          <td>pullPolicy</td>
          <td>Always</td>
      </tr>
      <tr>
          <td>image.tag</td>
          <td>image tag</td>
          <td>2.1</td>
      </tr>
      <tr>
          <td>imagePullSecrets</td>
          <td>imagePullSecrets list</td>
          <td>[]</td>
      </tr>
      <tr>
          <td>podSecurityContext.fsGroup</td>
          <td>mount id</td>
          <td>10001</td>
      </tr>
      <tr>
          <td>serviceAccount.create</td>
          <td>create serviceAccount</td>
          <td>true</td>
      </tr>
      <tr>
          <td>serviceAccount.annotations</td>
          <td>add annotation to serviceAccount</td>
          <td>{}</td>
      </tr>
      <tr>
          <td>serviceAccount.name</td>
          <td>name of the serviceAccount</td>
          <td>trivy-operator</td>
      </tr>
      <tr>
          <td>monitoring.port</td>
          <td>prometheus endpoint port</td>
          <td>9115</td>
      </tr>
      <tr>
          <td>serviceMonitor.enabled</td>
          <td>enable serviceMonitor object creation</td>
          <td>false</td>
      </tr>
      <tr>
          <td>serviceMonitor.namespace</td>
          <td>where to create serviceMonitor object</td>
          <td>kube-system</td>
      </tr>
      <tr>
          <td>storage.enabled</td>
          <td>enable pv to store trivy database</td>
          <td>true</td>
      </tr>
      <tr>
          <td>storage.size</td>
          <td>pv size</td>
          <td>1Gi</td>
      </tr>
      <tr>
          <td>NamespaceScanner.crontab</td>
          <td>cronjob scheduler</td>
          <td>&ldquo;*/5 * * * *&rdquo;</td>
      </tr>
      <tr>
          <td>NamespaceScanner.namespaceSelector</td>
          <td>Namespace Selector</td>
          <td>&ldquo;trivy-scan&rdquo;</td>
      </tr>
      <tr>
          <td>registryAuth.enabled</td>
          <td>enable registry authentication in operator</td>
          <td>false</td>
      </tr>
      <tr>
          <td>registryAuth.registry</td>
          <td>registry name for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>registryAuth.user</td>
          <td>username for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>registryAuth.password</td>
          <td>password for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>githubToken.enabled</td>
          <td>Enable githubToken usage for trivy database update</td>
          <td>false</td>
      </tr>
      <tr>
          <td>githubToken.token</td>
          <td>githubToken value</td>
          <td>&quot;&quot;</td>
      </tr>
  </tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns trivy-operator
</span></span><span style="display:flex;"><span>kubens trivy-operator
</span></span><span style="display:flex;"><span>helm upgrade --install trivy devopstales/trivy-operator -f values.yaml
</span></span></code></pre></div><h3 id="monitoring">Monitoring</h3>
<p>Trivy-operatos has a prometheus endpoint op port <code>9115</code> and can be deployed wit <code>ServiceMonitor</code> for automated scrapping.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -s http://10.43.179.39:9115/metrics | grep so_vulnerabilities
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;UNKNOWN&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">23</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">93</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">76</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">25</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;UNKNOWN&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">23</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">88</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">60</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">8</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-operators" term="k8s-operators" label="k8s-operators" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="trivy-operator" term="trivy-operator" label="trivy-operator" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-log4shell/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-elasticsearch-error/?utm_source=atom_feed" rel="related" type="text/html" title="Opeshift elasticsearch search-guard error" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-ansible-service-broker-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix Ansible Service Broker in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-cluster-monitoring-operator-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix cluster-monitoring-operator in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-registry-console-ui-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix registry console UI in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/openshift-cert-manager/?utm_source=atom_feed" rel="related" type="text/html" title="Install cert-manager to Openshift" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-log4shell/</id>
            
            
            <published>2021-12-15T00:00:00+00:00</published>
            <updated>2021-12-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>On OpenShift 4 and OpenShift 3.11 in OpenShift Logging the above mitigation can be applied to the affected Elasticsearch component.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="openshift-311">OpenShift 3.11</h3>
<p>Resolution:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc project openshift-logging
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc get dc -l component<span style="color:#f92672">=</span>es
</span></span><span style="display:flex;"><span>NAME                              REVISION   DESIRED   CURRENT   TRIGGERED BY
</span></span><span style="display:flex;"><span>logging-es-data-master-9fgtlhi4   <span style="color:#ae81ff">1</span>          <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc set env -c elasticsearch dc/logging-es-data-master-9fgtlhi4 ES_JAVA_OPTS<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;-Dlog4j2.formatMsgNoLookups=true&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># test the configuration</span>
</span></span><span style="display:flex;"><span>oc set env -c elasticsearch dc -l component<span style="color:#f92672">=</span>es --list | grep ES_JAVA_OPTS
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc scale dc/logging-es-data-master-9fgtlhi4 --replicas<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>oc rollout latest dc/logging-es-data-master-9fgtlhi4
</span></span><span style="display:flex;"><span>oc scale dc/logging-es-data-master-9fgtlhi4 --replicas<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span></code></pre></div><p>Afther the pod is recreated test the variable in the pods:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> es_pod in <span style="color:#66d9ef">$(</span>oc get pods -l component<span style="color:#f92672">=</span>es --no-headers -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{range .items[?(@.status.phase==&#34;Running&#34;)]}{.metadata.name}{&#34;\n&#34;}{end}&#39;</span><span style="color:#66d9ef">)</span>; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   <span style="color:#66d9ef">do</span> echo <span style="color:#e6db74">&#34;Confirm changes on </span>$es_pod<span style="color:#e6db74">&#34;</span> ;  sleep <span style="color:#ae81ff">1</span> ; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   oc rsh -Tc elasticsearch $es_pod ps auxwww | grep log4j2.formatMsgNoLookups ; sleep 3; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   <span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> es_pod in <span style="color:#66d9ef">$(</span>oc get pods -l component<span style="color:#f92672">=</span>es --no-headers -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{range .items[?(@.status.phase==&#34;Running&#34;)]}{.metadata.name}{&#34;\n&#34;}{end}&#39;</span><span style="color:#66d9ef">)</span>; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   <span style="color:#66d9ef">do</span> echo <span style="color:#e6db74">&#34;Confirm changes on </span>$es_pod<span style="color:#e6db74">&#34;</span> ;  sleep <span style="color:#ae81ff">1</span> ; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   oc rsh -Tc elasticsearch $es_pod printenv | grep ES_JAVA_OPTS ; sleep 3; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>   <span style="color:#66d9ef">done</span>
</span></span></code></pre></div><h3 id="openshift-4">OpenShift 4</h3>
<p>Resolution:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc project openshift-logging
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc get deployment -l component<span style="color:#f92672">=</span>elasticsearch
</span></span><span style="display:flex;"><span>NAME                                      REVISION   DESIRED   CURRENT   TRIGGERED BY
</span></span><span style="display:flex;"><span>elasticsearch-cdm-ba9c6evk-1-796f6cfdbc   <span style="color:#ae81ff">1</span>          <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc patch deployment/elasticsearch-cdm-ba9c6evk-1-796f6cfdbc --type<span style="color:#f92672">=</span>merge -p <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;paused&#34;: false}}&#39;</span>
</span></span><span style="display:flex;"><span>oc set env deployment/elasticsearch-cdm-ba9c6evk-1-796f6cfdbc -c elasticsearch ES_JAVA_OPTS<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;-Dlog4j2.formatMsgNoLookups=true&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc set env -c elasticsearch deployment -l component<span style="color:#f92672">=</span>elasticsearch --list | grep ES_JAVA_OPTS
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc scale deployment/elasticsearch-cdm-ba9c6evk-1-796f6cfdbc --replicas<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p>Afther the pod is recreated test the variable in the pods:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc get pods -l component<span style="color:#f92672">=</span>elasticsearch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc  set env -c elasticsearch pods -l component<span style="color:#f92672">=</span>elasticsearch --list | grep ES_JAVA_OPTS
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc exec -c elasticsearch elasticsearch-cdm-ba9c6evk-1-796f6cfdbc-4dqc6 -- grep -a log4j2.formatMsgNoLookups /proc/1/cmdline
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Opeshift elasticsearch search-guard error]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-elasticsearch-error/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-log4shell/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-ansible-service-broker-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix Ansible Service Broker in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-cluster-monitoring-operator-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix cluster-monitoring-operator in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-registry-console-ui-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix registry console UI in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/openshift-cert-manager/?utm_source=atom_feed" rel="related" type="text/html" title="Install cert-manager to Openshift" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-elasticsearch-error/</id>
            
            
            <published>2021-12-15T00:00:00+00:00</published>
            <updated>2021-12-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show You How you can fix elasticsearch search-guard index error.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<p>If you get the following error:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>2021-12-15 09:10:17,949<span style="color:#f92672">][</span>INFO <span style="color:#f92672">][</span>container.run            <span style="color:#f92672">]</span> Seeding the searchguard ACL index.  Will wait up to <span style="color:#ae81ff">604800</span> seconds.
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>2021-12-15 09:10:18,027<span style="color:#f92672">][</span>INFO <span style="color:#f92672">][</span>container.run            <span style="color:#f92672">]</span> Seeding the searchguard ACL index.  Will wait up to <span style="color:#ae81ff">604800</span> seconds.
</span></span><span style="display:flex;"><span>/etc/elasticsearch ~
</span></span><span style="display:flex;"><span>Search Guard Admin v5
</span></span><span style="display:flex;"><span>Will connect to localhost:9300 ... <span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>ERROR StatusLogger No Log4j <span style="color:#ae81ff">2</span> configuration file found. Using default configuration <span style="color:#f92672">(</span>logging only errors to the console<span style="color:#f92672">)</span>, or user programmatically provided configurations. Set system property <span style="color:#e6db74">&#39;log4j2.debug&#39;</span> to show Log4j <span style="color:#ae81ff">2</span> internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html <span style="color:#66d9ef">for</span> instructions on how to configure Log4j <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>Elasticsearch Version: 5.6.13
</span></span><span style="display:flex;"><span>Search Guard Version: &lt;unknown&gt;
</span></span><span style="display:flex;"><span>Contacting elasticsearch cluster <span style="color:#e6db74">&#39;elasticsearch&#39;</span> ...
</span></span><span style="display:flex;"><span>Clustername: logging-es
</span></span><span style="display:flex;"><span>Clusterstate: RED
</span></span><span style="display:flex;"><span>Number of nodes: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>Number of data nodes: <span style="color:#ae81ff">1</span>
</span></span></code></pre></div><p>Try to rerun the inicialization script:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc get pods -l component<span style="color:#f92672">=</span>es
</span></span><span style="display:flex;"><span>NAME                                      READY     STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>logging-es-data-master-9fgtlhi4-3-d48rs   2/2       Running   <span style="color:#ae81ff">0</span>          21m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc exec -c elasticsearch logging-es-data-master-9fgtlhi4-3-d48rs -- es_seed_acl
</span></span></code></pre></div><p>If you get the same log we need to delete the searchguard index and reinicilaize:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc exec -c elasticearch logging-es-data-master-9fgtlhi4-3-d48rs --es_util --query<span style="color:#f92672">=</span>.searchguard -XDELETE
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;acknowledged&#34;</span>:true<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc exec -c elasticsearch logging-es-data-master-9fgtlhi4-3-d48rs -- es_seed_acl
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>2021-12-15 09:15:47,762<span style="color:#f92672">][</span>INFO <span style="color:#f92672">][</span>container.run            <span style="color:#f92672">]</span> Seeding the searchguard ACL index.  Will wait up to <span style="color:#ae81ff">604800</span> seconds.
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>2021-12-15 09:15:47,931<span style="color:#f92672">][</span>INFO <span style="color:#f92672">][</span>container.run            <span style="color:#f92672">]</span> Seeding the searchguard ACL index.  Will wait up to <span style="color:#ae81ff">604800</span> seconds.
</span></span><span style="display:flex;"><span>/etc/elasticsearch ~
</span></span><span style="display:flex;"><span>Search Guard Admin v5
</span></span><span style="display:flex;"><span>Will connect to localhost:9300 ... <span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>ERROR StatusLogger No Log4j <span style="color:#ae81ff">2</span> configuration file found. Using default configuration <span style="color:#f92672">(</span>logging only errors to the console<span style="color:#f92672">)</span>, or user programmatically provided configurations. Set system property <span style="color:#e6db74">&#39;log4j2.debug&#39;</span> to show Log4j <span style="color:#ae81ff">2</span> internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html <span style="color:#66d9ef">for</span> instructions on how to configure Log4j <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>Elasticsearch Version: 5.6.16
</span></span><span style="display:flex;"><span>Search Guard Version: &lt;unknown&gt;
</span></span><span style="display:flex;"><span>Contacting elasticsearch cluster <span style="color:#e6db74">&#39;elasticsearch&#39;</span> ...
</span></span><span style="display:flex;"><span>Clustername: logging-es
</span></span><span style="display:flex;"><span>Clusterstate: RED
</span></span><span style="display:flex;"><span>Number of nodes: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>Number of data nodes: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>.searchguard index does not exists, attempt to create it ...
</span></span><span style="display:flex;"><span>Populate config from /opt/app-root/src/sgconfig/
</span></span><span style="display:flex;"><span>Will update <span style="color:#e6db74">&#39;config&#39;</span> with /opt/app-root/src/sgconfig/sg_config.yml
</span></span><span style="display:flex;"><span>   SUCC: Configuration <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#39;config&#39;</span> created or updated
</span></span><span style="display:flex;"><span>Will update <span style="color:#e6db74">&#39;roles&#39;</span> with /opt/app-root/src/sgconfig/sg_roles.yml
</span></span><span style="display:flex;"><span>   SUCC: Configuration <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#39;roles&#39;</span> created or updated
</span></span><span style="display:flex;"><span>Will update <span style="color:#e6db74">&#39;rolesmapping&#39;</span> with /opt/app-root/src/sgconfig/sg_roles_mapping.yml
</span></span><span style="display:flex;"><span>   SUCC: Configuration <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#39;rolesmapping&#39;</span> created or updated
</span></span><span style="display:flex;"><span>Will update <span style="color:#e6db74">&#39;internalusers&#39;</span> with /opt/app-root/src/sgconfig/sg_internal_users.yml
</span></span><span style="display:flex;"><span>   SUCC: Configuration <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#39;internalusers&#39;</span> created or updated
</span></span><span style="display:flex;"><span>Will update <span style="color:#e6db74">&#39;actiongroups&#39;</span> with /opt/app-root/src/sgconfig/sg_action_groups.yml
</span></span><span style="display:flex;"><span>   SUCC: Configuration <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#39;actiongroups&#39;</span> created or updated
</span></span><span style="display:flex;"><span>Done with success
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Configure OKD OpenShift 4 authentication]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-auth/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift4-ceph-rbd-csi/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 Ceph Persisten Storage" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 ingress" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-install/?utm_source=atom_feed" rel="related" type="text/html" title="How To Install OKD OpenShift 4 on premise" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-logging/?utm_source=atom_feed" rel="related" type="text/html" title="Install Cluster Logging Operator on OpenShift 4" />
                <link href="https://devopstales.github.io/kubernetes/openshift_4/?utm_source=atom_feed" rel="related" type="text/html" title="OpenShift 4.2 with Red Hat CodeReady Containers" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-auth/</id>
            
            
            <published>2021-12-13T00:00:00+00:00</published>
            <updated>2021-12-13T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you can create multiple ingress route on an OpenShift 4 on premise.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<h3 id="create-a-cluster-admin-user">Create a Cluster Admin User</h3>
<p>The current kubeadmin user that we are using in the previous step is temporary. We need to create a permanent cluster administrator user. The fastest way to do this is by using htpasswd as an authentication provider. We will create a secret under the openshift-config namespace and add a htpasswd provider in the cluster oAuth.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>htpasswd -c -B -b users.htpasswd adminuser adminpassword
</span></span><span style="display:flex;"><span>htpasswd -c -B -b users.htpasswd testuser testpassword
</span></span><span style="display:flex;"><span>oc create secret generic htpass-secret --from-file<span style="color:#f92672">=</span>htpasswd<span style="color:#f92672">=</span>users.htpasswd -n <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>openshift-config
</span></span><span style="display:flex;"><span>oc apply -f htpasswd_provider.yaml
</span></span></code></pre></div><p>You can create groups to the cluster:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano groups.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">user.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">admins</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">users</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">adminuser</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">user.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-admins</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">users</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">adminuser</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">user.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">developers</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">users</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">testuser</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">okd-admins</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">admins</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">admin</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">okd-cluster-admin</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-admins</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-admin</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">okd-cluster-developers</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">developers</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">basic-user</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc apply -f group-admins.yaml
</span></span></code></pre></div><h3 id="enable-oauth-on-okd-cluster">Enable Oauth On OKD Cluster</h3>
<p>I will use Keycloak as the oauth prowider. In Keycloak <code>okd</code> realm I created a client called <code>okd4</code>. The <code>openid-client-secret</code> is the base64 encodid secret for the <code>okd4</code> Client ID.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano oauth-config.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">openid-client-secret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">clientSecret</span>: <span style="color:#ae81ff">OWI4OWUyZjgtYrM6ZC10ODU2LTgyN3YtN2ZiODUzNDUyZDc4</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">type</span>: <span style="color:#ae81ff">Opaque</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">config.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">OAuth</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">identityProviders</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mappingMethod</span>: <span style="color:#ae81ff">add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">sso.mydomain.intra</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">openID</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">claims</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">email</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">email</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">name</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">name</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">preferredUsername</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">email</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">preferred_username</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">clientID</span>: <span style="color:#ae81ff">okd4</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">clientSecret</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">name</span>: <span style="color:#ae81ff">openid-client-secret</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">extraScopes</span>: []
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">issuer</span>: <span style="color:#e6db74">&#39;https://sso.mydomain.intra/auth/realms/okd&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">OpenID</span>
</span></span></code></pre></div><p>Then apply the config <code>oc apply -f oauth-config.yaml</code></p>
<h3 id="fix-x509-certificate-signed-by-unknown-authority">Fix: x509: certificate signed by unknown authority</h3>
<p>If you get the fallowing error: The authentication operator can&rsquo;t honor OAuth configuration due to an <code>x509: certificate signed by unknown authority</code> error</p>
<p>Check the <code>openshift-authentication-operator</code> pod log:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc -n openshift-authentication-operator logs <span style="color:#66d9ef">$(</span>oc -n openshift-authentication-operator get pods -l app<span style="color:#f92672">=</span>authentication-operator -o<span style="color:#f92672">=</span>custom-columns<span style="color:#f92672">=</span>NAME:.metadata.name --no-headers<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>...<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>E1125 15:31:27.093873       <span style="color:#ae81ff">1</span> oauth.go:69<span style="color:#f92672">]</span> failed to honor IDP v1.IdentityProvider<span style="color:#f92672">{</span>Name:<span style="color:#e6db74">&#34;sso&#34;</span>, MappingMethod:<span style="color:#e6db74">&#34;claim&#34;</span>, IdentityProviderConfig:v1.IdentityProviderConfig<span style="color:#f92672">{</span>Type:<span style="color:#e6db74">&#34;OpenID&#34;</span>, BasicAuth:<span style="color:#f92672">(</span>*v1.BasicAuthIdentityProvider<span style="color:#f92672">)(</span>nil<span style="color:#f92672">)</span>, GitHub:<span style="color:#f92672">(</span>*v1.GitHubIdentityProvider<span style="color:#f92672">)(</span>nil<span style="color:#f92672">)</span>, GitLab:<span style="color:#f92672">(</span>*v1.GitLabIdentityProvider<span style="color:#f92672">)(</span>nil<span style="color:#f92672">)</span>, Google:<span style="color:#f92672">(</span>*v1.GoogleIdentityProvider<span style="color:#f92672">)(</span>nil<span style="color:#f92672">)</span>, HTPasswd:<span style="color:#f92672">(</span>*v1.HTPasswdIdentityProvider<span style="color:#f92672">)(</span>nil<span style="color:#f92672">)</span>, Keystone:<span style="color:#f92672">(</span>*v1.KeystoneIdentityProvider<span style="color:#f92672">)(</span>nil<span style="color:#f92672">)</span>, LDAP:<span style="color:#f92672">(</span>*v1.LDAPIdentityProvider<span style="color:#f92672">)(</span>nil<span style="color:#f92672">)</span>, OpenID:<span style="color:#f92672">(</span>*v1.OpenIDIdentityProvider<span style="color:#f92672">)(</span>0xc010181ef0<span style="color:#f92672">)</span>, RequestHeader:<span style="color:#f92672">(</span>*v1.RequestHeaderIdentityProvider<span style="color:#f92672">)(</span>nil<span style="color:#f92672">)}}</span>: x509: certificate signed by unknown authority
</span></span><span style="display:flex;"><span>I1125 15:31:28.369400       <span style="color:#ae81ff">1</span> status_controller.go:165<span style="color:#f92672">]</span> clusteroperator/authentication diff <span style="color:#f92672">{</span><span style="color:#e6db74">&#34;status&#34;</span>:<span style="color:#f92672">{</span><span style="color:#e6db74">&#34;conditions&#34;</span>:<span style="color:#f92672">[{</span><span style="color:#e6db74">&#34;lastTransitionTime&#34;</span>:<span style="color:#e6db74">&#34;2019-11-20T10:17:18Z&#34;</span>,<span style="color:#e6db74">&#34;message&#34;</span>:<span style="color:#e6db74">&#34;IdentityProviderConfigDegraded: failed to apply IDP sso config: x509: certificate signed by unknown authority&#34;</span>,<span style="color:#e6db74">&#34;reason&#34;</span>:<span style="color:#e6db74">&#34;AsExpected&#34;</span>,<span style="color:#e6db74">&#34;status&#34;</span>:<span style="color:#e6db74">&#34;False&#34;</span>,<span style="color:#e6db74">&#34;type&#34;</span>:<span style="color:#e6db74">&#34;Degraded&#34;</span><span style="color:#f92672">}</span>,<span style="color:#f92672">{</span><span style="color:#e6db74">&#34;lastTransitionTime&#34;</span>:<span style="color:#e6db74">&#34;2019-11-22T11:41:09Z&#34;</span>,<span style="color:#e6db74">&#34;reason&#34;</span>:<span style="color:#e6db74">&#34;AsExpected&#34;</span>,<span style="color:#e6db74">&#34;status&#34;</span>:<span style="color:#e6db74">&#34;False&#34;</span>,<span style="color:#e6db74">&#34;type&#34;</span>:<span style="color:#e6db74">&#34;Progressing&#34;</span><span style="color:#f92672">}</span>,<span style="color:#f92672">{</span><span style="color:#e6db74">&#34;lastTransitionTime&#34;</span>:<span style="color:#e6db74">&#34;2019-10-26T16:15:59Z&#34;</span>,<span style="color:#e6db74">&#34;reason&#34;</span>:<span style="color:#e6db74">&#34;AsExpected&#34;</span>,<span style="color:#e6db74">&#34;status&#34;</span>:<span style="color:#e6db74">&#34;True&#34;</span>,<span style="color:#e6db74">&#34;type&#34;</span>:<span style="color:#e6db74">&#34;Available&#34;</span><span style="color:#f92672">}</span>,<span style="color:#f92672">{</span><span style="color:#e6db74">&#34;lastTransitionTime&#34;</span>:<span style="color:#e6db74">&#34;2019-10-26T13:30:53Z&#34;</span>,<span style="color:#e6db74">&#34;reason&#34;</span>:<span style="color:#e6db74">&#34;AsExpected&#34;</span>,<span style="color:#e6db74">&#34;status&#34;</span>:<span style="color:#e6db74">&#34;True&#34;</span>,<span style="color:#e6db74">&#34;type&#34;</span>:<span style="color:#e6db74">&#34;Upgradeable&#34;</span><span style="color:#f92672">}]}}</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano oauth-config.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">config.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">OAuth</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">identityProviders</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mappingMethod</span>: <span style="color:#ae81ff">add</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">sso.mydomain.intra</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">openID</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ca</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">name</span>: <span style="color:#ae81ff">sso-ca-config-map</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ca.crt</span>: |+<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    -----BEGIN CERTIFICATE-----
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    MIIEFTCCAv2gAwIBAgIGSUEs...
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    -----END CERTIFICATE-----</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">sso-ca-config-map</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-config</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Configure OKD OpenShift 4 Ceph Persisten Storage]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-ceph-rbd-csi/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift4-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 authentication" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 ingress" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-install/?utm_source=atom_feed" rel="related" type="text/html" title="How To Install OKD OpenShift 4 on premise" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-logging/?utm_source=atom_feed" rel="related" type="text/html" title="Install Cluster Logging Operator on OpenShift 4" />
                <link href="https://devopstales.github.io/kubernetes/openshift_4/?utm_source=atom_feed" rel="related" type="text/html" title="OpenShift 4.2 with Red Hat CodeReady Containers" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-ceph-rbd-csi/</id>
            
            
            <published>2021-12-13T00:00:00+00:00</published>
            <updated>2021-12-13T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you can create peristent storage on an OpenShift 4 with Ceph RBD CSI Driver.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<table>
  <thead>
      <tr>
          <th style="text-align: center">Host</th>
          <th style="text-align: center">ROLES</th>
          <th style="text-align: center">OS</th>
          <th style="text-align: center">IP</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">okd4-ceph1</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">CentOS 7</td>
          <td style="text-align: center">192.168.1.221</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-ceph2</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">CentOS 7</td>
          <td style="text-align: center">192.168.1.222</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-ceph3</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">CentOS 7</td>
          <td style="text-align: center">192.168.1.223</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-ceph4</td>
          <td style="text-align: center">OSD</td>
          <td style="text-align: center">CentOS 7</td>
          <td style="text-align: center">192.168.1.224</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-ceph5</td>
          <td style="text-align: center">OSD</td>
          <td style="text-align: center">CentOS 7</td>
          <td style="text-align: center">192.168.1.225</td>
      </tr>
  </tbody>
</table>
<p>First we need a priject where we will install the Ceph Driver:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc adm new-project ceph-csi-rbd
</span></span><span style="display:flex;"><span>oc project ceph-csi-rbd
</span></span></code></pre></div><p>We need the cluster id from the ceph cluster so get it from the ceph cluster</p>
<pre tabindex="0"><code>ceph -s
  cluster:
    id:     f8b13ea1-2s52-4fe8-bd67-e7ddf259122b
    health: HEALTH_OK

  services:
    mon: 3 daemons, quorum okd4-ceph1,okd4-ceph2,okd4-ceph3
    mgr: okd4-ceph3(active), standbys: okd4-ceph2, okd4-ceph1
    mds: cephfs-1/1/1 up  {0=okd4-ceph4=up:active}, 3 up:standby
    osd: 8 osds: 8 up, 8 in
    rgw: 4 daemons active

  data:
    pools:   14 pools, 664 pgs
    objects: 1.72M objects, 6.26TiB
    usage:   16.7TiB used, 26.9TiB / 43.7TiB avail
    pgs:     663 active+clean
             1   active+clean+scrubbing+deep

  io:
    client:   253B/s rd, 2.04MiB/s wr, 0op/s rd, 49op/s wr
</code></pre><p>With the cluster id we can create the value file for the helm chart:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano values.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">csiConfig</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">clusterID</span>: <span style="color:#e6db74">&#34;f8b13ea1-2s52-4fe8-bd67-e7ddf259122b&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">monitors</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;192.168.1.221:6789&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;192.168.1.222:6789&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;192.168.1.223:6789&#34;</span>
</span></span></code></pre></div><p>Create the <code>SecurityContextConstraints</code> fot the <code>ceph-csi-rbd-provisioner</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano provisioner-scc.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">security.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">SecurityContextConstraints</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes.io/description</span>: <span style="color:#ae81ff">ceph-csi-rbd-provisioner scc is used for ceph-csi-rbd-provisioner</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ceph-csi-rbd-provisioner</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">allowHostDirVolumePlugin</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">allowHostIPC</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">allowHostNetwork</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">allowHostPID</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">allowHostPorts</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">allowPrivilegeEscalation</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">allowPrivilegedContainer</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">allowedCapabilities</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#39;SYS_ADMIN&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">priority</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">readOnlyRootFilesystem</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">requiredDropCapabilities</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">defaultAddCapabilities</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">runAsUser</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">RunAsAny</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">seLinuxContext</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">RunAsAny</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">fsGroup</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">RunAsAny</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">supplementalGroups</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">RunAsAny</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#39;configMap&#39;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#39;emptyDir&#39;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#39;projected&#39;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#39;secret&#39;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#39;downwardAPI&#39;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#39;hostPath&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">users</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">system:serviceaccount:ceph-csi-rbd:ceph-csi-rbd-provisioner</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">groups</span>: []
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc apply -f provisioner-scc.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm repo add ceph-csi https://ceph.github.io/csi-charts 
</span></span><span style="display:flex;"><span>helm install --namespace <span style="color:#e6db74">&#34;ceph-csi-rbd&#34;</span> <span style="color:#e6db74">&#34;ceph-csi-rbd&#34;</span> ceph-csi/ceph-csi-rbd -f values.yaml
</span></span></code></pre></div><p>Now we need to configure the athentication for the ceph cluster. First get the ceph cluster admin userKey:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;admin&#34;</span> | base64
</span></span><span style="display:flex;"><span>YWRtaW4K
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ceph auth get-key client.admin|base64
</span></span><span style="display:flex;"><span>QVFDTDliVmNEb21I32SHoPxXNGhmRkczTFNtcXM0ZW5VaXlTZEE977<span style="color:#f92672">==</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano secret.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">csi-rbd-secret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">userID</span>: <span style="color:#ae81ff">YWRtaW4=</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">userKey</span>: <span style="color:#ae81ff">QVFDTDliVmNEb21I32SHoPxXNGhmRkczTFNtcXM0ZW5VaXlTZEE977==</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">type</span>: <span style="color:#ae81ff">Opaque</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano okd4-pool.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">storage.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">StorageClass</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">csi-rbd-sc</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">storageclass.kubernetes.io/is-default-class</span>: <span style="color:#e6db74">&#39;true&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">provisioner</span>: <span style="color:#ae81ff">rbd.csi.ceph.com</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">parameters</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">pool</span>: <span style="color:#ae81ff">okd4-pool</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">clusterID</span>: <span style="color:#ae81ff">f8b13ea1-2s52-4fe8-bd67-e7ddf259122b</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumeNamePrefix</span>: <span style="color:#ae81ff">okd4-vol-</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">imageFeatures</span>: <span style="color:#ae81ff">layering</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/fstype</span>: <span style="color:#ae81ff">ext4</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/provisioner-secret-namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/provisioner-secret-name</span>: <span style="color:#ae81ff">csi-rbd-secret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/node-stage-secret-namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/node-stage-secret-name</span>: <span style="color:#ae81ff">csi-rbd-secret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/controller-expand-secret-namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">csi.storage.k8s.io/controller-expand-secret-name</span>: <span style="color:#ae81ff">csi-rbd-secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">volumeBindingMode</span>: <span style="color:#ae81ff">Immediate</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">reclaimPolicy</span>: <span style="color:#ae81ff">Delete</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">allowVolumeExpansion</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">mountOptions</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">discard</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc apply -f secret.yaml
</span></span><span style="display:flex;"><span>oc apply -f okd4-pool.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano raw-block-pvc.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PersistentVolumeClaim</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">raw-block-pvc</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">accessModes</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">ReadWriteOnce</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumeMode</span>: <span style="color:#ae81ff">Block</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">50Mi</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">storageClassName</span>: <span style="color:#ae81ff">csi-rbd-sc</span>
</span></span></code></pre></div><p>The test with a pvc <code>oc apply raw-block-pvc.yaml</code></p>
<h3 id="configuring-registry-storage">Configuring registry storage</h3>
<p>Edit the imageregistry-operator:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;managementState&#34;:&#34;Managed&#34;}}&#39;</span>
</span></span><span style="display:flex;"><span>oc edit configs.imageregistry.operator.openshift.io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># from</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  storage: <span style="color:#f92672">{}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># to</span>
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  storage:
</span></span><span style="display:flex;"><span>    pvc:
</span></span><span style="display:flex;"><span>      claim:
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc get pod -n openshift-image-registry
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                                               READY     STATUS    RESTARTS      AGE
</span></span><span style="display:flex;"><span>cluster-image-registry-operator-5897c9d897-46rg8   1/1       Running   <span style="color:#ae81ff">1</span> <span style="color:#f92672">(</span>12h ago<span style="color:#f92672">)</span>   33h
</span></span><span style="display:flex;"><span>image-registry-7467dd65f9-vhnvx                    1/1       Pending   <span style="color:#ae81ff">0</span>             5m
</span></span><span style="display:flex;"><span>node-ca-6q6bh                                      1/1       Running   <span style="color:#ae81ff">2</span>             9d
</span></span><span style="display:flex;"><span>node-ca-7hphd                                      1/1       Running   <span style="color:#ae81ff">2</span>             9d
</span></span><span style="display:flex;"><span>node-ca-cbt2x                                      1/1       Running   <span style="color:#ae81ff">2</span>             9d
</span></span><span style="display:flex;"><span>node-ca-cfqf5                                      1/1       Running   <span style="color:#ae81ff">2</span>             9d
</span></span><span style="display:flex;"><span>node-ca-gk5ps                                      1/1       Running   <span style="color:#ae81ff">2</span>             9d
</span></span><span style="display:flex;"><span>node-ca-r5jnx                                      1/1       Running   <span style="color:#ae81ff">2</span>             9d
</span></span></code></pre></div><h3 id="enable-the-image-registry-default-route">Enable the Image Registry default route</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc patch configs.imageregistry.operator.openshift.io/cluster --type merge -p <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;defaultRoute&#34;:true}}&#39;</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Configure OKD OpenShift 4 ingress]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-ingress/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift4-ceph-rbd-csi/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 Ceph Persisten Storage" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 authentication" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-install/?utm_source=atom_feed" rel="related" type="text/html" title="How To Install OKD OpenShift 4 on premise" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-logging/?utm_source=atom_feed" rel="related" type="text/html" title="Install Cluster Logging Operator on OpenShift 4" />
                <link href="https://devopstales.github.io/kubernetes/openshift_4/?utm_source=atom_feed" rel="related" type="text/html" title="OpenShift 4.2 with Red Hat CodeReady Containers" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-ingress/</id>
            
            
            <published>2021-12-13T00:00:00+00:00</published>
            <updated>2021-12-13T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you can create multiple ingress route on an OpenShift 4 on premise.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<h3 id="what-is-ingress-operator">What is Ingress Operator</h3>
<p>Ingress Operator is an OpenShift component which enables external access to cluster services by configuring Ingress Controllers, which route traffic as specified by OpenShift Route and Kubernetes Ingress resources.</p>
<p>To provide this functionality, Ingress Operator deploys and manages an OpenShift router — a HAProxy-based Kubernetes ingress controller.</p>
<h3 id="add-default-certificate-for-ingress-operator">Add default certificate for Ingress Operator</h3>
<p>Create the secret containing the certificate:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat tls.crt | base64
</span></span><span style="display:flex;"><span>LS0tLS1CRUdJTiBDRVJUSUZ...
</span></span><span style="display:flex;"><span>cat tls.key | base64
</span></span><span style="display:flex;"><span>LS0tLS1CRUdJTiBQUklWQVR...
</span></span></code></pre></div><blockquote>
<p>Always use the full certificate chain for thi ingress secret</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano cert.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default-tls-cert</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls.crt</span>: <span style="color:#ae81ff">LS0tLS1CRUdJTiBDRVJUSUZ...</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls.key</span>: <span style="color:#ae81ff">LS0tLS1CRUdJTiBQUklWQVR...</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">type</span>: <span style="color:#ae81ff">Opaque</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default-tls-cert</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls.crt</span>: <span style="color:#ae81ff">LS0tLS1CRUdJTiBDRVJUSUZ...</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls.key</span>: <span style="color:#ae81ff">LS0tLS1CRUdJTiBQUklWQVR...</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">type</span>: <span style="color:#ae81ff">Opaque</span>
</span></span></code></pre></div><h3 id="create-multiple-ingress-route">Create multiple ingress route</h3>
<p>For the example I will create a private and a public rout for the cluster</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano default.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operator.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">IngressController</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-ingress-operator</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">defaultCertificate</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default-tls-cert</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nodePlacement</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nodeSelector</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">node-role.kubernetes.io/ingress-internal</span>: <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano public.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operator.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">IngressController</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">public</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-ingress-operator</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">defaultCertificate</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default-tls-cert</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">domain</span>: <span style="color:#ae81ff">external.okd.mydomain.intra</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nodePlacement</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nodeSelector</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">node-role.kubernetes.io/ingress-public</span>: <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">routeSelector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">router</span>: <span style="color:#ae81ff">public</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc label nodes okd4-worker-1 node-role.kubernetes.io/ingress-internal<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>oc label nodes okd4-worker-2 node-role.kubernetes.io/ingress-internal<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>oc label nodes okd4-worker-3 node-role.kubernetes.io/ingress-public<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>oc label nodes okd4-worker-4 node-role.kubernetes.io/ingress-public<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc apply -f cert.yaml
</span></span><span style="display:flex;"><span>oc apply -f ingress/
</span></span><span style="display:flex;"><span>oc patch ingresscontroller.operator default --type<span style="color:#f92672">=</span>merge -p <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;defaultCertificate&#34;: {&#34;name&#34;: &#34;default-tls-cert&#34;}}}&#39;</span> -n openshift-ingress-operator
</span></span><span style="display:flex;"><span>oc patch consoles.operator.openshift.io cluster --type<span style="color:#f92672">=</span>merge -p <span style="color:#e6db74">&#39;{&#34;spec&#34;:{&#34;route&#34;:{&#34;secret&#34;:{&#34;name&#34;: &#34;default-tls-cert&#34;}}}}&#39;</span> -n openshift-config
</span></span></code></pre></div><h3 id="enable-http2">enable HTTP/2</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc annotate ingresses.config/cluster ingress.operator.openshift.io/default-enable-http2<span style="color:#f92672">=</span>true
</span></span></code></pre></div><h3 id="add-okd-311-type-conole-url">Add OKD 3.11 type conole url</h3>
<p>I used OKD 3.11 and ther the conosle usrl wa master.okd.mydomain.intra so I desided to create the same route for okd4:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano master-okf-mydomain-intra.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Route</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">route.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">master-okd-mydomain-intra</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-console</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">console</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">host</span>: <span style="color:#ae81ff">master.okd.mydomain.intra</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">to</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">console</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">port</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">https</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">termination</span>: <span style="color:#ae81ff">reencrypt</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">insecureEdgeTerminationPolicy</span>: <span style="color:#ae81ff">Redirect</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">wildcardPolicy</span>: <span style="color:#ae81ff">None</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How To Install OKD OpenShift 4 on premise]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-install/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift4-ceph-rbd-csi/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 Ceph Persisten Storage" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 authentication" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Configure OKD OpenShift 4 ingress" />
                <link href="https://devopstales.github.io/kubernetes/openshift4-logging/?utm_source=atom_feed" rel="related" type="text/html" title="Install Cluster Logging Operator on OpenShift 4" />
                <link href="https://devopstales.github.io/kubernetes/openshift_4/?utm_source=atom_feed" rel="related" type="text/html" title="OpenShift 4.2 with Red Hat CodeReady Containers" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-install/</id>
            
            
            <published>2021-12-13T00:00:00+00:00</published>
            <updated>2021-12-13T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you can install the an OpenShift 4 on premise.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<h3 id="infrastructure">Infrastructure</h3>
<table>
  <thead>
      <tr>
          <th style="text-align: center">Host</th>
          <th style="text-align: center">ROLES</th>
          <th style="text-align: center">OS</th>
          <th style="text-align: center">IP</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">pfsense</td>
          <td style="text-align: center">Load Balancer, dhcp, dns</td>
          <td style="text-align: center">pfsense</td>
          <td style="text-align: center">192.168.1.1</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-services</td>
          <td style="text-align: center">pxeboot</td>
          <td style="text-align: center">CentOS 7</td>
          <td style="text-align: center">192.168.1.200</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-bootstrap</td>
          <td style="text-align: center">bootstrap</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.210</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-mastr-1</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.201</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-mastr-2</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.202</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-mastr-3</td>
          <td style="text-align: center">master</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.203</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-1</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.204</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-2</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.205</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-4</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.206</td>
      </tr>
      <tr>
          <td style="text-align: center">okd4-worker-5</td>
          <td style="text-align: center">worker</td>
          <td style="text-align: center">Fedora Core OS</td>
          <td style="text-align: center">192.168.1.207</td>
      </tr>
  </tbody>
</table>
<h3 id="dns-config">DNS Config</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>; OpenShift Container Platform Cluster - A records
</span></span><span style="display:flex;"><span>pfsense.okd.mydomain.intra.          IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>okd4-bootstrap.okd.mydomain.intra.   IN      A      192.168.1.210
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>okd4-mastr-1.okd.mydomain.intra.        IN      A      192.168.1.201
</span></span><span style="display:flex;"><span>okd4-mastr-2.okd.mydomain.intra.        IN      A      192.168.1.202
</span></span><span style="display:flex;"><span>okd4-mastr-3.okd.mydomain.intra.        IN      A      192.168.1.203
</span></span><span style="display:flex;"><span>okd4-worker-1.okd.mydomain.intra.        IN      A      192.168.1.204
</span></span><span style="display:flex;"><span>okd4-worker-2.okd.mydomain.intra.        IN      A      192.168.1.205
</span></span><span style="display:flex;"><span>okd4-worker-3.okd.mydomain.intra.        IN      A      192.168.1.206
</span></span><span style="display:flex;"><span>okd4-worker-4.okd.mydomain.intra.        IN      A      192.168.1.207
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>; OpenShift internal cluster IPs - A records
</span></span><span style="display:flex;"><span>api.okd.mydomain.intra.            IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>api-int.okd.mydomain.intra.        IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>etcd-0.okd.mydomain.intra.         IN      A     192.168.1.201
</span></span><span style="display:flex;"><span>etcd-1.okd.mydomain.intra.         IN      A     192.168.1.202
</span></span><span style="display:flex;"><span>etcd-2.okd.mydomain.intra.         IN      A     192.168.1.203
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>okd.mydomain.intra.                IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>*.okd.mydomain.intra.              IN      A      192.168.1.1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>; OpenShift internal cluster IPs - SRV records
</span></span><span style="display:flex;"><span>_etcd-server-ssl._tcp.okd.mydomain.intra.    <span style="color:#ae81ff">86400</span>     IN    SRV     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">10</span>    <span style="color:#ae81ff">2380</span>    etcd-0.okd.mydomain.intra.
</span></span><span style="display:flex;"><span>_etcd-server-ssl._tcp.okd.mydomain.intra.    <span style="color:#ae81ff">86400</span>     IN    SRV     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">10</span>    <span style="color:#ae81ff">2380</span>    etcd-1.okd.mydomain.intra.
</span></span><span style="display:flex;"><span>_etcd-server-ssl._tcp.okd.mydomain.intra.    <span style="color:#ae81ff">86400</span>     IN    SRV     <span style="color:#ae81ff">0</span>    <span style="color:#ae81ff">10</span>    <span style="color:#ae81ff">2380</span>    etcd-2.okd.mydomain.intra.
</span></span></code></pre></div><h3 id="dhcp-config">DHCP Config:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>32:89:07:57:27:00  192.168.1.200 	okd4-services
</span></span><span style="display:flex;"><span>32:89:07:57:27:10  192.168.1.210 	okd4-bootstrap
</span></span><span style="display:flex;"><span>32:89:07:57:27:01  192.168.1.201 	okd4-mastr-1
</span></span><span style="display:flex;"><span>32:89:07:57:27:02  192.168.1.202 	okd4-mastr-2
</span></span><span style="display:flex;"><span>32:89:07:57:27:03  192.168.1.203 	okd4-mastr-3
</span></span><span style="display:flex;"><span>32:89:07:57:27:04  192.168.1.204 	okd4-worker-1
</span></span><span style="display:flex;"><span>32:89:07:57:27:05  192.168.1.205 	okd4-worker-2
</span></span><span style="display:flex;"><span>32:89:07:57:27:06  192.168.1.206 	okd4-worker-3
</span></span><span style="display:flex;"><span>32:89:07:57:27:07  192.168.1.207 	okd4-worker-4
</span></span></code></pre></div><p>PXE Bootserver Config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Next Server: 192.168.1.200
</span></span><span style="display:flex;"><span>Default BIOS file name: pxelinux.0
</span></span></code></pre></div><h2 id="haproxy-config">HAPROXY Config:</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.210   <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.201  <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.202  <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">6443</span>  --&gt;  192.168.1.202  <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.210   <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.201  <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.202  <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">22623</span> --&gt;  192.168.1.202  <span style="color:#ae81ff">22623</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.204  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.205  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.204  <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>192.168.201.1 <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.205  <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.206  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">80</span>    --&gt;  192.168.1.207  <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.206  <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>&lt;publicip&gt; <span style="color:#ae81ff">443</span>   --&gt;  192.168.1.207  <span style="color:#ae81ff">443</span>
</span></span></code></pre></div><h3 id="install-and-configure-pxeboot">Install and configure pxeboot</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh okd4-services
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install epel-release -y
</span></span><span style="display:flex;"><span>yum install httpd nano jq -y
</span></span><span style="display:flex;"><span>dnf install -y tftp-server syslinux-tftpboot
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p /var/lib/tftpboot
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/menu.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/mboot.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/chain.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/ldlinux.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>cp -v /usr/share/syslinux/libutil.c32 /var/lib/tftpboot/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p /var/lib/tftpboot/fcsos33
</span></span><span style="display:flex;"><span>cd /var/lib/tftpboot/fcsos33
</span></span><span style="display:flex;"><span>RHCOS_BASEURL<span style="color:#f92672">=</span>https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/
</span></span><span style="display:flex;"><span>wget <span style="color:#e6db74">${</span>RHCOS_BASEURL<span style="color:#e6db74">}</span>33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span><span style="display:flex;"><span>wget <span style="color:#e6db74">${</span>RHCOS_BASEURL<span style="color:#e6db74">}</span>33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img
</span></span><span style="display:flex;"><span>wget <span style="color:#e6db74">${</span>RHCOS_BASEURL<span style="color:#e6db74">}</span>33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img
</span></span><span style="display:flex;"><span>cd ~
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir /var/lib/tftpboot/pxelinux.cfg
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat &gt; /var/lib/tftpboot/pxelinux.cfg/default <span style="color:#e6db74">&lt;&lt; EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">default menu.c32
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">prompt 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">timeout 30
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu title PXE Menu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^1) Boot from local drive
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">localboot 0x00
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 2
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^2) Install OKD Bootstrap
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KERNEL /fcsos33/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">APPEND initrd=/fcsos33/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img,/fcsos33/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img coreos.inst.install_dev=/dev/vda coreos.inst.image_url=http://192.168.201.4/fcos.raw.xz coreos.inst.ignition_url=http://192.168.201.4/bootstrap.ign
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 3
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^3) Install OKD Master
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KERNEL /fcsos33/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">APPEND initrd=/fcsos33/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img,/fcsos33/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img coreos.inst.install_dev=/dev/vda coreos.inst.image_url=http://192.168.201.4/fcos.raw.xz coreos.inst.ignition_url=http://192.168.201.4/master.ign
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">label 4
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">menu label ^4) Install OKD Worker
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KERNEL /fcsos33/fedora-coreos-33.20210117.3.2-live-kernel-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">APPEND initrd=/fcsos33/fedora-coreos-33.20210117.3.2-live-initramfs.x86_64.img,/fcsos33/fedora-coreos-33.20210117.3.2-live-rootfs.x86_64.img coreos.inst.install_dev=/dev/vda coreos.inst.image_url=http://192.168.201.4/fcos.raw.xz coreos.inst.ignition_url=http://192.168.201.4/worker.ign
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>Then run: <code>systemctl enable --now tftp.service</code></p>
<h3 id="create-okd-config">Create okd config</h3>
<blockquote>
<p>find the raw image:
<a href="https://getfedora.org/en/coreos/download?tab=metal_virtualized&amp;stream=stable">https://getfedora.org/en/coreos/download?tab=metal_virtualized&amp;stream=stable</a>
4K vs non 4K
For Proxmox you need the 4K version</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz
</span></span><span style="display:flex;"><span>wget https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/33.20210117.3.2/x86_64/fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz.sig
</span></span><span style="display:flex;"><span>cp fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz /var/www/html/fcos.raw.xz
</span></span><span style="display:flex;"><span>cp fedora-coreos-33.20210117.3.2-metal.x86_64.raw.xz.sig /var/www/html/fcos.raw.xz.sig
</span></span></code></pre></div><pre tabindex="0"><code># find installer
# https://github.com/openshift/okd/releases

wget https://github.com/openshift/okd/releases/download/4.6.0-0.okd-2021-02-14-205305/openshift-client-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz
wget https://github.com/openshift/okd/releases/download/4.6.0-0.okd-2021-02-14-205305/openshift-install-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz

tar -xzf openshift-client-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz
tar -xzf openshift-install-linux-4.6.0-0.okd-2021-02-14-205305.tar.gz

sudo mv kubectl oc openshift-install /usr/local/bin/
oc version
openshift-install version

mkdir install_dir
</code></pre><p>You can obtain the image <a href="https://console.redhat.com/openshift/install/pull-secret">pull secret from the Red Hat OpenShift Cluster Manager</a>. This pull secret is called <code>pullSecret</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &gt; install_dir/install-config.yaml &lt;&lt; EOF</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">baseDomain</span>: <span style="color:#ae81ff">mydomain.intra</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">okd</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">compute</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">hyperthreading</span>: <span style="color:#ae81ff">Enabled</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">worker</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">controlPlane</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hyperthreading</span>: <span style="color:#ae81ff">Enabled</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">master</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networking</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">clusterNetwork</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">cidr</span>: <span style="color:#ae81ff">10.128.0.0</span><span style="color:#ae81ff">/14</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hostPrefix</span>: <span style="color:#ae81ff">23</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">networkType</span>: <span style="color:#ae81ff">OpenShiftSDN</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceNetwork</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">172.30.0.0</span><span style="color:#ae81ff">/16</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">platform</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">none</span>: {}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">fips</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">pullSecret</span>: <span style="color:#e6db74">&#39;{&#34;auths&#34;:{&#34;fake&#34;:{&#34;auth&#34;: &#34;bar&#34;}}}&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">sshKey</span>: <span style="color:#e6db74">&#39;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDK7lDozs9WLJD14H+nz...&#39;</span> 
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>If you are in an aire-gapped environment and you need to use a local registry mirror you can do this by adding the dollowind to the end of the install-confg:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">pullSecret</span>: <span style="color:#e6db74">&#39;{&#34;auths&#34;:{&#34;registry.mydomain.intra:18443&#34;: {&#34;auth&#34;: &#34;YWRtaW46SGFyYm9yMTIzNDU=&#34;,&#34;email&#34;: &#34;&#34;}}}&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">imageContentSources</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">mirrors</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">registry.mydomain.intra:18443/openshift/okd</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>: <span style="color:#ae81ff">quay.io/openshift/okd</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">mirrors</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">registry.mydomain.intra:18443/openshift/okd</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>: <span style="color:#ae81ff">quay.io/openshift/okd-content</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>openshift-install create manifests --dir<span style="color:#f92672">=</span>install_dir/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># remove .app from url</span>
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/apps.okd.mydomain.intra/okd.mydomain.intra/&#39;</span> install_dir/manifests/cluster-ingress-02-config.yml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># this is how to disable workload on master nodes</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#sed -i &#39;s/mastersSchedulable: true/mastersSchedulable: False/&#39; install_dir/manifests/cluster-scheduler-02-config.yml</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>openshift-install create ignition-configs --dir<span style="color:#f92672">=</span>install_dir/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo cp -R install_dir/*.ign /var/www/html/
</span></span><span style="display:flex;"><span>sudo cp -R install_dir/metadata.json /var/www/html/
</span></span><span style="display:flex;"><span>sudo chown -R apache: /var/www/html/
</span></span><span style="display:flex;"><span>sudo chmod -R <span style="color:#ae81ff">755</span> /var/www/html/
</span></span></code></pre></div><blockquote>
<p>The config contains certificates that is walid for 24 hours.</p></blockquote>
<h3 id="starting-the-vms">Starting the VMs</h3>
<p>It&rsquo;s time to start the VMs. Select the okd4-bootstrap VM and navigate to Console. Start the VM. Then one by one the masters and the workers too.</p>
<h3 id="bootstrap-okd-cluster">Bootstrap OKD Cluster</h3>
<p>You can monitor the installation progress by running the following command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>openshift-install --dir<span style="color:#f92672">=</span>install_dir/ wait-for bootstrap-complete --log-level<span style="color:#f92672">=</span>info
</span></span></code></pre></div><blockquote>
<p>The certificates in the cluster is not authomaticle approved so I use the abow <code>tmux</code> command to approve</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>tmux
</span></span><span style="display:flex;"><span>export KUBECONFIG<span style="color:#f92672">=</span>~/install_dir/auth/kubeconfig
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> true; <span style="color:#66d9ef">do</span> echo <span style="color:#e6db74">`</span>oc get csr -o go-template<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;{{range .items}}{{if not .status}}{{.metadata.name}}{{&#34;\n&#34;}}{{end}}{{end}}&#39;</span> | xargs -r oc adm certificate approve<span style="color:#e6db74">`</span>; sleep 60; <span style="color:#66d9ef">done</span>
</span></span></code></pre></div><p>Once the bootstrap process completes, you should see the following messages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>INFO It is now safe to remove the bootstrap resources
</span></span></code></pre></div><p>Then stop the bootstrap node.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># debug command to check the health of the cluster.</span>
</span></span><span style="display:flex;"><span>watch oc get csr
</span></span><span style="display:flex;"><span>watch oc get node
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>oc get clusteroperator
</span></span><span style="display:flex;"><span>oc get clusterversion
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>watch <span style="color:#e6db74">&#34;oc get clusteroperator&#34;</span>
</span></span><span style="display:flex;"><span>watch <span style="color:#e6db74">&#34;oc get po -A | grep -v Running | grep -v Completed&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -X GET https://api.okd.mydomain.intra:6443/healthz -k
</span></span></code></pre></div><p>Wait for the console to be available. Once it is available, we can point a browser to <a href="https://console-openshift-console.okd.mydomain.intra">https://console-openshift-console.okd.mydomain.intra</a></p>
<p>You will get an SSL error because the certificate is not valid for this domain. That&rsquo;s normal. Just bypass the SSL error.</p>
<p>Login with user &ldquo;kubeadmin&rdquo;.You can find the kubeadmin password in a file generated during the installation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat install_dir/auth/kubeadmin-password
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="pxe" term="pxe" label="pxe" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install Cluster Logging Operator on OpenShift 4]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift4-logging/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift_4/?utm_source=atom_feed" rel="related" type="text/html" title="OpenShift 4.2 with Red Hat CodeReady Containers" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-ansible-service-broker-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix Ansible Service Broker in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-cluster-monitoring-operator-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix cluster-monitoring-operator in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-registry-console-ui-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix registry console UI in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/openshift-cert-manager/?utm_source=atom_feed" rel="related" type="text/html" title="Install cert-manager to Openshift" />
            
                <id>https://devopstales.github.io/kubernetes/openshift4-logging/</id>
            
            
            <published>2021-12-12T00:00:00+00:00</published>
            <updated>2021-12-12T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this Post I will show you how you can install the Cluster Logging Operator on an OpenShift 4.</p>


<H3>Parts of the Openshift 4 series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/openshift4-install/">Install Opeshift 4</a></li>
     <li>Part1b: <a href="../../kubernetes/openshift4-calico/">Install Opeshift 4 with calico</a></li>
     <li>Part1c: <a href="../../kubernetes/openshift4-cilium/">Install Opeshift 4 with cilium</a></li>
     <li>Part2: <a href="../../kubernetes/openshift4-ingress/">Configure OKD OpenShift 4 ingress</a></li>
     <li>Part3: <a href="../../kubernetes/openshift4-auth/">Configure OKD OpenShift 4 authentication</a></li>
     <li>Part4: <a href="../../kubernetes/openshift4-ceph-rbd-csi/">Configure OKD OpenShift 4 Ceph Persisten Storage</a></li>
     <li>Part5: <a href="../../kubernetes/openshift4-registry/">Configuringure OKD OpenShift 4 registry for bare metal</a></li>
     <li>Part6a: <a href="../../kubernetes/openshift4-logging/">Install Cluster Logging Operator on OpenShift 4</a></li>
     <li>Part6b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
     <li>Part7: <a href="../../kubernetes/openshift4-buildconfig/">Understand OKD OpenShift 4 Buildconfig Configurations</a></li>
     <li>Part8: <a href="../../kubernetes/openshift4-tekton/">Install RadHat OpenShift pipelines (Tekton) OKD 4</a></li>
</ul>



<h3 id="redhat-pull-secret-and-enable-red-hat-operators">RedHat pull secret and enable Red Hat Operators</h3>
<p>To install the <a href="https://console.redhat.com/openshift/install/pull-secret">RedHat pull secret</a>. First download it from the url.</p>
<p>If you did&rsquo;t addid at the install create the secret kike this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano pull-secret.json</span>
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;auths&#34;: </span>{
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;registry.redhat.io&#34;: </span>{
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;username&#34;: </span><span style="color:#e6db74">&#34;redhat-user&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;password&#34;: </span><span style="color:#e6db74">&#34;redhat-user-pass&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;email&#34;: </span><span style="color:#e6db74">&#34;redhat-user-email&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;auth&#34;: </span><span style="color:#e6db74">&#34;redhat-user-auth-key&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc set data secret/pull-secret -n openshift-config --from-file=.dockerconfigjson=./pull-secret.json</span>
</span></span></code></pre></div><p>Modify the following objects to enable Red Hat Operators.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">oc edit configs.samples.operator.openshift.io/cluster -o yaml</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">samples.operator.openshift.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">...</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">architectures</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">x86_64</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">managementState</span>: <span style="color:#ae81ff">Managed</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">architectures</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#ae81ff">...</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">managementState</span>: <span style="color:#ae81ff">Managed</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">version</span>: <span style="color:#ae81ff">4.9.0-0.</span><span style="color:#ae81ff">okd-2021-11-28-035710</span>
</span></span></code></pre></div><p>Second, run the following command to edit the Operator Hub configuration file and set all source to <code>disabled: false</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">oc edit operatorhub cluster -o yaml</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">disableAllDefaultSources</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">disabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">community-operators</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">disabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">certified-operators</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">disabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">redhat-operators</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">disabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">redhat-marketplace</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">disabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">community-operators</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">status</span>: <span style="color:#ae81ff">Success</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">disabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">message</span>: <span style="color:#ae81ff">CatalogSource.operators.coreos.com &#34;redhat-marketplace&#34; not found</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">redhat-marketplace</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">status</span>: <span style="color:#ae81ff">Error</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">disabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">message</span>: <span style="color:#ae81ff">CatalogSource.operators.coreos.com &#34;redhat-operators&#34; not found</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">redhat-operators</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">status</span>: <span style="color:#ae81ff">Error</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">disabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">message</span>: <span style="color:#ae81ff">CatalogSource.operators.coreos.com &#34;certified-operators&#34; not found</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">certified-operators</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">status</span>: <span style="color:#ae81ff">Error</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>oc get catalogsource --all-namespaces
</span></span><span style="display:flex;"><span>NAMESPACE               NAME                  DISPLAY               TYPE      PUBLISHER   AGE
</span></span><span style="display:flex;"><span>openshift-marketplace   certified-operators   Certified Operators   grpc      Red Hat     37m
</span></span><span style="display:flex;"><span>openshift-marketplace   community-operators   Community Operators   grpc      Red Hat     289d
</span></span><span style="display:flex;"><span>openshift-marketplace   redhat-marketplace    Red Hat Marketplace   grpc      Red Hat     37m
</span></span><span style="display:flex;"><span>openshift-marketplace   redhat-operators      Red Hat Operators     grpc      Red Hat     37m
</span></span></code></pre></div><h3 id="install-ellasticsearch-operator">Install Ellasticsearch Operator</h3>
<p>Create Operators namespaces:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt;penshift_operators_redhatnamespace.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">openshift-operators-redhat </span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">openshift.io/node-selector</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">openshift.io/cluster-monitoring</span>: <span style="color:#e6db74">&#34;true&#34;</span> 
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc apply -f penshift_operators_redhatnamespace.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc project openshift-logging</span>
</span></span></code></pre></div><p>Create OperatorGroup object</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt;openshift-operators-redhat-operatorgroup.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">OperatorGroup</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">openshift-operators-redhat</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-operators-redhat </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>: {}
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc apply -f openshift-operators-redhat-operatorgroup.yaml</span>
</span></span></code></pre></div><p>Subscribe a Namespace to the Cluster Logging Operator:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt;cluster-logging-sub.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Subscription</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">elasticsearch-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-operators-redhat</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">channel</span>: <span style="color:#ae81ff">stable</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">installPlanApproval</span>: <span style="color:#ae81ff">Automatic</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">elasticsearch-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>: <span style="color:#ae81ff">redhat-operators</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sourceNamespace</span>: <span style="color:#ae81ff">openshift-marketplace</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc apply -f cluster-logging-sub.yaml</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc get csv</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">NAME                               DISPLAY                            VERSION    REPLACES                           PHASE</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">elasticsearch-operator.5.3.1-12    OpenShift Elasticsearch Operator   5.3.1-12                                      Succeeded</span>
</span></span></code></pre></div><h3 id="install-logging-operator">Install Logging Operator</h3>
<p>Create Operators namespaces:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt;ocp_cluster_logging_namespace.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">openshift-logging</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">openshift.io/node-selector</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">openshift.io/cluster-logging</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">openshift.io/cluster-monitoring</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc apply -f ocp_cluster_logging_namespace.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc project openshift-logging</span>
</span></span></code></pre></div><p>Create OperatorGroup object</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt;cluster-logging-operatorgroup.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">OperatorGroup</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-logging</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-logging </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetNamespaces</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">openshift-logging</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc apply -f cluster-logging-operatorgroup.yaml</span>
</span></span></code></pre></div><p>Subscribe a Namespace to the Cluster Logging Operator:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt;cluster-logging-sub.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Subscription</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-logging</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-logging</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">channel</span>: <span style="color:#e6db74">&#34;stable&#34;</span> <span style="color:#75715e"># Set Channel</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cluster-logging</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>: <span style="color:#ae81ff">redhat-operators</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sourceNamespace</span>: <span style="color:#ae81ff">openshift-marketplace</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc apply -f cluster-logging-sub.yaml</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc get csv</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">NAME                               DISPLAY                            VERSION    REPLACES                           PHASE</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cluster-logging.5.3.1-12           Red Hat OpenShift Logging          5.3.1-12                                      Succeeded</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">elasticsearch-operator.5.3.1-12    OpenShift Elasticsearch Operator   5.3.1-12                                      Succeeded</span>
</span></span></code></pre></div><h3 id="deploy-cluster-logging-stack">Deploy Cluster logging stack</h3>
<p>Create a Cluster Logging instance:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt;cluster-logging-instance.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;logging.openshift.io/v1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#e6db74">&#34;ClusterLogging&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;instance&#34;</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;openshift-logging&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">managementState</span>: <span style="color:#e6db74">&#34;Managed&#34;</span>  
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">logStore</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#e6db74">&#34;elasticsearch&#34;</span>  
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">retentionPolicy</span>: 
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">application</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">maxAge</span>: <span style="color:#ae81ff">1d</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">infra</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">maxAge</span>: <span style="color:#ae81ff">7d</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">audit</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">maxAge</span>: <span style="color:#ae81ff">7d</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">elasticsearch</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">nodeCount</span>: <span style="color:#ae81ff">3</span> 
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">storageClassName</span>: <span style="color:#e6db74">&#34;&lt;storage_class_name&gt;&#34;</span> 
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">size</span>: <span style="color:#ae81ff">200G</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: 
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;16Gi&#34;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;16Gi&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">proxy</span>: 
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">256Mi</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">256Mi</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">redundancyPolicy</span>: <span style="color:#e6db74">&#34;SingleRedundancy&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">visualization</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#e6db74">&#34;kibana&#34;</span>  
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kibana</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">curation</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">type</span>: <span style="color:#e6db74">&#34;curator&#34;</span>  
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">curator</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">schedule</span>: <span style="color:#e6db74">&#34;30 3 * * *&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">collection</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">logs</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#e6db74">&#34;fluentd&#34;</span>  
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">fluentd</span>: {}
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">oc apply -f cluster-logging-instance.yaml</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">oc get deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cluster-logging-operator       1/1     1            1           18h</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">elasticsearch-cd-x6kdekli-1    0/1     1            0           6m54s</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">elasticsearch-cdm-x6kdekli-1   1/1     1            1           18h</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">elasticsearch-cdm-x6kdekli-2   0/1     1            0           6m49s</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">elasticsearch-cdm-x6kdekli-3   0/1     1            0           6m44s</span>
</span></span></code></pre></div><h3 id="defining-kibana-index-patterns">Defining Kibana index patterns</h3>
<p>In the OpenShift Container Platform console, click the <code>Application Launcher</code> and select <code>Logging</code>.</p>
<p><img src="/img/include/logging-openshift-1.png" alt="Logging Operator"  class="zoomable" /></p>
<p>Create your Kibana index patterns by clicking <code>Management</code> → <code>Index Patterns</code> → <code>Create index pattern</code>:</p>
<ul>
<li>Each user must manually create index patterns when logging into Kibana the first time in order to see logs for their projects. Users must create an index pattern named <code>app</code> and use the <code>@timestamp</code> time field to view their container logs.</li>
<li>Each admin user must create index patterns when logged into Kibana the first time for the <code>app</code>, <code>infra</code>, and <code>audit</code> indices using the <code>@timestamp</code> time field.</li>
</ul>
<p><img src="/img/include/logging-openshift-2.png" alt="Logging Operator"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="operator" term="operator" label="Operator" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install kubernetes with kubeadm]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-install-containerd/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-kyverno-cosign/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification with Kyverno" />
                <link href="https://devopstales.github.io/kubernetes/kyverno-image-mirror/?utm_source=atom_feed" rel="related" type="text/html" title="Automatically change registry in pod definition" />
                <link href="https://devopstales.github.io/kubernetes/k8s-connaisseur-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-install-containerd/</id>
            
            
            <published>2021-11-09T00:00:00+00:00</published>
            <updated>2021-11-09T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Kubeadm is a tool that helps you bootstrap a simple Kubernetes cluster and simplifies the deployment process.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>192.168.1.41  kubernetes01 <span style="color:#75715e"># master node</span>
</span></span><span style="display:flex;"><span>192.168.1.42  kubernetes02 <span style="color:#75715e"># frontend node</span>
</span></span><span style="display:flex;"><span>192.168.1.43  kubernetes03 <span style="color:#75715e"># worker node</span>
</span></span><span style="display:flex;"><span>192.168.1.44  kubernetes04 <span style="color:#75715e"># worker node</span>
</span></span><span style="display:flex;"><span>192.168.1.45  kubernetes05 <span style="color:#75715e"># worker node</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># hardware requirement</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4</span> CPU
</span></span><span style="display:flex;"><span>16G RAM
</span></span></code></pre></div><h3 id="install-docker">Install Docker</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apt-get update
</span></span><span style="display:flex;"><span>apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common
</span></span><span style="display:flex;"><span>curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -
</span></span><span style="display:flex;"><span>add-apt-repository <span style="color:#e6db74">&#34;deb [arch=amd64] https://download.docker.com/linux/debian </span><span style="color:#66d9ef">$(</span>lsb_release -cs<span style="color:#66d9ef">)</span><span style="color:#e6db74"> stable&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>apt-get update
</span></span><span style="display:flex;"><span>apt-get install containerd.io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Configure containerd</span>
</span></span><span style="display:flex;"><span>sudo mkdir -p /etc/containerd
</span></span><span style="display:flex;"><span>sudo containerd config default &gt; /etc/containerd/config.toml
</span></span></code></pre></div><p>To use the <code>systemd</code> cgroup driver in <code>/etc/containerd/config.toml</code> with <code>runc</code>, set</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc.options<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>            SystemdCgroup <span style="color:#f92672">=</span> true
</span></span></code></pre></div><h3 id="configuuration">Configuuration</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kvm-intel
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><h3 id="disable-swap">Disable swap</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><h3 id="install-kubeadm">Install kubeadm</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;runtime-endpoint: unix:///run/containerd/containerd.sock&#34;</span> &gt; /etc/crictl.yaml
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Start containerd</span>
</span></span><span style="display:flex;"><span>systemctl enable --now containerd
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apt-get install ebtables ethtool apt-transport-https
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">deb http://apt.kubernetes.io/ kubernetes-xenial main
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>Change runtime in kubeadm config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e"># add the following flags to KUBELET_KUBEADM_ARGS variable</span>
</span></span><span style="display:flex;"><span>Environment<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;KUBELET_KUBEADM_ARGS=--node-ip=192.168.1.41 --container-runtime=remote --container-runtime-endpoint=/run/containerd/containerd.sock --cgroup-driver=systemd&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apt-get update <span style="color:#f92672">&amp;&amp;</span> apt-get install -y kubelet kubeadm kubectl
</span></span><span style="display:flex;"><span>apt-mark hold kubelet kubeadm kubect
</span></span><span style="display:flex;"><span>systemctl enable kubelet <span style="color:#f92672">&amp;&amp;</span> systemctl start kubelet
</span></span><span style="display:flex;"><span>kubeadm config images pul
</span></span></code></pre></div><h3 id="init-master">Init master</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm init --pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--apiserver-advertise-address<span style="color:#f92672">=</span>192.168.1.41 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--cri-socket<span style="color:#f92672">=</span>unix:///run/containerd/containerd.sock
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
</span></span></code></pre></div><h3 id="join-workers-to-cluster">Join workers to cluster</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm join 192.168.1.41:6443 --token XXXXXXXX <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --discovery-token-ca-cert-hash sha256:XXXXXXXX
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="debian" term="debian" label="Debian" />
                             
                                <category scheme="containerd" term="containerd" label="containerd" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Central authentication with oauth2-proxy]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-central-oauth/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/sso/k8s-gangway/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes authentication with Keycloak and gangway" />
                <link href="https://devopstales.github.io/sso/k8s-dasboard-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Dashboard authentication with Keycloak and gatekeeper" />
                <link href="https://devopstales.github.io/sso/foreman-sso/?utm_source=atom_feed" rel="related" type="text/html" title="Foreman openidc SSO with keycloak" />
                <link href="https://devopstales.github.io/sso/mattermost-keycloak-sso/?utm_source=atom_feed" rel="related" type="text/html" title="Free sso for Mattermost Teams Edition" />
                <link href="https://devopstales.github.io/sso/k8s-kuberos/?utm_source=atom_feed" rel="related" type="text/html" title="Kubectl authentication with Kuberos" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-central-oauth/</id>
            
            
            <published>2021-11-05T00:00:00+00:00</published>
            <updated>2021-11-05T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to use one central OAuth2 Proxy for multiple services inside your Kubernetes Cluster.</p>
<p>The default example on how to secure a service with Nginx and OAuth2 Proxy shows you how to secure only one service. With this setup you need to create one oauth2-proxy for every service. . Another problem of this setup is that it is not supported by most Helm charts.</p>
<p>First we need an oauth2-proxy to authenticate all of the requests:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apiVersion: helm.cattle.io/v1
</span></span><span style="display:flex;"><span>kind: HelmChart
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: auth-proxy
</span></span><span style="display:flex;"><span>  namespace: ingress-system
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  repo: <span style="color:#e6db74">&#34;https://oauth2-proxy.github.io/manifests&#34;</span>
</span></span><span style="display:flex;"><span>  chart: oauth2-proxy
</span></span><span style="display:flex;"><span>  targetNamespace: ingress-system
</span></span><span style="display:flex;"><span>  valuesContent: |-
</span></span><span style="display:flex;"><span>    config:
</span></span><span style="display:flex;"><span>      clientID: <span style="color:#e6db74">&#34;&lt;client-id&gt;&#34;</span>
</span></span><span style="display:flex;"><span>      clientSecret: <span style="color:#e6db74">&#34;&lt;clinet-secret&gt;&#34;</span>
</span></span><span style="display:flex;"><span>      cookieSecret: <span style="color:#e6db74">&#34;bkJnQW1ua2xGa2tCV2pGTlZDdHJWS0t4SWJ2MFFSOWY=&#34;</span>
</span></span><span style="display:flex;"><span>    extraArgs:
</span></span><span style="display:flex;"><span>      email-domain: <span style="color:#e6db74">&#39;*&#39;</span>
</span></span><span style="display:flex;"><span>      provider: keycloak
</span></span><span style="display:flex;"><span>      login-url: https://&lt;keycloak-url&gt;/auth/realms/&lt;keycloak-relm&gt;/protocol/openid-connect/auth
</span></span><span style="display:flex;"><span>      redeem-url: https://&lt;keycloak-url&gt;/auth/realms/&lt;keycloak-relm&gt;/protocol/openid-connect/token
</span></span><span style="display:flex;"><span>      profile-url: https://&lt;keycloak-url&gt;/auth/realms/&lt;keycloak-relm&gt;/protocol/openid-connect/userinfo
</span></span><span style="display:flex;"><span>      validate-url: https://&lt;keycloak-url&gt;/auth/realms/&lt;keycloak-relm&gt;/protocol/openid-connect/userinfo
</span></span><span style="display:flex;"><span>      scope: email
</span></span><span style="display:flex;"><span>      skip-provider-button: <span style="color:#e6db74">&#39;true&#39;</span>
</span></span><span style="display:flex;"><span>      force-https: <span style="color:#e6db74">&#39;false&#39;</span>
</span></span><span style="display:flex;"><span>      cookie-secure: <span style="color:#e6db74">&#39;false&#39;</span>
</span></span><span style="display:flex;"><span>      pass-authorization-header: <span style="color:#e6db74">&#39;true&#39;</span>
</span></span><span style="display:flex;"><span>      pass-basic-auth: <span style="color:#e6db74">&#39;false&#39;</span>
</span></span><span style="display:flex;"><span>      skip-jwt-bearer-tokens: <span style="color:#e6db74">&#39;true&#39;</span>
</span></span><span style="display:flex;"><span>      whitelist-domain: .k8s.intra
</span></span><span style="display:flex;"><span>      cookie-domain: .k8s.intra
</span></span><span style="display:flex;"><span>      oidc-issuer-url: https://&lt;keycloak-url&gt;/auth/realms/&lt;keycloak-relm&gt;
</span></span><span style="display:flex;"><span>    ingress:
</span></span><span style="display:flex;"><span>      enabled: true
</span></span><span style="display:flex;"><span>      path: /oauth2
</span></span><span style="display:flex;"><span>      hosts:
</span></span><span style="display:flex;"><span>        - oauth.k8s.intra
</span></span><span style="display:flex;"><span>      annotations:
</span></span><span style="display:flex;"><span>        kubernetes.io/ingress.class: nginx
</span></span><span style="display:flex;"><span>        cert-manager.io/cluster-issuer: ca-issuer
</span></span><span style="display:flex;"><span>        nginx.ingress.kubernetes.io/proxy-buffer-size: <span style="color:#e6db74">&#34;16k&#34;</span>
</span></span><span style="display:flex;"><span>      tls:
</span></span><span style="display:flex;"><span>      - secretName: oauth2-proxy-tls-cert
</span></span><span style="display:flex;"><span>        hosts:
</span></span><span style="display:flex;"><span>          - oauth.k8s.intra
</span></span><span style="display:flex;"><span>    metrics:
</span></span><span style="display:flex;"><span>      enabled: true
</span></span><span style="display:flex;"><span><span style="color:#75715e">#      servicemonitor:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#        enabled: true</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#        namespace: &#34;ingress-system&#34;</span>
</span></span></code></pre></div><p>For the service you want to secure, add the below annotations to the Ingress:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apiVersion: networking.k8s.io/v1
</span></span><span style="display:flex;"><span>kind: Ingress
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  annotations:
</span></span><span style="display:flex;"><span>    kubernetes.io/ingress.class: nginx
</span></span><span style="display:flex;"><span>    cert-manager.io/cluster-issuer: ca-issuer
</span></span><span style="display:flex;"><span>    nginx.ingress.kubernetes.io/force-ssl-redirect: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>    nginx.ingress.kubernetes.io/auth-url: <span style="color:#e6db74">&#34;http://auth-proxy-oauth2-proxy.ingress-system.svc.cluster.local/oauth2/auth&#34;</span>
</span></span><span style="display:flex;"><span>    nginx.ingress.kubernetes.io/auth-signin: <span style="color:#e6db74">&#34;https://oauth.k8s.intra/oauth2/start?rd=https%3A%2F%2F</span>$host$request_uri<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>  name: alertmanager
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  rules:
</span></span><span style="display:flex;"><span>  - host: alertmanager.example.com
</span></span><span style="display:flex;"><span>    http:
</span></span><span style="display:flex;"><span>      paths:
</span></span><span style="display:flex;"><span>      - backend:
</span></span><span style="display:flex;"><span>          serviceName: alertmanager
</span></span><span style="display:flex;"><span>          servicePort: <span style="color:#ae81ff">9093</span>
</span></span><span style="display:flex;"><span>        path: /
</span></span><span style="display:flex;"><span>        pathType: ImplementationSpecific
</span></span><span style="display:flex;"><span>  tls:
</span></span><span style="display:flex;"><span>  - hosts:
</span></span><span style="display:flex;"><span>    - alertmanager.example.com
</span></span><span style="display:flex;"><span>    secretName: tls-cert
</span></span></code></pre></div><p>The <code>auth-sigin</code> redirects any needed login to the OAuth2 Proxy Ingress.
The <code>auth-url</code> annotation can access the OAuth2 Proxy internally via its service to verify a submitted token.</p>
<p>The OAuth2 Proxy will handle the authentication and later redirect you to the protected service again.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-authentication" term="k8s-authentication" label="k8s-authentication" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                             
                                <category scheme="oidc" term="oidc" label="oidc" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to create kubeconfig?]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-rbac-gen/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/sso/k8s-gangway/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes authentication with Keycloak and gangway" />
                <link href="https://devopstales.github.io/sso/k8s-dasboard-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Dashboard authentication with Keycloak and gatekeeper" />
                <link href="https://devopstales.github.io/kubernetes/k8s-falco/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes audit logs and Falco" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cisa-install/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Hardening Guide with CISA 1.6 Benchmark" />
                <link href="https://devopstales.github.io/kubernetes/trivy-operator-1.0/?utm_source=atom_feed" rel="related" type="text/html" title="trivy-operator 1.0" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-rbac-gen/</id>
            
            
            <published>2021-11-03T00:00:00+00:00</published>
            <updated>2021-11-03T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this blog, I will show you how to create a kubeconfig file with limited access to kubernetes cluster using service account, secret token and RBAC</p>
<p>Create namespace:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export NAMESPACE<span style="color:#f92672">=</span>test-ns
</span></span><span style="display:flex;"><span>export SERVICEACCOUNT<span style="color:#f92672">=</span>devopstales
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create namespace $NAMESPACE
</span></span><span style="display:flex;"><span>kubens $NAMESPACE
</span></span></code></pre></div><p>Create serviceaccount with RBAC:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | envsubst | kubectl create -f -</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceAccount</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">$SERVICEACCOUNT</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">$NAMESPACE</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">developer-access</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">$NAMESPACE</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;&#34;</span>, <span style="color:#e6db74">&#34;extensions&#34;</span>, <span style="color:#e6db74">&#34;apps&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;*&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;*&#34;</span>]
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;batch&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">jobs</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">cronjobs</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;*&#34;</span>]
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">$SERVICEACCOUNT</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">$NAMESPACE</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceAccount</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">$SERVICEACCOUNT</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">$NAMESPACE</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">developer-access</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>Create kubeconfig for serviceaccount:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/devopstales/k8s_sec_lab.git
</span></span><span style="display:flex;"><span>cd k8s_sec_lab/kubernetes-scripts
</span></span><span style="display:flex;"><span>chmod +x create-kubeconfig.sh
</span></span><span style="display:flex;"><span>./create-kubeconfig.sh $SERVICEACCOUNT &gt; kubeconfig-$NAMESPACE
</span></span></code></pre></div><p>Use kubeconfig:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --kubeconfig<span style="color:#f92672">=</span>kubeconfig-$NAMESPACE get po
</span></span></code></pre></div><h3 id="permission-managger">Permission Managger</h3>
<p>Permission Manager is an application developed by SIGHUP that enables a super-easy and user-friendly RBAC management for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create namespace permission-manager
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano pm-secret.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">permission-manager</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">permission-manager</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">type</span>: <span style="color:#ae81ff">Opaque</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">stringData</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">PORT</span>: <span style="color:#e6db74">&#34;4000&#34;</span> <span style="color:#75715e"># port where server is exposed</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">CLUSTER_NAME</span>: <span style="color:#e6db74">&#34;my-cluster&#34;</span> <span style="color:#75715e"># name of the cluster to use in the generated kubeconfig file</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">CONTROL_PLANE_ADDRESS</span>: <span style="color:#e6db74">&#34;https://172.17.0.3:6443&#34;</span> <span style="color:#75715e"># full address of the control plane to use in the generated kubeconfig file</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">BASIC_AUTH_PASSWORD</span>: <span style="color:#e6db74">&#34;changeMe&#34;</span> <span style="color:#75715e"># password used by basic auth (username is `admin`)</span>
</span></span></code></pre></div><p>Deploy permission-manager:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f pm-secret.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/sighupio/permission-manager/releases/download/v1.7.1-rc1/crd.yml
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/sighupio/permission-manager/releases/download/v1.7.1-rc1/seed.yml
</span></span><span style="display:flex;"><span>kubectl apply -f https://github.com/sighupio/permission-manager/releases/download/v1.7.1-rc1/deploy.yml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl port-forward svc/permission-manager <span style="color:#ae81ff">4000</span> --namespace permission-manager
</span></span></code></pre></div><p>Connect on localhost:</p>
<p><img src="/img/include/permission-manager.gif" alt="permission-manager"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-authentication" term="k8s-authentication" label="k8s-authentication" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="rbac" term="rbac" label="RBAC" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes audit logs and Falco]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-falco/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-cisa-install/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Hardening Guide with CISA 1.6 Benchmark" />
                <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="related" type="text/html" title="Hardening Kubernetes with seccomp" />
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/firecracker-cri-o/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy CRI-O with Firecracker?" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-falco/</id>
            
            
            <published>2021-11-02T00:00:00+00:00</published>
            <updated>2021-11-02T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this blog post I will show you how how you can use Kubernetes the audit logs and Falco for detecting suspicious activities in you cluster.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>In the <a href="../k8s-cisa-install">previous post</a> I configured CISA&rsquo;s best practices for the Kubernetes cluster. One of this best practice is to enable Kubernetes audit logging.  It’s a key feature in securing your Kubernetes cluster, as the audit logs capture events like creating a new deployment, deleting namespaces, starting a node port service, etc.</p>
<p>When a request, for example, creates a pod, it’s sent to the <code>kube-apiserver</code>. You can configure <code>kube-apiserver</code> to write all of this activities to a log file. Each request can be recorded with an associated stage. The defined stages are:</p>
<ul>
<li>RequestReceived: The event is generated as soon as the request is received by the audit handler without processing it.</li>
<li>ResponseStarted: Once the response headers are sent, but before the response body is sent. This stage is only generated for long-running requests (e.g., watch).</li>
<li>ResponseComplete: The event is generated when a response body is sent.</li>
<li>Panic: Event is generated when panic occurs.</li>
</ul>
<h3 id="enable-kubernetes-audit-policy">Enable Kubernetes audit policy</h3>
<p>You can enable this in the <code>kubeadm</code> conif as I did it in the previous post or edit the manifest of the running api server on the masters:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/kubernetes/manifests/kube-apiserver.yaml
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  containers:
</span></span><span style="display:flex;"><span>  - command:
</span></span><span style="display:flex;"><span>    - kube-apiserver
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>    - --audit-log-path<span style="color:#f92672">=</span>/var/log/kube-audit/audit.log
</span></span><span style="display:flex;"><span>    - --audit-policy-file<span style="color:#f92672">=</span>/etc/kubernetes/audit-policy.yaml
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>With security in mind, we’ll create a policy that filters requests related to pods, kube-proxy, secrets, configurations, and other key components.
Such a policy would look like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">mkdir /var/log/kube-audit</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">nano /etc/kubernetes/audit-policy.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">audit.k8s.io/v1</span> <span style="color:#75715e"># This is required.</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Policy</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Don&#39;t generate audit events for all requests in RequestReceived stage.</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">omitStages</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#34;RequestReceived&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log pod changes at RequestResponse level</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">RequestResponse</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># Resource &#34;pods&#34; doesn&#39;t match requests to any subresource of pods,</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># which is consistent with the RBAC policy.</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;pods&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log &#34;pods/log&#34;, &#34;pods/status&#34; at Metadata level</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Metadata</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;pods/log&#34;</span>, <span style="color:#e6db74">&#34;pods/status&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Don&#39;t log requests to a configmap called &#34;controller-leader&#34;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;configmaps&#34;</span>]
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resourceNames</span>: [<span style="color:#e6db74">&#34;controller-leader&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Don&#39;t log watch requests by the &#34;system:kube-proxy&#34; on endpoints or services</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">users</span>: [<span style="color:#e6db74">&#34;system:kube-proxy&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;watch&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#75715e"># core API group</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;endpoints&#34;</span>, <span style="color:#e6db74">&#34;services&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Don&#39;t log authenticated requests to certain non-resource URL paths.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">userGroups</span>: [<span style="color:#e6db74">&#34;system:authenticated&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nonResourceURLs</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;/api*&#34;</span> <span style="color:#75715e"># Wildcard matching.</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;/version&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log the request body of configmap changes in kube-system.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Request</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#75715e"># core API group</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;configmaps&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># This rule only applies to resources in the &#34;kube-system&#34; namespace.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># The empty string &#34;&#34; can be used to select non-namespaced resources.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">namespaces</span>: [<span style="color:#e6db74">&#34;kube-system&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log configmap and secret changes in all other namespaces at the Metadata level.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#- level: Metadata</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Request</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#75715e"># core API group</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;secrets&#34;</span>, <span style="color:#e6db74">&#34;configmaps&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Log all other resources in core and extensions at the Request level.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Request</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#75715e"># core API group</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">group</span>: <span style="color:#e6db74">&#34;extensions&#34;</span> <span style="color:#75715e"># Version of group should NOT be included.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># A catch-all rule to log all other requests at the Metadata level.</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Metadata</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Long-running requests like watches that fall under this rule will not</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># generate an audit event in RequestReceived.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">omitStages</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;RequestReceived&#34;</span>
</span></span></code></pre></div><p>Then restart the api server:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl restart kubelet
</span></span></code></pre></div><h3 id="what-is-falco">What is Falco?</h3>
<p>OK we hawe a log file at <code>/var/log/kube-audit/audit.log</code>, but what can we do with it? We need a tool to monitor and alert based on the events in the audit log. This tool is Falco. Falco makes it possible to monitor suspicious events directly inside the cluster. The events may include the following:</p>
<ul>
<li>Outgoing connections to specific IPs or domains</li>
<li>Use or mutation of sensitive files such as /etc/passwd</li>
<li>Execution of system binaries such as su</li>
<li>Privilege escalation or changes to the namespace</li>
<li>Modifications in certain folders such as /sbin</li>
</ul>
<h3 id="falco-architecture">Falco architecture</h3>
<p><img src="/img/include/falco01.png" alt="alco architecture"  class="zoomable" /></p>
<p>From a high-level view, Falco is comprised of the following components:</p>
<ul>
<li>Event sources (drivers, Kubernetes audit events)</li>
<li>A rule engine and a rule set</li>
<li>An output system integration</li>
</ul>
<p>Falco uses so-called drivers to monitor syscalls made by applications at the kernel level; it can therefore monitor everything that results in a syscall. As containers share a kernel, it is possible to monitor syscalls by all the containers on a host. This is not possible in the case of more isolated container engines like Kata Containers or Firecracker. Falco supports two types of drivers: kernel module, eBPF probe:</p>
<ul>
<li>Kernel module (the default): A kernel module that must be compiled for the kernel that Falco will run on.</li>
<li>eBPF probe: No need to load a kernel module, but requires a newer kernel that supports eBPF. Not supported on many managed services.</li>
</ul>
<h3 id="install-falco">Install falco</h3>
<p>First we need to install the devel kernel headers to allow falco to build the kernel mosul that Falco use to get syscalls.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apt-get -y install linux-headers-<span style="color:#66d9ef">$(</span>uname -r<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or</span>
</span></span><span style="display:flex;"><span>yum -y install kernel-devel-<span style="color:#66d9ef">$(</span>uname -r<span style="color:#66d9ef">)</span>
</span></span></code></pre></div><p>We can install falco client az a package:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -s https://falco.org/repo/falcosecurity-3672BA8F.asc | apt-key add -
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;deb https://download.falco.org/packages/deb stable main&#34;</span> | tee -a /etc/apt/sources.list.d/falcosecurity.list
</span></span><span style="display:flex;"><span>apt-get update -y
</span></span><span style="display:flex;"><span>apt-get install -y falco
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or</span>
</span></span><span style="display:flex;"><span>rpm --import https://falco.org/repo/falcosecurity-3672BA8F.asc
</span></span><span style="display:flex;"><span>curl -s -o /etc/yum.repos.d/falcosecurity.repo https://falco.org/repo/falcosecurity-rpm.repo
</span></span><span style="display:flex;"><span>yum -y install falco
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>falco-driver-loader
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>service falco start
</span></span><span style="display:flex;"><span>journalctl -fu falco
</span></span></code></pre></div><p>Or install as docker container:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add falcosecurity https://falcosecurity.github.io/charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm upgrade --install falco falcosecurity/falco --namespace falco <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set falcosidekick.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set falcosidekick.webui.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set auditLog.enabled<span style="color:#f92672">=</span>true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm ls
</span></span><span style="display:flex;"><span>kubectl get pods --namespace falco
</span></span><span style="display:flex;"><span>NAME                                      READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>falco-falcosidekick-76f5885f7f-956vj      1/1     Running   <span style="color:#ae81ff">0</span>          4m27s
</span></span><span style="display:flex;"><span>falco-falcosidekick-76f5885f7f-tmff6      1/1     Running   <span style="color:#ae81ff">0</span>          4m27s
</span></span><span style="display:flex;"><span>falco-falcosidekick-ui-5b64749bc8-k8v4p   1/1     Running   <span style="color:#ae81ff">0</span>          4m27s
</span></span><span style="display:flex;"><span>falco-h4qvx 
</span></span></code></pre></div><p>I prefer this solution because it is more elegant. For the easier installation I created a helmfile:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd /opt
</span></span><span style="display:flex;"><span>git clone https://github.com/devopstales/k8s_sec_lab
</span></span><span style="display:flex;"><span>cd k8s_sec_lab/k8s-manifest
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f 120-falco-ns.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f 122-falco.yaml
</span></span></code></pre></div><h3 id="processing-falco-logs-with-a-logging-system">Processing Falco logs with a logging system</h3>
<p>Falco provides support for a variety of output channels for generated alerts. These can include stdout, gRPC, syslog, a file, and more. In my exaple I used loki and alertmanager.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat 122-falco.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  chart: falco
</span></span><span style="display:flex;"><span>  repo: <span style="color:#e6db74">&#34;https://falcosecurity.github.io/charts&#34;</span>
</span></span><span style="display:flex;"><span>  targetNamespace: falco-system
</span></span><span style="display:flex;"><span>  valuesContent: |-
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>      config:
</span></span><span style="display:flex;"><span>        loki:
</span></span><span style="display:flex;"><span>          hostport: http://logging-loki.logging-system:3100
</span></span><span style="display:flex;"><span>        customfields: <span style="color:#e6db74">&#34;source:falco&#34;</span>
</span></span><span style="display:flex;"><span>        alertmanager:
</span></span><span style="display:flex;"><span>          hostport: http://monitoring-kube-prometheus-alertmanager.monitoring-system:9093
</span></span><span style="display:flex;"><span>          minimumpriority: error
</span></span><span style="display:flex;"><span>          mutualtls: false
</span></span><span style="display:flex;"><span>          checkcert: false
</span></span></code></pre></div><h3 id="gathering-audit-logs-by-using-fluentbit">Gathering Audit Logs by using FluentBit</h3>
<p>In order to deploy FluentBit, I created a helmfile:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f 123-falco-fluentbit.yaml
</span></span></code></pre></div><p>I use FluentBit to send the Kubernetes Kubernetes audit logs to falco.</p>
<h3 id="test">Test</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --namespace<span style="color:#f92672">=</span>falco-system port-forward svc/falco-falcosidekick-ui <span style="color:#ae81ff">2802</span>
</span></span><span style="display:flex;"><span>Forwarding from 127.0.0.1:2802 -&gt; <span style="color:#ae81ff">2802</span>
</span></span><span style="display:flex;"><span>Forwarding from <span style="color:#f92672">[</span>::1<span style="color:#f92672">]</span>:2802 -&gt; <span style="color:#ae81ff">2802</span>
</span></span></code></pre></div><p>On the master node edit the <code>/etc/hosts</code> file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/hosts
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#75715e"># test</span>
</span></span></code></pre></div><p><img src="/img/include/falco02.png" alt="alco architecture"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="falco" term="falco" label="falco" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Hardening Guide with CISA 1.6 Benchmark]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-cisa-install/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="related" type="text/html" title="Hardening Kubernetes with seccomp" />
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/firecracker-cri-o/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy CRI-O with Firecracker?" />
                <link href="https://devopstales.github.io/kubernetes/gvisor-cri-o/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy CRI-O with gVisor?" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-cisa-install/</id>
            
            
            <published>2021-10-15T00:00:00+00:00</published>
            <updated>2021-10-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>On August 3rd, 2021 the National Security Agency (NSA) and the Cybersecurity and Infrastructure Security Agency (CISA) released, <a href="https://media.defense.gov/2021/Aug/03/2002820425/-1/-1/1/CTR_KUBERNETES%20HARDENING%20GUIDANCE.PDF">Kubernetes Hardening Guidance</a>, a cybersecurity technical report detailing the complexities of securely managing Kubernetes. This blog post will show you how you can harden your Kubernetes cluster based on CISA best practices.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="disable-swap">Disable swap</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><h3 id="project-longhorn-prerequisites">Project Longhorn Prerequisites</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install -y iscsi-initiator-utils 
</span></span><span style="display:flex;"><span>modprobe iscsi_tcp
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;iscsi_tcp&#34;</span> &gt;/etc/modules-load.d/iscsi-tcp.conf
</span></span><span style="display:flex;"><span>systemctl enable iscsid
</span></span><span style="display:flex;"><span>systemctl start iscsid 
</span></span></code></pre></div><h3 id="install-and-configure-containerd">Install and configure containerd</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install -y yum-utils device-mapper-persistent-data lvm2 git nano wget iproute-tc vim-common
</span></span><span style="display:flex;"><span>yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install -y containerd.io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Configure containerd</span>
</span></span><span style="display:flex;"><span>sudo mkdir -p /etc/containerd
</span></span><span style="display:flex;"><span>sudo containerd config default &gt; /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc.options<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>            SystemdCgroup <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl enable --now containerd
</span></span><span style="display:flex;"><span>systemctl status containerd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;runtime-endpoint: unix:///run/containerd/containerd.sock&#34;</span> &gt; /etc/crictl.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cd /tmp
</span></span><span style="display:flex;"><span>wget https://github.com/containerd/nerdctl/releases/download/v0.12.0/nerdctl-0.12.0-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar -xzf nerdctl-0.12.0-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>mv nerdctl /usr/local/bin
</span></span><span style="display:flex;"><span>nerdctl ps
</span></span></code></pre></div><h3 id="kubaedm-preconfiguuration">kubaedm preConfiguuration</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">#
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># protectKernelDefaults
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">#
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kernel.keys.root_maxbytes           = 25000000
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kernel.keys.root_maxkeys            = 1000000
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kernel.panic                        = 10
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kernel.panic_on_oops                = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">vm.overcommit_memory                = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">vm.panic_on_oom                     = 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd /opt
</span></span><span style="display:flex;"><span>git clone https://github.com/devopstales/k8s_sec_lab
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir /etc/kubernetes/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>head -c <span style="color:#ae81ff">32</span> /dev/urandom | base64
</span></span><span style="display:flex;"><span>nano /opt/k8s_sec_lab/k8s-manifest/002-etcd-encription.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cp /opt/k8s_sec_lab/k8s-manifest/001-audit-policy.yaml /etc/kubernetes/audit-policy.yaml
</span></span><span style="display:flex;"><span>cp /opt/k8s_sec_lab/k8s-manifest/002-etcd-encription.yaml /etc/kubernetes/etcd-encription.yaml
</span></span></code></pre></div><h3 id="install-kubeadm">Install kubeadm</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">       https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install epel-release
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install -y kubeadm kubelet kubectl
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;KUBELET_KUBEADM_ARGS=&#34;--node-ip=172.17.13.10 --container-runtime=remote --container-runtime-endpoint=/run/containerd/containerd.sock&#34;&#39;</span> &gt; /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm config images pull --config 010-kubeadm-conf-1-22-2.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl enable kubelet.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano 010-kubeadm-conf.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># add the ips, short hostnames, fqdns of the nodes and the ip of the loadbalancer as certSANs to the apiServer config.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm init --skip-phases<span style="color:#f92672">=</span>addon/kube-proxy --config 010-kubeadm-conf-1-22-2.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># In my kubeadm config I forced the usage of PSP.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># At the beginning there is no psp deployed, so non of the pods can start.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Thi is tru for the kube-apiserver too.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f 011-psp.yaml 
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get csr --all-namespaces
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get csr -oname | xargs kubectl certificate approve
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f 012-k8s-clusterrole.yaml
</span></span></code></pre></div><h3 id="cilium">cilium</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mount | grep /sys/fs/bpf
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install -y https://harbottle.gitlab.io/harbottle-main/7/x86_64/harbottle-main-release.rpm
</span></span><span style="display:flex;"><span>yum install -y kubectx helm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm repo add cilium https://helm.cilium.io/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl taint nodes --all node-role.kubernetes.io/master-
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm upgrade --install cilium cilium/cilium <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --namespace kube-system <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -f 031-cilium-helm-values.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pods -A
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f 013-k8s-cert-approver.yaml
</span></span></code></pre></div><h3 id="harden-kubernetes">harden kubernetes</h3>
<p>There is an opensource tool theat tests CISA&rsquo;s best best practices on your clsuter. We vill use this to test the resoults.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># kube-bench</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># https://github.com/aquasecurity/kube-bench/releases/</span>
</span></span><span style="display:flex;"><span>yum install -y https://github.com/aquasecurity/kube-bench/releases/download/v0.6.5/kube-bench_0.6.5_linux_amd64.rpm
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>useradd -r -c <span style="color:#e6db74">&#34;etcd user&#34;</span> -s /sbin/nologin -M etcd
</span></span><span style="display:flex;"><span>chown etcd:etcd /var/lib/etcd
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">700</span> /var/lib/etcd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># kube-bench</span>
</span></span><span style="display:flex;"><span>kube-bench
</span></span><span style="display:flex;"><span>kube-bench | grep <span style="color:#e6db74">&#34;\[FAIL\]&#34;</span>
</span></span></code></pre></div><p>There is no FAIL jusk WARNING. Jeee.</p>
<h3 id="join-nodes">join nodes</h3>
<p>Firs we need to get the join command from the master:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># on master1</span>
</span></span><span style="display:flex;"><span>kubeadm token create --print-join-command
</span></span><span style="display:flex;"><span>kubeadm join 172.17.9.10:6443 --token c2t0rj.cofbfnwwrb387890 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> --discovery-token-ca-cert-hash sha256:a52f4c16a6ce9ef72e3d6172611d17d9752dfb1c3870cf7c8ad4ce3bcb97547e
</span></span></code></pre></div><p>If the next node is a worke we can just use the command what we get. If a next node is a master we need to generate a certificate-key. You need a separate certificate-key for every new master.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># on master1</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## generate cert key</span>
</span></span><span style="display:flex;"><span>kubeadm certs certificate-key
</span></span><span style="display:flex;"><span>29ab8a6013od73s8d3g4ba3a3b24679693e98acd796356eeb47df098c47f2773
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## store cert key in secret</span>
</span></span><span style="display:flex;"><span>kubeadm init phase upload-certs --upload-certs --certificate-key<span style="color:#f92672">=</span>29ab8a6013od73s8d3g4ba3a3b24679693e98acd796356eeb47df098c47f2773
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># on master2</span>
</span></span><span style="display:flex;"><span>kubeadm join 172.17.9.10:6443 --token c2t0rj.cofbfnwwrb387890 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--discovery-token-ca-cert-hash sha256:a52f4c16a6ce9ef72e3d6172611d17d9752dfb1c3870cf7c8ad4ce3bcb97547e <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--control-plane --certificate-key 29ab8a6013od73s8d3g4ba3a3b24679693e98acd796356eeb47df098c47f2773
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># on master3</span>
</span></span><span style="display:flex;"><span>kubeadm join 172.17.9.10:6443 --token c2t0rj.cofbfnwwrb387890 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--discovery-token-ca-cert-hash sha256:a52f4c16a6ce9ef72e3d6172611d17d9752dfb1c3870cf7c8ad4ce3bcb97547e <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--control-plane --certificate-key 29ab8a6013od73s8d3g4ba3a3b24679693e98acd796356eeb47df098c47f2773
</span></span></code></pre></div><p>In the end withevery new node we need to approve the certificate requests for the node.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get csr -oname | xargs kubectl certificate approve
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>useradd -r -c <span style="color:#e6db74">&#34;etcd user&#34;</span> -s /sbin/nologin -M etcd
</span></span><span style="display:flex;"><span>chown etcd:etcd /var/lib/etcd
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">700</span> /var/lib/etcd
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[trivy-operator 1.0]]></title>
            <link href="https://devopstales.github.io/kubernetes/trivy-operator-1.0/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Multicluster with Cilium Cluster Mesh" />
                <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="related" type="text/html" title="Hardening Kubernetes with seccomp" />
                <link href="https://devopstales.github.io/kubernetes/k8s-git-backup/?utm_source=atom_feed" rel="related" type="text/html" title="How to Backup Kubernetes to git?" />
                <link href="https://devopstales.github.io/kubernetes/firecracker-cri-o/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy CRI-O with Firecracker?" />
                <link href="https://devopstales.github.io/kubernetes/gvisor-cri-o/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy CRI-O with gVisor?" />
            
                <id>https://devopstales.github.io/kubernetes/trivy-operator-1.0/</id>
            
            
            <published>2021-10-09T00:00:00+00:00</published>
            <updated>2021-10-09T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Today I am happy to announce the release of trivy-operator 1.0 and assign the first ever stable release number. This blog post focuses on the functionality provided by the trivy-operator 1.0 release.</p>
<h3 id="what-is-trivy-operator">What is trivy-operator?</h3>
<p>Trivy-operator is a Kubernetes Operator based on the open-source container vulnerability scanner Trivy. The goal of this project is to provide a vulnerability scanner that continuously scans containers deployed in a Kubernetes cluster. <a href="https://github.com/nolar/kopf">Built with Kubernetes Operator Pythonic Framework (Kopf)</a> There are a few solution for checking the images when you deploy them to the Kubernetes cluster, but fighting against vulnerabilities is a day to day task. Check once is not enough when every day is a new das for frats. That is why I created trivy-operator so you can create scheduled image scans on your running pods.</p>
<h3 id="scheduled-image-scans">Scheduled Image scans</h3>
<p>Default trivy-operator execute a scan script every 5 minutes. It will get images from all the namespaces with the label <code>trivy-scan=true</code>, and then check these images with trivy for vulnerabilities. You can modify the namespace selector. Finally we will get metrics on <code>http://[pod-ip]:9115/metrics</code></p>
<h2 id="usage">Usage</h2>
<p>To ease deployment I created a helm chart for trivy-operator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add devopstales https://devopstales.github.io/helm-charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span></code></pre></div><p>Create a value file for deploy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;&#39;EOF&#39;&gt; values.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">image</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repository</span>: <span style="color:#ae81ff">devopstales/trivy-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">pullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tag</span>: <span style="color:#e6db74">&#34;1.0&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">imagePullSecrets</span>: []
</span></span><span style="display:flex;"><span><span style="color:#f92672">podSecurityContext</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroup</span>: <span style="color:#ae81ff">10001</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroupChangePolicy</span>: <span style="color:#e6db74">&#34;OnRootMismatch&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceAccount</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>: {}
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;trivy-operator&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">monitoring</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">port</span>: <span style="color:#e6db74">&#34;9115&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;kube-system&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">size</span>: <span style="color:#ae81ff">1Gi</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">NamespaceScanner</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">crontab</span>: <span style="color:#e6db74">&#34;*/5 * * * *&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespaceSelector</span>: <span style="color:#e6db74">&#34;trivy-scan&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">registryAuth</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">registry</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">docker.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">user</span>: <span style="color:#e6db74">&#34;user&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">password</span>: <span style="color:#e6db74">&#34;password&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">githubToken</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">token</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>When the trivy in the container want to scan an image first download the vulnerability database from github. If you test many images you need a  <code>githubToken</code> overcome the github rate limit and dockerhub username and password for overcome the dockerhub rate limit. If your store you images in a private repository you need to add an username and password for authentication.</p>
<p>The following tables lists configurable parameters of the trivy-operator chart and their default values.</p>
<table>
  <thead>
      <tr>
          <th>Parameter</th>
          <th>Description</th>
          <th>Default</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>image.repository</td>
          <td>image</td>
          <td>devopstales/trivy-operator</td>
      </tr>
      <tr>
          <td>image.pullPolicy</td>
          <td>pullPolicy</td>
          <td>Always</td>
      </tr>
      <tr>
          <td>image.tag</td>
          <td>image tag</td>
          <td>1.0</td>
      </tr>
      <tr>
          <td>imagePullSecrets</td>
          <td>imagePullSecrets list</td>
          <td>[]</td>
      </tr>
      <tr>
          <td>podSecurityContext.fsGroup</td>
          <td>mount id</td>
          <td>10001</td>
      </tr>
      <tr>
          <td>serviceAccount.create</td>
          <td>create serviceAccount</td>
          <td>true</td>
      </tr>
      <tr>
          <td>serviceAccount.annotations</td>
          <td>add annotation to serviceAccount</td>
          <td>{}</td>
      </tr>
      <tr>
          <td>serviceAccount.name</td>
          <td>name of the serviceAccount</td>
          <td>trivy-operator</td>
      </tr>
      <tr>
          <td>monitoring.port</td>
          <td>prometheus endpoint port</td>
          <td>9115</td>
      </tr>
      <tr>
          <td>serviceMonitor.enabled</td>
          <td>enable serviceMonitor object creation</td>
          <td>false</td>
      </tr>
      <tr>
          <td>serviceMonitor.namespace</td>
          <td>where to create serviceMonitor object</td>
          <td>kube-system</td>
      </tr>
      <tr>
          <td>storage.enabled</td>
          <td>enable pv to store trivy database</td>
          <td>true</td>
      </tr>
      <tr>
          <td>storage.size</td>
          <td>pv size</td>
          <td>1Gi</td>
      </tr>
      <tr>
          <td>NamespaceScanner.crontab</td>
          <td>cronjob scheduler</td>
          <td>&ldquo;*/5 * * * *&rdquo;</td>
      </tr>
      <tr>
          <td>NamespaceScanner.namespaceSelector</td>
          <td>Namespace Selector</td>
          <td>&ldquo;trivy-scan&rdquo;</td>
      </tr>
      <tr>
          <td>registryAuth.enabled</td>
          <td>enable registry authentication in operator</td>
          <td>false</td>
      </tr>
      <tr>
          <td>registryAuth.registry</td>
          <td>registry name for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>registryAuth.user</td>
          <td>username for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>registryAuth.password</td>
          <td>password for authentication</td>
          <td></td>
      </tr>
      <tr>
          <td>githubToken.enabled</td>
          <td>Enable githubToken usage for trivy database update</td>
          <td>false</td>
      </tr>
      <tr>
          <td>githubToken.token</td>
          <td>githubToken value</td>
          <td>&quot;&quot;</td>
      </tr>
  </tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns trivy-operator
</span></span><span style="display:flex;"><span>kubens trivy-operator
</span></span><span style="display:flex;"><span>helm upgrade --install trivy devopstales/trivy-operator -f values.yaml
</span></span></code></pre></div><h3 id="monitoring">Monitoring</h3>
<p>Trivy-operatos has a prometheus endpoint op port <code>9115</code> and can be deployed wit <code>ServiceMonitor</code> for automated scrapping.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -s http://10.43.179.39:9115/metrics | grep so_vulnerabilities
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;UNKNOWN&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">23</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">93</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">76</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:1.18&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">25</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;UNKNOWN&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LOW&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">23</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;MEDIUM&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">88</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;HIGH&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">60</span>
</span></span><span style="display:flex;"><span>so_vulnerabilities<span style="color:#f92672">{</span>exported_namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;trivytest&#34;</span>,image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;docker.io/library/nginx:latest&#34;</span>,severity<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;CRITICAL&#34;</span><span style="color:#f92672">}</span> <span style="color:#ae81ff">8</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-operators" term="k8s-operators" label="k8s-operators" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="trivy-operator" term="trivy-operator" label="trivy-operator" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Multicluster with Cilium Cluster Mesh]]></title>
            <link href="https://devopstales.github.io/kubernetes/cilium-clustermesh/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="related" type="text/html" title="Hardening Kubernetes with seccomp" />
                <link href="https://devopstales.github.io/kubernetes/k8s-git-backup/?utm_source=atom_feed" rel="related" type="text/html" title="How to Backup Kubernetes to git?" />
            
                <id>https://devopstales.github.io/kubernetes/cilium-clustermesh/</id>
            
            
            <published>2021-10-06T00:00:00+00:00</published>
            <updated>2021-10-06T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install Cilium on multiple Kubernetes clusters and connect those clusters with Cluster Mesh.</p>
<h3 id="what-is-cluster-mesh">What is Cluster Mesh</h3>
<p>Cluster mesh extends the networking datapath across multiple clusters. It allows endpoints in all connected clusters to communicate while providing full policy enforcement. Load-balancing is available via Kubernetes annotations.</p>
<h3 id="the-infrastructure">The infrastructure</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>k3s-cl1:
</span></span><span style="display:flex;"><span>ip: 172.17.11.11
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3s-cl2:
</span></span><span style="display:flex;"><span>ip: 172.17.11.12
</span></span><span style="display:flex;"><span>etcd
</span></span><span style="display:flex;"><span>kube-vip
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3s-cl3:
</span></span><span style="display:flex;"><span>ip: 172.17.11.13
</span></span><span style="display:flex;"><span>etcd
</span></span><span style="display:flex;"><span>kube-vip
</span></span></code></pre></div><h2 id="installing-k3s-with-k3sup">Installing k3s with k3sup</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.11.11
</span></span><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.11.12
</span></span><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.11.13
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>tmux-cssh vagrant@172.17.11.11 vagrant@172.17.11.12 vagrant@172.17.11.13
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>curl -sLS https://get.k3sup.dev | sh
</span></span><span style="display:flex;"><span>sudo install k3sup /usr/local/bin/
</span></span><span style="display:flex;"><span>k3sup --help
</span></span></code></pre></div><h3 id="bootstrap-cl1">Bootstrap cl1</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.11.11
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3sup install <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip<span style="color:#f92672">=</span>172.17.11.11 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cluster <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel<span style="color:#f92672">=</span>stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--flannel-backend=none --cluster-cidr=10.11.0.0/16 --disable-network-policy --no-deploy=traefik --no-deploy=servicelb --node-ip=172.17.11.11&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --merge <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local-path $HOME/.kube/config <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --context<span style="color:#f92672">=</span>k3scl1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><h3 id="bootstrap-cl2">Bootstrap cl2</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.11.12
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3sup install <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip<span style="color:#f92672">=</span>172.17.11.12 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cluster <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel<span style="color:#f92672">=</span>stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--flannel-backend=none --cluster-cidr=10.12.0.0/16 --disable-network-policy --no-deploy=traefik --no-deploy=servicelb --node-ip=172.17.11.12&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --merge <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local-path $HOME/.kube/config <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --context<span style="color:#f92672">=</span>k3scl2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><h3 id="bootstrap-cl3">Bootstrap cl3</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.11.13
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3sup install <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip<span style="color:#f92672">=</span>172.17.11.13 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cluster <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel<span style="color:#f92672">=</span>stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--flannel-backend=none --cluster-cidr=10.13.0.0/16 --disable-network-policy --no-deploy=traefik --no-deploy=servicelb --node-ip=172.17.11.13&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --merge <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local-path $HOME/.kube/config <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --context<span style="color:#f92672">=</span>k3scl3
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><h2 id="deploy-cilium">Deploy cilium</h2>
<p>Each Kubernetes cluster maintains its own etcd cluster which contains the state of that cluster&rsquo;s cilium. State from multiple clusters is never mixed in etcd itself. Each cluster exposes its own etcd via a set of etcd proxies. In this demo I will use NodePort service. Cilium agents running in other clusters connect to the etcd proxies to watch for changes and replicate the multi-cluster relevant state into their own cluster. Use of etcd proxies ensures scalability of etcd watchers. Access is protected with TLS certificates.</p>
<p><img src="/img/include/clustermesh-arch.png" alt="Cilium clustermesh"  class="zoomable" /></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.11.11
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm repo add cilium https://helm.cilium.io/
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>helm upgrade --install cilium cilium/cilium <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set operator.replicas<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set cluster.id<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set cluster.name<span style="color:#f92672">=</span>k3scl1 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set tunnel<span style="color:#f92672">=</span>vxlan <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set kubeProxyReplacement<span style="color:#f92672">=</span>strict <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set containerRuntime.integration<span style="color:#f92672">=</span>containerd <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set etcd.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set etcd.managed<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set k8sServiceHost<span style="color:#f92672">=</span>10.0.2.15 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set k8sServicePort<span style="color:#f92672">=</span><span style="color:#ae81ff">6443</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-n kube-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | kubectl -n kube-system apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Service
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: cilium-etcd-external
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  type: NodePort
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - port: 2379
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: etcd
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    etcd_cluster: cilium-etcd
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    io.cilium/app: etcd-operator
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.11.12
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm repo add cilium https://helm.cilium.io/
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>helm upgrade --install cilium cilium/cilium <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set operator.replicas<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set cluster.id<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set cluster.name<span style="color:#f92672">=</span>k3scl2 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set tunnel<span style="color:#f92672">=</span>vxlan <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set containerRuntime.integration<span style="color:#f92672">=</span>containerd <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set etcd.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set etcd.managed<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set k8sServiceHost<span style="color:#f92672">=</span>10.0.2.15 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set k8sServicePort<span style="color:#f92672">=</span><span style="color:#ae81ff">6443</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-n kube-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | kubectl -n kube-system apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Service
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: cilium-etcd-external
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  type: NodePort
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - port: 2379
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: etcd
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    etcd_cluster: cilium-etcd
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    io.cilium/app: etcd-operator
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.11.13
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm repo add cilium https://helm.cilium.io/
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>helm upgrade --install cilium cilium/cilium <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set operator.replicas<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set cluster.id<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set cluster.name<span style="color:#f92672">=</span>k3scl3 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set tunnel<span style="color:#f92672">=</span>vxlan <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set containerRuntime.integration<span style="color:#f92672">=</span>containerd <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set etcd.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set etcd.managed<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set k8sServiceHost<span style="color:#f92672">=</span>10.0.2.15 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set k8sServicePort<span style="color:#f92672">=</span><span style="color:#ae81ff">6443</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-n kube-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | kubectl -n kube-system apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Service
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: cilium-etcd-external
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  type: NodePort
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - port: 2379
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: etcd
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    etcd_cluster: cilium-etcd
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    io.cilium/app: etcd-operator
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><h3 id="configure-cluster-mesh">Configure cluster mesh</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.11.11
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cd /tmp
</span></span><span style="display:flex;"><span>git clone https://github.com/cilium/clustermesh-tools.git
</span></span><span style="display:flex;"><span>cd clustermesh-tools
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>./extract-etcd-secrets.sh 
</span></span><span style="display:flex;"><span>Derived cluster-name k3scl1 from present ConfigMap
</span></span><span style="display:flex;"><span><span style="color:#f92672">====================================================</span>
</span></span><span style="display:flex;"><span> WARNING: The directory config contains private keys.
</span></span><span style="display:flex;"><span>          Delete after use.
</span></span><span style="display:flex;"><span><span style="color:#f92672">====================================================</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.11.12
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cd /tmp
</span></span><span style="display:flex;"><span>git clone https://github.com/cilium/clustermesh-tools.git
</span></span><span style="display:flex;"><span>cd clustermesh-tools
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>./extract-etcd-secrets.sh 
</span></span><span style="display:flex;"><span>Derived cluster-name k3scl2 from present ConfigMap
</span></span><span style="display:flex;"><span><span style="color:#f92672">====================================================</span>
</span></span><span style="display:flex;"><span> WARNING: The directory config contains private keys.
</span></span><span style="display:flex;"><span>          Delete after use.
</span></span><span style="display:flex;"><span><span style="color:#f92672">====================================================</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>scp -r config/ 172.17.11.11:/tmp/clustermesh-tools/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.11.13
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cd /tmp
</span></span><span style="display:flex;"><span>git clone https://github.com/cilium/clustermesh-tools.git
</span></span><span style="display:flex;"><span>cd clustermesh-tools
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>./extract-etcd-secrets.sh 
</span></span><span style="display:flex;"><span>Derived cluster-name k3scl3 from present ConfigMap
</span></span><span style="display:flex;"><span><span style="color:#f92672">====================================================</span>
</span></span><span style="display:flex;"><span> WARNING: The directory config contains private keys.
</span></span><span style="display:flex;"><span>          Delete after use.
</span></span><span style="display:flex;"><span><span style="color:#f92672">====================================================</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>scp -r config/ 172.17.11.11:/tmp/clustermesh-tools/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.11.11
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cd /tmp/clustermesh-tools/
</span></span><span style="display:flex;"><span>./generate-secret-yaml.sh &gt; clustermesh.yaml
</span></span><span style="display:flex;"><span>./generate-name-mapping.sh &gt; ds.patch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>scp clustermesh.yaml ds.patch 172.17.11.12:
</span></span><span style="display:flex;"><span>scp clustermesh.yaml ds.patch 172.17.11.13:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl -n kube-system patch ds cilium -p <span style="color:#e6db74">&#34;</span><span style="color:#66d9ef">$(</span>cat ds.patch<span style="color:#66d9ef">)</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>kubectl -n kube-system apply -f clustermesh.yaml
</span></span><span style="display:flex;"><span>kubectl -n kube-system delete pod -l k8s-app<span style="color:#f92672">=</span>cilium
</span></span><span style="display:flex;"><span>kubectl -n kube-system delete pod -l name<span style="color:#f92672">=</span>cilium-operator
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ssh 172.17.11.12 <span style="color:#e6db74">&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  kubectl -n kube-system patch ds cilium -p &#34;$(cat ds.patch)&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  kubectl -n kube-system apply -f clustermesh.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  kubectl -n kube-system delete pod -l k8s-app=cilium
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  kubectl -n kube-system delete pod -l name=cilium-operator
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ssh 172.17.11.13 <span style="color:#e6db74">&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  kubectl -n kube-system patch ds cilium -p &#34;$(cat ds.patch)&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  kubectl -n kube-system apply -f clustermesh.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  kubectl -n kube-system delete pod -l k8s-app=cilium
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  kubectl -n kube-system delete pod -l name=cilium-operator
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;</span>
</span></span></code></pre></div><p>Verify the cluster mesh by dumping the node list from any cilium. It should show all nodes in both the clusters.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get po -l k8s-app<span style="color:#f92672">=</span>cilium
</span></span><span style="display:flex;"><span>NAME           READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>cilium-6z8zf   1/1     Running   <span style="color:#ae81ff">0</span>          3m54s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl -n kube-system exec -ti cilium-6z8zf -- cilium node list
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>Defaulted container <span style="color:#e6db74">&#34;cilium-agent&#34;</span> out of: cilium-agent, mount-cgroup <span style="color:#f92672">(</span>init<span style="color:#f92672">)</span>, clean-cilium-state <span style="color:#f92672">(</span>init<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Name           IPv4 Address   Endpoint CIDR   IPv6 Address   Endpoint CIDR
</span></span><span style="display:flex;"><span>k3scl1/k3s01   172.17.11.11   10.0.0.0/24                    
</span></span><span style="display:flex;"><span>k3scl2/k3s02   172.17.11.12   10.0.0.0/24                    
</span></span><span style="display:flex;"><span>k3scl3/k3s03   172.17.11.13   10.0.0.0/24      
</span></span></code></pre></div><h3 id="test-the-connection">Test the connection</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">ssh vagrant@172.17.11.11</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">sudo su -</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl create ns test</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubens test</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl apply -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">test</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>The service discovery of Cilium&rsquo;s multi-cluster model is built using standard Kubernetes services and designed to be completely transparent to existing Kubernetes application deployments:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | kubectl apply -f -</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx-global</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">test</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">io.cilium/global-service</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><p>Cilium monitors Kubernetes services and endpoints and watches for services with an annotation <code>io.cilium/global-service: &quot;true&quot;</code>. For such services, all services with identical name and namespace information are automatically merged together and form a global service that is available across clusters.</p>
<h3 id="test-cl1">Test cl1</h3>
<p>After you deploy the global service to both of the clusters, you can test the connection:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl -n kube-system exec -ti cilium-6z8zf -- cilium service list 
</span></span><span style="display:flex;"><span>Defaulted container <span style="color:#e6db74">&#34;cilium-agent&#34;</span> out of: cilium-agent, mount-cgroup <span style="color:#f92672">(</span>init<span style="color:#f92672">)</span>, clean-cilium-state <span style="color:#f92672">(</span>init<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>ID   Frontend             Service Type   Backend                  
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">5</span>    10.43.200.118:80     ClusterIP      1 <span style="color:#f92672">=</span>&gt; 10.0.0.145:80       
</span></span><span style="display:flex;"><span>                                         2 <span style="color:#f92672">=</span>&gt; 10.0.0.69:80        
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl -n kube-system exec -ti cilium-6z8zf -- cilium bpf lb list 
</span></span><span style="display:flex;"><span>Defaulted container <span style="color:#e6db74">&#34;cilium-agent&#34;</span> out of: cilium-agent, mount-cgroup <span style="color:#f92672">(</span>init<span style="color:#f92672">)</span>, clean-cilium-state <span style="color:#f92672">(</span>init<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>SERVICE ADDRESS      BACKEND ADDRESS
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>10.43.200.118:80     10.0.0.69:80 <span style="color:#f92672">(</span>5<span style="color:#f92672">)</span>                          
</span></span><span style="display:flex;"><span>                     10.0.0.145:80 <span style="color:#f92672">(</span>5<span style="color:#f92672">)</span>                         
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run -it --rm --image<span style="color:#f92672">=</span>tianon/network-toolbox debian
</span></span><span style="display:flex;"><span>curl nginx-global
</span></span><span style="display:flex;"><span>&lt;!DOCTYPE html&gt;
</span></span><span style="display:flex;"><span>&lt;html&gt;
</span></span><span style="display:flex;"><span>&lt;head&gt;
</span></span><span style="display:flex;"><span>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span><span style="display:flex;"><span>&lt;style&gt;
</span></span><span style="display:flex;"><span>html <span style="color:#f92672">{</span> color-scheme: light dark; <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>body <span style="color:#f92672">{</span> width: 35em; margin: <span style="color:#ae81ff">0</span> auto;
</span></span><span style="display:flex;"><span>font-family: Tahoma, Verdana, Arial, sans-serif; <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>&lt;/style&gt;
</span></span><span style="display:flex;"><span>&lt;/head&gt;
</span></span><span style="display:flex;"><span>&lt;body&gt;
</span></span><span style="display:flex;"><span>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
</span></span><span style="display:flex;"><span>&lt;p&gt;If you see this page, the nginx web server is successfully installed and
</span></span><span style="display:flex;"><span>working. Further configuration is required.&lt;/p&gt;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&lt;p&gt;For online documentation and support please refer to
</span></span><span style="display:flex;"><span>&lt;a href<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;http://nginx.org/&#34;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
</span></span><span style="display:flex;"><span>Commercial support is available at
</span></span><span style="display:flex;"><span>&lt;a href<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;http://nginx.com/&#34;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&lt;p&gt;&lt;em&gt;Thank you <span style="color:#66d9ef">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;
</span></span><span style="display:flex;"><span>&lt;/body&gt;
</span></span><span style="display:flex;"><span>&lt;/html&gt;
</span></span></code></pre></div><h3 id="test-on-cl3">Test on cl3:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh 172.17.11.12
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create ns test
</span></span><span style="display:flex;"><span>kubens test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Service
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: nginx-global
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: test
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  annotations:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    io.cilium/global-service: &#34;true&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - name: http
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    port: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    protocol: TCP
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    targetPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: nginx
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl -n kube-system exec -ti cilium-8wzrc -- cilium service list
</span></span><span style="display:flex;"><span>Defaulted container <span style="color:#e6db74">&#34;cilium-agent&#34;</span> out of: cilium-agent, mount-cgroup <span style="color:#f92672">(</span>init<span style="color:#f92672">)</span>, clean-cilium-state <span style="color:#f92672">(</span>init<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>ID   Frontend            Service Type   Backend                  
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">8</span>    10.43.189.53:80     ClusterIP      1 <span style="color:#f92672">=</span>&gt; 10.0.0.69:80        
</span></span><span style="display:flex;"><span>                                        2 <span style="color:#f92672">=</span>&gt; 10.0.0.145:80
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl -n kube-system exec -ti cilium-8wzrc -- cilium bpf lb list
</span></span><span style="display:flex;"><span>Defaulted container <span style="color:#e6db74">&#34;cilium-agent&#34;</span> out of: cilium-agent, mount-cgroup <span style="color:#f92672">(</span>init<span style="color:#f92672">)</span>, clean-cilium-state <span style="color:#f92672">(</span>init<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>SERVICE ADDRESS     BACKEND ADDRESS
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>10.43.189.53:80     0.0.0.0:0 <span style="color:#f92672">(</span>8<span style="color:#f92672">)</span> <span style="color:#f92672">[</span>ClusterIP, non-routable<span style="color:#f92672">]</span>   
</span></span><span style="display:flex;"><span>                    10.0.0.69:80 <span style="color:#f92672">(</span>8<span style="color:#f92672">)</span>                          
</span></span><span style="display:flex;"><span>                    10.0.0.145:80 <span style="color:#f92672">(</span>8<span style="color:#f92672">)</span>                    
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl run -it --rm --image<span style="color:#f92672">=</span>tianon/network-toolbox debian
</span></span><span style="display:flex;"><span>curl nginx-global
</span></span><span style="display:flex;"><span>&lt;!DOCTYPE html&gt;
</span></span><span style="display:flex;"><span>&lt;html&gt;
</span></span><span style="display:flex;"><span>&lt;head&gt;
</span></span><span style="display:flex;"><span>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span><span style="display:flex;"><span>&lt;style&gt;
</span></span><span style="display:flex;"><span>html <span style="color:#f92672">{</span> color-scheme: light dark; <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>body <span style="color:#f92672">{</span> width: 35em; margin: <span style="color:#ae81ff">0</span> auto;
</span></span><span style="display:flex;"><span>font-family: Tahoma, Verdana, Arial, sans-serif; <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>&lt;/style&gt;
</span></span><span style="display:flex;"><span>&lt;/head&gt;
</span></span><span style="display:flex;"><span>&lt;body&gt;
</span></span><span style="display:flex;"><span>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
</span></span><span style="display:flex;"><span>&lt;p&gt;If you see this page, the nginx web server is successfully installed and
</span></span><span style="display:flex;"><span>working. Further configuration is required.&lt;/p&gt;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&lt;p&gt;For online documentation and support please refer to
</span></span><span style="display:flex;"><span>&lt;a href<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;http://nginx.org/&#34;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
</span></span><span style="display:flex;"><span>Commercial support is available at
</span></span><span style="display:flex;"><span>&lt;a href<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;http://nginx.com/&#34;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&lt;p&gt;&lt;em&gt;Thank you <span style="color:#66d9ef">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;
</span></span><span style="display:flex;"><span>&lt;/body&gt;
</span></span><span style="display:flex;"><span>&lt;/html&gt;
</span></span></code></pre></div><h3 id="multi-cluster-network-policy">Multi-cluster network policy</h3>
<p>It is possible to establish policies that apply to pod in particular clusters only. The cluster name is represented as a label on each pod by Cilium which allows to match on the cluster name in both the <code>endpointSelector</code> as well as the <code>matchLabels</code> for <code>toEndpoints</code> and fromEndpoints constructs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;cilium.io/v2&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">CiliumNetworkPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;allow-cross-cluster&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">description</span>: <span style="color:#e6db74">&#34;Allow x-wing in cluster1 to contact rebel-base in cluster2&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">endpointSelector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">x-wing</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">io.cilium.k8s.policy.cluster</span>: <span style="color:#ae81ff">cluster1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">egress</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">toEndpoints</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rebel-base</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">io.cilium.k8s.policy.cluster</span>: <span style="color:#ae81ff">cluster2</span>
</span></span></code></pre></div><p>The above example policy will allow <code>x-wing</code> in cluster1 to talk to <code>rebel-base</code> in cluster2. X-wings won&rsquo;t be able to talk to rebel bases in the local cluster unless additional policies exist that whitelist the communication.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                             
                                <category scheme="cluster-mesh" term="cluster-mesh" label="cluster-mesh" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="cilium" term="cilium" label="Cilium" />
                             
                                <category scheme="bgp" term="bgp" label="BGP" />
                             
                                <category scheme="cluster-mesh" term="cluster-mesh" label="cluster-mesh" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Free Docker Desktop Alternative For Mac And Windows]]></title>
            <link href="https://devopstales.github.io/kubernetes/docker-desktop-alternatives/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="related" type="text/html" title="Hardening Kubernetes with seccomp" />
                <link href="https://devopstales.github.io/kubernetes/kubernetes-deprecated-docker-containderd-docker/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes deprecated Docker? Containderd is the new Docker!!" />
                <link href="https://devopstales.github.io/linux/docker-on-fedora31/?utm_source=atom_feed" rel="related" type="text/html" title="Install docker on fedora 31" />
            
                <id>https://devopstales.github.io/kubernetes/docker-desktop-alternatives/</id>
            
            
            <published>2021-09-20T00:00:00+00:00</published>
            <updated>2021-09-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>At Aug. 31, 2022 Docker announced a new subscription plan for Docker Desktop. So we will Check the best alternatives for docker desktop on Windows an MacOS.</p>
<p>Docker Desktop remain free for:</p>
<ul>
<li>Small businesses with fewer than 250 employees and less than $10 million in annual revenue.</li>
<li>Personal use.</li>
<li>Educational institutions.</li>
<li>Non-commercial open-source projects.</li>
</ul>
<p>For professional usage, Docker Desktop will require a paid subscription (either Pro, Team or Business), which starts at $5 per month and goes up from there.</p>
<h2 id="podman">podman</h2>
<p>Podman is a tool for running OCI containers and pods.</p>
<h3 id="macos">MacOS</h3>
<p>You can do this from a MacOS desktop as long as you have access to a linux box either running inside of a VM on the host, or available via the network. Podman includes a command, podman machine that automatically manages VM’s.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install podman
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>podman machine init
</span></span><span style="display:flex;"><span>podman machine start
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>podman info
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>podman run -it --rm -d -p 8080:80 --name web nginx
</span></span></code></pre></div><h3 id="windows">Windows</h3>
<p>Podman can be run in the Windows Subsystem for Linux system.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wsl.exe --install
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>bash
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo apt-get -y update
</span></span><span style="display:flex;"><span>sudo apt-get -y install podman
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>podman info
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>podman run -it --rm -d -p 8080:80 --name web nginx
</span></span></code></pre></div><h2 id="lima-and-colima">lima and Colima</h2>
<p>Lima (Linux virtual machines, on macOS) launches Linux virtual machines with automatic file sharing, port forwarding, and containerd.</p>
<h3 id="macos-1">MacOS</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install lima
</span></span><span style="display:flex;"><span>limactl start
</span></span><span style="display:flex;"><span>lima nerdctl run -it --rm alpine
</span></span></code></pre></div><blockquote>
<p>NOTE: ARM Mac requires installing a patched version of QEMU, see <a href="https://github.com/lima-vm/lima#does-lima-work-on-arm-mac">Lima documentation</a></p></blockquote>
<p>If you want to use Kubernetes on Lima there is a project called Colima.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install lima docker kubectl
</span></span><span style="display:flex;"><span>curl -LO https://raw.githubusercontent.com/abiosoft/colima/v0.1.10/colima <span style="color:#f92672">&amp;&amp;</span> sudo install colima /usr/local/bin/colima
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>colima version
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>colima start --with-kubernetes
</span></span><span style="display:flex;"><span><span style="color:#75715e"># configure vm</span>
</span></span><span style="display:flex;"><span>colima stop
</span></span><span style="display:flex;"><span>colima start --cpu <span style="color:#ae81ff">4</span> --memory <span style="color:#ae81ff">8</span>
</span></span></code></pre></div><p>Lima is already adopted by Rancher Desktop to run k3s on macOS.</p>
<h2 id="rancher-desktop">Rancher Desktop</h2>
<p>Rancher Desktop is an open-source project to bring Kubernetes and container management to the desktop. Windows and macOS versions of Rancher Desktop are available for download.</p>
<h3 id="macos-2">MacOS</h3>
<p>Rancher Desktop requires the following on macOS.</p>
<ul>
<li>macOS 10.10 or higher.</li>
<li>Intel CPU with VT-x.</li>
<li>Persistent internet connection.</li>
</ul>
<p>Apple Silion (M1) support is planned, but not currently implemented.</p>
<h3 id="windows-1">Windows</h3>
<p>Rancher Desktop requires the following on Windows:</p>
<ul>
<li>Windows 10, at least version 1903.</li>
<li>Running on a machine with virtualization capabilities.</li>
<li>Persistent internet connection.</li>
</ul>
<p>Rancher Desktop requires Windows Subsystem for Linux on Windows; this will automatically be installed as part of the Rancher Desktop setup. Manually downloading a distribution is not necessary.</p>
<h3 id="install">Install</h3>
<p>Download and install the newes version fro <a href="https://github.com/rancher-sandbox/rancher-desktop/releases">GitHub</a> Then Start it.</p>
<p><img src="/img/include/racherdesktop01.png" alt="Rancher Desktop Architecture"  class="zoomable" /></p>
<p>Rancher Desktop installs a new Linux VM in WSL2 that has a Kubernetes cluster based on k3s as well as installs various components in it such as KIM (for building docker images on the cluster), helm cli and the Traefik Ingress Controller</p>
<p><img src="/img/include/racherdesktop02.png" alt="Rancher Desktop GUI1"  class="zoomable" /></p>
<p><img src="/img/include/racherdesktop03.png" alt="Rancher Desktop GUI2"  class="zoomable" /></p>
<h2 id="mikrok8s">mikrok8s</h2>
<p>MicroK8s is the simplest production-grade upstream K8s distribution.</p>
<h3 id="macos-3">MacOS</h3>
<p>To run mikrok8s on macOS you need at least 8GB of RAM:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install ubuntu/microk8s/microk8s
</span></span><span style="display:flex;"><span>microk8s install
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>microk8s status --wait-ready
</span></span><span style="display:flex;"><span>microk8s kubectl get nodes
</span></span><span style="display:flex;"><span>microk8s kubectl get services
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># enable addons</span>
</span></span><span style="display:flex;"><span>microk8s enable dns storage
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># manage vm</span>
</span></span><span style="display:flex;"><span>microk8s stop
</span></span><span style="display:flex;"><span>microk8s start
</span></span></code></pre></div><h3 id="windows-2">Windows</h3>
<p>To run mikrok8s on windows the requirements are:</p>
<ul>
<li>A Windows 10 machine with at least 8 GB of RAM and 40 GB storage</li>
<li>If you have Windows 10 Home edition, you will also need to install VirtualBox (Windows 10 Professional, Enterprise and Student editions include Hyper-v for virtualisation).</li>
</ul>
<p>MicroK8s has a Windows installer that will take care of setting up the software for you. <a href="https://github.com/ubuntu/microk8s/releases">Download the latest installer here.</a></p>
<p><img src="/img/include/mikrok8s01.png" alt="mikrok8s installer"  class="zoomable" /></p>
<p>The installer checks if Hyper-V is available and switched on. If you don’t have Hyper-v (e.g. on Windows 10 Home edition) it is possible to use VirtualBox as an alternative.</p>
<p>You can now configure MicroK8s - the minimum recommendations are already filled in.</p>
<p><img src="/img/include/mikrok8s02.png" alt="mikrok8s Config"  class="zoomable" /></p>
<p>Now you can tart an use micro k8s:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>microk8s status --wait-ready
</span></span><span style="display:flex;"><span>microk8s kubectl get nodes
</span></span><span style="display:flex;"><span>microk8s kubectl get services
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># enable addons</span>
</span></span><span style="display:flex;"><span>microk8s enable dns storage
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># manage vm</span>
</span></span><span style="display:flex;"><span>microk8s stop
</span></span><span style="display:flex;"><span>microk8s start
</span></span></code></pre></div><h2 id="minikube">minikube</h2>
<p>minikube implements a local Kubernetes cluster on macOS, Linux, and Windows. minikube&rsquo;s primary goals are to be the best tool for local Kubernetes application development and to support all Kubernetes features that fit.</p>
<h3 id="macos-4">MacOS</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install hyperkit minikube docker kubectl
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># configure vm</span>
</span></span><span style="display:flex;"><span>minikube config set memory <span style="color:#ae81ff">16384</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># set driver</span>
</span></span><span style="display:flex;"><span>minikube start --driver hyperkit
</span></span><span style="display:flex;"><span>minikube config set driver hyperkit
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># configure docker cli to connect minikube vm</span>
</span></span><span style="display:flex;"><span>eval <span style="color:#66d9ef">$(</span>minikube -p minikube docker-env<span style="color:#66d9ef">)</span>
</span></span></code></pre></div><h3 id="windows-3">Windows</h3>
<p>Install with exe from powershell:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -Lo minikube.exe https://github.com/kubernetes/minikube/releases/latest/download/minikube-windows-amd64.exe
</span></span><span style="display:flex;"><span>New-Item -Path <span style="color:#e6db74">&#34;c:\&#34; -Name &#34;</span>minikube<span style="color:#e6db74">&#34; -ItemType &#34;</span>directory<span style="color:#e6db74">&#34; -Force
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Move-Item .\minikube.exe c:\minikube\minikube.exe -Force
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"></span>$oldpath<span style="color:#e6db74">=[Environment]::GetEnvironmentVariable(&#34;</span>Path<span style="color:#e6db74">&#34;, [EnvironmentVariableTarget]::Machine)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">if(</span>$oldpath<span style="color:#e6db74"> -notlike &#34;</span>*;C:<span style="color:#ae81ff">\m</span>inikube*<span style="color:#e6db74">&#34;){`
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  [Environment]::SetEnvironmentVariable(&#34;</span>Path<span style="color:#e6db74">&#34;, </span>$oldpath<span style="color:#e6db74">+&#34;</span>;C:<span style="color:#ae81ff">\m</span>inikube<span style="color:#e6db74">&#34;, [EnvironmentVariableTarget]::Machine)`
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">}
</span></span></span></code></pre></div><p>Install wit Windows Package Manager:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>winget install minikube
</span></span></code></pre></div><p>using Chocolatey:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>choco install minikube
</span></span></code></pre></div><blockquote>
<p>VirtualBox and VMware Workstation (and VMware Player) are &ldquo;level 2 hypervisors.&rdquo; Hyper-V and VMware ESXi are &ldquo;level 1 hypervisors.&rdquo;
So wen Hyper-V is enabled your Windows 10 pc become a Virtualization Host. Hyper-V blocks all other Hyper Visors like VirtualBox from calling VT hardware.</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># to use with Hyper-V yo need to install</span>
</span></span><span style="display:flex;"><span>Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># configure vm</span>
</span></span><span style="display:flex;"><span>minikube config set memory <span style="color:#ae81ff">16384</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># set driver</span>
</span></span><span style="display:flex;"><span>minikube start --driver hyperv
</span></span><span style="display:flex;"><span>minikube config set driver hyperv
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="containerd" term="containerd" label="Containerd" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="docker" term="docker" label="docker" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Hardening Kubernetes with seccomp]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-seccomp/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/firecracker-cri-o/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy CRI-O with Firecracker?" />
                <link href="https://devopstales.github.io/kubernetes/gvisor-cri-o/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy CRI-O with gVisor?" />
                <link href="https://devopstales.github.io/kubernetes/firecracker-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with Firecracker?" />
                <link href="https://devopstales.github.io/kubernetes/gvisor-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with gVisor?" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-seccomp/</id>
            
            
            <published>2021-09-03T00:00:00+00:00</published>
            <updated>2021-09-03T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will attempt to demystify the relationship of <code>seccomp</code> and Kubernetes This first part will look at containers and pods.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>With Kubernetes version v1.22 there is a new alpha feature that provides a way to use the <code>RuntimeDefault</code> as the defaut seccomp profile insted of <code>Unconfined</code>. By default, when Kubernetes makes a new container it creates with <code>Unconfined</code> seccomp profile. This means that seccomp filtering is disabled.</p>
<h3 id="wthat-is-seccomp-profile">Wthat is seccomp profile?</h3>
<p><a href="https://en.wikipedia.org/wiki/Seccomp">Seccomp (Secure Computing)</a> is a feature in the Linux kernel. It allow to create profiles to filter <a href="https://en.wikipedia.org/wiki/System_call">system calls</a>. Usage of seccomp profiles on containers reduces the chance that a Linux kernel vulnerability will be exploited. All container runtimes ship with a default seccomp profile. The problem come when we using Kubernetes, beasuse Kubernetes use <code>Unconfined</code> as default and disables seccomp filtering.</p>
<p>For example Docker&rsquo;s default seccomp profile disables approximately 44 system calls of the 300+ currently availble.</p>
<h3 id="test-seccomp-profile">Test Seccomp profile.</h3>
<p>For the test I will use <code>amicontained</code> to inspection tool. First test in a simple docker.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker run --rm -it r.j3ss.co/amicontained bash
</span></span><span style="display:flex;"><span>Container Runtime: docker
</span></span><span style="display:flex;"><span>Has Namespaces:
</span></span><span style="display:flex;"><span>	pid: true
</span></span><span style="display:flex;"><span>	user: false
</span></span><span style="display:flex;"><span>AppArmor Profile: docker-default <span style="color:#f92672">(</span>enforce<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Capabilities:
</span></span><span style="display:flex;"><span>	BOUNDING -&gt; chown dac_override fowner fsetid kill setgid setuid setpcap net_bind_service net_raw sys_chroot mknod audit_write setfcap
</span></span><span style="display:flex;"><span>Seccomp: filtering
</span></span><span style="display:flex;"><span>Blocked Syscalls <span style="color:#f92672">(</span>60<span style="color:#f92672">)</span>:
</span></span><span style="display:flex;"><span>	SYSLOG SETPGID SETSID USELIB USTAT SYSFS VHANGUP PIVOT_ROOT _SYSCTL ACCT SETTIMEOFDAY MOUNT UMOUNT2 SWAPON SWAPOFF REBOOT SETHOSTNAME SETDOMAINNAME IOPL IOPERM CREATE_MODULE INIT_MODULE DELETE_MODULE GET_KERNEL_SYMS QUERY_MODULE QUOTACTL NFSSERVCTL GETPMSG PUTPMSG AFS_SYSCALL TUXCALL SECURITY LOOKUP_DCOOKIE CLOCK_SETTIME VSERVER MBIND SET_MEMPOLICY GET_MEMPOLICY KEXEC_LOAD ADD_KEY REQUEST_KEY KEYCTL MIGRATE_PAGES UNSHARE MOVE_PAGES PERF_EVENT_OPEN FANOTIFY_INIT NAME_TO_HANDLE_AT OPEN_BY_HANDLE_AT SETNS PROCESS_VM_READV PROCESS_VM_WRITEV KCMP FINIT_MODULE KEXEC_FILE_LOAD BPF USERFAULTFD PKEY_MPROTECT PKEY_ALLOC PKEY_FREE
</span></span><span style="display:flex;"><span>Looking <span style="color:#66d9ef">for</span> Docker.sock
</span></span></code></pre></div><p>As you can see with the default Docker secom profile 60 Syscalls are being blocked. Now test wit default Kubernetes config on docker.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run -it bash --image<span style="color:#f92672">=</span>r.j3ss.co/amicontained --restart<span style="color:#f92672">=</span>Never bash
</span></span><span style="display:flex;"><span>Container Runtime: docker
</span></span><span style="display:flex;"><span>Has Namespaces:
</span></span><span style="display:flex;"><span> pid: true
</span></span><span style="display:flex;"><span> user: false
</span></span><span style="display:flex;"><span>AppArmor Profile: unconfined
</span></span><span style="display:flex;"><span>Capabilities:
</span></span><span style="display:flex;"><span> BOUNDING -&gt; chown dac_override fowner fsetid kill setgid setuid setpcap net_bind_service net_raw sys_chroot mknod audit_write setfcap
</span></span><span style="display:flex;"><span>Seccomp: disabled
</span></span><span style="display:flex;"><span>Blocked Syscalls <span style="color:#f92672">(</span>21<span style="color:#f92672">)</span>:
</span></span><span style="display:flex;"><span> MSGRCV SYSLOG SETSID VHANGUP PIVOT_ROOT ACCT SETTIMEOFDAY SWAPON SWAPOFF REBOOT SETHOSTNAME SETDOMAINNAME INIT_MODULE DELETE_MODULE LOOKUP_DCOOKIE KEXEC_LOAD FANOTIFY_INIT OPEN_BY_HANDLE_AT FINIT_MODULE KEXEC_FILE_LOAD BPF
</span></span><span style="display:flex;"><span>Looking <span style="color:#66d9ef">for</span> Docker.sock
</span></span></code></pre></div><p>In the output above you can see that seccomp is disabled and that 21 syscalls are being blocked. Now test wit default Kubernetes config on rke2 (containerd).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run -it bash --image<span style="color:#f92672">=</span>r.j3ss.co/amicontained --restart<span style="color:#f92672">=</span>Never bash
</span></span><span style="display:flex;"><span>Container Runtime: kube
</span></span><span style="display:flex;"><span>Has Namespaces:
</span></span><span style="display:flex;"><span>	pid: true
</span></span><span style="display:flex;"><span>	user: false
</span></span><span style="display:flex;"><span>AppArmor Profile: system_u:system_r:container_t:s0:c575,c847
</span></span><span style="display:flex;"><span>Capabilities:
</span></span><span style="display:flex;"><span>	BOUNDING -&gt; chown dac_override fowner fsetid kill setgid setuid setpcap net_bind_service net_raw sys_chroot mknod audit_write setfcap
</span></span><span style="display:flex;"><span>Seccomp: disabled
</span></span><span style="display:flex;"><span>Blocked Syscalls <span style="color:#f92672">(</span>22<span style="color:#f92672">)</span>:
</span></span><span style="display:flex;"><span>	SYSLOG SETPGID SETSID VHANGUP PIVOT_ROOT ACCT SETTIMEOFDAY UMOUNT2 SWAPON SWAPOFF REBOOT SETHOSTNAME SETDOMAINNAME INIT_MODULE DELETE_MODULE LOOKUP_DCOOKIE KEXEC_LOAD FANOTIFY_INIT OPEN_BY_HANDLE_AT FINIT_MODULE KEXEC_FILE_LOAD BPF
</span></span><span style="display:flex;"><span>Looking <span style="color:#66d9ef">for</span> Docker.sock
</span></span><span style="display:flex;"><span>pod default/bash terminated <span style="color:#f92672">(</span>Error<span style="color:#f92672">)</span>
</span></span></code></pre></div><p>The <code>containerd</code> is similar then docker so lets test with <code>CRI-O</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run -it bash --image<span style="color:#f92672">=</span>bash --restart<span style="color:#f92672">=</span>Never bash
</span></span><span style="display:flex;"><span><span style="color:#75715e"># apk add curl</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># curl -LO k8s.work/amicontained</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># chmod +x amicontained</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ./amicontained</span>
</span></span><span style="display:flex;"><span>Container Runtime: kube
</span></span><span style="display:flex;"><span>Has Namespaces:
</span></span><span style="display:flex;"><span>	pid: true
</span></span><span style="display:flex;"><span>	user: false
</span></span><span style="display:flex;"><span>AppArmor Profile: system_u:system_r:spc_t:s0
</span></span><span style="display:flex;"><span>Capabilities:
</span></span><span style="display:flex;"><span>	BOUNDING -&gt; chown dac_override fowner fsetid kill setgid setuid setpcap net_bind_service
</span></span><span style="display:flex;"><span>Seccomp: disabled
</span></span><span style="display:flex;"><span>Blocked Syscalls <span style="color:#f92672">(</span>22<span style="color:#f92672">)</span>:
</span></span><span style="display:flex;"><span>	MSGRCV SYSLOG SETSID VHANGUP PIVOT_ROOT ACCT SETTIMEOFDAY UMOUNT2 SWAPON SWAPOFF REBOOT SETHOSTNAME SETDOMAINNAME INIT_MODULE DELETE_MODULE LOOKUP_DCOOKIE KEXEC_LOAD FANOTIFY_INIT OPEN_BY_HANDLE_AT FINIT_MODULE KEXEC_FILE_LOAD BPF
</span></span><span style="display:flex;"><span>Looking <span style="color:#66d9ef">for</span> Docker.sock
</span></span></code></pre></div><h3 id="enable-runtimedefault-seccomp-profile">Enable RuntimeDefault seccomp profile</h3>
<p>Enable in local kubelet config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /var/lib/kubelet/config.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>--feature-gates<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;...,SeccompDefault=true&#34;</span>
</span></span><span style="display:flex;"><span>--seccomp-default RuntimeDefault
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl restart kubelet
</span></span></code></pre></div><p>Enable in running kubelet config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl edit cm kubelet-config-1.22 -n kub-system
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>- --feature-gates<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;...,SeccompDefault=true&#34;</span>
</span></span><span style="display:flex;"><span>- --seccomp-default RuntimeDefault
</span></span></code></pre></div><p>Then test:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run -it bash --image<span style="color:#f92672">=</span>r.j3ss.co/amicontained --restart<span style="color:#f92672">=</span>Never bash
</span></span><span style="display:flex;"><span>Container Runtime: docker
</span></span><span style="display:flex;"><span>Has Namespaces:
</span></span><span style="display:flex;"><span> pid: true
</span></span><span style="display:flex;"><span> user: false
</span></span><span style="display:flex;"><span>AppArmor Profile: unconfined
</span></span><span style="display:flex;"><span>Capabilities:
</span></span><span style="display:flex;"><span> BOUNDING -&gt; chown dac_override fowner fsetid kill setgid setuid setpcap net_bind_service net_raw sys_chroot mknod audit_write setfcap
</span></span><span style="display:flex;"><span>Seccomp: filtering
</span></span><span style="display:flex;"><span>Blocked Syscalls <span style="color:#f92672">(</span>61<span style="color:#f92672">)</span>:
</span></span><span style="display:flex;"><span> MSGRCV PTRACE SYSLOG SETSID USELIB USTAT SYSFS VHANGUP PIVOT_ROOT _SYSCTL ACCT SETTIMEOFDAY MOUNT UMOUNT2 SWAPON SWAPOFF REBOOT SETHOSTNAME SETDOMAINNAME IOPL IOPERM CREATE_MODULE INIT_MODULE DELETE_MODULE GET_KERNEL_SYMS QUERY_MODULE QUOTACTL NFSSERVCTL GETPMSG PUTPMSG AFS_SYSCALL TUXCALL SECURITY LOOKUP_DCOOKIE CLOCK_SETTIME VSERVER MBIND SET_MEMPOLICY GET_MEMPOLICY KEXEC_LOAD ADD_KEY REQUEST_KEY KEYCTL MIGRATE_PAGES UNSHARE MOVE_PAGES PERF_EVENT_OPEN FANOTIFY_INIT NAME_TO_HANDLE_AT OPEN_BY_HANDLE_AT SETNS PROCESS_VM_READV PROCESS_VM_WRITEV KCMP FINIT_MODULE KEXEC_FILE_LOAD BPF USERFAULTFD PKEY_MPROTECT PKEY_ALLOC PKEY_FREE
</span></span><span style="display:flex;"><span>Looking <span style="color:#66d9ef">for</span> Docker.sock
</span></span></code></pre></div><h3 id="customizing-a-profile">Customizing a Profile</h3>
<p>One way to write <code>seccomp</code> filter is to use Berkeley packet filter (BPF) language. Using this language isn&rsquo;t really simple or convenient. We can write JSON that is compiled into profile by <code>libseccomp</code>.</p>
<p>If you were to create a profile to allow a container to execute a ping against a website, you can use <code>strace</code> command to find the syscalls it makes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>strace -fqc ping -c <span style="color:#ae81ff">20</span> www.google.com% time     seconds  usecs/call     calls    errors syscall
</span></span><span style="display:flex;"><span>------ ----------- ----------- --------- --------- ----------------
</span></span><span style="display:flex;"><span> 29.55    0.000078           <span style="color:#ae81ff">4</span>        <span style="color:#ae81ff">20</span>        <span style="color:#ae81ff">11</span> openat
</span></span><span style="display:flex;"><span> 14.02    0.000037           <span style="color:#ae81ff">9</span>         <span style="color:#ae81ff">4</span>         <span style="color:#ae81ff">4</span> socket
</span></span><span style="display:flex;"><span> 11.74    0.000031           <span style="color:#ae81ff">3</span>        <span style="color:#ae81ff">12</span>           mprotect
</span></span><span style="display:flex;"><span>  6.06    0.000016           <span style="color:#ae81ff">2</span>         <span style="color:#ae81ff">7</span>           read
</span></span><span style="display:flex;"><span>  5.68    0.000015           <span style="color:#ae81ff">1</span>        <span style="color:#ae81ff">17</span>           mmap
</span></span><span style="display:flex;"><span>  5.68    0.000015           <span style="color:#ae81ff">3</span>         <span style="color:#ae81ff">5</span>           capget
</span></span><span style="display:flex;"><span>  4.92    0.000013          <span style="color:#ae81ff">13</span>         <span style="color:#ae81ff">1</span>           munmap
</span></span><span style="display:flex;"><span>  3.79    0.000010           <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">9</span>           fstat
</span></span><span style="display:flex;"><span>  3.41    0.000009           <span style="color:#ae81ff">9</span>         <span style="color:#ae81ff">1</span>           write
</span></span><span style="display:flex;"><span>  3.41    0.000009           <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">9</span>           close
</span></span><span style="display:flex;"><span>  2.65    0.000007           <span style="color:#ae81ff">2</span>         <span style="color:#ae81ff">3</span>           brk
</span></span><span style="display:flex;"><span>  2.65    0.000007           <span style="color:#ae81ff">4</span>         <span style="color:#ae81ff">2</span>           prctl
</span></span><span style="display:flex;"><span>  2.27    0.000006           <span style="color:#ae81ff">3</span>         <span style="color:#ae81ff">2</span>           getuid
</span></span><span style="display:flex;"><span>  1.52    0.000004           <span style="color:#ae81ff">4</span>         <span style="color:#ae81ff">1</span>           setuid
</span></span><span style="display:flex;"><span>  1.52    0.000004           <span style="color:#ae81ff">4</span>         <span style="color:#ae81ff">1</span>           capset
</span></span><span style="display:flex;"><span>  1.14    0.000003           <span style="color:#ae81ff">3</span>         <span style="color:#ae81ff">1</span>           geteuid
</span></span><span style="display:flex;"><span>  0.00    0.000000           <span style="color:#ae81ff">0</span>         <span style="color:#ae81ff">9</span>         <span style="color:#ae81ff">9</span> access
</span></span><span style="display:flex;"><span>  0.00    0.000000           <span style="color:#ae81ff">0</span>         <span style="color:#ae81ff">1</span>           execve
</span></span><span style="display:flex;"><span>  0.00    0.000000           <span style="color:#ae81ff">0</span>         <span style="color:#ae81ff">3</span>           fcntl
</span></span><span style="display:flex;"><span>  0.00    0.000000           <span style="color:#ae81ff">0</span>         <span style="color:#ae81ff">1</span>           arch_prctl
</span></span><span style="display:flex;"><span>------ ----------- ----------- --------- --------- ----------------
</span></span><span style="display:flex;"><span>100.00    0.000264                   <span style="color:#ae81ff">109</span>        <span style="color:#ae81ff">24</span> total
</span></span></code></pre></div><p>A nothe solution is a tool called <a href="https://github.com/pjbgf/zaz">zaz</a> created by <a href="https://github.com/pjbgf">Paulo Gomes</a> That generate a seccomp prifile for you with the minimum system calls:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>zaz seccomp docker alpine <span style="color:#e6db74">&#34;ping -c5 8.8.8.8&#34;</span>
</span></span></code></pre></div><p>A basic seccomp has three key elements: the <code>defaultAction</code>, the <code>architectures</code> (or <code>archMap</code>) and the <code>syscalls</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">mkdir</span> <span style="color:#960050;background-color:#1e0010">/var/lib/kubelet/seccomp</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">nano</span> <span style="color:#960050;background-color:#1e0010">/var/lib/kubelet/seccomp/sample.json</span>
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;defaultAction&#34;</span>: <span style="color:#e6db74">&#34;SCMP_ACT_ERRNO&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;architectures&#34;</span>: [
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;SCMP_ARCH_X86_64&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;SCMP_ARCH_X86&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;SCMP_ARCH_X32&#34;</span>
</span></span><span style="display:flex;"><span>    ],
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;syscalls&#34;</span>: [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;names&#34;</span>: [
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;arch_prctl&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;sched_yield&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;futex&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;write&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;mmap&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;exit_group&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;madvise&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;rt_sigprocmask&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;getpid&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;gettid&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;tgkill&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;rt_sigaction&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;read&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;getpgrp&#34;</span>
</span></span><span style="display:flex;"><span>            ],
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;action&#34;</span>: <span style="color:#e6db74">&#34;SCMP_ACT_ALLOW&#34;</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">&#34;args&#34;</span>: [],
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">&#34;comment&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">&#34;includes&#34;</span>: {},
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">&#34;excludes&#34;</span>: {}
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>defaultAction</code> is <code>SCMP_ACT_ERRNO</code> which will block the execution of any system call. The we list the <code>syscalls</code> what we want to whitelist.</p>
<h3 id="the-different-types-of-actions">The different types of actions</h3>
<p>Below is a list of all the different types of actions and what they do:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>SCMP_ACT_KILL_THREAD <span style="color:#f92672">(</span>or SCMP_ACT_KILL<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Does not execute the syscall and terminate the thread that attempted making the call. Note that depending on the application being enforced <span style="color:#f92672">(</span>i.e. multi-threading<span style="color:#f92672">)</span> and its error handling, syscalls blocked using this action may <span style="color:#66d9ef">do</span> so silently which may result in side effects on the overall application.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>SCMP_ACT_TRAP
</span></span><span style="display:flex;"><span>Does not execute the syscall. The kernel will send a thread-directed SIGSYS signal to the thread that attempted making the call.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>SCMP_ACT_ERRNO
</span></span><span style="display:flex;"><span>Does not execute the syscall, returns error instead. Note that depending on the error handling of the application being enforced, syscalls blocked using this action may <span style="color:#66d9ef">do</span> so silently which may result in side effects on the overall application.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>SCMP_ACT_TRACE
</span></span><span style="display:flex;"><span>The decision on whether or not to execute the syscall will come from a tracer. If no tracer is present behaves like SECCOMP_RET_ERRNO.
</span></span><span style="display:flex;"><span>This can be used to automate profile generation and also can be used to change the syscall being made. Not recommended when trying to enforce seccomp to line of business applications.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>SCMP_ACT_ALLOW
</span></span><span style="display:flex;"><span>Executes the syscall.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>SCMP_ACT_LOG <span style="color:#f92672">(</span>since Linux 4.14<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Executes the syscall. Useful <span style="color:#66d9ef">for</span> running seccomp in <span style="color:#e6db74">&#34;complain-mode&#34;</span>, logging the syscalls that are mapped <span style="color:#f92672">(</span>or catch-all<span style="color:#f92672">)</span> and not blocking their execution. It can be used together with other action types to provide an allow and deny list approach.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>SCMP_ACT_KILL_PROCESS <span style="color:#f92672">(</span>since Linux 4.14<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Does not execute the syscall and terminates the entire process with a core dump. Very useful when automating the profile generation.
</span></span></code></pre></div><h3 id="configure-on-a-pod">Configure on a pod</h3>
<p>With Kubernetes version v1.19 Seccomp Profile for a Container is GA. The sintax looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">some-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">some-pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">seccompProfile</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Localhost</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">localhostProfile</span>: <span style="color:#ae81ff">sample.json</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">...</span>
</span></span></code></pre></div><p>Valid options for <code>type</code> include <code>RuntimeDefault</code>, <code>Unconfined</code>, and <code>Localhost</code>. Here is an example that sets the Seccomp profile to the node&rsquo;s container runtime default profile:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">some-pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">some-pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">seccompProfile</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">type</span>: <span style="color:#ae81ff">RuntimeDefault</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">...</span>
</span></span></code></pre></div><p>This Configuration is the same then setting <code>SeccompDefault=true</code> in kubelet config.</p>
<h3 id="add-audit-profile">Add audit profile</h3>
<p>Since linux kernel 4.14 it is now possible to define parts of your profile to run in audit mode, logging into syslog all the system calls you want without blocking them. To do that you can use the action SCMT_ACT_LOG:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">nano</span> <span style="color:#960050;background-color:#1e0010">/var/lib/kubelet/seccomp/audit.json</span>
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;defaultAction&#34;</span>: <span style="color:#e6db74">&#34;SCMP_ACT_LOG&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;architectures&#34;</span>: [
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;SCMP_ARCH_X86_64&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;SCMP_ARCH_X86&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;SCMP_ARCH_X32&#34;</span>
</span></span><span style="display:flex;"><span>    ],
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;syscalls&#34;</span>: [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;names&#34;</span>: [
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;arch_prctl&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;sched_yield&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;futex&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;write&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;mmap&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;exit_group&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;madvise&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;rt_sigprocmask&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;getpid&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;gettid&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;tgkill&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;rt_sigaction&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;read&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;getpgrp&#34;</span>
</span></span><span style="display:flex;"><span>            ],
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;action&#34;</span>: <span style="color:#e6db74">&#34;SCMP_ACT_ALLOW&#34;</span>
</span></span><span style="display:flex;"><span>        },
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;names&#34;</span>: [
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;add_key&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;keyctl&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;ptrace&#34;</span>
</span></span><span style="display:flex;"><span>            ],
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;action&#34;</span>: <span style="color:#e6db74">&#34;SCMP_ACT_ERRNO&#34;</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>~ $ tail /var/log/syslog
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Nov <span style="color:#ae81ff">25</span> 19:38:18 kernel: <span style="color:#f92672">[</span>461698.749294<span style="color:#f92672">]</span> audit: ... syscall<span style="color:#f92672">=</span><span style="color:#ae81ff">21</span> compat<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> ip<span style="color:#f92672">=</span>0x7ff8f8412d5b code<span style="color:#f92672">=</span>0x7ffc0000    <span style="color:#75715e"># access</span>
</span></span><span style="display:flex;"><span>Nov <span style="color:#ae81ff">25</span> 19:38:18 kernel: <span style="color:#f92672">[</span>461698.749306<span style="color:#f92672">]</span> audit: ... syscall<span style="color:#f92672">=</span><span style="color:#ae81ff">257</span> compat<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> ip<span style="color:#f92672">=</span>0x7ff8f8412ec8 code<span style="color:#f92672">=</span>0x7ffc0000   <span style="color:#75715e"># openat</span>
</span></span><span style="display:flex;"><span>Nov <span style="color:#ae81ff">25</span> 19:38:18 kernel: <span style="color:#f92672">[</span>461698.749315<span style="color:#f92672">]</span> audit: ... syscall<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span> compat<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> ip<span style="color:#f92672">=</span>0x7ff8f8412c99 code<span style="color:#f92672">=</span>0x7ffc0000     <span style="color:#75715e"># fstat</span>
</span></span><span style="display:flex;"><span>Nov <span style="color:#ae81ff">25</span> 19:38:18 kernel: <span style="color:#f92672">[</span>461698.749317<span style="color:#f92672">]</span> audit: ... syscall<span style="color:#f92672">=</span><span style="color:#ae81ff">9</span> compat<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> ip<span style="color:#f92672">=</span>0x7ff8f84130e6 code<span style="color:#f92672">=</span>0x7ffc0000     <span style="color:#75715e"># mmap</span>
</span></span><span style="display:flex;"><span>Nov <span style="color:#ae81ff">25</span> 19:38:18 kernel: <span style="color:#f92672">[</span>461698.749323<span style="color:#f92672">]</span> audit: ... syscall<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> compat<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> ip<span style="color:#f92672">=</span>0x7ff8f8412d8b code<span style="color:#f92672">=</span>0x7ffc0000     <span style="color:#75715e"># close</span>
</span></span></code></pre></div><h3 id="set-capabilities-for-a-container">Set capabilities for a Container</h3>
<p>With version 1.22 you should be able to change the sysctl in the security context of your pod manifests, allowing containers that are running as unprivileged users to bind low ports.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">sysctls</span>:
</span></span><span style="display:flex;"><span>     - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">net.ipv4.ip_unprivileged_port_start</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;1&#34;</span>
</span></span></code></pre></div><h3 id="final-words">Final Words</h3>
<p>Whatever you define in your seccomp profile, the kernel will enforce it. Even if that is not what you want. For example, if you block access to calls such as exit or exit_group your container may not be able to exit and it could trap the container in an exit loop indefinitely. Leading to high CPU usage of your cluster.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="docker" term="docker" label="docker" />
                             
                                <category scheme="containerd" term="containerd" label="containerd" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                             
                                <category scheme="seccomp" term="seccomp" label="seccomp" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Understanding kubernetes networking: owerlay networks]]></title>
            <link href="https://devopstales.github.io/kubernetes/kubernetes-networking-2/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/kubernetes-networking-1/?utm_source=atom_feed" rel="related" type="text/html" title="Understanding kubernetes networking: pods and services" />
                <link href="https://devopstales.github.io/kubernetes/rke2-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With cilium" />
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
                <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s and calico with eBPF mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kyverno-cosign/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification with Kyverno" />
            
                <id>https://devopstales.github.io/kubernetes/kubernetes-networking-2/</id>
            
            
            <published>2021-08-31T00:00:00+00:00</published>
            <updated>2021-08-31T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In my previous posts We check <a href="/kubernetes-networking-1/">how the pod networking</a> and <a href="/kubernetes-networking-1/">How Kubernetes use services for loadbalancing</a>. Now we check how the diferente Networking solutions works. How Theas solutins link the kubernetes nodes together.</p>
<p>Kubernetes was built to run distributed systems over a cluster of machines. This meanns networking is a central point of all Kubernetes clusters. Kubernetes dose not hawe an includid network solution, you haw to chouse one. Withouth this solutions all host whou be a closed separated ecosistem. Many kubernetes deployment guides provide instructions for deploying a kubernetes networking (CNI) to your cluster. The most polular solutions are Calico, Flannel, Weave, and Cilium. Most time you simpli deploy a yaml or a helm chart, but we didn&rsquo;t undestand how theas solutions works. Understanding the Kubernetes networking model will allow you to easely troubleshoot your applications running on Kubernetes.</p>
<h2 id="what-is-a-cni">What is a CNI?</h2>
<p>The CNI (Container Network Interface) project describes the specifications to provide a generic plugin-based networking solution for linux containers. A CNI plugin is an executable and it&rsquo;s config that follows the CNI spec and we’ll discuss some plugins in the post below.</p>
<h3 id="overlay-network">Overlay network</h3>
<p>The concept of overlay networking has been around for a while, but has made a return to the spotlight with the rise of Docker and Kubernetes. It is  basicly a virtual network of nodes and logical links, which are built on top of an existing network. To solve this chelange the CNI plugins use two main aprouch VXLAN (Virtual Extensible LAN) and simple layer3 routing. The aim of an overlay network is to enable a new service or function without having to reconfigure the entire network design.</p>
<h3 id="node-ipam-controller">Node IPAM Controller</h3>
<p>All pods are required to have an IP address. it’s important to ensure that all pods across the entire cluster have a unique IP address. <code>kube-controller-manager</code> allocates each node a dedicated subnet (podCIDR) from the cluster CIDR (IP range for the cluster network) For example if the overlay network is <code>10.244.0.0/16</code> all the kubernetes hosts gets a <code>/24</code> segment so the master01 is <code>10.244.0.0/24</code> the master02 is <code>10.244.1.0/24</code> and so on. podCIDR for a node can be listed using the following command:
cidr</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get no &lt;nodeName&gt; -o json | jq <span style="color:#e6db74">&#39;.spec.podCIDR&#39;</span>
</span></span><span style="display:flex;"><span>10.244.0.0/24
</span></span></code></pre></div><h3 id="flannel">Flannel</h3>
<p>Flannel runs a small, single binary agent called flanneld on each host, and is responsible for allocating a subnet lease to each host out of a larger, preconfigured address space. Flannel uses either the Kubernetes API or etcd directly to store the network configuration, the allocated subnets, and any auxiliary data (such as the host&rsquo;s public IP). Packets are forwarded using one of several backend mechanisms including VXLAN and various cloud integrations. (Refer to <a href="https://github.com/flannel-io/flannel">Flannel</a>)</p>
<p><img src="/img/include/flannel-01.png" alt="Flannel"  class="zoomable" /></p>
<h3 id="calico">Calico</h3>
<p>Calico originally used a pure 3-layer protocol to support multi-host network communication. On each host a vRouter propagates workload reachability information (routes) to the rest of the data center using BGP protocol. The pure Layer 3 approach avoids the packet encapsulation associated with the Layer 2 solution which simplifies diagnostics, reduces transport overhead and improves performance. Calico also implements VxLAN and the newer version use VxLAN as it&rsquo;s default soluton.</p>
<p><img src="/img/include/calicodd.png" alt="Calico"  class="zoomable" /></p>
<h3 id="weave-net">Weave Net</h3>
<p>Connectivity is set up by the weave-net binary by attaching pods to the weave Linux bridge. The bridge is, in turn, attached to the Open vSwitch’s kernel datapath which forwards the packets over the vxlan interface towards the target node.</p>
<h3 id="cilium">Cilium</h3>
<p>Cilium is one of the most advanced and powerful Kubernetes networking solutions. At its core, it utilizes the power of <a href="https://ebpf.io/">eBPF</a> to perform a wide range of functionality ranging from traffic filtering for NetworkPolicies all the way to CNI and <a href="https://k8s.networkop.co.uk/cni/cilium/">kube-proxy replacement</a>. BPF is basically the ability of an application developer to write a program, load that into the Linux kernel, then run it when certain events happen.</p>
<p><img src="/img/include/ciliumart2.png" alt="Cilium"  class="zoomable" /></p>
<table>
  <thead>
      <tr>
          <th>Features/Capabilities</th>
          <th>Calico</th>
          <th>Flannel</th>
          <th>Weave</th>
          <th>Cilium</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Network Model</td>
          <td>BGP or VxLAN</td>
          <td>VxLAN or UDP Channel</td>
          <td>VxLAN or UDP Channel</td>
          <td>VXLAN or Geneve</td>
      </tr>
      <tr>
          <td>Encryption Channel</td>
          <td>✓</td>
          <td>✓</td>
          <td>✓</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>NetworkPolicies</td>
          <td>✓</td>
          <td>X</td>
          <td>✓</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>kube-proxy replacement</td>
          <td>✓</td>
          <td>X</td>
          <td>X</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>Egress Routing</td>
          <td>X</td>
          <td>X</td>
          <td>X</td>
          <td>✓</td>
      </tr>
  </tbody>
</table>
<h2 id="cluster-mesh">Cluster mesh</h2>
<p>Cluster mesh enables direct networking between Pods and Services in different Kubernetes clusters, either on-premises or in the cloud.</p>
<h3 id="cilium-clustermesh">Cilium ClusterMesh</h3>
<p>As Kubernetes gains adoption, teams are finding they must deploy and manage multiple clusters to facilitate features like geo-redundancy, scale, and fault isolation for their applications. Cilium’s multi-cluster implementation provides the following features:</p>
<ul>
<li>Inter-cluster pod-to-pod connectivity without gateways or proxies.</li>
<li>Transparent service discovery across clusters using standard Kubernetes services and CoreDNS.</li>
<li>Network policy enforcement across clusters.</li>
<li>Encryption in transit between nodes within a cluster as well as across cluster boundaries.</li>
</ul>
<p><img src="/img/include/clustermesh-arch.png" alt="Cilium clustermesh"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="calico" term="calico" label="calico" />
                             
                                <category scheme="cilium" term="cilium" label="cilium" />
                             
                                <category scheme="flannel" term="flannel" label="Flannel" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Understanding kubernetes networking: pods and services]]></title>
            <link href="https://devopstales.github.io/kubernetes/kubernetes-networking-1/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s and calico with eBPF mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ipvs/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s with IPVS mode" />
                <link href="https://devopstales.github.io/kubernetes/rke2-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With cilium" />
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kyverno-cosign/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification with Kyverno" />
            
                <id>https://devopstales.github.io/kubernetes/kubernetes-networking-1/</id>
            
            
            <published>2021-08-30T00:00:00+00:00</published>
            <updated>2021-08-30T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this series I will attempt to demystify the Kubernetes networkiing layers. This first part will look at containers and pods.</p>
<h3 id="what-is-a-pod">What is a pod?</h3>
<p>A Pod is the atom of Kubernetes — the smallest deployable object for building applications.  A single Pod represents an applications in your cluster and encapsulates one or more containers. Containers that make up a pod are designed to be co-located and scheduled on the same machine. They share the same resources like ip, network and volumes. In Linux, each running process communicates within a <a href="https://en.wikipedia.org/wiki/Linux_namespaces">Linux namespace</a> that provides a logical networking stack. In essence, a pod is a representation of a Linux namespace that allow the containers to usa the same resources. Containers within a Pod all have the same IP address and port range. They can find each other via localhost since they reside in the same namespace. This means the containers in a pod can not us the same ports.</p>
<p><img src="/img/include/k8s-pod-ip-with-cni.png" alt="Pow With IP"  class="zoomable" /></p>
<p><img src="/img/include/kubernetes-network-1-1.png" alt="Pod Network"  class="zoomable" /></p>
<p>Kubernetes creates a special container for each pod whose purpose is to provide a network interface for the other containers. This is the &ldquo;pause&rdquo; container.</p>
<p><img src="/img/include/kubernetes-network-1-2.png" alt="Pod Network"  class="zoomable" /></p>
<h3 id="pod-to-pod-communication">Pod-to-Pod communication</h3>
<p>Every Pod has a real IP address and each Pod communicates with other Pods using that IP address. From the Pod’s perspective, it exists in its own Ethernet namespace that needs to communicate with other network namespaces on the same Node. Namespaces can be connected using a Linux Virtual Ethernet Device (veth) This setup can be replicated for as many Pods as we have on the machine. The default Gateway in this internal network is a Linux bridge. A bridge is a virtual Layer 2 networking device used to unite two or more network segments to connect networks together.</p>
<p><img src="/img/include/kubernetes-network-1-3.gif" alt="Pod to Pod"  class="zoomable" /></p>
<p>Bridges implement the ARP protocol to discover the link-layer MAC address associated with a given IP address.</p>
<h4 id="what-is-a-service">What is a Service?</h4>
<p>As we know containers are considered disposable. That means there is no guarantee that the pod&rsquo;s address won’t change the next time the pod is recreated. That is a common problem in cloud environments too, and it has a standard solution: run the traffic through a reverse-proxy. This proxy is represented by a Kubernetes resource type called a service.</p>
<p><img src="/img/include/kubernetes-network-1-4.gif" alt="Pod to Service"  class="zoomable" /></p>
<h3 id="service-types">Service Types</h3>
<h4 id="clusterip">ClusterIP</h4>
<p>ClusterIP is the default and most common service type. Kubernetes will assign a cluster-internal IP address to ClusterIP service. This makes the service only reachable within the cluster. You can use it for inter service communication within the cluster. For example, communication between the front-end and back-end components of your app.</p>
<p><img src="/img/include/k8s-cluster-ip-service.png" alt="ClusterIP"  class="zoomable" /></p>
<h4 id="nodeport">NodePort</h4>
<p>NodePort service is an extension of ClusterIP service. It exposes the service outside of the cluster by adding a cluster-wide port nat on top of ClusterIP. Each node proxies that port to there ip. So, external traffic has access to fixed port on each Node. ode port must be in the range of 30000–32767. Manually allocating a port to the service is optional. If it is undefined, Kubernetes will automatically assign one.</p>
<p><img src="/img/include/k8s-node-port.png" alt="NodePort"  class="zoomable" /></p>
<h4 id="loadbalancer">LoadBalancer</h4>
<p>LoadBalancer service is an extension of NodePort service. It integrates NodePort with cloud-based load balancers. It exposes the Service externally using a cloud provider’s load balancer. Each cloud provider (AWS, Azure, GCP, etc) has its own native load balancer implementation. The cloud provider will create a load balancer, which then automatically routes requests to your Kubernetes Service. Traffic from the external load balancer is directed at the backend Pods. The cloud provider decides how it is load balanced. Every time you want to expose a service to the outside world, you have to create a new LoadBalancer and get an IP address.</p>
<p><img src="/img/include/k8s-external-ip-service.png" alt="LoadBalancer"  class="zoomable" /></p>
<p><img src="/img/include/k8s-external-ip-service.png" alt="External IP"  class="zoomable" /></p>
<h4 id="externalname">ExternalName</h4>
<p>ExternalName map a Service to a DNS name, not to a typical selector. It maps the Service to the contents of the externalName field (e.g. foo.bar.example.com), by returning a CNAME record with its value. This is commonly used to create a service within Kubernetes to represent an external datastore like a database that runs externally to Kubernetes.</p>
<h3 id="pod-to-service-communication">Pod-to-Service communication</h3>
<p>When creating a new Kubernetes Service, a new virtual IP is created on your behalf. Anywhere within the cluster, traffic addressed to this virtual IP will be routed or load-balanced to the Pod or Pods associated with the Service. Kubernetes use a networking framework built in to Linux kernel called <code>netfilter</code>.</p>
<p><code>iptables</code> is a user-space utility program that allows a system administrator to configure the IP packet filter rules of the Linux kernel firewall, implemented as different <code>Netfilter</code> modules. In Kubernetes, <code>iptables</code> rules are configured by the <code>kube-proxy</code> controller that watches the Kubernetes API for changes. Creation of a service or change of the pod ip will trigger iptables rules update on the host. When a traffic destined for a Service’s virtual IP is detected the <code>kube-proxy</code> select a random pod ip from the set of available Pods and manipulate the <code>iptables</code> rules to change the destination ip in the package to it. This method is called destination nat. In the return path <code>iptables</code> again rewrites the IP header to replace the Pod IP with the Service’s IP. The path taken by a packet through the networking stack is depicted in the figure shown below:</p>
<p><img src="/img/include/services-userspace-overview.svg" alt="Pod to Service"  class="zoomable" /></p>
<p>In the iptables perspective:</p>
<p><img src="/img/include/kubernetes-network-1-5.png" alt="iptables structure"  class="zoomable" /></p>
<h3 id="ipvs">IPVS</h3>
<p>Since verion 1.11 Kubernetes includes a second option for load balancing. IPVS (IP Virtual Server) is also built on top of <code>netfilter</code> and implements load balancing as part of the Linux kernel. IPVS can direct requests for TCP- and UDP-based services to the real servers, and make services of the real servers appear as virtual services on a single IP address. When creating a Service load balanced with IPVS, three things happen: a dummy IPVS interface is created on the Node, the Service’s IP address is bound to the dummy IPVS interface, and IPVS servers are created for each Service IP address.</p>
<p><img src="/img/include/services-ipvs-overview.svg" alt="Pod to Service"  class="zoomable" /></p>
<h3 id="ebpf">eBPF</h3>
<p>Some Network plugin is Kubernetes can act as a replacement for <code>kube-proxy</code> like Calico and Cilium. They use eBPF as a solution to solve the load-balancing problem.</p>
<h3 id="what-is-ebpf">What is eBPF?</h3>
<p>eBPF is a virtual machine embedded within the Linux kernel. It allows small programs to be loaded into the kernel, and attached to hooks, which are triggered when some event occurs. This allows the behavior of the kernel to be (sometimes heavily) customized. While the eBPF virtual machine is the same for each type of hook, the capabilities of the hooks vary considerably. Since loading programs into the kernel could be dangerous; the kernel runs all programs through a very strict static verifier; the verifier sandboxes the program, ensuring it can only access allowed parts of memory and ensuring that it must terminate quickly.</p>
<p>eBPF dataplane attaches eBPF programs to hooks on each bridge interface as well as your data and tunnel interfaces. This allows Calico or Cilium to spot workload packets early and handle them through a fast-path that bypasses iptables and other packet processing that the kernel would normally do.</p>
<p><em><strong>Calico:</strong></em>
<img src="/img/include/kubernetes-network-1-5.svg" alt="Calico Architecture"  class="zoomable" /></p>
<p><em><strong>Cilium:</strong></em>
<img src="/img/include/kubernetes-network-1-6.png" alt="Cilium Architecture"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="calico" term="calico" label="calico" />
                             
                                <category scheme="cilium" term="cilium" label="cilium" />
                             
                                <category scheme="flannel" term="flannel" label="Flannel" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to Backup Kubernetes to git?]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-git-backup/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-longhorn/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes project longhorn" />
                <link href="https://devopstales.github.io/kubernetes/firecracker-cri-o/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy CRI-O with Firecracker?" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-git-backup/</id>
            
            
            <published>2021-08-28T00:00:00+00:00</published>
            <updated>2021-08-28T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how you can backup the kubernetes object to git as yaml-s.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>Thanky to <a href="https://github.com/WoozyMasta">Maxim Levchenko</a> ther is a grate tool called <a href="https://github.com/WoozyMasta/kube-dump">kube-dump</a> that is dump all of the kubernetes objects to a git repository as yaml. We will use this tool to backup.</p>
<p>Key features:</p>
<ul>
<li>Saving is done only for those resources to which you have read access.</li>
<li>You can pass a list of namespaces as an input, otherwise all available for your context will be used.</li>
<li>Both namespace resources and global cluster resources are subject to persistence.</li>
<li>You can use the utility locally as a regular script or run it in a container or in a kubernetes cluster, for example, as a CronJob.</li>
<li>It can create archives and rotate them after itself.</li>
<li>Can commit state to git repository and push to remote repository.</li>
<li>You can specify a specific list of cluster resources for unloading.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns kube-dump
</span></span><span style="display:flex;"><span>kubectl -n kube-dump apply -f <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  https://raw.githubusercontent.com/WoozyMasta/kube-dump/master/deploy/cluster-role-view.yaml
</span></span></code></pre></div><h3 id="deploy-with-git-repository-oauth-token">Deploy with git repository oauth token</h3>
<blockquote>
<p>Project access tokens are supported for self-managed instances on Free and above. They are also supported on GitLab SaaS Premium and above. If you use GitLab SaaS on Free you can us Personal access token instead of Project Access Token.</p></blockquote>
<p>As an example, I will use authorization in GitLab using the Project Access Token, so we will create a secret with the repository address and an authorization token:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl -n kube-dump create secret generic kube-dump <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --from-literal<span style="color:#f92672">=</span>GIT_REMOTE_URL<span style="color:#f92672">=</span>https://oauth2:$TOKEN@corp-gitlab.com/devops/cluster-01.git
</span></span></code></pre></div><blockquote>
<p>Before Kubernetes 1.22 CronJob&rsquo;s timezone is always UTC. If you want to change this use <a href="https://github.com/hiddeco/cronjobber">cronjobber</a>
Since Kubernetes 1.22 you can add <a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/">timezon in cronjob</a> with <code>CRON_TZ</code> variable.</p></blockquote>
<p>Let’s set up a CronJob in which we indicate the frequency of the task launch:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/WoozyMasta/kube-dump/blob/master/deploy/cronjob-git-token.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano cronjob-git-token.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  schedule: <span style="color:#e6db74">&#34;0 1 * * *&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f cronjob-git-token.yaml -n kube-dump
</span></span></code></pre></div><h3 id="deploy-with-git-repository-write-allowed-ssh-key">Deploy with git repository write allowed ssh key</h3>
<p>Generate ssh key:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p ./.ssh
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">0700</span> ./.ssh
</span></span><span style="display:flex;"><span>ssh-keygen -t ed25519 -C <span style="color:#e6db74">&#34;kube-dump&#34;</span> -f ./.ssh/kube-dump
</span></span><span style="display:flex;"><span>cat ./.ssh/kube-dump.pub
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl -n kube-dump create secret generic kube-dump-key <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --from-file<span style="color:#f92672">=</span>./.ssh/kube-dump <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --from-file<span style="color:#f92672">=</span>./.ssh/kube-dump.pub
</span></span></code></pre></div><p>Create pvc for store data such as cache:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -n kube-dump -f deploy/pvc.yaml
</span></span></code></pre></div><p>And apply the cron job manifest, previously you could set up environment variables:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/WoozyMasta/kube-dump/blob/master/deploy/cronjob-git-key.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano cronjob-git-key.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  schedule: <span style="color:#e6db74">&#34;0 1 * * *&#34;</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>              env:
</span></span><span style="display:flex;"><span>                - name: MODE
</span></span><span style="display:flex;"><span>                  value: <span style="color:#e6db74">&#34;dump&#34;</span>
</span></span><span style="display:flex;"><span>                - name: DESTINATION_DIR
</span></span><span style="display:flex;"><span>                  value: <span style="color:#e6db74">&#34;/data/dump&#34;</span>
</span></span><span style="display:flex;"><span>                - name: GIT_PUSH
</span></span><span style="display:flex;"><span>                  value: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>                - name: GIT_BRANCH
</span></span><span style="display:flex;"><span>                  value: <span style="color:#e6db74">&#34;master&#34;</span>
</span></span><span style="display:flex;"><span>                - name: GIT_COMMIT_USER
</span></span><span style="display:flex;"><span>                  value: <span style="color:#e6db74">&#34;Kube Dump&#34;</span>
</span></span><span style="display:flex;"><span>                - name: GIT_COMMIT_EMAIL
</span></span><span style="display:flex;"><span>                  value: <span style="color:#e6db74">&#34;kube@dump.local&#34;</span>
</span></span><span style="display:flex;"><span>                - name: GIT_REMOTE_URL
</span></span><span style="display:flex;"><span>                  value: <span style="color:#e6db74">&#34;git@corp-gitlab.com:devops/cluster-bkp.git&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f cronjob-git-key.yaml -n kube-dump
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="backup" term="backup" label="Backup" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to deploy CRI-O with Firecracker?]]></title>
            <link href="https://devopstales.github.io/kubernetes/firecracker-cri-o/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/firecracker-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with Firecracker?" />
                <link href="https://devopstales.github.io/kubernetes/kata-container-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with kata containers?" />
                <link href="https://devopstales.github.io/kubernetes/gvisor-cri-o/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy CRI-O with gVisor?" />
                <link href="https://devopstales.github.io/kubernetes/gvisor-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with gVisor?" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
            
                <id>https://devopstales.github.io/kubernetes/firecracker-cri-o/</id>
            
            
            <published>2021-08-23T00:00:00+00:00</published>
            <updated>2021-08-23T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can install and use kata-container with Firecracker engine in kubernetes.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-kata-container-engine">What is Kata container engine</h3>
<p>Kata Containers is an open source community working to build a secure container runtime with lightweight virtual machines that feel and perform like containers, but provide stronger workload isolation using hardware virtualization technology as a second layer of defense. (Source: <a href="https://katacontainers.io/">Kata Containers Website</a> )</p>
<p><img src="/img/include/katacontainers.jpg" alt="Kata container engine"  class="zoomable" /></p>
<h3 id="why-should-you-use-firecracker">Why should you use Firecracker?</h3>
<p>Firecracker is a way to run virtual machines, but its primary goal is to be used as a container runtime interface, making it use very few resources by design.</p>
<h3 id="enable-qvemu">Enable qvemu</h3>
<p>I will use Vagrant and VirtualBox for running the AlmaLinux VM so first I need to enable then Nested virtualization on the VM:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VBoxManage modifyvm alma8 --nested-hw-virt on
</span></span></code></pre></div><p>After the Linux is booted test the virtualization flag in the VM:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>egrep --color -i <span style="color:#e6db74">&#34;svm|vmx&#34;</span> /proc/cpuinfo
</span></span></code></pre></div><p>If you find one of this flags everything is ok. Now we need to enable the kvm kernel module.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo modprobe kvm-intel
</span></span><span style="display:flex;"><span>sudo modprobe vhost_vsock
</span></span></code></pre></div><h3 id="disable-selinux">Disable selinux</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>setenforce <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/=\(enforcing\|permissive\)/=disabled/g&#39;</span> /etc/sysconfig/selinux
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/=\(enforcing\|permissive\)/=disabled/g&#39;</span> /etc/selinux/config
</span></span></code></pre></div><h3 id="install-and-configure-cri-o">Install and configure CRI-O</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf install epel-release nano wget -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export VERSION<span style="color:#f92672">=</span>1.21
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/CentOS_8/devel:kubic:libcontainers:stable.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable_cri-o_<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>/CentOS_8/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install cri-o
</span></span></code></pre></div><p>Devmapper is the only storage driver supported by Firecracker. The stable pubic verion of <code>cri-o</code> dose not contained the support for devicemapper. Thanx to <code>Sascha Grunert</code> ther is a new version built with libdevmapper. He answered my question on slack immediately and created a patch for this bug.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/containers/storage.conf
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>storage<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;devicemapper&#34;</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>storage.options.thinpool<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>autoextend_percent <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;20&#34;</span>
</span></span><span style="display:flex;"><span>autoextend_threshold <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;80&#34;</span>
</span></span><span style="display:flex;"><span>basesize <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;8G&#34;</span>
</span></span><span style="display:flex;"><span>directlvm_device <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/dev/sdb&#34;</span>
</span></span><span style="display:flex;"><span>directlvm_device_force <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;True&#34;</span>
</span></span><span style="display:flex;"><span>fs<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;xfs&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano /etc/containers/registries.conf
</span></span><span style="display:flex;"><span>registries <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;quay.io&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;docker.io&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>unqualified-search-registries <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;quay.io&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;docker.io&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl enable crio
</span></span><span style="display:flex;"><span>systemctl restart crio
</span></span><span style="display:flex;"><span>systemctl status crio
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ crio-status info
</span></span><span style="display:flex;"><span>storage root: /var/lib/containers/storage
</span></span><span style="display:flex;"><span>default GID mappings <span style="color:#f92672">(</span>format &lt;container&gt;:&lt;host&gt;:&lt;size&gt;<span style="color:#f92672">)</span>:
</span></span><span style="display:flex;"><span>  0:0:4294967295
</span></span><span style="display:flex;"><span>default UID mappings <span style="color:#f92672">(</span>format &lt;container&gt;:&lt;host&gt;:&lt;size&gt;<span style="color:#f92672">)</span>:
</span></span><span style="display:flex;"><span>  0:0:4294967295
</span></span></code></pre></div><h3 id="install-tools">Install tools</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install git -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubectx /usr/local/sbin/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubens /usr/local/sbin/kubens
</span></span></code></pre></div><h3 id="install-kubernetes">Install Kubernetes</h3>
<p>Configure Kernel parameters for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>modprobe overlay
</span></span><span style="display:flex;"><span>modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kvm-intel
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">vhost_vsock
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv6.conf.all.disable_ipv6 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv6.conf.default.disable_ipv6 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><p>Disable swap for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><p>The I will add the kubernetes repo and Install the packages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CRIP_VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>crio --version | awk <span style="color:#e6db74">&#39;{print $3}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>yum install kubelet-$CRIP_VERSION kubeadm-$CRIP_VERSION kubectl-$CRIP_VERSION -y
</span></span></code></pre></div><p>You nee the same cgroup manager in cri-o and kubeadm. The default for kubeadm is cgroupfs and for cri-o the default is systemd. In this example I configured cri-o for cgroupfs.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/crio/crio.conf
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>crio.runtime<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>conmon_cgroup <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;pod&#34;</span>
</span></span><span style="display:flex;"><span>cgroup_manager <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;cgroupfs&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl restart crio
</span></span></code></pre></div><p>If you want to use systemd:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;KUBELET_EXTRA_ARGS=--cgroup-driver=systemd&#34;</span> | tee /etc/sysconfig/kubelet
</span></span></code></pre></div><p>Start Kubernetes with containerd engine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export IP<span style="color:#f92672">=</span>172.17.13.10
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf install -y iproute-tc
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl enable kubelet.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># for multi interface configuration</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;KUBELET_EXTRA_ARGS=&#34;--node-ip=&#39;</span>$IP<span style="color:#e6db74">&#39; --cgroup-driver=systemd&#34;&#39;</span> &gt; /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm config images pull --cri-socket<span style="color:#f92672">=</span>unix:///var/run/crio/crio.sock --kubernetes-version<span style="color:#f92672">=</span>$CRIP_VERSION
</span></span><span style="display:flex;"><span>kubeadm init --pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16 --apiserver-advertise-address<span style="color:#f92672">=</span>$IP  --kubernetes-version<span style="color:#f92672">=</span>$CRIP_VERSION --cri-socket<span style="color:#f92672">=</span>unix:///var/run/crio/crio.sock
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get no
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl taint nodes <span style="color:#66d9ef">$(</span>hostname<span style="color:#66d9ef">)</span> node-role.kubernetes.io/master:NoSchedule-
</span></span></code></pre></div><h3 id="initialize-network">Initialize network</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span></span><span style="display:flex;"><span>kubectl aplly -f kube-flannel.yml
</span></span></code></pre></div><p>OR</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
</span></span><span style="display:flex;"><span>wget https://docs.projectcalico.org/manifests/custom-resources.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano custom-resources.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>      cidr: 10.244.0.0/16
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f custom-resources.yaml
</span></span></code></pre></div><h3 id="install-kata-container-engine">Install Kata container engine</h3>
<p>If all the Nodes are ready deploy a Daemonsets to build Kata containers and firecracker wit <code>kata-deploy</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get no
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME    STATUS   ROLES                  AGE     VERSION
</span></span><span style="display:flex;"><span>alma8   Ready    control-plane,master   2m31s   v1.22.1
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Installing the latest image</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-deploy/kata-rbac/base/kata-rbac.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-deploy/kata-deploy/base/kata-deploy.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># OR</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Installing the stable image</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-deploy/kata-rbac/base/kata-rbac.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-deploy/kata-deploy/base/kata-deploy-stable.yaml
</span></span></code></pre></div><p>Verify the pod:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens kube-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl get DaemonSet
</span></span><span style="display:flex;"><span>NAME          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
</span></span><span style="display:flex;"><span>kata-deploy   <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>       <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           &lt;none&gt;                   3m43s
</span></span><span style="display:flex;"><span>kube-proxy    <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>       <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           kubernetes.io/os<span style="color:#f92672">=</span>linux   10m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl get po kata-deploy-5zwmq
</span></span><span style="display:flex;"><span>NAME                READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>kata-deploy-5zwmq   1/1     Running   <span style="color:#ae81ff">0</span>          4m24
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl logs kata-deploy-5zwmq
</span></span><span style="display:flex;"><span>copying kata artifacts onto host
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash</span>
</span></span><span style="display:flex;"><span>KATA_CONF_FILE<span style="color:#f92672">=</span>/opt/kata/share/defaults/kata-containers/configuration-fc.toml /opt/kata/bin/containerd-shim-kata-v2 <span style="color:#e6db74">&#34;</span>$@<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash</span>
</span></span><span style="display:flex;"><span>KATA_CONF_FILE<span style="color:#f92672">=</span>/opt/kata/share/defaults/kata-containers/configuration-qemu.toml /opt/kata/bin/containerd-shim-kata-v2 <span style="color:#e6db74">&#34;</span>$@<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash</span>
</span></span><span style="display:flex;"><span>KATA_CONF_FILE<span style="color:#f92672">=</span>/opt/kata/share/defaults/kata-containers/configuration-clh.toml /opt/kata/bin/containerd-shim-kata-v2 <span style="color:#e6db74">&#34;</span>$@<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>Add Kata Containers as a supported runtime <span style="color:#66d9ef">for</span> CRIO:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Path to the Kata Containers runtime binary that uses the fc</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>crio.runtime.runtimes.kata-fc<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>	runtime_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/usr/local/bin/containerd-shim-kata-fc-v2&#34;</span>
</span></span><span style="display:flex;"><span>	runtime_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;vm&#34;</span>
</span></span><span style="display:flex;"><span>	runtime_root <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/run/vc&#34;</span>
</span></span><span style="display:flex;"><span>	privileged_without_host_devices <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Path to the Kata Containers runtime binary that uses the qemu</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>crio.runtime.runtimes.kata-qemu<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>	runtime_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/usr/local/bin/containerd-shim-kata-qemu-v2&#34;</span>
</span></span><span style="display:flex;"><span>	runtime_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;vm&#34;</span>
</span></span><span style="display:flex;"><span>	runtime_root <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/run/vc&#34;</span>
</span></span><span style="display:flex;"><span>	privileged_without_host_devices <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Path to the Kata Containers runtime binary that uses the clh</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>crio.runtime.runtimes.kata-clh<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>	runtime_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/usr/local/bin/containerd-shim-kata-clh-v2&#34;</span>
</span></span><span style="display:flex;"><span>	runtime_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;vm&#34;</span>
</span></span><span style="display:flex;"><span>	runtime_root <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/run/vc&#34;</span>
</span></span><span style="display:flex;"><span>	privileged_without_host_devices <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>node/alma8 labeled
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ ll /opt/kata/bin/
</span></span><span style="display:flex;"><span>total <span style="color:#ae81ff">157532</span>
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">4045032</span> Jul <span style="color:#ae81ff">19</span> 06:10 cloud-hypervisor
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">42252997</span> Jul <span style="color:#ae81ff">19</span> 06:12 containerd-shim-kata-v2
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3290472</span> Jul <span style="color:#ae81ff">19</span> 06:14 firecracker
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">2589888</span> Jul <span style="color:#ae81ff">19</span> 06:14 jailer
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">16686</span> Jul <span style="color:#ae81ff">19</span> 06:12 kata-collect-data.sh
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">37429099</span> Jul <span style="color:#ae81ff">19</span> 06:12 kata-monitor
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">54149384</span> Jul <span style="color:#ae81ff">19</span> 06:12 kata-runtime
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">17521656</span> Jul <span style="color:#ae81ff">19</span> 06:18 qemu-system-x86_64
</span></span></code></pre></div><p>Restart containerd to enable the new config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl restart containerd
</span></span></code></pre></div><hr>
<h3 id="start-deployment">Start Deployment</h3>
<p>First I create a <code>RuntimeClass</code> for kata-fc then start a pod with this <code>RuntimeClass</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens default
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: node.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: RuntimeClass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: kata-fc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">handler: kata-fc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: untrusted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-kata-fc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  runtimeClassName: kata-fc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: node.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: RuntimeClass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: kata-qemu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">handler: kata-qemu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: untrusted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-kata-qemu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  runtimeClassName: kata-qemu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: node.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: RuntimeClass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: kata-clh
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">handler: kata-clh
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: untrusted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-kata-clh
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  runtimeClassName: kata-clh
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get po
</span></span><span style="display:flex;"><span>NAME            READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>www-kata-clh    1/1     Running   <span style="color:#ae81ff">0</span>          59s
</span></span><span style="display:flex;"><span>www-kata-fc     1/1     Running   <span style="color:#ae81ff">0</span>          12s
</span></span><span style="display:flex;"><span>www-kata-qemu   1/1     Running   <span style="color:#ae81ff">0</span>          69s
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="kata-container" term="kata-container" label="kata-container" />
                             
                                <category scheme="firecracker" term="firecracker" label="Firecracker" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                             
                                <category scheme="almalinux" term="almalinux" label="AlmaLinux" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to deploy CRI-O with gVisor?]]></title>
            <link href="https://devopstales.github.io/kubernetes/gvisor-cri-o/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/firecracker-cri-o/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy CRI-O with Firecracker?" />
                <link href="https://devopstales.github.io/kubernetes/gvisor-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with gVisor?" />
                <link href="https://devopstales.github.io/kubernetes/firecracker-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with Firecracker?" />
                <link href="https://devopstales.github.io/kubernetes/kata-container-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with kata containers?" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
            
                <id>https://devopstales.github.io/kubernetes/gvisor-cri-o/</id>
            
            
            <published>2021-08-23T00:00:00+00:00</published>
            <updated>2021-08-23T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can install and use gvisor engine in kubernetes.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-gvisor">What is gvisor</h3>
<p>gVisor is an application kernel, written in Go, that implements a substantial portion of the Linux system call interface. It provides an additional layer of isolation between running applications and the host operating system.</p>
<p>gVisor includes an Open Container Initiative (OCI) runtime called <code>runsc</code> that makes it easy to work with existing container tooling. The <code>runsc</code> runtime integrates with Docker, CRI-O and Kubernetes, making it simple to run sandboxed containers.</p>
<p><img src="/img/include/gvisor2.png" alt="gvisor"  class="zoomable" />
<img src="/img/include/gvisor.png" alt="gvisor"  class="zoomable" /></p>
<h3 id="install-gvisor">Install gvisor</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf install epel-release nano wget -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano gvisor.sh
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/bash</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">(</span>
</span></span><span style="display:flex;"><span>  set -e
</span></span><span style="display:flex;"><span>  ARCH<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>uname -m<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>  URL<span style="color:#f92672">=</span>https://storage.googleapis.com/gvisor/releases/release/latest/<span style="color:#e6db74">${</span>ARCH<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>  wget <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/runsc <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/runsc.sha512 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/containerd-shim-runsc-v1 <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/containerd-shim-runsc-v1.sha512
</span></span><span style="display:flex;"><span>  sha512sum -c runsc.sha512 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -c containerd-shim-runsc-v1.sha512
</span></span><span style="display:flex;"><span>  rm -f *.sha512
</span></span><span style="display:flex;"><span>  chmod a+rx runsc containerd-shim-runsc-v1
</span></span><span style="display:flex;"><span>  sudo mv runsc containerd-shim-runsc-v1 /usr/local/bin
</span></span><span style="display:flex;"><span><span style="color:#f92672">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>bash gvisor.sh
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>runsc: OK
</span></span><span style="display:flex;"><span>containerd-shim-runsc-v1: OK
</span></span></code></pre></div><h3 id="install-and-configure-cri-o">Install and configure CRI-O</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export VERSION<span style="color:#f92672">=</span>1.21
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/CentOS_8/devel:kubic:libcontainers:stable.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable_cri-o_<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>/CentOS_8/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install cri-o
</span></span></code></pre></div><p><code>runsc</code> implements cgroups using <code>cgroupfs</code> so I will use <code>cgroupfs</code> in <code>CRI-O</code> and Kubernets config.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/crio/crio.conf
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>crio.runtime<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>conmon_cgroup <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;pod&#34;</span>
</span></span><span style="display:flex;"><span>cgroup_manager <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;cgroupfs&#34;</span>
</span></span><span style="display:flex;"><span>selinux <span style="color:#f92672">=</span> false
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano /etc/containers/registries.conf
</span></span><span style="display:flex;"><span>registries <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;quay.io&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;docker.io&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>unqualified-search-registries <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;quay.io&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;docker.io&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">]</span>
</span></span></code></pre></div><p>Now I need to configure <code>CRI-O</code> to use <code>runsc</code> as low-level runetime egine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir /etc/crio/crio.conf.d/
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/crio/crio.conf.d/99-gvisor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># Path to the gVisor runtime binary that uses runsc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[crio.runtime.runtimes.runsc]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">runtime_path = &#34;/usr/local/bin/runsc&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl enable crio
</span></span><span style="display:flex;"><span>systemctl restart crio
</span></span><span style="display:flex;"><span>systemctl status crio
</span></span></code></pre></div><h3 id="install-tools">Install tools</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install git -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubectx /usr/local/sbin/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubens /usr/local/sbin/kubens
</span></span></code></pre></div><h3 id="install-kubernetes">Install Kubernetes</h3>
<p>Configure Kernel parameters for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/CRI-O.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><p>Disable swap for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><p>The I will add the kubernetes repo and Install the packages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CRIP_VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>crio --version | awk <span style="color:#e6db74">&#39;{print $3}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>yum install kubelet-$CRIP_VERSION kubeadm-$CRIP_VERSION kubectl-$CRIP_VERSION -y
</span></span></code></pre></div><p>Start Kubernetes with CRI-O engine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export IP<span style="color:#f92672">=</span>172.17.13.10
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf install -y iproute-tc
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl enable kubelet.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># for multi interface configuration</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;KUBELET_EXTRA_ARGS=&#34;--node-ip=&#39;</span>$IP<span style="color:#e6db74">&#39; --cgroup-driver=cgroupfs&#34;&#39;</span> &gt; /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm config images pull --cri-socket<span style="color:#f92672">=</span>unix:///var/run/crio/crio.sock --kubernetes-version<span style="color:#f92672">=</span>$CRIP_VERSION
</span></span><span style="display:flex;"><span>kubeadm init --pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16 --apiserver-advertise-address<span style="color:#f92672">=</span>$IP --kubernetes-version<span style="color:#f92672">=</span>$CRIP_VERSION --cri-socket<span style="color:#f92672">=</span>unix:///var/run/crio/crio.sock
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get no
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl taint nodes <span style="color:#66d9ef">$(</span>hostname<span style="color:#66d9ef">)</span> node-role.kubernetes.io/master:NoSchedule-
</span></span></code></pre></div><h3 id="inincialize-network">Inincialize network</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span></span><span style="display:flex;"><span>kubectl aplly -f kube-flannel.yml
</span></span></code></pre></div><p>OR</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
</span></span><span style="display:flex;"><span>wget https://docs.projectcalico.org/manifests/custom-resources.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano custom-resources.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>      cidr: 10.244.0.0/16
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f custom-resources.yaml
</span></span></code></pre></div><h3 id="start-deployment">Start Deployment</h3>
<p>First I create a <code>RuntimeClass</code> for gvisor then start a pod with this <code>RuntimeClass</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: node.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: RuntimeClass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: gvisor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">handler: runsc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: untrusted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-gvisor2
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  runtimeClassName: gvisor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get po
</span></span><span style="display:flex;"><span>NAME        READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>www-gvisor  1/1     Running   <span style="color:#ae81ff">0</span>          2m47s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl describe po www-gvisor
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Events:
</span></span><span style="display:flex;"><span>  Type    Reason     Age    From               Message
</span></span><span style="display:flex;"><span>  ----    ------     ----   ----               -------
</span></span><span style="display:flex;"><span>  Normal  Scheduled  2m42s  default-scheduler  Successfully assigned default/www-kata to alma8
</span></span><span style="display:flex;"><span>  Normal  Pulled     2m13s  kubelet            Container image <span style="color:#e6db74">&#34;nginx:1.18&#34;</span> already present on machine
</span></span><span style="display:flex;"><span>  Normal  Created    2m13s  kubelet            Created container www
</span></span><span style="display:flex;"><span>  Normal  Started    2m11s  kubelet            Started container www
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="gvisor" term="gvisor" label="gvisor" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                             
                                <category scheme="almalinux" term="almalinux" label="AlmaLinux" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to deploy containerd with Firecracker?]]></title>
            <link href="https://devopstales.github.io/kubernetes/firecracker-containerd/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/kata-container-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with kata containers?" />
                <link href="https://devopstales.github.io/kubernetes/gvisor-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with gVisor?" />
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/being-productive-with-kubectl/?utm_source=atom_feed" rel="related" type="text/html" title="Being Productive with K8S" />
            
                <id>https://devopstales.github.io/kubernetes/firecracker-containerd/</id>
            
            
            <published>2021-08-22T00:00:00+00:00</published>
            <updated>2021-08-22T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can install and use kata-container with Firecracker engine in kubernetes.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-kata-container-engine">What is Kata container engine</h3>
<p>Kata Containers is an open source community working to build a secure container runtime with lightweight virtual machines that feel and perform like containers, but provide stronger workload isolation using hardware virtualization technology as a second layer of defense. (Source: <a href="https://katacontainers.io/">Kata Containers Website</a> )</p>
<p><img src="/img/include/katacontainers.jpg" alt="Kata container engine"  class="zoomable" /></p>
<h3 id="why-should-you-use-firecracker">Why should you use Firecracker?</h3>
<p>Firecracker is a way to run virtual machines, but its primary goal is to be used as a container runtime interface, making it use very few resources by design.</p>
<h3 id="enable-qvemu">Enable qvemu</h3>
<p>I will use Vagrant and VirtualBox for running the AlmaLinux VM so first I need to enable then Nested virtualization on the VM:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VBoxManage modifyvm alma8 --nested-hw-virt on
</span></span></code></pre></div><p>After the Linux is booted test the virtualization flag in the VM:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>egrep --color -i <span style="color:#e6db74">&#34;svm|vmx&#34;</span> /proc/cpuinfo
</span></span></code></pre></div><p>If you find one of this flags everything is ok. Now we need to enable the kvm kernel module.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo modprobe kvm-intel
</span></span><span style="display:flex;"><span>sudo modprobe vhost_vsock
</span></span></code></pre></div><h3 id="install-and-configure-containerd">Install and configure containerd</h3>
<p>To work with firecracker the containerd must use devmapper for snapsoter plugin.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf install epel-release nano wget -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style="display:flex;"><span>sudo dnf install -y containerd.io lvm2
</span></span></code></pre></div><p>First I installed the containerd. Devmapper is the only storage driver supported by Firecracker so now I create the thin-pool lvm for devmapper snapsoter:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo pvcreate /dev/sdb
</span></span><span style="display:flex;"><span>sudo vgcreate containerd /dev/sdb
</span></span><span style="display:flex;"><span>sudo lvcreate --wipesignatures y -n data containerd -l 95%VG
</span></span><span style="display:flex;"><span>sudo lvcreate --wipesignatures y -n meta containerd -l 1%VG
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo lvconvert -y <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--zero n <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-c 512K <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--thinpool containerd/data <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--poolmetadata containerd/meta
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano /etc/lvm/profile/ontainerd-thinpool.profile
</span></span><span style="display:flex;"><span>activation <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  thin_pool_autoextend_threshold<span style="color:#f92672">=</span><span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>  thin_pool_autoextend_percent<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo lvchange --metadataprofile ontainerd-thinpool containerd/data
</span></span><span style="display:flex;"><span>sudo lvchange --monitor y containerd/data
</span></span></code></pre></div><p>And <code>dmsetup</code> will produce the following output:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>containerd-data	<span style="color:#f92672">(</span>253:2<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>containerd-data_tdata	<span style="color:#f92672">(</span>253:1<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>containerd-data_tmeta	<span style="color:#f92672">(</span>253:0<span style="color:#f92672">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo mkdir -p /etc/containerd
</span></span><span style="display:flex;"><span>sudo containerd config default &gt; /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>nano /etc/containerd/config.toml
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>plugins<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    snapshotter <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;devmapper&#34;</span>
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.snapshotter.v1.devmapper&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    pool_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;containerd-data&#34;</span>
</span></span><span style="display:flex;"><span>    base_image_size <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;8GB&#34;</span>
</span></span><span style="display:flex;"><span>    async_remove <span style="color:#f92672">=</span> false
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;runtime-endpoint: unix:///run/containerd/containerd.sock&#34;</span> &gt; /etc/crictl.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Restart containerd</span>
</span></span><span style="display:flex;"><span>sudo systemctl restart containerd
</span></span><span style="display:flex;"><span>systemctl enable containerd.service
</span></span></code></pre></div><p>Test if working correctly:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl restart containerd
</span></span><span style="display:flex;"><span>ctr images pull --snapshotter devmapper docker.io/library/hello-world:latest
</span></span><span style="display:flex;"><span>ctr run --snapshotter devmapper docker.io/library/hello-world:latest test
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ ctr plugin ls
</span></span><span style="display:flex;"><span>TYPE                            ID                       PLATFORMS      STATUS
</span></span><span style="display:flex;"><span>io.containerd.content.v1        content                  -              ok
</span></span><span style="display:flex;"><span>io.containerd.snapshotter.v1    aufs                     linux/amd64    error
</span></span><span style="display:flex;"><span>io.containerd.snapshotter.v1    devmapper                linux/amd64    ok
</span></span><span style="display:flex;"><span>io.containerd.snapshotter.v1    native                   linux/amd64    ok
</span></span><span style="display:flex;"><span>io.containerd.snapshotter.v1    overlayfs                linux/amd64    ok
</span></span><span style="display:flex;"><span>io.containerd.snapshotter.v1    zfs                      linux/amd64    error
</span></span><span style="display:flex;"><span>io.containerd.metadata.v1       bolt                     -              ok
</span></span><span style="display:flex;"><span>io.containerd.differ.v1         walking                  linux/amd64    ok
</span></span><span style="display:flex;"><span>io.containerd.gc.v1             scheduler                -              ok
</span></span><span style="display:flex;"><span>io.containerd.service.v1        introspection-service    -              ok
</span></span><span style="display:flex;"><span>io.containerd.service.v1        containers-service       -              ok
</span></span><span style="display:flex;"><span>io.containerd.service.v1        content-service          -              ok
</span></span><span style="display:flex;"><span>io.containerd.service.v1        diff-service             -              ok
</span></span><span style="display:flex;"><span>io.containerd.service.v1        images-service           -              ok
</span></span><span style="display:flex;"><span>io.containerd.service.v1        leases-service           -              ok
</span></span><span style="display:flex;"><span>io.containerd.service.v1        namespaces-service       -              ok
</span></span><span style="display:flex;"><span>io.containerd.service.v1        snapshots-service        -              ok
</span></span><span style="display:flex;"><span>io.containerd.runtime.v1        linux                    linux/amd64    ok
</span></span><span style="display:flex;"><span>io.containerd.runtime.v2        task                     linux/amd64    ok
</span></span><span style="display:flex;"><span>io.containerd.monitor.v1        cgroups                  linux/amd64    ok
</span></span><span style="display:flex;"><span>io.containerd.service.v1        tasks-service            -              ok
</span></span><span style="display:flex;"><span>io.containerd.internal.v1       restart                  -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           containers               -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           content                  -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           diff                     -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           events                   -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           healthcheck              -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           images                   -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           leases                   -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           namespaces               -              ok
</span></span><span style="display:flex;"><span>io.containerd.internal.v1       opt                      -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           snapshots                -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           tasks                    -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           version                  -              ok
</span></span><span style="display:flex;"><span>io.containerd.grpc.v1           cri                      linux/amd64    ok
</span></span></code></pre></div><h3 id="install-nerdctl">Install nerdctl</h3>
<p>I like to use <code>nerdctl</code> instad of <code>ctr</code> or <code>crictl</code> cli so I will install it.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/containerd/nerdctl/releases/download/v0.11.0/nerdctl-0.11.0-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar -xzf nerdctl-0.11.0-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>mv nerdctl /usr/local/bin
</span></span><span style="display:flex;"><span>nerdctl ps
</span></span></code></pre></div><h3 id="install-tools">Install tools</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install git -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubectx /usr/local/sbin/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubens /usr/local/sbin/kubens
</span></span></code></pre></div><h3 id="install-kubernetes">Install Kubernetes</h3>
<p>Configure Kernel parameters for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kvm-intel
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">vhost_vsock
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><p>Disable swap for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><p>The I will add the kubernetes repo and Install the packages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf install kubelet kubeadm kubectl -y
</span></span></code></pre></div><p>Start Kubernetes with containerd engine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export IP<span style="color:#f92672">=</span>172.17.13.10
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf install -y iproute-tc
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl enable kubelet.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;KUBELET_EXTRA_ARGS=--cgroup-driver=systemd&#34;</span> | tee /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm config images pull --cri-socket<span style="color:#f92672">=</span>unix:///run/containerd/containerd.sock
</span></span><span style="display:flex;"><span>kubeadm init --pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16 --apiserver-advertise-address<span style="color:#f92672">=</span>$IP --cri-socket<span style="color:#f92672">=</span>unix:///run/containerd/containerd.sock
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get no
</span></span><span style="display:flex;"><span>nerdctl -n k8s.io ps
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl taint nodes <span style="color:#66d9ef">$(</span>hostname<span style="color:#66d9ef">)</span> node-role.kubernetes.io/master:NoSchedule-
</span></span></code></pre></div><h3 id="inincialize-network">Inincialize network</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span></span><span style="display:flex;"><span>kubectl aplly -f kube-flannel.yml
</span></span></code></pre></div><p>OR</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
</span></span><span style="display:flex;"><span>wget https://docs.projectcalico.org/manifests/custom-resources.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano custom-resources.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>      cidr: 10.244.0.0/16
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f custom-resources.yaml
</span></span></code></pre></div><h3 id="install-kata-container-engine">Install Kata container engine</h3>
<p>If all the Nodes are ready deploy a Daemonsets to build Kata containers and firecracker wit <code>kata-deploy</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get no
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME    STATUS   ROLES                  AGE     VERSION
</span></span><span style="display:flex;"><span>alma8   Ready    control-plane,master   2m31s   v1.22.1
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Installing the latest image</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-deploy/kata-rbac/base/kata-rbac.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-deploy/kata-deploy/base/kata-deploy.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># OR</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Installing the stable image</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-deploy/kata-rbac/base/kata-rbac.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-deploy/kata-deploy/base/kata-deploy-stable.yaml
</span></span></code></pre></div><p>Verify the pod:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens kube-system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl get DaemonSet
</span></span><span style="display:flex;"><span>NAME          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
</span></span><span style="display:flex;"><span>kata-deploy   <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>       <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           &lt;none&gt;                   3m43s
</span></span><span style="display:flex;"><span>kube-proxy    <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>       <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           kubernetes.io/os<span style="color:#f92672">=</span>linux   10m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl get po kata-deploy-5zwmq
</span></span><span style="display:flex;"><span>NAME                READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>kata-deploy-5zwmq   1/1     Running   <span style="color:#ae81ff">0</span>          4m24
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl logs kata-deploy-5zwmq
</span></span><span style="display:flex;"><span>copying kata artifacts onto host
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash</span>
</span></span><span style="display:flex;"><span>KATA_CONF_FILE<span style="color:#f92672">=</span>/opt/kata/share/defaults/kata-containers/configuration-fc.toml /opt/kata/bin/containerd-shim-kata-v2 <span style="color:#e6db74">&#34;</span>$@<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash</span>
</span></span><span style="display:flex;"><span>KATA_CONF_FILE<span style="color:#f92672">=</span>/opt/kata/share/defaults/kata-containers/configuration-qemu.toml /opt/kata/bin/containerd-shim-kata-v2 <span style="color:#e6db74">&#34;</span>$@<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash</span>
</span></span><span style="display:flex;"><span>KATA_CONF_FILE<span style="color:#f92672">=</span>/opt/kata/share/defaults/kata-containers/configuration-clh.toml /opt/kata/bin/containerd-shim-kata-v2 <span style="color:#e6db74">&#34;</span>$@<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>Add Kata Containers as a supported runtime <span style="color:#66d9ef">for</span> containerd
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.kata<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  runtime_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;io.containerd.kata.v2&#34;</span>
</span></span><span style="display:flex;"><span>  privileged_without_host_devices <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>  pod_annotations <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;io.katacontainers.*&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.kata.options<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    ConfigPath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/opt/kata/share/defaults/kata-containers/configuration.toml&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.kata-fc<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  runtime_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;io.containerd.kata-fc.v2&#34;</span>
</span></span><span style="display:flex;"><span>  privileged_without_host_devices <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>  pod_annotations <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;io.katacontainers.*&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.kata-fc.options<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    ConfigPath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/opt/kata/share/defaults/kata-containers/configuration-fc.toml&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.kata-qemu<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  runtime_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;io.containerd.kata-qemu.v2&#34;</span>
</span></span><span style="display:flex;"><span>  privileged_without_host_devices <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>  pod_annotations <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;io.katacontainers.*&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.kata-qemu.options<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    ConfigPath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/opt/kata/share/defaults/kata-containers/configuration-qemu.toml&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.kata-clh<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  runtime_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;io.containerd.kata-clh.v2&#34;</span>
</span></span><span style="display:flex;"><span>  privileged_without_host_devices <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>  pod_annotations <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;io.katacontainers.*&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.kata-clh.options<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    ConfigPath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/opt/kata/share/defaults/kata-containers/configuration-clh.toml&#34;</span>
</span></span><span style="display:flex;"><span>node/alma8 labeled
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ ll /opt/kata/bin/
</span></span><span style="display:flex;"><span>total <span style="color:#ae81ff">157532</span>
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">4045032</span> Jul <span style="color:#ae81ff">19</span> 06:10 cloud-hypervisor
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">42252997</span> Jul <span style="color:#ae81ff">19</span> 06:12 containerd-shim-kata-v2
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">3290472</span> Jul <span style="color:#ae81ff">19</span> 06:14 firecracker
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root  <span style="color:#ae81ff">2589888</span> Jul <span style="color:#ae81ff">19</span> 06:14 jailer
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root    <span style="color:#ae81ff">16686</span> Jul <span style="color:#ae81ff">19</span> 06:12 kata-collect-data.sh
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">37429099</span> Jul <span style="color:#ae81ff">19</span> 06:12 kata-monitor
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">54149384</span> Jul <span style="color:#ae81ff">19</span> 06:12 kata-runtime
</span></span><span style="display:flex;"><span>-rwxr-xr-x. <span style="color:#ae81ff">1</span> root root <span style="color:#ae81ff">17521656</span> Jul <span style="color:#ae81ff">19</span> 06:18 qemu-system-x86_64
</span></span></code></pre></div><p>Restart containerd to enable the new config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl restart containerd
</span></span></code></pre></div><p>Now I can start a Kata container from commadnline.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo ctr image pull docker.io/library/hello-world:latest
</span></span><span style="display:flex;"><span>sudo ctr run --runtime io.containerd.run.kata-qemu.v2 -t --rm docker.io/library/hello-world:latest hello
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo ctr run --runtime io.containerd.run.kata-clh.v2 -t --rm docker.io/library/hello-world:latest hello
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ctr run --snapshotter devmapper --runtime io.containerd.run.kata-fc.v2 -t docker.io/library/hello-world:latest hello
</span></span></code></pre></div><hr>
<h3 id="start-deployment">Start Deployment</h3>
<p>First I create a <code>RuntimeClass</code> for kata-fc then start a pod with this <code>RuntimeClass</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens default
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: node.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: RuntimeClass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: kata-fc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">handler: kata-fc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: untrusted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-kata-fc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  runtimeClassName: kata-fc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: node.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: RuntimeClass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: kata-qemu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">handler: kata-qemu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: untrusted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-kata-qemu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  runtimeClassName: kata-qemu
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: node.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: RuntimeClass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: kata-clh
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">handler: kata-clh
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: untrusted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-kata-clh
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  runtimeClassName: kata-clh
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get po
</span></span><span style="display:flex;"><span>NAME            READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>www-kata-clh    1/1     Running   <span style="color:#ae81ff">0</span>          59s
</span></span><span style="display:flex;"><span>www-kata-fc     1/1     Running   <span style="color:#ae81ff">0</span>          12s
</span></span><span style="display:flex;"><span>www-kata-qemu   1/1     Running   <span style="color:#ae81ff">0</span>          69s
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="kata-container" term="kata-container" label="kata-container" />
                             
                                <category scheme="firecracker" term="firecracker" label="Firecracker" />
                             
                                <category scheme="containerd" term="containerd" label="containerd" />
                             
                                <category scheme="nerdctl" term="nerdctl" label="nerdctl" />
                             
                                <category scheme="almalinux" term="almalinux" label="AlmaLinux" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to deploy containerd with gVisor?]]></title>
            <link href="https://devopstales.github.io/kubernetes/gvisor-containerd/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/firecracker-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with Firecracker?" />
                <link href="https://devopstales.github.io/kubernetes/kata-container-containerd/?utm_source=atom_feed" rel="related" type="text/html" title="How to deploy containerd with kata containers?" />
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/being-productive-with-kubectl/?utm_source=atom_feed" rel="related" type="text/html" title="Being Productive with K8S" />
            
                <id>https://devopstales.github.io/kubernetes/gvisor-containerd/</id>
            
            
            <published>2021-08-22T00:00:00+00:00</published>
            <updated>2021-08-22T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can install and use gvisor engine in kubernetes.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-gvisor">What is gvisor</h3>
<p>gVisor is an application kernel, written in Go, that implements a substantial portion of the Linux system call interface. It provides an additional layer of isolation between running applications and the host operating system.</p>
<p>gVisor includes an Open Container Initiative (OCI) runtime called <code>runsc</code> that makes it easy to work with existing container tooling. The <code>runsc</code> runtime integrates with Docker, containerd and Kubernetes, making it simple to run sandboxed containers.</p>
<p><img src="/img/include/gvisor2.png" alt="gvisor"  class="zoomable" />
<img src="/img/include/gvisor.png" alt="gvisor"  class="zoomable" /></p>
<h3 id="install-gvisor">Install gvisor</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf install epel-release nano wget -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano gvisor.sh
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/bash</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">(</span>
</span></span><span style="display:flex;"><span>  set -e
</span></span><span style="display:flex;"><span>  URL<span style="color:#f92672">=</span>https://storage.googleapis.com/gvisor/releases/release/latest
</span></span><span style="display:flex;"><span>  wget <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/runsc <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/runsc.sha512 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/gvisor-containerd-shim <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/gvisor-containerd-shim.sha512 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/containerd-shim-runsc-v1 <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/containerd-shim-runsc-v1.sha512
</span></span><span style="display:flex;"><span>  sha512sum -c runsc.sha512 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -c gvisor-containerd-shim.sha512 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -c containerd-shim-runsc-v1.sha512
</span></span><span style="display:flex;"><span>  rm -f *.sha512
</span></span><span style="display:flex;"><span>  chmod a+rx runsc gvisor-containerd-shim containerd-shim-runsc-v1
</span></span><span style="display:flex;"><span>  sudo mv runsc gvisor-containerd-shim containerd-shim-runsc-v1 /usr/local/bin
</span></span><span style="display:flex;"><span><span style="color:#f92672">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>bash gvisor.sh
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>runsc: OK
</span></span><span style="display:flex;"><span>gvisor-containerd-shim: OK
</span></span><span style="display:flex;"><span>containerd-shim-runsc-v1: OK
</span></span></code></pre></div><h3 id="install-and-configure-containerd">Install and configure containerd</h3>
<p>First I install containerd then I add Kata container as a containerd plugin to the config.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style="display:flex;"><span>sudo dnf install -y containerd.io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo mkdir -p /etc/containerd
</span></span><span style="display:flex;"><span>sudo containerd config default &gt; /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runsc<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>          runtime_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;io.containerd.runsc.v1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Restart containerd</span>
</span></span><span style="display:flex;"><span>sudo systemctl restart containerd
</span></span><span style="display:flex;"><span>systemctl enable containerd.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;runtime-endpoint: unix:///run/containerd/containerd.sock&#34;</span> &gt; /etc/crictl.yaml
</span></span><span style="display:flex;"><span>crictl ps
</span></span></code></pre></div><p>Now I can start a Kata container from commadnline.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo ctr image pull docker.io/library/busybox:latest
</span></span><span style="display:flex;"><span>sudo ctr run --runtime io.containerd.run.runsc.v1 -t --rm docker.io/library/busybox:latest hello sh
</span></span></code></pre></div><h3 id="install-nerdctl">Install nerdctl</h3>
<p>I like to use <code>nerdctl</code> instad of <code>ctr</code> or <code>crictl</code> cli so I will install it.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/containerd/nerdctl/releases/download/v0.11.0/nerdctl-0.11.0-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar -xzf nerdctl-0.11.0-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>mv nerdctl /usr/local/bin
</span></span><span style="display:flex;"><span>nerdctl ps
</span></span></code></pre></div><h3 id="install-tools">Install tools</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install git -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubectx /usr/local/sbin/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubens /usr/local/sbin/kubens
</span></span></code></pre></div><h3 id="install-kubernetes">Install Kubernetes</h3>
<p>Configure Kernel parameters for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><p>Disable swap for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><p>The I will add the kubernetes repo and Install the packages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf install kubelet kubeadm kubectl -y
</span></span></code></pre></div><p>Start Kubernetes with containerd engine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export IP<span style="color:#f92672">=</span>172.17.13.10
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf install -y iproute-tc
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl enable kubelet.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;KUBELET_EXTRA_ARGS=--cgroup-driver=systemd&#34;</span> | tee /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm config images pull --cri-socket<span style="color:#f92672">=</span>unix:///run/containerd/containerd.sock
</span></span><span style="display:flex;"><span>kubeadm init --pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16 --apiserver-advertise-address<span style="color:#f92672">=</span>$IP --cri-socket<span style="color:#f92672">=</span>unix:///run/containerd/containerd.sock
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get no
</span></span><span style="display:flex;"><span>nerdctl -n k8s.io ps
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl taint nodes <span style="color:#66d9ef">$(</span>hostname<span style="color:#66d9ef">)</span> node-role.kubernetes.io/master:NoSchedule-
</span></span></code></pre></div><h3 id="inincialize-network">Inincialize network</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span></span><span style="display:flex;"><span>kubectl aplly -f kube-flannel.yml
</span></span></code></pre></div><p>OR</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
</span></span><span style="display:flex;"><span>wget https://docs.projectcalico.org/manifests/custom-resources.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano custom-resources.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>      cidr: 10.244.0.0/16
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f custom-resources.yaml
</span></span></code></pre></div><h3 id="start-deployment">Start Deployment</h3>
<p>First I create a <code>RuntimeClass</code> for gvisor then start a pod with this <code>RuntimeClass</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: node.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: RuntimeClass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: gvisor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">handler: runsc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: untrusted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-gvisor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  runtimeClassName: gvisor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get po
</span></span><span style="display:flex;"><span>NAME        READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>www-gvisor  1/1     Running   <span style="color:#ae81ff">0</span>          2m47s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl describe po www-gvisor
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Events:
</span></span><span style="display:flex;"><span>  Type    Reason     Age    From               Message
</span></span><span style="display:flex;"><span>  ----    ------     ----   ----               -------
</span></span><span style="display:flex;"><span>  Normal  Scheduled  2m42s  default-scheduler  Successfully assigned default/www-kata to alma8
</span></span><span style="display:flex;"><span>  Normal  Pulled     2m13s  kubelet            Container image <span style="color:#e6db74">&#34;nginx:1.18&#34;</span> already present on machine
</span></span><span style="display:flex;"><span>  Normal  Created    2m13s  kubelet            Created container www
</span></span><span style="display:flex;"><span>  Normal  Started    2m11s  kubelet            Started container www
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="gvisor" term="gvisor" label="gvisor" />
                             
                                <category scheme="containerd" term="containerd" label="containerd" />
                             
                                <category scheme="nerdctl" term="nerdctl" label="nerdctl" />
                             
                                <category scheme="almalinux" term="almalinux" label="AlmaLinux" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to deploy containerd with kata containers?]]></title>
            <link href="https://devopstales.github.io/kubernetes/kata-container-containerd/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="related" type="text/html" title="Use Cilium BGP integration with OPNsense" />
                <link href="https://devopstales.github.io/kubernetes/being-productive-with-kubectl/?utm_source=atom_feed" rel="related" type="text/html" title="Being Productive with K8S" />
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
            
                <id>https://devopstales.github.io/kubernetes/kata-container-containerd/</id>
            
            
            <published>2021-08-20T00:00:00+00:00</published>
            <updated>2021-08-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can install and use kata-container engine in kubernetes.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-kata-container-engine">What is Kata container engine</h3>
<p>Kata Containers is an open source community working to build a secure container runtime with lightweight virtual machines that feel and perform like containers, but provide stronger workload isolation using hardware virtualization technology as a second layer of defense. (Source: <a href="https://katacontainers.io/">Kata Containers Website</a> )</p>
<p><img src="/img/include/katacontainers.jpg" alt="Kata container engine"  class="zoomable" /></p>
<h3 id="enable-qvemu">Enable qvemu</h3>
<p>I will use Vagrant and VirtualBox for running the AlmaLinux VM so first I need to enable then Nested virtualization on the VM:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VBoxManage modifyvm alma8 --nested-hw-virt on
</span></span></code></pre></div><p>After the Linux is booted test the virtualization flag in the VM:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>egrep --color -i <span style="color:#e6db74">&#34;svm|vmx&#34;</span> /proc/cpuinfo
</span></span></code></pre></div><p>If you find one of this flags everything is ok. Now we need to enable the kvm kernel module.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo modprobe kvm-intel
</span></span></code></pre></div><h3 id="install-kata-container-engine">Install Kata container engine</h3>
<p>I use Almalinux 8 for this install:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo -E dnf install -y centos-release-advanced-virtualization
</span></span><span style="display:flex;"><span>sudo -E dnf module disable -y virt:rhel
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo -E tee /etc/yum.repos.d/kata-containers.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kata-containers]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kata Containers
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=http://mirror.centos.org/centos-8/8/virt/x86_64/kata-containers
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">skip_if_unavailable=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo -E dnf install -y kata-containers
</span></span></code></pre></div><h3 id="install-and-configure-containerd">Install and configure containerd</h3>
<p>First I install containerd then I add Kata container as a containerd plugin to the config.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style="display:flex;"><span>sudo dnf install -y containerd.io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo mkdir -p /etc/containerd
</span></span><span style="display:flex;"><span>sudo containerd config default &gt; /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.kata<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>          runtime_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;io.containerd.kata.v2&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Restart containerd</span>
</span></span><span style="display:flex;"><span>sudo systemctl restart containerd
</span></span><span style="display:flex;"><span>systemctl enable containerd.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;runtime-endpoint: unix:///run/containerd/containerd.sock&#34;</span> &gt; /etc/crictl.yaml
</span></span><span style="display:flex;"><span>crictl ps
</span></span></code></pre></div><p>Now I can start a Kata container from commadnline.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo ctr image pull docker.io/library/busybox:latest
</span></span><span style="display:flex;"><span>sudo ctr run --runtime io.containerd.run.kata.v2 -t --rm docker.io/library/busybox:latest hello sh
</span></span></code></pre></div><h3 id="install-nerdctl">Install nerdctl</h3>
<p>I like to use <code>nerdctl</code> instad of <code>ctr</code> or <code>crictl</code> cli so I will install it.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/containerd/nerdctl/releases/download/v0.11.0/nerdctl-0.11.0-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar -xzf nerdctl-0.11.0-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>mv nerdctl /usr/local/bin
</span></span><span style="display:flex;"><span>nerdctl ps
</span></span></code></pre></div><h3 id="install-kubernetes">Install Kubernetes</h3>
<p>Configure Kernel parameters for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">overlay
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">br_netfilter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kvm-intel
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo modprobe overlay
</span></span><span style="display:flex;"><span>sudo modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><p>Disable swap for Kubernetes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><p>The I will add the kubernetes repo and Install the packages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf install kubelet kubeadm kubectl -y
</span></span></code></pre></div><p>Start Kubernetes with containerd engine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export IP<span style="color:#f92672">=</span>172.17.13.10
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dnf install -y iproute-tc
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl enable kubelet.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;KUBELET_EXTRA_ARGS=--cgroup-driver=systemd&#34;</span> | tee /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm config images pull --cri-socket<span style="color:#f92672">=</span>unix:///run/containerd/containerd.sock
</span></span><span style="display:flex;"><span>kubeadm init --pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16 --apiserver-advertise-address<span style="color:#f92672">=</span>$IP --cri-socket<span style="color:#f92672">=</span>unix:///run/containerd/containerd.sock
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get no
</span></span><span style="display:flex;"><span>nerdctl -n k8s.io ps
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl taint nodes <span style="color:#66d9ef">$(</span>hostname<span style="color:#66d9ef">)</span> node-role.kubernetes.io/master:NoSchedule-
</span></span></code></pre></div><h3 id="inincialize-network">Inincialize network</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span></span><span style="display:flex;"><span>kubectl aplly -f kube-flannel.yml
</span></span></code></pre></div><p>OR</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
</span></span><span style="display:flex;"><span>wget https://docs.projectcalico.org/manifests/custom-resources.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano custom-resources.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>      cidr: 10.244.0.0/16
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f custom-resources.yaml
</span></span></code></pre></div><h3 id="start-deployment">Start Deployment</h3>
<p>First I create a <code>RuntimeClass</code> for Kata then start a pod with this <code>RuntimeClass</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: RuntimeClass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: node.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: kata
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">handler: kata
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: untrusted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-kata
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  runtimeClassName: kata
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get po
</span></span><span style="display:flex;"><span>NAME       READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>www-kata   1/1     Running   <span style="color:#ae81ff">0</span>          2m47s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl describe po www-kata
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Events:
</span></span><span style="display:flex;"><span>  Type    Reason     Age    From               Message
</span></span><span style="display:flex;"><span>  ----    ------     ----   ----               -------
</span></span><span style="display:flex;"><span>  Normal  Scheduled  2m42s  default-scheduler  Successfully assigned default/www-kata to alma8
</span></span><span style="display:flex;"><span>  Normal  Pulled     2m13s  kubelet            Container image <span style="color:#e6db74">&#34;nginx:1.18&#34;</span> already present on machine
</span></span><span style="display:flex;"><span>  Normal  Created    2m13s  kubelet            Created container www
</span></span><span style="display:flex;"><span>  Normal  Started    2m11s  kubelet            Started container www
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="kata-container" term="kata-container" label="kata-container" />
                             
                                <category scheme="containerd" term="containerd" label="containerd" />
                             
                                <category scheme="nerdctl" term="nerdctl" label="nerdctl" />
                             
                                <category scheme="almalinux" term="almalinux" label="AlmaLinux" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Image Signature Verification with Kyverno]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-kyverno-cosign/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/kyverno-image-mirror/?utm_source=atom_feed" rel="related" type="text/html" title="Automatically change registry in pod definition" />
                <link href="https://devopstales.github.io/kubernetes/k8s-connaisseur-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-kyverno-cosign/</id>
            
            
            <published>2021-08-18T00:00:00+00:00</published>
            <updated>2021-08-18T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use Kyverno and Cosign for Image Signature Verification in a Kubernetes cluster.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="wat-is-cosign">Wat is Cosign?</h3>
<p>Cosign is a new open-source tool to manage the process of signing and verifying container images. Developed by Googele in collaboration with Linux Foundation’s sigstore project. The motivation for cosign is &ldquo;to make signatures invisible infrastructure.&rdquo; With Images signed by Cosign you didn&rsquo;t neet to change your infrastructure to store the public signing key, like Notary. (With Notary you need a Notary server connected to your registry to store the keys) With Cosign, the signatures directly appear as tags of the image linked to the associated image via the digest:</p>
<p><img src="/img/include/Cosign.png" alt="Notice how the signature tag below corresponds to the sha256 digest of the image tag ‘latest’ above."  class="zoomable" /></p>
<p>Key Management options:</p>
<ul>
<li>fixed, text-based keys generated using <code>cosign generate-key-pair</code></li>
<li>cloud KMS-based keys generated using <code>cosign generate-key-pair -kms</code></li>
<li>keys generated on hardware tokens using the PIV interface using <code>cosign piv-tool</code></li>
<li>Kubernetes-secret based keys generated using <code>cosign generate-key-pair -k8s</code></li>
</ul>
<h3 id="installing-cosign">Installing Cosign</h3>
<p>It’s a golang project, so it’s fairly easy to get started, there’s a single binary available from their <a href="https://github.com/sigstore/cosign/releases">release pag</a> and it has been signed by them.</p>
<p>Generate key pair with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ cosign generate-key-pair
</span></span><span style="display:flex;"><span>Enter password <span style="color:#66d9ef">for</span> private key:
</span></span><span style="display:flex;"><span>Enter again:
</span></span><span style="display:flex;"><span>Private key written to cosign.key
</span></span><span style="display:flex;"><span>Public key written to cosign.pub
</span></span></code></pre></div><p>Sign an image with cosign:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker pull alpine:edge
</span></span><span style="display:flex;"><span>docker tag alpine:edge devopstales/testimage:unsigned
</span></span><span style="display:flex;"><span>docker push devopstales/testimage:unsigned
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>docker pull alpine:latest
</span></span><span style="display:flex;"><span>docker tag alpine:latest devopstales/testimage:cosign
</span></span><span style="display:flex;"><span>docker push devopstales/testimage:cosign
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cosign sign -key ~/data/cosign.key devopstales/testimage:cosign
</span></span><span style="display:flex;"><span>Enter password <span style="color:#66d9ef">for</span> private key: 
</span></span><span style="display:flex;"><span>Pushing signature to: index.docker.io/devopstales/testimage:sha256-4661fb57f7890b9145907a1fe2555091d333ff3d28db86c3bb906f6a2be93c87.sig
</span></span></code></pre></div><p>Verify a container against a public key:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ cosign verify -key ~/data/cosign.pub devopstales/testimage:cosign
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Verification <span style="color:#66d9ef">for</span> devopstales/testimage:cosign --
</span></span><span style="display:flex;"><span>The following checks were performed on each of these signatures:
</span></span><span style="display:flex;"><span>  - The cosign claims were validated
</span></span><span style="display:flex;"><span>  - The signatures were verified against the specified public key
</span></span><span style="display:flex;"><span>  - Any certificates were verified against the Fulcio roots.
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;critical&#34;</span>:<span style="color:#f92672">{</span><span style="color:#e6db74">&#34;identity&#34;</span>:<span style="color:#f92672">{</span><span style="color:#e6db74">&#34;docker-reference&#34;</span>:<span style="color:#e6db74">&#34;index.docker.io/devopstales/testimage&#34;</span><span style="color:#f92672">}</span>,<span style="color:#e6db74">&#34;image&#34;</span>:<span style="color:#f92672">{</span><span style="color:#e6db74">&#34;docker-manifest-digest&#34;</span>:<span style="color:#e6db74">&#34;sha256:4661fb57f7890b9145907a1fe2555091d333ff3d28db86c3bb906f6a2be93c87&#34;</span><span style="color:#f92672">}</span>,<span style="color:#e6db74">&#34;type&#34;</span>:<span style="color:#e6db74">&#34;cosign container image signature&#34;</span><span style="color:#f92672">}</span>,<span style="color:#e6db74">&#34;optional&#34;</span>:null<span style="color:#f92672">}</span>
</span></span></code></pre></div><h3 id="image-signature-verification-tools">Image Signature Verification tools</h3>
<p>In a <a href="">previous post</a> I used Connaisseur to Image Signature Verification. I could youse Connaisseur with Cosign too but with the new release of Kyverno we didn&rsquo;t need to deploy a separate tool for Image Signature Verification. We can use Kyverno&rsquo;s <code>verifyImages</code> rule.</p>
<p>It validate signatures for matching images using Cosign and mutates image references with the digest returned by Cosign. Using an image digest guarantees immutability of images and hence improves security.</p>
<p>Install the latest version of Kyverno:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -f https://raw.githubusercontent.com/kyverno/kyverno/main/definitions/release/install.yaml
</span></span></code></pre></div><p>Patch the Kyverno webhook, to allow time for calling the OCI registry:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl patch mutatingwebhookconfigurations kyverno-resource-mutating-webhook-cfg <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--type json <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-p<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/webhooks/0/failurePolicy&#34;, &#34;value&#34;: &#34;Ignore&#34;},{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/webhooks/0/timeoutSeconds&#34;, &#34;value&#34;: 15}]&#39;</span>
</span></span></code></pre></div><p>Here is a policy that verifies all images from a specific repository:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kyverno.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">check-image</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">validationFailureAction</span>: <span style="color:#ae81ff">enforce</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">background</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">check-image</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">match</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">kinds</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">verifyImages</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#34;docker.io/devopstales/testimage:*&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">key</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          -----BEGIN PUBLIC KEY-----
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEL53O1V5FP2Vaa60BTwRjrOxhuu5C
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          iB/mODf/V2eiGw+WbA689ZZRjWwXCf+4jwzfRSrik0YvTCMqvl3BDaPG2A==
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          -----END PUBLIC KEY-----</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create deployment signed-my <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--image<span style="color:#f92672">=</span>devopstales/testimage:cosign
</span></span></code></pre></div><p>Try running an unsigned image that matches the configured rule:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create deployment unsigned-my <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--image<span style="color:#f92672">=</span>docker.io/devopstales/testimage:unsigned
</span></span></code></pre></div><p>This will be blocked:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>error: failed to create deployment: admission webhook <span style="color:#e6db74">&#34;mutate.kyverno.svc&#34;</span> denied the request: 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>resource Deployment/kyverno-system/unsigned-my was blocked due to the following policies
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>verify-image:
</span></span><span style="display:flex;"><span>  autogen-verify-image: <span style="color:#e6db74">&#39;image verification failed for docker.io/devopstales/testimage:unsigned:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    failed to verify image: fetching signatures: getting signature manifest: GET https://index.docker.io/v2/devopstales/testimage/manifests/sha256-0119f88f395766eb52f9b817c3d23576bf31935dc8e94abe14bae9a083ce4639.sig:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    MANIFEST_UNKNOWN: manifest unknown; map[Tag:sha256-0119f88f395766eb52f9b817c3d23576bf31935dc8e94abe14bae9a083ce4639.sig]&#39;</span>
</span></span></code></pre></div><hr>
<ul>
<li><a href="https://nirmata.com/2021/08/12/kubernetes-supply-chain-policy-management-with-cosign-and-kyverno/">Kyverno Blog post</a></li>
</ul>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="cosign" term="cosign" label="Cosign" />
                             
                                <category scheme="kyverno" term="kyverno" label="Kyverno" />
                             
                                <category scheme="mutating-webhook" term="mutating-webhook" label="mutating webhook" />
                             
                                <category scheme="admission-controller" term="admission-controller" label="Admission Controller" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Automatically change registry in pod definition]]></title>
            <link href="https://devopstales.github.io/kubernetes/kyverno-image-mirror/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes integration with external Vault" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes and Vault integration" />
            
                <id>https://devopstales.github.io/kubernetes/kyverno-image-mirror/</id>
            
            
            <published>2021-08-16T00:00:00+00:00</published>
            <updated>2021-08-16T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can automatically change the registry part in deployed pods in Kubernetes.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="imageswap-mutating-admission-controller-for-kubernetes">ImageSwap Mutating Admission Controller for Kubernetes</h3>
<p>The ImageSwap webhook enables you to define one or more mappings to automatically swap image definitions within Kubernetes Pods with a different registry.</p>
<p>Install ImageSwap:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl apply -f https://raw.githubusercontent.com/phenixblue/imageswap-webhook/v1.4.2/deploy/install.yaml
</span></span></code></pre></div><p>For swapping configuration ImageSwap use a configmap to define what image should change to what:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">maps</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    default:registry.example.com
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    #gcr.io: # This is a comment
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    gitlab.com:registry.example.com/gitlab
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    noswap_wildcards:example.com</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">imageswap-maps</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">imageswap-system</span>
</span></span></code></pre></div><p>Example MAPS Configs:</p>
<p>Disable image swapping for all registries EXCEPT <code>gcr.io</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>default:
</span></span><span style="display:flex;"><span>gcr.io:harbor.internal.example.com
</span></span></code></pre></div><p>Enable image swapping for all registries except <code>gcr.io</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"></code></pre></div><p>With this, all images will be swapped except those that already match the <code>harbor.internal.example.com</code> pattern</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>default:harbor.internal.example.com
</span></span><span style="display:flex;"><span>noswap_wildcards:harbor.internal.example.com
</span></span></code></pre></div><h3 id="test-imageswap">Test ImageSwap</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl create ns test1
</span></span><span style="display:flex;"><span>$ kubectl label ns test1 k8s.twr.io/imageswap<span style="color:#f92672">=</span>enabled
</span></span></code></pre></div><p>Then deploy a pod:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create deployment unsigned-my <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--image<span style="color:#f92672">=</span>docker.io/devopstales/testimage:unsigned
</span></span></code></pre></div><p>ImageSwap can be disabled on a per workload level by adding the <code>k8s.twr.io/imageswap</code> label with a value of <code>disabled</code> to the pod template.</p>
<h3 id="kyverno">Kyverno</h3>
<p>Here is an example of a Kyverno policy that validates that images are only pulled from an allowed list of image registries (based on wildcard patterns):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion </span>: <span style="color:#ae81ff">kyverno.io/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Policy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">check-registries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">check-registries</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resource</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kinds</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">StatefulSet</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">validate</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">message</span>: <span style="color:#e6db74">&#34;Registry is not allowed&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">pattern</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>              - <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Check allowed registries</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#34;*/nirmata/* | https://private.registry.io/*&#34;</span>
</span></span></code></pre></div><p>Rather than blocking Pods which come from outside registries, it is also possible to mutate them so the pulls are directed to approved registries.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kyverno.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">replace-image-registry</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">policies.kyverno.io/title</span>: <span style="color:#ae81ff">Replace Image Registry</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">policies.kyverno.io/category</span>: <span style="color:#ae81ff">Sample</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">policies.kyverno.io/severity</span>: <span style="color:#ae81ff">medium</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">policies.kyverno.io/subject</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">policies.kyverno.io/minversion</span>: <span style="color:#ae81ff">1.3.6</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">policies.kyverno.io/description</span>: &gt;-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      Rather than blocking Pods which come from outside registries,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      it is also possible to mutate them so the pulls are directed to
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      approved registries. In some cases, those registries may function as
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      pull-through proxies and can fetch the image if not cached.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      This policy policy mutates all images either
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      in the form &#39;image:tag&#39; or &#39;registry.corp.com/image:tag&#39; to be prefaced
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      with `myregistry.corp.com/`.      </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">background</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">replace-image-registry</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">match</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">kinds</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mutate</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">patchStrategicMerge</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#f92672">(name)</span>: <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">image</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                {{ regex_replace_all(&#39;^[^/]+&#39;, &#39;{{@}}&#39;, &#39;myregistry.corp.com&#39;) }}</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="kyverno" term="kyverno" label="Kyverno" />
                             
                                <category scheme="mutating-webhook" term="mutating-webhook" label="mutating webhook" />
                             
                                <category scheme="admission-controller" term="admission-controller" label="Admission Controller" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Use Cilium BGP integration with OPNsense]]></title>
            <link href="https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="related" type="text/html" title="Speed up docker pull with lazypull" />
                <link href="https://devopstales.github.io/kubernetes/k3s-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with k3sup and Cilium" />
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-longhorn/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes project longhorn" />
            
                <id>https://devopstales.github.io/kubernetes/cilium-opnsense-bgp/</id>
            
            
            <published>2021-08-05T00:00:00+00:00</published>
            <updated>2021-08-05T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install Cilium with BGP integration for Kubernetes.</p>
<p>Cilium recently announced the release of 1.10 which allo to advertise routes to Service IPs via BGP, so we didn&rsquo;t need to install MetalLB.</p>
<h3 id="how-does-the-full-setup-look-like">How does the full setup look like?</h3>
<p>For this Demo I will use a pfsense in virtualbox and tree vm for kubernetes in the same host-only network.</p>
<table>
  <thead>
      <tr>
          <th>vm</th>
          <th>nic</th>
          <th>ip</th>
          <th>mode</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>opnsense01</td>
          <td>em1</td>
          <td>192.168.0.200</td>
          <td>bridged</td>
      </tr>
      <tr>
          <td>opnsense01</td>
          <td>em2</td>
          <td>172.17.9.200</td>
          <td>host-only</td>
      </tr>
      <tr>
          <td>k8sm01</td>
          <td>enp0s8</td>
          <td>172.17.9.10</td>
          <td>host-only</td>
      </tr>
      <tr>
          <td>k8sm02</td>
          <td>enp0s8</td>
          <td>172.17.9.11</td>
          <td>host-only</td>
      </tr>
      <tr>
          <td>k8sm02</td>
          <td>enp0s8</td>
          <td>172.17.9.12</td>
          <td>host-only</td>
      </tr>
  </tbody>
</table>
<h3 id="install-bgp-to-opnsense">Install BGP to OPNsense</h3>
<p>Go to <code>System &gt; Firmware &gt; Plugins</code> and install <code>os-frr</code></p>
<h3 id="configure-bgp-on-opnsense">Configure BGP on OPNsense</h3>
<p>Go tp <code>Routing &gt; General</code> and enable enable the plugin. Next go to <code>Routing &gt; BGP</code> and enble, then add AS Number.</p>
<p><img src="/img/include/cilium-opnsense-bgp1.jpg" alt="Enable BGP"  class="zoomable" /></p>
<h3 id="configure-neighbor">Configure Neighbor</h3>
<p>Go to  <code>Routing &gt; BGP</code> the switch to the <code>Neighbor</code> tab and add the following three neighbors.</p>
<p><img src="/img/include/cilium-opnsense-bgp2.jpg" alt="Neighbor"  class="zoomable" /></p>
<p><img src="/img/include/cilium-opnsense-bgp3.jpg" alt="Neighbor"  class="zoomable" /></p>
<p><img src="/img/include/cilium-opnsense-bgp4.PNG" alt="Neighbor"  class="zoomable" /></p>
<h3 id="cilium-configuration">Cilium configuration</h3>
<p>BGP support is enabled by providing the BGP configuration via a ConfigMap and by setting a few Helm values. Otherwise, BGP is disabled by default.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm install cilium cilium/cilium <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--version 1.10.3 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set bgp.enabled<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set bgp.announce.loadbalancerIP<span style="color:#f92672">=</span>true
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">bgp-config</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config.yaml</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    peers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - peer-address: 172.17.9.200
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      peer-asn: 64512
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      my-asn: 64513
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    address-pools:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - name: default
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      protocol: bgp
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      addresses:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - 10.25.0.10-10.25.3.250</span>
</span></span></code></pre></div><h3 id="demo-time">Demo Time</h3>
<p>Let’s create a demo application for testing.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano test.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">LoadBalancer</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f bgpconfig.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f test.yaml
</span></span></code></pre></div><p>After a few moments, you can run this command to get the IP address:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl describe service test-nginx | grep <span style="color:#e6db74">&#34;LoadBalancer Ingress&#34;</span>
</span></span><span style="display:flex;"><span>LoadBalancer Ingress:     10.25.0.11
</span></span></code></pre></div><p>Let&rsquo;s check the address in a browser. If pfSense is you default gateway it will work perfectly, but in my demo enviroment I need to create a route to pfSense for this network on my host machine:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo route add -net 10.25.0.0/22 gw 172.17.9.200
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>route -n
</span></span><span style="display:flex;"><span>Kernel IP routing table
</span></span><span style="display:flex;"><span>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span></span><span style="display:flex;"><span>0.0.0.0         192.168.0.1     0.0.0.0         UG    <span style="color:#ae81ff">600</span>    <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> wlan0
</span></span><span style="display:flex;"><span>10.25.0.0       172.17.9.200    255.255.252.0   UG    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> vboxnet7
</span></span><span style="display:flex;"><span>172.17.9.0      0.0.0.0         255.255.255.0   U     <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> vboxnet7
</span></span></code></pre></div><p><img src="/img/include/pfsense-bgp-kubernetes.png" alt="Demo"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="opnsense" term="opnsense" label="OPNsense" />
                             
                                <category scheme="cilium" term="cilium" label="Cilium" />
                             
                                <category scheme="bgp" term="bgp" label="BGP" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Multi-Tenancy With vCluster]]></title>
            <link href="https://devopstales.github.io/kubernetes/vcluster/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k3sup-calico/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with k3sup and Calico" />
                <link href="https://devopstales.github.io/kubernetes/k3s-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with k3sup and Cilium" />
                <link href="https://devopstales.github.io/kubernetes/k3s-etcd-kube-vip/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with k3sup and kube-vip" />
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k3s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with CRI-O and kadalu" />
            
                <id>https://devopstales.github.io/kubernetes/vcluster/</id>
            
            
            <published>2021-08-03T00:00:00+00:00</published>
            <updated>2021-08-03T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will use vCluster to run virtual Kubernetes clusters inside a Kubernetes cluster.</p>


<H3>Parts of the K3S series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/k3s-etcd-kube-vip/">Install K3S with k3sup and kube-vip</a></li>
     <li>Part1b: <a href="../../kubernetes/k3s-crio/">Install K3S with CRI-O</a></li>
     <li>Part1c: <a href="../../kubernetes/k3s-fcos/">Install K3S on Fedora CoreOS</a></li>
<!-- K3S falnnel wiregard - https://medium.com/@bestpractices/k3s-with-flannel-wireguard-backend-fa433065a401 -->
     <li>Part2b: <a href="../../kubernetes/k3sup-calico/">Install K3S with k3sup and Calico</a></li>
     <li>Part2c: <a href="../../kubernetes/k3s-cilium/">Install K3S with k3sup and Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/k3s-helm-controller/">K3S helm CR</a></li>
<!-- K3D -->
     <li>Part5: <a href="../../kubernetes/k3s-gvisor/">Secure k3s with gVisor</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>



<h3 id="what-is-vcluster">What is vCluster</h3>
<p>We all know about <code>k3d</code> is not, it is a lightweight wrapper to run <code>k3s</code> n docker. In that scenario a Kubernetes node is a container running on docker. Probably <code>k3sd</code> was the inspiration for <code>vCluster</code> but they take the idea to the next level. With <code>vCluster</code> you can run a <code>k3s</code> cluster in a single namespace This solution is similar the <a href="https://github.com/kcp-dev/kcp">kcp</a> but they used the tools that already exists.</p>
<p><img src="/img/include/vcluster-architecture.svg" alt="vcluster - Architecture"  class="zoomable" /></p>
<p><code>vCluster</code> runs a component called <code>syncert</code> that is synchronize the Low-Level component from the <code>k3s</code> cluster like pods, services, ingress. So in reality the parent cluster will run these objects.</p>
<h3 id="getting-started">Getting Started</h3>
<p><code>vCluster</code> give you a cli to ease the task of installation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -s -L <span style="color:#e6db74">&#34;https://github.com/loft-sh/vcluster/releases/latest&#34;</span> | sed -nE <span style="color:#e6db74">&#39;s!.*&#34;([^&#34;]*vcluster-linux-amd64)&#34;.*!https://github.com\1!p&#39;</span> | xargs -n <span style="color:#ae81ff">1</span> curl -L -o vcluster <span style="color:#f92672">&amp;&amp;</span> chmod +x vcluster;
</span></span><span style="display:flex;"><span>sudo mv vcluster /usr/local/bin;
</span></span></code></pre></div><p>In the background <code>vCluster CLI</code> use <code>helm</code> and <code>kubectl</code> to do the magic. So you can easily modify the configuration in the <code>values.yaml</code> file if you want.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns vcluster-1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vcluster create vcluster-1 -n vcluster-1
</span></span></code></pre></div><h3 id="exposing-vcluster">Exposing vcluster</h3>
<p>By default, vcluster is not reachable. To directly access vcluste you need to use one of the following methods:</p>
<ul>
<li>port-forwarding</li>
<li>LoadBalancer service</li>
<li>NodePort service</li>
<li>Ingress</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Use --expose to create a vcluster with an LoadBalancer Service</span>
</span></span><span style="display:flex;"><span>vcluster create vcluster-1 -n vcluster-1 --expose 
</span></span></code></pre></div><p>I have a preinstalled <code>MetalLB</code> so the <code>LoadBalancer Service</code> will work perfectly for me, but if you want to use ingress you can do just fine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">extensions/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes.io/ingress.class</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nginx.ingress.kubernetes.io/backend-protocol</span>: <span style="color:#ae81ff">HTTPS</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nginx.ingress.kubernetes.io/ssl-passthrough</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nginx.ingress.kubernetes.io/ssl-redirect</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vcluster-1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">vcluster-1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">vcluster-1.example.com</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">serviceName</span>: <span style="color:#ae81ff">vcluster-1</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">servicePort</span>: <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
</span></span></code></pre></div><p>When you manually add an ingress or service you mast add the ip or the hostname to the certificate of the <code>k3s</code> cluster</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">syncer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>  - --<span style="color:#ae81ff">tls-san=my-vcluster.example.com</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">syncer</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">extraArgs</span>:
</span></span><span style="display:flex;"><span>  - --<span style="color:#ae81ff">tls-san=10.10.10.5</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vcluster create vcluster-1 -n vcluster-1 -f values.yaml
</span></span></code></pre></div><h3 id="external-datastorage">External Datastorage</h3>
<p>In the default scenario <code>k3s</code> in the namespace will use SQLite as the Datastorage but <code>vCluster</code> can run <code>k3s</code> with all the other supported Datastorage:</p>
<ul>
<li>Embedded SQLite (default)</li>
<li>PostgreSQL</li>
<li>MySQL</li>
<li>MariaDB</li>
<li>etcd</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">vcluster</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">K3S_DATASTORE_ENDPOINT</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#ae81ff">https://etcd-host-1:2379,https://etcd-host-2:2379,https://etcd-host-3:2379</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">vcluster</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">K3S_DATASTORE_ENDPOINT</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#ae81ff">postgres://username:password@hostname:5432/k3s</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">vcluster</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">K3S_DATASTORE_ENDPOINT</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#39;mysql://username:password@tcp(hostname:3306)/k3s&#39;</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">K3S_DATASTORE_CERTFILE</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#39;/path/to/client.crt&#39;</span> 
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">K3S_DATASTORE_KEYFILE</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#39;/path/to/client.key&#39;</span> 
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/data</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">data</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/path/to</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">datastore-tls</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">datastore-tls</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">secret</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">my-datastore-secret</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">items</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">tls.key</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">path</span>: <span style="color:#ae81ff">client.key</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">tls.crt</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">path</span>: <span style="color:#ae81ff">client.crt</span>
</span></span></code></pre></div><p>For this demo I will use the default Datastorage.</p>
<h3 id="access-the-vcluster">Access the vcluster</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vcluster connect vcluster-1 -n vcluster-1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export KUBECONFIG<span style="color:#f92672">=</span>./kubeconfig.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get ns
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Speed up docker pull with lazypull]]></title>
            <link href="https://devopstales.github.io/kubernetes/lazyimage/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-longhorn/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes project longhorn" />
                <link href="https://devopstales.github.io/kubernetes/k8s-connaisseur-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
            
                <id>https://devopstales.github.io/kubernetes/lazyimage/</id>
            
            
            <published>2021-08-02T00:00:00+00:00</published>
            <updated>2021-08-02T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you the solutions to speed up the container downloads.</p>
<p>According to Googles&rsquo;s analisys &ldquo;pulling packages accounts for 76% of container start time, but only 6.4% of that data is read&rdquo; This of course affecting various kinds of workloads on our Kubernetes clusters like cold-start of containers, serverless functions, build and CI/CD. In the community, workarounds are known but they still have unavoidable drawbacks. Let&rsquo;s check this workarounds:</p>
<h3 id="background">Background</h3>
<p>When you run a container the command will pull images from a repository if they are not already available locally. The image is downloaded but not in one big file then multiple smaller one. The runtime engin downloads this files simultaneously to speed up this process. In the background all part is a tar-file downloaded with wget the extracted.</p>
<p>The AUFS storage driver is a common default in container runtime. The AUFS driver takes advantage of the AUFS file system’s layering and copy-on-write (COW) capabilities while also accessing the file system underlying AUFS directly. The driver creates a new directory in the underlying file system for each layer it stores. As a union file system it does not store data directly on disk, but instead uses another file system (e.g. ext4) as underlying storage. A union mount point provides a view of multiple directories in the underlying file system.</p>
<p>Using a HelloBench tool that they wrote, the authors analyse 57 different container images pulled from the Docker Hub. Across these images there are 550 nodes and and 19 roots. They realized that the average uncompressed image is 15 x larger that the amount of image data needed for container startup.</p>
<p>For solving this problem several solution have been proposed including <a href="https://cernvm.cern.ch/fs/">CernVM-FS</a>, <a href="https://stevelasker.blog/2019/10/29/azure-container-registry-teleportation/">Microsoft Teleportation</a>, <a href="https://github.com/google/crfs">Google CRFS</a> and <a href="https://d7y.io/en-us/">Dragonfly</a></p>
<h3 id="standard-compatible-solution">Standard compatible solution</h3>
<p>Containerd started <a href="https://github.com/containerd/stargz-snapshotter">Stargz Snapshotter</a> as a plugin to improve the pull performance. It enables to lazy pull container images leveraging <a href="https://github.com/google/crfs">stargz image format from Google</a>.</p>
<p><img src="/img/include/lazypull1.png" alt="lazypull"  class="zoomable" /></p>
<p>The lazy pull here means containerd doesn’t download the entire image on pull operation but fetches necessary contents on-demand. This shortens the container startup latency from tens of seconds into a few seconds at the best.</p>
<p><img src="/img/include/lazypull2.png" alt="Benchmarking result from the project repository."  class="zoomable" /></p>
<h3 id="quick-start">Quick start</h3>
<p>Containerd supports lazy pulling since version 1.4. Stargz Snapshotter is the plugin that enables containerd to handle eStargz.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>proxy_plugins<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">[</span>proxy_plugins.stargz<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;snapshot&#34;</span>
</span></span><span style="display:flex;"><span>    address <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/run/containerd-stargz-grpc/containerd-stargz-grpc.sock&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Use stargz snapshotter through CRI</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>plugins.<span style="color:#e6db74">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  snapshotter <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;stargz&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nerdctl --snapshotter<span style="color:#f92672">=</span>stargz run -it --rm docker.io/stargz-containers/fedora:30-esgz
</span></span></code></pre></div><p>CRI-O experimentally supports lazy pulling. The plugin that enables this is called <a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/INSTALL.md#whats-stargz-snapshotter-and-stargz-store">Additional Layer Store</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/containers/storage.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Additional Layer Store is supported only by overlay driver as of now </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>storage<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>driver <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;overlay&#34;</span>
</span></span><span style="display:flex;"><span>graphroot <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/var/lib/containers/storage&#34;</span>
</span></span><span style="display:flex;"><span>runroot <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/run/containers/storage&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Interact with Additional Layer Store over a directory</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>storage.options<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>additionallayerstores <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;/path/to/additional/layer/store:ref&#34;</span><span style="color:#f92672">]</span>
</span></span></code></pre></div><p><img src="/img/include/lazypull3.png" alt="eStargz in container workflow"  class="zoomable" /></p>
<h3 id="build-images">Build images</h3>
<p>You can create an eStarge image using eStargz-aware image builders (e.g. <a href="https://github.com/GoogleContainerTools/kaniko">Kaniko</a>) or image converters (e.g. ctr-remote and nerdctl).</p>
<p><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/ctr-remote.md">ctr-remote</a> is a CLI for converting an OCI/Docker image into eStargz.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ctr-remote image pull docker.io/library/ubuntu:21.04
</span></span><span style="display:flex;"><span>ctr-remote image optimize --oci <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    docker.io/library/ubuntu:21.04 docker.io/devopstales/ubuntu:21.04-esgz
</span></span><span style="display:flex;"><span>ctr-remote image push docker.io/devopstales/ubuntu:21.04-esgz
</span></span></code></pre></div><p>nerdctl supports creating eStargz images</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nerdctl build -t docker.io/devopstales/foo:1 .
</span></span><span style="display:flex;"><span>nerdctl image convert --estargz --oci <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    docker.io/devopstales/foo:1 docker.io/devopstales/foo:1-esgz
</span></span><span style="display:flex;"><span>nerdctl push docker.io/devopstales/foo:1-esgz
</span></span></code></pre></div><p><a href="https://github.com/GoogleContainerTools/kaniko">Kaniko</a> is an image builder runnable in containers and Kubernetes. Since v1.5.0, it experimentally supports building eStargz. 7</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker run --rm -e GGCR_EXPERIMENT_ESTARGZ<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -v /tmp/context:/workspace <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -v ~/.docker/config.json:/kaniko/.docker/config.json:ro <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    gcr.io/kaniko-project/executor:v1.6.0 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>      --destination <span style="color:#e6db74">&#34;docker.io/devopstales/sample:esgz&#34;</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Image Signature Verification Admission Controller V2]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-connaisseur-v2/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-connaisseur/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
                <link href="https://devopstales.github.io/kubernetes/k8s-prometheus-stack/?utm_source=atom_feed" rel="related" type="text/html" title="K8S Logging And Monitoring" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-connaisseur-v2/</id>
            
            
            <published>2021-08-01T00:00:00+00:00</published>
            <updated>2021-08-01T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can deploy Connaisseur 2.0 to Image Signature Verification into a Kubernetes cluster.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-connaisseur">What is Connaisseur?</h3>
<p>Connaisseur is an admission controller for Kubernetes that integrates Image Signature Verification into a cluster, as a means to ensure that only valid images are being deployed.</p>
<h3 id="notary">Notary</h3>
<p>Notary is an open source signing solution for containers based on The Update Framework Notary uses TUFs’ roles and key hierarchy for signing of the images. There are five keys to sign the metadata files which lists all filenames in the collection, their sizes and respective hashes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apt install notary
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker pull alpine
</span></span><span style="display:flex;"><span>docker tag alpine:latest devopstales/testimage:unsigned
</span></span><span style="display:flex;"><span>docker push devopstales/testimage:unsigned
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>notary -s https://notary.docker.io -d ~/.docker/trust init -p docker.io/devopstales/testimage     
</span></span><span style="display:flex;"><span>Root key found, using: 31579f2a034add499da6e799bc9260d08a15ab1804298218f05f78d97a669f77
</span></span><span style="display:flex;"><span>Enter passphrase <span style="color:#66d9ef">for</span> root key with ID 31579f2: 
</span></span><span style="display:flex;"><span>Enter passphrase <span style="color:#66d9ef">for</span> new targets key with ID 42e49c6: 
</span></span><span style="display:flex;"><span>Repeat passphrase <span style="color:#66d9ef">for</span> new targets key with ID 42e49c6: 
</span></span><span style="display:flex;"><span>Enter passphrase <span style="color:#66d9ef">for</span> new snapshot key with ID 399243c: 
</span></span><span style="display:flex;"><span>Repeat passphrase <span style="color:#66d9ef">for</span> new snapshot key with ID 399243c: 
</span></span><span style="display:flex;"><span>Enter username: devopstales
</span></span><span style="display:flex;"><span>Enter password: 
</span></span><span style="display:flex;"><span>Auto-publishing changes to docker.io/devopstales/testimage
</span></span><span style="display:flex;"><span>Enter username: devopstales
</span></span><span style="display:flex;"><span>Enter password: 
</span></span><span style="display:flex;"><span>Successfully published changes <span style="color:#66d9ef">for</span> repository docker.io/devopstales/testimage
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export DOCKER_CONTENT_TRUST<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>export DOCKER_CONTENT_TRUST_SERVER<span style="color:#f92672">=</span>https://notary.docker.io
</span></span><span style="display:flex;"><span>docker tag alpine:latest devopstales/testimage:signed
</span></span><span style="display:flex;"><span>docker push devopstales/testimage:signed
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ find ~/.docker/trust/ | head
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private/1f4a9a0922605b3bc19c97e180d962d530721288f4fd0845ad0aa37ba4a6f95d.key
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private/fe30e72f5976b2ae7d0d365f28dacfae9c71f11ad854065603ccc806900e84fa.key
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private/3da0d27e2d3b964d238d1d184c7578b5f2737b918ec5b8265474e22b07b2ea22.key
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private/root-priv.key
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private/root-pub.pem
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/tuf
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/tuf/docker.io
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/tuf/docker.io/devopstales
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>notary -s https://notary.docker.io -d ~/.docker/trust list docker.io/devopstales/testimage
</span></span><span style="display:flex;"><span>NAME     DIGEST                                                              SIZE <span style="color:#f92672">(</span>BYTES<span style="color:#f92672">)</span>    ROLE
</span></span><span style="display:flex;"><span>----     ------                                                              ------------    ----
</span></span><span style="display:flex;"><span>signed    4661fb57f7890b9145907a1fe2555091d333ff3d28db86c3bb906f6a2be93c87    <span style="color:#ae81ff">528</span>             targets/devopstales
</span></span></code></pre></div><h3 id="install-connaisseur">Install Connaisseur</h3>
<pre tabindex="0"><code># The installer use yq so we need to install it

wget https://github.com/mikefarah/yq/releases/download/v4.2.0/yq_linux_amd64 -O /usr/bin/yq &amp;&amp;\
    chmod +x /usr/bin/yq
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># generate the public root cert</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cd ~/.docker/trust/private
</span></span><span style="display:flex;"><span>sed <span style="color:#e6db74">&#39;/^role:\sroot$/d&#39;</span> <span style="color:#66d9ef">$(</span>grep -iRl <span style="color:#e6db74">&#34;role: root&#34;</span> .<span style="color:#66d9ef">)</span> &gt; root-priv.key
</span></span><span style="display:flex;"><span>openssl ec -in root-priv.key -pubout -out root-pub.pem
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">git clone https://github.com/sse-secure-systems/connaisseur.git</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cd connaisseur</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">nano helm/values.yaml</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">validators</span>:
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#75715e"># static validator that allows each image</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">allow</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">static</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">approve</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># pre-configured nv1 validator for public notary from Docker Hub</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">name</span>: <span style="color:#ae81ff">dockerhub_basics</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">notaryv1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">host</span>: <span style="color:#ae81ff">notary.docker.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">trust_roots</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># public key for official docker images (https://hub.docker.com/search?q=&amp;type=image&amp;image_filter=official)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># !if not needed feel free to remove the key!</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">docker_official</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">key</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      -----BEGIN PUBLIC KEY-----
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEOXYta5TgdCwXTCnLU09W5T4M4r9f
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      QQrqJuADP6U7g5r9ICgPSmZuRHP/1AYUfOQW3baveKsT969EfELKj1lfCA==
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      -----END PUBLIC KEY-----</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># public key securesystemsengineering repo including Connaisseur images</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># !this key is critical for Connaisseur!</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">securesystemsengineering_official</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">key</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      -----BEGIN PUBLIC KEY-----
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEsx28WV7BsQfnHF1kZmpdCTTLJaWe
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      d0CA+JOi8H4REuBaWSZ5zPDe468WuOJ6f71E7WFg3CVEVYHuoZt2UYbN/Q==
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      -----END PUBLIC KEY-----</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># public key securesystemsengineering repo including devopstales images</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">devopstales_official</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">key</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      -----BEGIN PUBLIC KEY-----
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE9m6WfwViwT8lYjLF6jAs1bvd1hPp
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      cRUmONP49JszW1X/6Q22DygylIJGyC8IXeb3zBWVMoYDxauiqrFomHUOEA==
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      -----END PUBLIC KEY-----</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">policy</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">pattern</span>: <span style="color:#e6db74">&#34;*:*&#34;</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">pattern</span>: <span style="color:#e6db74">&#34;docker.io/library/*:*&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">validator</span>: <span style="color:#ae81ff">dockerhub_basics</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">with</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">trust_root</span>: <span style="color:#ae81ff">docker_official</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">pattern</span>: <span style="color:#e6db74">&#34;k8s.gcr.io/*:*&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">validator</span>: <span style="color:#ae81ff">allow</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">pattern</span>: <span style="color:#e6db74">&#34;docker.io/securesystemsengineering/*:*&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">validator</span>: <span style="color:#ae81ff">dockerhub_basics</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">with</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">trust_root</span>: <span style="color:#ae81ff">securesystemsengineering_official</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">pattern</span>: <span style="color:#e6db74">&#34;docker.io/devopstales/*:*&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">validator</span>: <span style="color:#ae81ff">dockerhub_basics</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">with</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">trust_root</span>: <span style="color:#ae81ff">devopstales_official</span>
</span></span></code></pre></div><ul>
<li>the <code>default</code> validator is used if no validator is specified in image policy</li>
<li>type: supported validators (e.g. &ldquo;cosign&rdquo; or &ldquo;notaryv1&rdquo;) notaryv2 is not yet supported</li>
<li>host: url of the notary server</li>
<li>key: the public part of the root key, for verifying notary&rsquo;s signatures</li>
</ul>
<p>Then deploy the helm chart. This can take a few minutes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm install connaisseur helm --atomic --create-namespace --namespace connaisseur
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get all -n connaisseur
</span></span><span style="display:flex;"><span>NAME                                          READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>pod/connaisseur-deployment-565d45bb74-ktbmb   1/1     Running   <span style="color:#ae81ff">0</span>          71s
</span></span><span style="display:flex;"><span>pod/connaisseur-deployment-565d45bb74-pfghx   1/1     Running   <span style="color:#ae81ff">0</span>          71s
</span></span><span style="display:flex;"><span>pod/connaisseur-deployment-565d45bb74-rcj44   1/1     Running   <span style="color:#ae81ff">0</span>          71s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                      TYPE        CLUSTER-IP    EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>   AGE
</span></span><span style="display:flex;"><span>service/connaisseur-svc   ClusterIP   10.43.196.6   &lt;none&gt;        443/TCP   71s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style="display:flex;"><span>deployment.apps/connaisseur-deployment   3/3     <span style="color:#ae81ff">3</span>            <span style="color:#ae81ff">3</span>           71s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                                                DESIRED   CURRENT   READY   AGE
</span></span><span style="display:flex;"><span>replicaset.apps/connaisseur-deployment-565d45bb74   <span style="color:#ae81ff">3</span>         <span style="color:#ae81ff">3</span>         <span style="color:#ae81ff">3</span>       71s
</span></span></code></pre></div><h3 id="test-the-image-signature-verification">Test the Image Signature Verification</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens default
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl run unsigned --image<span style="color:#f92672">=</span>docker.io/devopstales/testimage:unsigned
</span></span><span style="display:flex;"><span>Error from server: admission webhook <span style="color:#e6db74">&#34;connaisseur-svc.connaisseur.svc&#34;</span> denied the request: Unable to find signed digest <span style="color:#66d9ef">for</span> image docker.io/devopstales/testimage:unsigned.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl run signed --image<span style="color:#f92672">=</span>docker.io/devopstales/testimage:signed
</span></span><span style="display:flex;"><span>pod/signed created
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get po
</span></span></code></pre></div><h3 id="final-words">Final words</h3>
<p>Connaisseur is a grate tool and with the 2.0 it solved all of the 1.0&rsquo;s shortcomings:</p>
<ul>
<li>There is no option to whitelist images in a specific namespace.</li>
<li>Connaisseur supports only one Notary server</li>
<li>Connaisseur supports only one public key</li>
</ul>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="notary" term="notary" label="Notary" />
                             
                                <category scheme="cosign" term="cosign" label="Cosign" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Create a Helm reposirory with GitHub Pages]]></title>
            <link href="https://devopstales.github.io/kubernetes/helm-repositoty/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/helm3-loki/?utm_source=atom_feed" rel="related" type="text/html" title="Install Grafana Loki with Helm3" />
                <link href="https://devopstales.github.io/kubernetes/k8s-error-at-kubectl-logs/?utm_source=atom_feed" rel="related" type="text/html" title="K8s ERROR at kubectl logs" />
                <link href="https://devopstales.github.io/sso/k8s-kuberos/?utm_source=atom_feed" rel="related" type="text/html" title="Kubectl authentication with Kuberos" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph-storage-with-csi-driver/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD volume with CSI driver" />
                <link href="https://devopstales.github.io/monitoring/grafana-loki/?utm_source=atom_feed" rel="related" type="text/html" title="Grafana Loki" />
            
                <id>https://devopstales.github.io/kubernetes/helm-repositoty/</id>
            
            
            <published>2021-07-25T00:00:00+00:00</published>
            <updated>2021-07-25T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can host your own Helm repository with GitHub Pages.</p>
<h2 id="create-a-new-github-repository">Create a new GitHub Repository</h2>
<p>Log into GitHub and create a <a href="https://github.com/new">new repository</a> called helm-charts. I chose to hav a README file and an Apache2 licence in mye repository.</p>
<p>Clone the repository to start working.</p>
<pre tabindex="0"><code>git clone git@github.com:devopstales/helm-charts.git
cd helm-charts

tree
.
├── LICENSE
└── README.md
</code></pre><p>Create a hem chart in the repository:</p>
<pre tabindex="0"><code>mkdir charts
helm create charts/chart1
helm create charts/chart2

tree
.
├── charts
│   ├── chart1
│   │   ├── charts
│   │   ├── Chart.yaml
│   │   ├── templates
│   │   │   ├── deployment.yaml
│   │   │   ├── _helpers.tpl
│   │   │   ├── ingress.yaml
│   │   │   ├── NOTES.txt
│   │   │   ├── service.yaml
│   │   │   └── tests
│   │   │       └── test-connection.yaml
│   │   └── values.yaml
│   └── chart2
│       ├── charts
│       ├── Chart.yaml
│       ├── templates
│       │   ├── deployment.yaml
│       │   ├── _helpers.tpl
│       │   ├── ingress.yaml
│       │   ├── NOTES.txt
│       │   ├── service.yaml
│       │   └── tests
│       │       └── test-connection.yaml
│       └── values.yaml
├── LICENSE
└── README.md
</code></pre><h3 id="push-to-github">Push to GitHub:</h3>
<pre tabindex="0"><code>echo &#34;.deploy&#34; &gt;&gt; .gitignore
git add . --all
git commit -m &#39;Initial Commit&#39;
git push origin main
</code></pre><p>Create brach for GitHub Pages and release:</p>
<pre tabindex="0"><code>git checkout --orphan gh-pages
Switched to a new branch &#39;gh-pages&#39;

rm -rf charts
git add . --all
git commit -m &#39;initial gh-pages&#39;
git push origin gh-pages
git checkout main
</code></pre><p>Next enable GitHub Pages i the repository settings. After a few minutes you should have a default rendering on your README.md at the provided URL.</p>
<h2 id="use-chart-releaser">Use chart-releaser</h2>
<p>Yo can create a chart Helm repository by usin the <code>helm package</code> and <code>helm repo</code> commands but you can simplify your life by using <code>chart-releaser</code>.</p>
<h3 id="install-for-lnux">Install for Lnux:</h3>
<pre tabindex="0"><code>cd /tmp
curl -sSL https://github.com/helm/chart-releaser/releases/download/v1.2.1/chart-releaser_1.2.1_linux_amd64.tar.gz | tar xzf -
mv cr ~/bin/cr
cr help
</code></pre><h2 id="install-for-mac-osx">Install for Mac osX:</h2>
<pre tabindex="0"><code>$ brew tap helm/tap
$ brew install chart-releaser
</code></pre><h3 id="usage">Usage:</h3>
<p>The <code>cr index</code> will create the appropriate <code>index.yaml</code> and <code>cr upload</code> will upload the packages to GitHub Releases. Fot theat you need a GitHub Token.
In your browser go to your <a href="https://github.com/settings/tokens">github developer settings</a> and create a new personal access token and add full access to the repo.</p>
<p>Create an environment variable for the token:</p>
<pre tabindex="0"><code>export CH_TOKEN=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sdf

helm package charts/{chart1,chart2} --destination .deploy

cr upload -o devopstales -r helm-charts -p .deploy
git checkout gh-pages
cr index -i ./index.yaml -p .deploy -o devopstales -r helm-charts -c https://devopstales.github.io/helm-charts/

git add index.yaml
git commit -m &#39;release 0.1.0&#39;
git push origin gh-pages
</code></pre><h3 id="update-the-readmemd-with-instructions-to-usage">Update the README.md with instructions to usage</h3>
<pre tabindex="0"><code>nano README.md
git add README.md
git commit -m &#39;update readme with instructions&#39;
git push origin gh-pages
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm3" term="helm3" label="helm3" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Add a Custom Host to Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-custom-host/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V3" />
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
                <link href="https://devopstales.github.io/kubernetes/k8s-prometheus-stack/?utm_source=atom_feed" rel="related" type="text/html" title="K8S Logging And Monitoring" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes integration with external Vault" />
                <link href="https://devopstales.github.io/kubernetes/rke2-calico/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With Calico" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-custom-host/</id>
            
            
            <published>2021-07-22T00:00:00+00:00</published>
            <updated>2021-07-22T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to add custom hosts to kubernetes.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>CoreDNS is the DNS server in kubernetes. I some situation I need to add custom hosts to be resolvable in the kubernetes netwok.</p>
<p>First, edit the ConfigMap of the coredns using the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl edit cm -n kube-system coredns
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or</span>
</span></span><span style="display:flex;"><span>kubectl edit cm -n kube-system rke2-coredns-rke2-coredns
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Corefile</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    .:53 {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        errors
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        health {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          lameduck 5s
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ready
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        kubernetes cluster.local in-addr.arpa ip6.arpa {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          pods insecure
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          fallthrough in-addr.arpa ip6.arpa
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        prometheus :9153
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        forward . 8.8.8.8 8.8.4.4
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        cache 30
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        loop
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        reload
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        loadbalance
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        hosts /etc/coredns/customdomains.db k8s.intra {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          172.17.14.10 rancher.k8s.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          172.17.14.10 hubble.k8s.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          172.17.14.10 grafana.k8s.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          172.17.14.10 alertmanager.k8s.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          172.17.14.10 prometheus.k8s.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          172.17.14.10 sso.k8s.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          fallthrough
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }</span>
</span></span></code></pre></div><p>Delete coredens pods:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get pod -n kube-system | grep dns
</span></span><span style="display:flex;"><span>kubectl delete pod -n kube-system core-dns-#########
</span></span></code></pre></div><p>It’s done! You can now reach that custom host from inside any pod on the cluster.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="coredns" term="coredns" label="CoreDNS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[RKE2 Image security Admission Controller V3]]></title>
            <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes integration with external Vault" />
                <link href="https://devopstales.github.io/kubernetes/rke2-calico/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With Calico" />
            
                <id>https://devopstales.github.io/kubernetes/image-security-admission-controller-v3/</id>
            
            
            <published>2021-06-21T00:00:00+00:00</published>
            <updated>2021-06-21T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In a previous posts we talked about the <a href="https://devopstales.github.io/home/image-security-admission-controller/">anchore-image-validator made by Banzaicloud</a> and the <a href="https://devopstales.github.io/home/image-security-admission-controller-v2/">admission-controller made by Anchore</a>. In this post I will show you my own admission-controller for image scanning.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>I found multiple solution for Anchore Engine but only one for Trivy. The <a href="https://github.com/aquasecurity/trivy-enforcer">trivy-enforcer</a> that is an experimental project and use OPA for enforce the policy. So I decide to create mey own dmission-controller.</p>
<h3 id="how-an-admission-controller-works">How an admission controller works</h3>
<p>An Admission Controller Webhook is triggered when a Kubernetes object is created. It sends a JSON formatted HTTP request to a specific Kubernetes Service in a namespace which returns a JSON response. If you whoud like to now more aboute admission controllers you can read about it in my previous post <a href="https://devopstales.github.io/kubernetes/admission-controllers/">Using Admission Controllers</a></p>
<h3 id="writing-a-validating-admission-controller">Writing a Validating Admission Controller</h3>
<p>I want to walidate the Pod object to check how many vulnerability has the image in this pod. So I wrote a <a href="https://github.com/devopstales/trivy-image-validator/blob/master/trivy-scanner.py">python script</a> that will pars the JSON request for the pods image, rin a trivy scan on it and sen back the answer. Then I build it to a docker image called <code>devopstales/trivy-scanner-admission:1.0.1</code>. I run it as a deployment:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>--- 
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PersistentVolumeClaim</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>: 
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-cache</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>: 
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">accessModes</span>: 
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">ReadWriteOnce</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>: 
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">requests</span>: 
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">1G</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-scanner</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">trivy-scanner</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">validation</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">trivy-scanner</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">trivy-scanner</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">fsGroup</span>: <span style="color:#ae81ff">10001</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-scanner</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">image</span>: <span style="color:#ae81ff">devopstales/trivy-scanner-admission:1.0.1</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#ae81ff">Always</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cache</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">mountPath</span>: <span style="color:#e6db74">&#34;/home/kube-trivy-admission/.cache/trivy&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#          - name: config-json</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#            mountPath: &#34;/home/kube-trivy-admission/.docker&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cache</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">persistentVolumeClaim</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">claimName</span>: <span style="color:#e6db74">&#34;trivy-cache&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#      - name: config-json</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#        secret:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#          secretName: config-json</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-scanner</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">validation</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">trivy-scanner</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">443</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">5000</span>
</span></span></code></pre></div><p>The Service must be an HTTPS port on 443 for the Admission Webhook so I created a self-signed certificate and placed in the docker container.</p>
<h3 id="create-the-admission-webhook">Create the Admission Webhook</h3>
<p>The abow Admission Webhook will send teh HTTP request to my <code>trivy-scanner</code> service:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">admissionregistration.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ValidatingWebhookConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-scanner</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">webhooks</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-scanner.devopstales.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">sideEffects</span>: <span style="color:#e6db74">&#34;None&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">admissionReviewVersions</span>: [<span style="color:#ae81ff">v1beta1, v1]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">clientConfig</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-scanner</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">validation</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#e6db74">&#34;/validate&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">caBundle</span>: <span style="color:#e6db74">&#34;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&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;apps&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>]
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#e6db74">&#34;pods&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">apiVersions</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">operations</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">CREATE</span>
</span></span></code></pre></div><p>I placed the root CA of my self-signed certificate in this Validating Webhook Configuration to make my Service&rsquo;s certiface valid for the Kubernetes api.</p>
<h3 id="policy">Policy</h3>
<p>Now If I create a Deployment, Pod &hellip; It scan the Image with tryvi. To block an Image I need to add the limits of the maximum numer of vulnerability for the severities.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/medium</span>: <span style="color:#e6db74">&#34;5&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/low</span>: <span style="color:#e6db74">&#34;10&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">trivy.security.devopstales.io/critical</span>: <span style="color:#e6db74">&#34;2&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:latest</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">80</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="rke2" term="rke2" label="rke2" />
                             
                                <category scheme="rancher" term="rancher" label="rancher" />
                             
                                <category scheme="admission-controller" term="admission-controller" label="Admission Controller" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Continuous Image Security]]></title>
            <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes integration with external Vault" />
                <link href="https://devopstales.github.io/kubernetes/rke2-calico/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With Calico" />
                <link href="https://devopstales.github.io/kubernetes/rke2-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With cilium" />
            
                <id>https://devopstales.github.io/kubernetes/continuous-image-security/</id>
            
            
            <published>2021-06-15T00:00:00+00:00</published>
            <updated>2021-06-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you my tool to Continuously scann deployed images in your Kubernetes cluster.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>In a previous posts we talked about admission-controllers that scnas the image at deploy. Like <a href="https://devopstales.github.io/home/image-security-admission-controller/">Banzaicloud&rsquo;s anchore-image-validator</a> and <a href="https://devopstales.github.io/home/image-security-admission-controller-v2/">Anchore&rsquo;s own admission-controller</a>. But what if you run your image for a long time. Last weak I realised I run containers wit imagest older the a year. I this time period many new vulnerability came up.</p>
<p>I find a tool called <a href="https://github.com/fleeto/trivy-scanner">trivy-scanner</a> that do almast what I want. It scans the docker images in all namespaces with the label <code>trivy=true</code> and get the resoults to a prometheus endpoint. It based on <a href="https://github.com/flant/shell-operator">Shell Operator</a> that runs a small python script. I made my own version from it:</p>
<h3 id="deploy-the-app">Deploy the app</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/devopstales/trivy-scanner
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano trivy-scanner/deploy/kubernetes/kustomization.yaml
</span></span><span style="display:flex;"><span>namespace: trivy-scanner
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create ns trivy-scanner
</span></span><span style="display:flex;"><span>kubectl aplly -k trivy-scanner/deploy/kubernetes/
</span></span></code></pre></div><h3 id="demo">Demo</h3>
<p>Test the <code>guestbook-demo</code> namespace:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl label namespaces guestbook-demo trivy<span style="color:#f92672">=</span>true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get service -n trivy-scanner
</span></span><span style="display:flex;"><span>NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>  AGE
</span></span><span style="display:flex;"><span>trivy-scanner   ClusterIP   10.43.179.39   &lt;none&gt;        9115/TCP   15m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -s http://10.43.179.39:9115/metrics | grep so_vulnerabilities
</span></span></code></pre></div><p>Now you need to add the <code>trivy-scanner</code> <code>Service</code> as target for your prometheus. I created a <code>ServiceMonitor</code> object for that:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">monitoring.coreos.com/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceMonitor</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">serviceapp</span>: <span style="color:#ae81ff">trivy-exporter-servicemonitor</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">release</span>: <span style="color:#ae81ff">prometheus</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">trivy-exporter-servicemonitor</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">trivy-scanner</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">endpoints</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">metrics</span>
</span></span></code></pre></div><p>If you use my grafana dasgboard from the repo you can see someting like this:</p>
<p><img src="/img/include/trivy-exporter.png" alt="image"  class="zoomable" /> <br></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="operator" term="operator" label="Operator" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="rke2" term="rke2" label="rke2" />
                             
                                <category scheme="rancher" term="rancher" label="rancher" />
                             
                                <category scheme="admission-controller" term="admission-controller" label="Admission Controller" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[K8S Logging And Monitoring]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-prometheus-stack/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/continuous-image-security/?utm_source=atom_feed" rel="related" type="text/html" title="Continuous Image Security" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault-v2/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes integration with external Vault" />
                <link href="https://devopstales.github.io/kubernetes/rke2-calico/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With Calico" />
                <link href="https://devopstales.github.io/kubernetes/rke2-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With cilium" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cert/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Certificate Rotation" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-prometheus-stack/</id>
            
            
            <published>2021-06-15T00:00:00+00:00</published>
            <updated>2021-06-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install a prometheus operator to monotor kubernetes and loki to gether logs.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>Prometheus is an open-source monitoring system with a built-in noSQL time-series database. It offers a multi-dimensional data model, a flexible query language, and diverse visualization possibilities. Prometheus collects metrics from http nedpoint. Most service dind&rsquo;t have this endpoint so you need optional programs that generate additional metrics cald exporters.</p>
<h3 id="monitoring">Monitoring</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano values.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">global</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rbac</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pspEnabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">alertmanager</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">alertmanagerSpec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumeClaimTemplate</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">10Gi</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cert-manager.io/cluster-issuer</span>: <span style="color:#ae81ff">ca-issuer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">alertmanager.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">ImplementationSpecific</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">tls-alertmanager-cert</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">alertmanager.k8s.intra</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">grafana</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rbac</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enable</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pspEnabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pspUseAppArmor</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">initChownData</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">adminPassword</span>: <span style="color:#ae81ff">Password1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">plugins</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">grafana-piechart-panel</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">persistence</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">size</span>: <span style="color:#ae81ff">10Gi</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cert-manager.io/cluster-issuer</span>: <span style="color:#ae81ff">ca-issuer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">grafana.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">ImplementationSpecific</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">tls-grafana-cert</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">grafana.k8s.intra</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">prometheus</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">prometheusSpec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">podMonitorSelectorNilUsesHelmValues</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">serviceMonitorSelectorNilUsesHelmValues</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secrets</span>: [<span style="color:#e6db74">&#39;etcd-client-cert&#39;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">storageSpec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumeClaimTemplate</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">10Gi</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cert-manager.io/cluster-issuer</span>: <span style="color:#ae81ff">ca-issuer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">prometheus.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">/</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">ImplementationSpecific</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">tls-prometheus-cert</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">prometheus.k8s.intra</span>
</span></span></code></pre></div><p>There is a bug in the Grafana helm chart so it didn&rsquo;t sreate the psp correcly for the init container: <a href="https://github.com/grafana/helm-charts/issues/427">https://github.com/grafana/helm-charts/issues/427</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># solution</span>
</span></span><span style="display:flex;"><span>kubectl edit psp prometheus-grafana
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>  runAsUser:
</span></span><span style="display:flex;"><span>    rule: RunAsAny
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get rs
</span></span><span style="display:flex;"><span>NAME                                             DESIRED   CURRENT   READY   AGE
</span></span><span style="display:flex;"><span>prometheus-grafana-74b5d957bc                    <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">0</span>         <span style="color:#ae81ff">0</span>       12m
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl delete rs prometheus-grafana-74b5d957bc
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">#### grafana dashboards</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## RKE2</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 14243</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## NGINX Ingress controller</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 9614</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## cert-manager</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 11001</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## longhorn</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 13032</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">### kyverno</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># https://raw.githubusercontent.com/kyverno/grafana-dashboard/master/grafana/dashboard.json</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">### calico</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 12175</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 3244</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">### cilium</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 6658</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 14500</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 14502</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 14501</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring -f values.yaml
</span></span></code></pre></div><p>For the proxy down status:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl edit cm/kube-proxy -n kube-system
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>kind: KubeProxyConfiguration
</span></span><span style="display:flex;"><span>metricsBindAddress: 0.0.0.0:10249
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>If you use rke2 you can configure this from the helm chart before first start:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /var/lib/rancher/rke2/server/manifests/rke2-kube-proxy-config.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: helm.cattle.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: HelmChartConfig
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: rke2-kube-proxy
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  valuesContent: |-
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    metricsBindAddress: 0.0.0.0:10249
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>For the controller-manager down status:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/kubernetes/manifests/kube-controller-manager.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># OR</span>
</span></span><span style="display:flex;"><span>nano /var/lib/rancher/rke2/agent/pod-manifests/kube-controller-manager.yaml
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Pod
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  containers:
</span></span><span style="display:flex;"><span>  - command:
</span></span><span style="display:flex;"><span>    - kube-controller-manager
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span>    - --address<span style="color:#f92672">=</span>0.0.0.0
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span>    - --bind-address<span style="color:#f92672">=</span>&lt;your control-plane IP or 0.0.0.0&gt;
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span>    livenessProbe:
</span></span><span style="display:flex;"><span>      failureThreshold: <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>      httpGet:
</span></span><span style="display:flex;"><span>       	host: 0.0.0.0
</span></span><span style="display:flex;"><span>    ...
</span></span></code></pre></div><p>For the kube-scheduler down status:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/kubernetes/manifests/kube-scheduler.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># OR</span>
</span></span><span style="display:flex;"><span>nano /var/lib/rancher/rke2/agent/pod-manifests/kube-scheduler.yaml
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Pod
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  containers:
</span></span><span style="display:flex;"><span>  - command:
</span></span><span style="display:flex;"><span>    - kube-scheduler
</span></span><span style="display:flex;"><span>    - --address<span style="color:#f92672">=</span>0.0.0.0
</span></span><span style="display:flex;"><span>    - --bind-address<span style="color:#f92672">=</span>0.0.0.0
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span>    livenessProbe:
</span></span><span style="display:flex;"><span>      failureThreshold: <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>      httpGet:
</span></span><span style="display:flex;"><span>       	host: 0.0.0.0
</span></span><span style="display:flex;"><span>    ...
</span></span></code></pre></div><p>For the etcd down status firs we need to create a secret to authenticate for the etcd:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># kubeadm</span>
</span></span><span style="display:flex;"><span>kubectl -n monitoring create secret generic etcd-client-cert <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--from-file<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/ca.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--from-file<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/healthcheck-client.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--from-file<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/healthcheck-client.key
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># rancher</span>
</span></span><span style="display:flex;"><span>kubectl -n monitoring create secret generic etcd-client-cert <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--from-file<span style="color:#f92672">=</span>/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--from-file<span style="color:#f92672">=</span>/var/lib/rancher/rke2/server/tls/etcd/server-client.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--from-file<span style="color:#f92672">=</span>/var/lib/rancher/rke2/server/tls/etcd/server-client.key
</span></span></code></pre></div><p>Then we configure the prometheus to use it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano values.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">prometheus</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">prometheusSpec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secrets</span>: [<span style="color:#e6db74">&#39;etcd-client-cert&#39;</span>]
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">kubeEtcd</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">port</span>: <span style="color:#ae81ff">2379</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">2379</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">component</span>: <span style="color:#ae81ff">etcd</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">interval</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">scheme</span>: <span style="color:#ae81ff">https</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">insecureSkipVerify</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">serverName</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metricRelabelings</span>: []
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">relabelings</span>: []
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">caFile</span>: <span style="color:#ae81ff">/etc/prometheus/secrets/etcd-client-cert/server-ca.crt</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">certFile</span>: <span style="color:#ae81ff">/etc/prometheus/secrets/etcd-client-cert/server-client.crt</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">keyFile</span>: <span style="color:#ae81ff">/etc/prometheus/secrets/etcd-client-cert/server-client.key</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># for kubeadm</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#    caFile: /etc/prometheus/secrets/etcd-client-cert/ca.crt</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#    certFile: /etc/prometheus/secrets/etcd-client-cert/healthcheck-client.crt</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#    keyFile: /etc/prometheus/secrets/etcd-client-cert/healthcheck-client.key</span>
</span></span></code></pre></div><h3 id="monitoring-nginx">Monitoring Nginx</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt; /var/lib/rancher/rke2/server/manifests/rke2-ingress-nginx-config.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.cattle.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmChartConfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rke2-ingress-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">valuesContent</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    controller:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      metrics:</span>
</span></span><span style="display:flex;"><span>	      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">prometheus.io/scrape</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">prometheus.io/port</span>: <span style="color:#e6db74">&#34;10254&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">serviceMonitor</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;monitoring&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kaf /var/lib/rancher/rke2/server/manifests/rke2-ingress-nginx-config.yaml</span>
</span></span></code></pre></div><h3 id="monitoring-core-dns">Monitoring Core-DNS</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt; default-network-dns-policy.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default-network-dns-policy</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">53</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">53</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">UDP</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">9153</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">podSelector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">k8s-app</span>: <span style="color:#ae81ff">kube-dns</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">policyTypes</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kaf default-network-dns-policy.yaml</span>
</span></span></code></pre></div><h3 id="monitor-cert-manager">Monitor cert-manager</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano 01-cert-managger.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ingress-system</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.cattle.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmChart</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cert-manager</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">ingress-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repo</span>: <span style="color:#e6db74">&#34;https://charts.jetstack.io&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">chart</span>: <span style="color:#ae81ff">cert-manager</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetNamespace</span>: <span style="color:#ae81ff">ingress-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">valuesContent</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    installCRDs: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    clusterResourceNamespace: &#34;ingress-system&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    prometheus:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      servicemonitor:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        namespace: &#34;monitoring&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl apply -f 01-cert-managger.yaml</span>
</span></span></code></pre></div><h3 id="longhorn">Longhorn</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">monitoring.coreos.com/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceMonitor</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">longhorn-prometheus-servicemonitor</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">monitoring</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">longhorn-prometheus-servicemonitor</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">longhorn-manager</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespaceSelector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchNames</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">longhorn-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">endpoints</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">manager</span>
</span></span></code></pre></div><h3 id="logging">Logging</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add grafana https://grafana.github.io/helm-charts
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>helm search repo loki
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>helm upgrade --install loki-stack grafana/loki-stack <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--create-namespace <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--namespace loki-stack <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set promtail.enabled<span style="color:#f92672">=</span>true,loki.persistence.enabled<span style="color:#f92672">=</span>true,loki.persistence.size<span style="color:#f92672">=</span>10Gi
</span></span></code></pre></div><p>Promtail dose not working with enabled <code>selinux</code>, because this promtail deployment store som files on the host filesystem and <code>selinux</code> dose not allow to write it, so you need ti use fluent-bit.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm upgrade --install loki-stack grafana/loki-stack <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--create-namespace <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--namespace loki-stack <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set fluent-bit.enabled<span style="color:#f92672">=</span>true,promtail.enabled<span style="color:#f92672">=</span>false <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--set loki.persistence.enabled<span style="color:#f92672">=</span>true,loki.persistence.size<span style="color:#f92672">=</span>10Gi
</span></span></code></pre></div><p>Add datasource to grafana:</p>
<pre tabindex="0"><code>type: loki
name: Loki
url: http://loki-stack.loki-stack:3100
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="prometheus" term="prometheus" label="Prometheus" />
                             
                                <category scheme="nosql" term="nosql" label="noSQL" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="loki" term="loki" label="loki" />
                             
                                <category scheme="grafana" term="grafana" label="grafana" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes integration with external Vault]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-vault-v2/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-vault/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes and Vault integration" />
                <link href="https://devopstales.github.io/kubernetes/rke2-calico/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With Calico" />
                <link href="https://devopstales.github.io/kubernetes/rke2-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With cilium" />
                <link href="https://devopstales.github.io/kubernetes/k3s-gvisor/?utm_source=atom_feed" rel="related" type="text/html" title="Secure k3s with gVisor" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-vault-v2/</id>
            
            
            <published>2021-06-05T00:00:00+00:00</published>
            <updated>2021-06-05T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can integrate an external HashiCorp Vault to Kubernetes.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="vhat-is-hashicorp-vault">Vhat is Hashicorp Vault</h3>
<p>HashiCorp Vault is a secrets management solution that brokers access for both humans and machines, through programmatic access, to systems. Secrets can be stored, dynamically generated, and in the case of encryption, keys can be consumed as a service without the need to expose the underlying key materials.</p>
<p><img src="/img/include/vault-k8s-auth-workflow.png" alt="Example image"  class="zoomable" /></p>
<h3 id="k3s-install">K3s install</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.8.101
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3sup install <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip<span style="color:#f92672">=</span>172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user<span style="color:#f92672">=</span>vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --tls-san<span style="color:#f92672">=</span>172.17.8.100 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cluster <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel<span style="color:#f92672">=</span>stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--no-deploy=traefik --flannel-iface=enp0s8 --node-ip=172.17.8.101&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --merge <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local-path $HOME/.kube/config <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --context<span style="color:#f92672">=</span>k3s-ha
</span></span></code></pre></div><h3 id="install-vault">Install vault</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf install -y dnf-plugins-core nano jq
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo dnf config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo
</span></span><span style="display:flex;"><span>sudo dnf install -y vault
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/vault.d/vault.hcl
</span></span><span style="display:flex;"><span><span style="color:#75715e"># HTTP listener</span>
</span></span><span style="display:flex;"><span>listener <span style="color:#e6db74">&#34;tcp&#34;</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  address <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;0.0.0.0:8200&#34;</span>
</span></span><span style="display:flex;"><span>  tls_disable <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># HTTPS listener</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#listener &#34;tcp&#34; {</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  address       = &#34;0.0.0.0:8200&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  tls_cert_file = &#34;/opt/vault/tls/tls.crt&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  tls_key_file  = &#34;/opt/vault/tls/tls.key&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>api_addr         <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://0.0.0.0:8200&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl start vault
</span></span><span style="display:flex;"><span>systemctl enable vault
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault -autocomplete-install
</span></span><span style="display:flex;"><span>complete -C /usr/bin/vault vault
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export VAULT_ADDR<span style="color:#f92672">=</span>http://127.0.0.1:8200
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;export VAULT_ADDR=http://127.0.0.1:8200&#34;</span> &gt;&gt; ~/.bashrc
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault status
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault operator init | tee /opt/vault/init.txt
</span></span><span style="display:flex;"><span>Unseal Key 1: t4PsGsw8cj25l9tSpvh2Avr5647HhdaI27aAzSiYJz0<span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Initial Root Token: s.sPKauYvv9iFKliclTIaMgbU1
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export VAULT_TOKEN<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;s.sPKauYvv9iFKliclTIaMgbU1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault operator unseal t4PsGsw8cj25l9tSpvh2Avr5647HhdaI27aAzSiYJz0<span style="color:#f92672">=</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vault auth enable userpass
</span></span><span style="display:flex;"><span>vault write auth/userpass/users/devopstales <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    password<span style="color:#f92672">=</span>Password1 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    policies<span style="color:#f92672">=</span>admins
</span></span></code></pre></div><h3 id="integrate-a-kubernetes-cluster-with-an-external-vault">Integrate a Kubernetes Cluster with an External Vault</h3>
<p><a href="https://3p8owy1gdkoh452nrc36wbnp-wpengine.netdna-ssl.com/wp-content/uploads/2018/12/nirmata-vault-7-1024x623.png">https://3p8owy1gdkoh452nrc36wbnp-wpengine.netdna-ssl.com/wp-content/uploads/2018/12/nirmata-vault-7-1024x623.png</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>vault secrets enable kv
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault kv put kv/secret/devwebapp/config username<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;giraffe&#39;</span> password<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;salsa&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault kv get -format<span style="color:#f92672">=</span>json kv/secret/devwebapp/config | jq <span style="color:#e6db74">&#34;.data&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># create policy</span>
</span></span><span style="display:flex;"><span>vault policy write devwebapp-kv-ro - <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">path &#34;kv/secret/devwebapp/*&#34; {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    capabilities = [&#34;read&#34;, &#34;list&#34;]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># create Kubernetes ServiceAccount</span>
</span></span><span style="display:flex;"><span>cat &gt; internal-app.yaml <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: ServiceAccount
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: devwebapp
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">---
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  apiVersion: rbac.authorization.k8s.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  kind: ClusterRoleBinding
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: role-tokenreview-binding
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    namespace: default
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  roleRef:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    apiGroup: rbac.authorization.k8s.io
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    kind: ClusterRole
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: system:auth-delegator
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  subjects:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - kind: ServiceAccount
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: devwebapp
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    namespace: default
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply --filename internal-app.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export EXTERNAL_VAULT_ADDR<span style="color:#f92672">=</span>172.17.8.101
</span></span><span style="display:flex;"><span>export K8S_HOST<span style="color:#f92672">=</span>172.17.8.101
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export VAULT_SA_NAME<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>kubectl get sa devwebapp <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.secrets[*][&#39;name&#39;]}&#34;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export SA_JWT_TOKEN<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>kubectl get secret $VAULT_SA_NAME <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.data.token}&#34;</span> | base64 --decode; echo<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export SA_CA_CRT<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>kubectl get secret $VAULT_SA_NAME <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.data[&#39;ca\.crt&#39;]}&#34;</span> | base64 --decode; echo<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault auth enable kubernetes
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault write auth/kubernetes/config <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  issuer<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;https://kubernetes.default.svc.cluster.local&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  token_reviewer_jwt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span>$SA_JWT_TOKEN<span style="color:#e6db74">&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  kubernetes_host<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;https://</span>$K8S_HOST<span style="color:#e6db74">:6443&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  kubernetes_ca_cert<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span>$SA_CA_CRT<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault write auth/kubernetes/role/devwebapp <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        bound_service_account_names<span style="color:#f92672">=</span>devwebapp <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        bound_service_account_namespaces<span style="color:#f92672">=</span>default <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        policies<span style="color:#f92672">=</span>devwebapp-kv-ro <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        ttl<span style="color:#f92672">=</span>24h
</span></span></code></pre></div><h3 id="install-vault-agent-injector">INstall Vault Agent Injector</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>dnf copr enable cerenit/helm -y
</span></span><span style="display:flex;"><span>dnf install helm -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>helm repo add hashicorp https://helm.releases.hashicorp.com
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">### változók???</span>
</span></span><span style="display:flex;"><span>helm install vault hashicorp/vault <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --set <span style="color:#e6db74">&#34;injector.externalVaultAddr=http://</span>$EXTERNAL_VAULT_ADDR<span style="color:#e6db74">:8200&#34;</span>
</span></span></code></pre></div><h3 id="demo">Demo</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat &gt; devwebapp.yaml <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">---
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: apps/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Deployment
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: orgchart
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: orgchart
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    matchLabels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      app: orgchart
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  replicas: 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  template:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      annotations:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        vault.hashicorp.com/agent-inject: &#34;true&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        vault.hashicorp.com/role: &#34;devwebapp&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        vault.hashicorp.com/agent-inject-secret-config.txt: &#34;kv/secret/devwebapp/config&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        app: orgchart
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      serviceAccountName: devwebapp
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        - name: orgchart
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          image: jweissig/app:0.0.1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f devwebapp.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl exec <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    <span style="color:#66d9ef">$(</span>kubectl get pod -l app<span style="color:#f92672">=</span>orgchart -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.items[0].metadata.name}&#34;</span><span style="color:#66d9ef">)</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --container orgchart -- cat /vault/secrets/config.txt
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="mutating-webhook" term="mutating-webhook" label="mutating webhook" />
                             
                                <category scheme="hashicorp-vault" term="hashicorp-vault" label="HashiCorp Vault" />
                             
                                <category scheme="k3s" term="k3s" label="k3s" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[RKE2 Install With Calico]]></title>
            <link href="https://devopstales.github.io/kubernetes/rke2-calico/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/rke2-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Install With cilium" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes and Vault integration" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
            
                <id>https://devopstales.github.io/kubernetes/rke2-calico/</id>
            
            
            <published>2021-05-25T00:00:00+00:00</published>
            <updated>2021-05-25T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can install a RKE2 with Calico and encripted VXLAN.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h2 id="rke2-setup">RKE2 Setup</h2>
<h3 id="project-longhorn-prerequisites">Project Longhorn Prerequisites</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install -y epel-release
</span></span><span style="display:flex;"><span>yum install -y nano curl wget git tmux jq
</span></span><span style="display:flex;"><span>yum install -y iscsi-initiator-utils 
</span></span><span style="display:flex;"><span>modprobe iscsi_tcp
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;iscsi_tcp&#34;</span> &gt;/etc/modules-load.d/iscsi-tcp.conf
</span></span><span style="display:flex;"><span>systemctl enable iscsid
</span></span><span style="display:flex;"><span>systemctl start iscsid 
</span></span></code></pre></div><p>Ensure the eBFP filesystem is mounted (which should already be the case on RHEL 8.3):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mount | grep /sys/fs/bpf
</span></span><span style="display:flex;"><span><span style="color:#75715e"># if present should output, e.g. &#34;none on /sys/fs/bpf type bpf&#34;...</span>
</span></span></code></pre></div><p>If that&rsquo;s not the case, mount it using the commands down here:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo mount bpffs -t bpf /sys/fs/bpf
</span></span><span style="display:flex;"><span>sudo bash -c <span style="color:#e6db74">&#39;cat &lt;&lt;EOF &gt;&gt; /etc/fstab
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">none /sys/fs/bpf bpf rw,relatime 0 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF&#39;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF&gt;&gt; /etc/NetworkManager/conf.d/rke2-canal.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[keyfile]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">unmanaged-devices=interface-name:cali*;interface-name:flannel*
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>systemctl reload NetworkManager
</span></span></code></pre></div><h3 id="rke2-rpm-install">RKE2 rpm Install</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /etc/yum.repos.d/rancher-rke2-1-20-latest.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[rancher-rke2-common-latest]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Rancher RKE2 Common Latest
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://rpm.rancher.io/rke2/latest/common/centos/8/noarch
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://rpm.rancher.io/public.key
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[rancher-rke2-1-20-latest]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Rancher RKE2 1.20 Latest
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://rpm.rancher.io/rke2/latest/1.20/centos/8/x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://rpm.rancher.io/public.key
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum -y install rke2-server
</span></span></code></pre></div><h3 id="kubectl-helm--rke2">Kubectl, Helm &amp; RKE2</h3>
<p>Install <code>kubectl</code>, <code>helm</code> and RKE2 to the host system:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubectx /usr/local/bin/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubens /usr/local/bin/kubens
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;PATH=$PATH:/usr/local/bin&#39;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;PATH=$PATH:/var/lib/rancher/rke2/bin&#39;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>source /etc/profile
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo dnf copr -y enable cerenit/helm
</span></span><span style="display:flex;"><span>sudo dnf install -y helm
</span></span></code></pre></div><h3 id="rke2-specific-ports">RKE2 specific ports</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9345/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>6443/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>10250/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>2379/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>2380/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>30000-32767/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Used for the Rancher Monitoring</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9796/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>19090/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>6942/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9091/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e">### CNI specific ports</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>179/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>4789/udp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>5473/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9098/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9099/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>5473/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e">### Ingress Controller specific ports</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>80/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>443/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e">### To get DNS resolution working, simply enable Masquerading.</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --zone<span style="color:#f92672">=</span>public  --add-masquerade --permanent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">### Finally apply all the firewall changes</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --reload
</span></span></code></pre></div><p>Verification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo firewall-cmd --list-all
</span></span><span style="display:flex;"><span>public <span style="color:#f92672">(</span>active<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>  target: default
</span></span><span style="display:flex;"><span>  icmp-block-inversion: no
</span></span><span style="display:flex;"><span>  interfaces: eno1
</span></span><span style="display:flex;"><span>  sources: 
</span></span><span style="display:flex;"><span>  services: cockpit dhcpv6-client ssh wireguard
</span></span><span style="display:flex;"><span>  ports: 9345/tcp 6443/tcp 10250/tcp 2379/tcp 2380/tcp 30000-32767/tcp 4240/tcp 6081/udp 80/tcp 443/tcp 4244/tcp 9796/tcp 19090/tcp 6942/tcp 9091/tcp
</span></span><span style="display:flex;"><span>  protocols: 
</span></span><span style="display:flex;"><span>  masquerade: yes
</span></span><span style="display:flex;"><span>  forward-ports: 
</span></span><span style="display:flex;"><span>  source-ports: 
</span></span><span style="display:flex;"><span>  icmp-blocks: 
</span></span><span style="display:flex;"><span>  rich rules: 
</span></span></code></pre></div><h3 id="basic-configuration">Basic Configuration</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p /etc/rancher/rke2
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt;  /etc/rancher/rke2/config.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">write-kubeconfig-mode: &#34;0644&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">profile: &#34;cis-1.5&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">selinux: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># add ips/hostname of hosts and loadbalancer
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">tls-san:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - &#34;k8s.mydomain.intra&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - &#34;172.17.9.10&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># Make a etcd snapshot every 6 hours
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">etcd-snapshot-schedule-cron: &#34;0 */6 * * *&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># Keep 56 etcd snapshorts (equals to 2 weeks with 6 a day)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">etcd-snapshot-retention: 56
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">cni:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - calico
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">disable:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - rke2-canal
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - rke2-kube-proxy
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p><strong>Note:</strong> I disabled <code>rke2-canal</code> and <code>rke2-kube-proxy</code> since I plan to install Canal as CNI in <a href="https://docs.projectcalico.org/maintenance/ebpf/enabling-bpf">&ldquo;kube-proxy less mode&rdquo;</a>. Do not disable <code>rke2-kube-proxy</code> if you use another CNI - it will not work afterwards!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo cp -f /usr/share/rke2/rke2-cis-sysctl.conf /etc/sysctl.d/60-rke2-cis.conf
</span></span><span style="display:flex;"><span>sysctl -p /etc/sysctl.d/60-rke2-cis.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>useradd -r -c <span style="color:#e6db74">&#34;etcd user&#34;</span> -s /sbin/nologin -M etcd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p /var/lib/rancher/rke2/server/manifests/
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /var/lib/rancher/rke2/server/manifests/rke2-ingress-nginx-config.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: helm.cattle.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: HelmChartConfig
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: rke2-ingress-nginx
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  valuesContent: |-
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    controller:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      metrics:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        service:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          annotations:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            prometheus.io/scrape: &#34;true&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            prometheus.io/port: &#34;10254&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get endpoints kubernetes -o wide
</span></span><span style="display:flex;"><span>NAME         ENDPOINTS        AGE
</span></span><span style="display:flex;"><span>kubernetes   10.0.2.15:6443   86m
</span></span></code></pre></div><h3 id="prevent-rke2-package-updates">Prevent RKE2 Package Updates</h3>
<p>In order to provide more stability, I chose to DNF/YUM &ldquo;mark/hold&rdquo; the RKE2 related packages so a <code>dnf update</code>/<code>yum update</code> does not mess around with them.</p>
<p>Add the following line to <code>/etc/dnf/dnf.conf</code> and/or <code>/etc/yum.conf</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>exclude<span style="color:#f92672">=</span>rke2-*
</span></span></code></pre></div><h2 id="starting-rke2">Starting RKE2</h2>
<p>Enable the <code>rke2-server</code> service and start it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl enable rke2-server --now
</span></span></code></pre></div><p>Verification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl status rke2-server
</span></span><span style="display:flex;"><span>sudo journalctl -u rke2-server -f
</span></span></code></pre></div><h2 id="configure-kubectl-on-rke2-host">Configure Kubectl (on RKE2 Host)</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir ~/.kube
</span></span><span style="display:flex;"><span>ln -s /etc/rancher/rke2/rke2.yaml ~/.kube/config
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">600</span> /root/.kube/config
</span></span><span style="display:flex;"><span>ln -s /var/lib/rancher/rke2/agent/etc/crictl.yaml /etc/crictl.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get node
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>crictl images
</span></span></code></pre></div><p>Verification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes
</span></span><span style="display:flex;"><span>NAME                    STATUS   ROLES         AGE     VERSION
</span></span><span style="display:flex;"><span>k8s.mydomain.intra   Ready   etcd,master   2m4s   v1.18.16+rke2r1
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="rke2" term="rke2" label="rke2" />
                             
                                <category scheme="rancher" term="rancher" label="rancher" />
                             
                                <category scheme="calico" term="calico" label="Calico" />
                             
                                <category scheme="ebpf" term="ebpf" label="ebpf" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[RKE2 Install With cilium]]></title>
            <link href="https://devopstales.github.io/kubernetes/rke2-cilium/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-vault/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes and Vault integration" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
                <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 The Secure Kubernetes Engine" />
            
                <id>https://devopstales.github.io/kubernetes/rke2-cilium/</id>
            
            
            <published>2021-05-24T00:00:00+00:00</published>
            <updated>2021-05-24T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can install a RKE2 with cilium and encripted VXLAN.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-cilium">What is Cilium?</h3>
<p>Cilium is open source software for transparently securing the network connectivity between application services deployed using Linux container management platforms like Docker and Kubernetes.</p>
<p>At the foundation of Cilium is a new Linux kernel technology called eBPF, which enables the dynamic insertion of powerful security visibility and control logic within Linux itself. Because eBPF runs inside the Linux kernel, Cilium security policies can be applied and updated without any changes to the application code or container configuration. (Source: <a href="https://docs.cilium.io/en/v1.9/intro/">cilium.io</a> )</p>
<h3 id="what-is-hubble">What is Hubble?</h3>
<p>Hubble is a fully distributed networking and security observability platform. It is built on top of Cilium and eBPF to enable deep visibility into the communication and behavior of services as well as the networking infrastructure in a completely transparent manner.</p>
<p>By building on top of Cilium, Hubble can leverage eBPF for visibility. By relying on eBPF, all visibility is programmable and allows for a dynamic approach that minimizes overhead while providing deep and detailed visibility as required by users. Hubble has been created and specifically designed to make best use of these new eBPF powers. (Source: <a href="https://docs.cilium.io/en/v1.9/intro/">cilium.io</a> )</p>
<h2 id="rke2-setup">RKE2 Setup</h2>
<h3 id="project-longhorn-prerequisites">Project Longhorn Prerequisites</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install -y epel-release
</span></span><span style="display:flex;"><span>yum install -y nano curl wget git tmux jq vim-common
</span></span><span style="display:flex;"><span>yum install -y iscsi-initiator-utils 
</span></span><span style="display:flex;"><span>modprobe iscsi_tcp
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;iscsi_tcp&#34;</span> &gt;/etc/modules-load.d/iscsi-tcp.conf
</span></span><span style="display:flex;"><span>systemctl enable iscsid
</span></span><span style="display:flex;"><span>systemctl start iscsid 
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF&gt;&gt; /etc/NetworkManager/conf.d/rke2-canal.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[keyfile]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">unmanaged-devices=interface-name:cali*;interface-name:flannel*
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>systemctl reload NetworkManager
</span></span></code></pre></div><h3 id="rke2-rpm-install">RKE2 rpm Install</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /etc/yum.repos.d/rancher-rke2-1-20-latest.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[rancher-rke2-common-latest]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Rancher RKE2 Common Latest
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://rpm.rancher.io/rke2/latest/common/centos/8/noarch
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://rpm.rancher.io/public.key
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[rancher-rke2-1-20-latest]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Rancher RKE2 1.20 Latest
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://rpm.rancher.io/rke2/latest/1.20/centos/8/x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://rpm.rancher.io/public.key
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum -y install rke2-server
</span></span></code></pre></div><h3 id="kubectl-helm--rke2">Kubectl, Helm &amp; RKE2</h3>
<p>Install <code>kubectl</code>, <code>helm</code> and RKE2 to the host system:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubectx /usr/local/bin/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubens /usr/local/bin/kubens
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;PATH=$PATH:/usr/local/bin&#39;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;PATH=$PATH:/var/lib/rancher/rke2/bin&#39;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>source /etc/profile
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo dnf copr -y enable cerenit/helm
</span></span><span style="display:flex;"><span>sudo dnf install -y helm
</span></span></code></pre></div><h3 id="rke2-specific-ports">RKE2 specific ports</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9345/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>6443/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>10250/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>2379/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>2380/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>30000-32767/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Used for the Monitoring</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9796/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>19090/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>6942/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>9091/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e">### CNI specific ports</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 4244/TCP is required when the Hubble Relay is enabled and therefore needs to connect to all agents to collect the flows</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>4244/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Cilium healthcheck related permits:</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>4240/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --remove-icmp-block<span style="color:#f92672">=</span>echo-request --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --remove-icmp-block<span style="color:#f92672">=</span>echo-reply --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Since we are using Cilium with GENEVE as overlay, we need the following port too:</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>6081/udp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e">### Ingress Controller specific ports</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>80/tcp --permanent
</span></span><span style="display:flex;"><span>sudo firewall-cmd --add-port<span style="color:#f92672">=</span>443/tcp --permanent
</span></span><span style="display:flex;"><span><span style="color:#75715e">### To get DNS resolution working, simply enable Masquerading.</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --zone<span style="color:#f92672">=</span>public  --add-masquerade --permanent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">### Finally apply all the firewall changes</span>
</span></span><span style="display:flex;"><span>sudo firewall-cmd --reload
</span></span></code></pre></div><p>Verification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo firewall-cmd --list-all
</span></span><span style="display:flex;"><span>public <span style="color:#f92672">(</span>active<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>  target: default
</span></span><span style="display:flex;"><span>  icmp-block-inversion: no
</span></span><span style="display:flex;"><span>  interfaces: eno1
</span></span><span style="display:flex;"><span>  sources: 
</span></span><span style="display:flex;"><span>  services: cockpit dhcpv6-client ssh wireguard
</span></span><span style="display:flex;"><span>  ports: 9345/tcp 6443/tcp 10250/tcp 2379/tcp 2380/tcp 30000-32767/tcp 4240/tcp 6081/udp 80/tcp 443/tcp 4244/tcp 9796/tcp 19090/tcp 6942/tcp 9091/tcp
</span></span><span style="display:flex;"><span>  protocols: 
</span></span><span style="display:flex;"><span>  masquerade: yes
</span></span><span style="display:flex;"><span>  forward-ports: 
</span></span><span style="display:flex;"><span>  source-ports: 
</span></span><span style="display:flex;"><span>  icmp-blocks: 
</span></span><span style="display:flex;"><span>  rich rules: 
</span></span></code></pre></div><h3 id="basic-configuration">Basic Configuration</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p /etc/rancher/rke2
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt;  /etc/rancher/rke2/config.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">write-kubeconfig-mode: &#34;0644&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">profile: &#34;cis-1.5&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">selinux: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># add ips/hostname of hosts and loadbalancer
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">tls-san:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - &#34;k8s.mydomain.intra&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - &#34;172.17.9.10&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># Make a etcd snapshot every 6 hours
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">etcd-snapshot-schedule-cron: &#34;0 */6 * * *&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># Keep 56 etcd snapshorts (equals to 2 weeks with 6 a day)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">etcd-snapshot-retention: 56
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">cni:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - cilium
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">disable:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - rke2-canal
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - rke2-kube-proxy
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">disable-cloud-controller: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">disable-kube-proxy: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p><strong>Note:</strong> I disabled <code>rke2-canal</code> and <code>rke2-kube-proxy</code> since I plan to install Cilium as CNI in <a href="https://docs.cilium.io/en/v1.9/gettingstarted/kubeproxy-free/">&ldquo;kube-proxy less mode&rdquo;</a> (<code>kubeProxyReplacement: &quot;strict&quot;</code>). Do not disable <code>rke2-kube-proxy</code> if you use another CNI - it will not work afterwards!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo cp -f /usr/share/rke2/rke2-cis-sysctl.conf /etc/sysctl.d/60-rke2-cis.conf
</span></span><span style="display:flex;"><span>sysctl -p /etc/sysctl.d/60-rke2-cis.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>useradd -r -c <span style="color:#e6db74">&#34;etcd user&#34;</span> -s /sbin/nologin -M etcd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p /var/lib/rancher/rke2/server/manifests/
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /var/lib/rancher/rke2/server/manifests/rke2-ingress-nginx-config.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: helm.cattle.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: HelmChartConfig
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: rke2-ingress-nginx
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  valuesContent: |-
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    controller:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      metrics:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        service:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          annotations:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            prometheus.io/scrape: &#34;true&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            prometheus.io/port: &#34;10254&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><h3 id="prevent-rke2-package-updates">Prevent RKE2 Package Updates</h3>
<p>In order to provide more stability, I chose to DNF/YUM &ldquo;mark/hold&rdquo; the RKE2 related packages so a <code>dnf update</code>/<code>yum update</code> does not mess around with them.</p>
<p>Add the following line to <code>/etc/dnf/dnf.conf</code> and/or <code>/etc/yum.conf</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>exclude<span style="color:#f92672">=</span>rke2-*
</span></span></code></pre></div><h3 id="cilium-prerequisites">Cilium Prerequisites</h3>
<p>Ensure the eBFP filesystem is mounted (which should already be the case on RHEL 8.3):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mount | grep /sys/fs/bpf
</span></span><span style="display:flex;"><span><span style="color:#75715e"># if present should output, e.g. &#34;none on /sys/fs/bpf type bpf&#34;...</span>
</span></span></code></pre></div><p>If that&rsquo;s not the case, mount it using the commands down here:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo mount bpffs -t bpf /sys/fs/bpf
</span></span><span style="display:flex;"><span>sudo bash -c <span style="color:#e6db74">&#39;cat &lt;&lt;EOF &gt;&gt; /etc/fstab
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">none /sys/fs/bpf bpf rw,relatime 0 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF&#39;</span>
</span></span></code></pre></div><h3 id="deploy-cilium">Deploy Cilium</h3>
<p>Cilium’s eBPF kube-proxy replacement currently cannot be used with Transparent Encryption.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt; EOF &gt;  /var/lib/rancher/rke2/server/manifests/rke2-cilium-config.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.cattle.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmChartConfig</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rke2-cilium</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">valuesContent</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    cilium:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      kubeProxyReplacement: &#34;strict&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      k8sServiceHost: 10.0.2.15
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      k8sServicePort: 6443
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      operator:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        replicas: 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      encryption:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        enabled: false
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        type: wireguard
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      l7Proxy: false
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      hubble:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        metrics:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          enabled:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          - dns:query;ignoreAAAA
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          - drop
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          - tcp
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          - flow
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          - icmp
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          - http
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        relay:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ui:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          replicas: 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          ingress:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            hosts:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              - hubble.k8s.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            annotations:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              cert-manager.io/cluster-issuer: ca-issuer
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            tls:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            - secretName: ingress-hubble-ui-tls
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              hosts:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              - hubble.k8s.intra
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      prometheus:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        # Default port value (9090) needs to be changed since the RHEL cockpit also listens on this port.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        port: 19090
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        # Configure this serviceMonitor section AFTER Rancher Monitoring is enabled!
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        #serviceMonitor:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        #  enabled: true</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><h2 id="starting-rke2">Starting RKE2</h2>
<p>Enable the <code>rke2-server</code> service and start it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl enable rke2-server --now
</span></span></code></pre></div><p>Verification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl status rke2-server
</span></span><span style="display:flex;"><span>sudo journalctl -u rke2-server -f
</span></span></code></pre></div><h2 id="configure-kubectl-on-rke2-host">Configure Kubectl (on RKE2 Host)</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir ~/.kube
</span></span><span style="display:flex;"><span>ln -s /etc/rancher/rke2/rke2.yaml ~/.kube/config
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">600</span> /root/.kube/config
</span></span><span style="display:flex;"><span>ln -s /var/lib/rancher/rke2/agent/etc/crictl.yaml /etc/crictl.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get node
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>crictl images
</span></span></code></pre></div><p>Verification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes
</span></span><span style="display:flex;"><span>NAME                    STATUS   ROLES         AGE     VERSION
</span></span><span style="display:flex;"><span>k8s.mydomain.intra   NotReady   etcd,master   2m4s   v1.18.16+rke2r1
</span></span></code></pre></div><h3 id="deploy-demo-app">Deploy demo app</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens default
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/v1.9/examples/minikube/http-sw-app.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f k8s_sec_lab/manifest/cilium_demo_rb.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
</span></span><span style="display:flex;"><span>kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="rke2" term="rke2" label="rke2" />
                             
                                <category scheme="rancher" term="rancher" label="rancher" />
                             
                                <category scheme="cilium" term="cilium" label="cilium" />
                             
                                <category scheme="ebpf" term="ebpf" label="ebpf" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flux2 and Mozilla SOPS to encrypt secrets]]></title>
            <link href="https://devopstales.github.io/kubernetes/gitops-flux2-sops/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/gitops-flux2-kubeseal/?utm_source=atom_feed" rel="related" type="text/html" title="Flux2 and kubeseal to encrypt secrets" />
                <link href="https://devopstales.github.io/kubernetes/gitops-flux2/?utm_source=atom_feed" rel="related" type="text/html" title="Flux2 Install and Usage" />
                <link href="https://devopstales.github.io/kubernetes/argocd-image-updater/?utm_source=atom_feed" rel="related" type="text/html" title="Argo CD Image Updater for automate image update" />
                <link href="https://devopstales.github.io/kubernetes/argocd-kubeseal/?utm_source=atom_feed" rel="related" type="text/html" title="ArgoCD and kubeseal to encrypt secrets" />
                <link href="https://devopstales.github.io/kubernetes/k8s-gitops/?utm_source=atom_feed" rel="related" type="text/html" title="GitOps solutions for Kubernetes" />
            
                <id>https://devopstales.github.io/kubernetes/gitops-flux2-sops/</id>
            
            
            <published>2021-05-08T00:00:00+00:00</published>
            <updated>2021-05-08T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use Mozilla SOPS with Flux2 to protect secrets.</p>


<H3>Parts of the K8S Gitops series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-gitops/">GitOps solutions for Kubernetes</a></li>
     <li>Part2: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-image-updater/">Argo CD Image Updater for automate image update</a></li>
<!-- ArgoCD notify
https://blog.argoproj.io/notifications-for-argo-bb7338231604
-->
<!----------------------------------------------->
     <li>Part4: <a href="../../kubernetes/gitops-flux2/">Flux2 Install and Usage</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part6: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>
<!-- Flux CD auto image update
https://particule.io/en/blog/flux-auto-image-update/
-->
<!----------------------------------------------->
<!-- Fleet 
Rancher fleet + helm-controller
-->
<!----------------------------------------------->
<!-- Canary Deployment:
Canary Basics - https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments
Canary with helm:
  https://itnext.io/safe-and-automation-friendly-canary-deployments-with-helm-669394d2c48a
  https://github.com/stoehdoi/canary-demo/tree/master/deploy
ArgoCD + Argo Rollouts for canary deploy:
-->
     <li>Part7: <a href="../../kubernetes/flagger-nginx-canary-deployments/">Flagger NGINX Canary Deployments</a></li>
</ul>



<p>First you need to bootstrap the fluxcomponent as I showd in the <a href="../gitops-flux2/">previous post</a>.</p>
<h2 id="install-ops-cli">Install OPS CLI</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>curl --silent <span style="color:#e6db74">&#34;https://api.github.com/repos/mozilla/sops/releases/latest&#34;</span> | grep <span style="color:#e6db74">&#39;&#34;tag_name&#34;&#39;</span> | sed -E <span style="color:#e6db74">&#39;s/.*&#34;([^&#34;]+)&#34;.*/\1/&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>VERSION:1<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://github.com/mozilla/sops/releases/download/v$VERSION/sops-<span style="color:#e6db74">&#34;</span>$VERSION<span style="color:#e6db74">&#34;</span>-1.x86_64.rpm
</span></span><span style="display:flex;"><span>yum install -y sops-<span style="color:#e6db74">&#34;</span>$VERSION<span style="color:#e6db74">&#34;</span>-1.x86_64.rpm
</span></span><span style="display:flex;"><span>rm -f sops-<span style="color:#e6db74">&#34;</span>$VERSION<span style="color:#e6db74">&#34;</span>-1.x86_64.rpm
</span></span></code></pre></div><h3 id="generate-a-gpg-key">Generate a GPG key</h3>
<p>Generate a GPG/OpenPGP key:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export KEY_NAME<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cl1.mydomain.intra&#34;</span>
</span></span><span style="display:flex;"><span>export KEY_COMMENT<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;flux secrets&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>gpg --batch --full-generate-key <span style="color:#e6db74">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">%no-protection
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Key-Type: 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Key-Length: 4096
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Subkey-Type: 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Subkey-Length: 4096
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Expire-Date: 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Name-Comment: ${KEY_COMMENT}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Name-Real: ${KEY_NAME}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>The above configuration creates an rsa4096 key that does not expire. Retrieve the GPG key fingerprint:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>gpg --list-secret-keys <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">${</span>KEY_NAME<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sec   rsa4096 2020-09-06 <span style="color:#f92672">[</span>SC<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>      1F3D1CED2F865F5E59CA564553241F147E7C5FA4
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Store the key fingerprint as an environment variable:</span>
</span></span><span style="display:flex;"><span>export KEY_FP<span style="color:#f92672">=</span>1F3D1CED2F865F5E59CA564553241F147E7C5FA4
</span></span></code></pre></div><p>Export the public and private key from your local GPG keyring and create a Kubernetes secret named sops-gpg in the flux-system namespace:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>gpg --export-secret-keys --armor <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">${</span>KEY_FP<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span> |
</span></span><span style="display:flex;"><span>kubectl create secret generic sops-gpg <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--namespace<span style="color:#f92672">=</span>flux-system <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--from-file<span style="color:#f92672">=</span>sops.asc<span style="color:#f92672">=</span>/dev/stdin
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir ./02_flux2/03_SOPS_demo/
</span></span><span style="display:flex;"><span>gpg --export-secret-keys --armor <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">${</span>KEY_FP<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span> &gt; ./02_flux2/03_SOPS_demo/sops.pub.asc
</span></span></code></pre></div><p>It’s a good idea to back up this secret-key/K8s-Secret with a password manager or offline storage. Also consider deleting the secret decryption key from you machine:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>gpg --delete-secret-keys <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">${</span>KEY_FP<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git add -A
</span></span><span style="display:flex;"><span>git commit -m <span style="color:#e6db74">&#34;add sops config&#34;</span>
</span></span><span style="display:flex;"><span>git push
</span></span></code></pre></div><h3 id="configure-in-cluster-secrets-decryption">Configure in-cluster secrets decryption</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano 02_flux2/flux-system/gotk-sync.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: source.toolkit.fluxcd.io/v1beta1
</span></span><span style="display:flex;"><span>kind: GitRepository
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: flux-system
</span></span><span style="display:flex;"><span>  namespace: flux-system
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  interval: 1m0s
</span></span><span style="display:flex;"><span>  ref:
</span></span><span style="display:flex;"><span>    branch: main
</span></span><span style="display:flex;"><span>  secretRef:
</span></span><span style="display:flex;"><span>    name: flux-system
</span></span><span style="display:flex;"><span>  url: ssh://git@github.com/devopstales/gitops-repo
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: kustomize.toolkit.fluxcd.io/v1beta1
</span></span><span style="display:flex;"><span>kind: Kustomization
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: flux-system
</span></span><span style="display:flex;"><span>  namespace: flux-system
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  decryption:
</span></span><span style="display:flex;"><span>    provider: sops
</span></span><span style="display:flex;"><span>    secretRef:
</span></span><span style="display:flex;"><span>      name: sops-gpg
</span></span><span style="display:flex;"><span>  interval: 10m0s
</span></span><span style="display:flex;"><span>  path: ./01_flux2
</span></span><span style="display:flex;"><span>  prune: true
</span></span><span style="display:flex;"><span>  sourceRef:
</span></span><span style="display:flex;"><span>    kind: GitRepository
</span></span><span style="display:flex;"><span>    name: flux-system
</span></span><span style="display:flex;"><span>  validation: client
</span></span></code></pre></div><p>Create a secret you want to encrypt:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cp 01_flux2/02_secret/*.yaml 02_flux2/03_SOPS_demo/</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">rm -f 02_flux2/03_SOPS_demo/sealedsecret.yaml</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">nano 02_flux2/03_SOPS_demo/secret.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">secret</span>: <span style="color:#ae81ff">UzNDUjNUCg==</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysecret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">demo-app</span>
</span></span></code></pre></div><p>ncrypt the secret with SOPS using your GPG key:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sops --encrypt --encrypted-regex <span style="color:#e6db74">&#39;^(data|stringData)$&#39;</span> --pgp <span style="color:#e6db74">${</span>KEY_FP<span style="color:#e6db74">}</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--in-place 02_flux2/03_SOPS_demo/secret.yaml
</span></span></code></pre></div><p>Check the result:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat 02_flux2/03_SOPS_demo/secret.yaml </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secret</span>: <span style="color:#ae81ff">ENC[AES256_GCM,data:RxdPIf8i5G+yjiT0,iv:A8iYsJ4hdd1MNZDAKQyD4L/b6Caa1TDn+MNKsFku3nc=,tag:QLN3Y6B/S87qzPYh2PATaQ==,type:str]</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysecret</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">demo-app</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">sops</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kms</span>: []
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">gcp_kms</span>: []
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">azure_kv</span>: []
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hc_vault</span>: []
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">age</span>: []
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">lastmodified</span>: <span style="color:#e6db74">&#34;2021-05-09T08:59:30Z&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">mac</span>: <span style="color:#ae81ff">ENC[AES256_GCM,data:2SwDXqI5R880Y/uf4yW6o3rraJ7WYQ5aIfKwIPEpss/evD15dfLulUUahN0bNmrwtSYuad0aXHopGfFsKEvxSVMx9UkPaAd0xVZHSj7aJ5Fi5D2De3Tw1yi8tuWjU8OMG81nIZkx6GdIa4yZlm+LEangYVIpzluWk6C7In8GNc8=,iv:9E0R+R6QjqCXBnzPlAzri/fYxEr0HPZ0FzQX5oddMZk=,tag:FEJknbbaqp402biU/hxUaA==,type:str]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">pgp</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">created_at</span>: <span style="color:#e6db74">&#34;2021-05-09T08:59:30Z&#34;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">enc</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            -----BEGIN PGP MESSAGE-----
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            hQIMA1gFjmLlSkpZAQ//ZwU9ZEL2jDtmg8ZvJ4Wrnaa66Rjvnr/Uz9VOUxKZk1WJ
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            V6+Wa1Od80tODzr9gfmjHor0ZCbdJmPxf96z4MhcBNbo9oBr43GX2Wm67ijwIEdo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            Wup2252ANsn1stZIk5krdlZVkRTW+GeAwEDHnW4zSOSVfc9Ad1SHGy1vgXM/i7Je
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            ttx3s/PZhPPZLUQ6SKQjEaf6Xod9nnLyqSb1SdB5idhBy/wV3nt08p/LJ8QVItzh
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            iFclOBRXeEQuYEt2O57Bo/kRGTaBjq6YE0KCbu7PMkm8gerZOyW2Od1maF4Bsjlz
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            c+qOaLjFOP4K/8OIDtzTOw9tXbQREWC9tl1ReadGHReTbdCs55msmMWscPJtq8wi
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            a3eMdLDwvJHhAERaJwvAa5Le6uIwr+lOEVzetj2ucK6LgVlTjgs9IPTMul4ASyji
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            tOtTUzXoEHu/wfGKP7QFDbROFBWalNBkSegdOQx+/GSLebfWY/HmTy+V7isRhoa3
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            iH4/hapCDUQVqwQSyvjpVUzoAsp9g7XaYITKGbSkIuUA3TI5aTp3SSF7sbNHdG8g
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            6i3jh4FxS9yzFgM7fGnlbHDta/DzyBQB5Z77cI8pJW9mri1/U6R63zJuDqSUvFlw
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            zf1zJwEV3xgwMog/7nx4aAItPBeqsT0pSYs5pQpciKgTJcCOTG8r6+3+cjckS/vS
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            XgH6CQtPyzD1JAVDz94n0RkZKC+TXUfLnRF0yLwaAeOJ9h6vFVnEggOIXiWF4Iy7
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            Ds1zIaq79+H/gWo0fGk2srKIHdcPZkQc7zAOqbO5X94fo0TtNx5y/QT6FUwUH4k=
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            =GMAU
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            -----END PGP MESSAGE-----</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">fp</span>: <span style="color:#ae81ff">FCF6E84DC263BDDB9A35D3C6DF8C27FF0C09F771</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">encrypted_regex</span>: <span style="color:#ae81ff">^(data|stringData)$</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">version</span>: <span style="color:#ae81ff">3.7.1</span>
</span></span></code></pre></div><p>Upload files and test:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git add -A
</span></span><span style="display:flex;"><span>git commit -m <span style="color:#e6db74">&#34;sops demo&#34;</span>
</span></span><span style="display:flex;"><span>git push
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl logs -n demo-app2 demo-app
</span></span><span style="display:flex;"><span>S3CR3T
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-gitops" term="k8s-gitops" label="k8s-gitops" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="gitops" term="gitops" label="gitops" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flux2 and kubeseal to encrypt secrets]]></title>
            <link href="https://devopstales.github.io/kubernetes/gitops-flux2-kubeseal/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/gitops-flux2/?utm_source=atom_feed" rel="related" type="text/html" title="Flux2 Install and Usage" />
                <link href="https://devopstales.github.io/kubernetes/argocd-kubeseal/?utm_source=atom_feed" rel="related" type="text/html" title="ArgoCD and kubeseal to encrypt secrets" />
                <link href="https://devopstales.github.io/kubernetes/argocd-image-updater/?utm_source=atom_feed" rel="related" type="text/html" title="Argo CD Image Updater for automate image update" />
                <link href="https://devopstales.github.io/kubernetes/k8s-gitops/?utm_source=atom_feed" rel="related" type="text/html" title="GitOps solutions for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cert/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Certificate Rotation" />
            
                <id>https://devopstales.github.io/kubernetes/gitops-flux2-kubeseal/</id>
            
            
            <published>2021-05-07T00:00:00+00:00</published>
            <updated>2021-05-07T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use kubeseal and Mozilla SOPS with Flux2 to protect secrets.</p>


<H3>Parts of the K8S Gitops series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-gitops/">GitOps solutions for Kubernetes</a></li>
     <li>Part2: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-image-updater/">Argo CD Image Updater for automate image update</a></li>
<!-- ArgoCD notify
https://blog.argoproj.io/notifications-for-argo-bb7338231604
-->
<!----------------------------------------------->
     <li>Part4: <a href="../../kubernetes/gitops-flux2/">Flux2 Install and Usage</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part6: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>
<!-- Flux CD auto image update
https://particule.io/en/blog/flux-auto-image-update/
-->
<!----------------------------------------------->
<!-- Fleet 
Rancher fleet + helm-controller
-->
<!----------------------------------------------->
<!-- Canary Deployment:
Canary Basics - https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments
Canary with helm:
  https://itnext.io/safe-and-automation-friendly-canary-deployments-with-helm-669394d2c48a
  https://github.com/stoehdoi/canary-demo/tree/master/deploy
ArgoCD + Argo Rollouts for canary deploy:
-->
     <li>Part7: <a href="../../kubernetes/flagger-nginx-canary-deployments/">Flagger NGINX Canary Deployments</a></li>
</ul>



<h2 id="install-kubeseal-cli">Install kubeseal cli</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>curl --silent <span style="color:#e6db74">&#34;https://api.github.com/repos/bitnami-labs/sealed-secrets/releases/latest&#34;</span> | grep <span style="color:#e6db74">&#39;&#34;tag_name&#34;&#39;</span> | sed -E <span style="color:#e6db74">&#39;s/.*&#34;([^&#34;]+)&#34;.*/\1/&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://github.com/bitnami-labs/sealed-secrets/releases/download/$VERSION/kubeseal-linux-amd64 -O /usr/local/bin/kubeseal
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">755</span> /usr/local/bin/kubeseal
</span></span><span style="display:flex;"><span>kubeseal --version
</span></span></code></pre></div><h3 id="deploy-sealed-secrets-with-a-helmrelease">Deploy sealed-secrets with a HelmRelease</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>flux create source helm sealed-secrets <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--interval<span style="color:#f92672">=</span>1h <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--url<span style="color:#f92672">=</span>https://bitnami-labs.github.io/sealed-secrets
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>flux create helmrelease sealed-secrets <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--interval<span style="color:#f92672">=</span>1h <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--release-name<span style="color:#f92672">=</span>sealed-secrets <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--target-namespace<span style="color:#f92672">=</span>flux-system <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--source<span style="color:#f92672">=</span>HelmRepository/sealed-secrets <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--chart<span style="color:#f92672">=</span>sealed-secrets <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--chart-version<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&gt;=1.15.0-0&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--crds<span style="color:#f92672">=</span>CreateReplace
</span></span></code></pre></div><p>At startup, the sealed-secrets controller generates a 4096-bit RSA key pair and persists the private and public keys as Kubernetes secrets in the flux-system namespace.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeseal --fetch-cert <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--controller-name<span style="color:#f92672">=</span>sealed-secrets <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--controller-namespace<span style="color:#f92672">=</span>flux-system <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>&gt; ../pub-sealed-secrets.pem
</span></span></code></pre></div><p>Generate a Kubernetes secret manifest with kubectl:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl -n default create secret generic basic-auth <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--from-literal<span style="color:#f92672">=</span>user<span style="color:#f92672">=</span>admin <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--from-literal<span style="color:#f92672">=</span>password<span style="color:#f92672">=</span>change-me <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--dry-run<span style="color:#f92672">=</span>client <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-o yaml &gt; ../basic-auth.yaml
</span></span></code></pre></div><h3 id="create-a-sealed-secret">Create a sealed secret</h3>
<p>Create a secret you want to encrypt:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">secret</span>: <span style="color:#ae81ff">UzNDUjNUCg==</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysecret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">demo-app</span>
</span></span></code></pre></div><p>A secret in Kubernetes cluster is encoded in base64 but not encrypted! Theses data are &ldquo;only&rdquo; encoded so if a user have access to your secrets, he can simply base64 decode to see your sensitive data:</p>
<pre tabindex="0"><code class="language-base" data-lang="base">echo &#34;UzNDUjNUCg==&#34; | base64 -d
S3CR3T
</code></pre><p>Encrypt the secret with kubeseal:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir ./01_flux2/02_secret/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeseal --format yaml --cert<span style="color:#f92672">=</span>../../../pub-sealed-secrets.pem <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>&lt; secret.yaml &gt;sealedsecret.yaml
</span></span><span style="display:flex;"><span>rm -f secret.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>git add -A
</span></span><span style="display:flex;"><span>git commit -m <span style="color:#e6db74">&#34;kubeseal&#34;</span>
</span></span><span style="display:flex;"><span>git push
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl logs -n demo-app demo-app
</span></span><span style="display:flex;"><span>S3CR3T
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-gitops" term="k8s-gitops" label="k8s-gitops" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="gitops" term="gitops" label="gitops" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Flux2 Install and Usage]]></title>
            <link href="https://devopstales.github.io/kubernetes/gitops-flux2/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/gitops-flux2-kubeseal/?utm_source=atom_feed" rel="related" type="text/html" title="Flux2 and kubeseal to encrypt secrets" />
                <link href="https://devopstales.github.io/kubernetes/argocd-image-updater/?utm_source=atom_feed" rel="related" type="text/html" title="Argo CD Image Updater for automate image update" />
                <link href="https://devopstales.github.io/kubernetes/argocd-kubeseal/?utm_source=atom_feed" rel="related" type="text/html" title="ArgoCD and kubeseal to encrypt secrets" />
                <link href="https://devopstales.github.io/kubernetes/k8s-gitops/?utm_source=atom_feed" rel="related" type="text/html" title="GitOps solutions for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cert/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Certificate Rotation" />
            
                <id>https://devopstales.github.io/kubernetes/gitops-flux2/</id>
            
            
            <published>2021-05-07T00:00:00+00:00</published>
            <updated>2021-05-07T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use Install and Use the GitOps Tool Flux2.</p>


<H3>Parts of the K8S Gitops series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-gitops/">GitOps solutions for Kubernetes</a></li>
     <li>Part2: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-image-updater/">Argo CD Image Updater for automate image update</a></li>
<!-- ArgoCD notify
https://blog.argoproj.io/notifications-for-argo-bb7338231604
-->
<!----------------------------------------------->
     <li>Part4: <a href="../../kubernetes/gitops-flux2/">Flux2 Install and Usage</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part6: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>
<!-- Flux CD auto image update
https://particule.io/en/blog/flux-auto-image-update/
-->
<!----------------------------------------------->
<!-- Fleet 
Rancher fleet + helm-controller
-->
<!----------------------------------------------->
<!-- Canary Deployment:
Canary Basics - https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments
Canary with helm:
  https://itnext.io/safe-and-automation-friendly-canary-deployments-with-helm-669394d2c48a
  https://github.com/stoehdoi/canary-demo/tree/master/deploy
ArgoCD + Argo Rollouts for canary deploy:
-->
     <li>Part7: <a href="../../kubernetes/flagger-nginx-canary-deployments/">Flagger NGINX Canary Deployments</a></li>
</ul>



<h3 id="install-flux2-cli">Install Flux2 cli</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -s https://fluxcd.io/install.sh | sudo bash
</span></span></code></pre></div><h3 id="bootstrap-flux2-server-components">Bootstrap Flux2 Server components</h3>
<p>Flux is installed in a GitOps way and its manifest will be pushed to the repository, so you will also need a GitHub account and a <a href="https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token">personal access token</a> that can create repositories (check all permissions under <code>repo</code>) to enable Flux do this.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export GITHUB_TOKEN<span style="color:#f92672">=</span>&lt;token&gt;
</span></span><span style="display:flex;"><span>export GITHUB_USER<span style="color:#f92672">=</span>devopstales
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>flux check --pre
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>flux bootstrap github <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --owner<span style="color:#f92672">=</span>$GITHUB_USER <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --repository<span style="color:#f92672">=</span>gitops-repo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --branch<span style="color:#f92672">=</span>main <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --path<span style="color:#f92672">=</span>./01_flux2/ <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --personal
</span></span></code></pre></div><p>If you try to install in a secure Kubernetes cluster with runAsNonRoot psp the notification-controller and the source-controller can&rsquo;t start because it runs as root.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano rb.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">psp-rolebinding-flux-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">flux-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">system-unrestricted-psp-role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">system:serviceaccounts</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl apply -f rb.yaml</span>
</span></span></code></pre></div><p>With <code>--path</code> you can configure the directory which will be used to reconcile the target cluster.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./01_flux2/
</span></span><span style="display:flex;"><span>└── flux-system <span style="color:#75715e"># &lt;- namespace dir generated by bootstrap</span>
</span></span><span style="display:flex;"><span>    ├── gotk-components.yaml
</span></span><span style="display:flex;"><span>    ├── gotk-sync.yaml
</span></span><span style="display:flex;"><span>    ├── rb.yaml <span style="color:#75715e"># &lt;- RoleBinding for psp created by me</span>
</span></span><span style="display:flex;"><span>    └── kustomization.yaml
</span></span></code></pre></div><h3 id="deploy-application">Deploy application</h3>
<p>Add an application to the cluster and upload to the git repository:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./01_flux2/
</span></span><span style="display:flex;"><span>├── 00_guestbook <span style="color:#75715e"># &lt;- guestbook application</span>
</span></span><span style="display:flex;"><span>│   ├── 00_ns.yaml
</span></span><span style="display:flex;"><span>│   ├── 01_rb.yaml
</span></span><span style="display:flex;"><span>│   ├── 02_guestbook-ui-svc.yaml
</span></span><span style="display:flex;"><span>│   └── 03_guestbook-ui-deployment.yaml
</span></span><span style="display:flex;"><span>└── flux-system <span style="color:#75715e"># &lt;- namespace dir generated by bootstrap</span>
</span></span><span style="display:flex;"><span>    ├── gotk-components.yaml
</span></span><span style="display:flex;"><span>    ├── gotk-sync.yaml
</span></span><span style="display:flex;"><span>    ├── rb.yaml <span style="color:#75715e"># &lt;- RoleBinding for psp created by me</span>
</span></span><span style="display:flex;"><span>    └── kustomization.yaml
</span></span></code></pre></div><h3 id="add-another-git-repository">Add another Git repository</h3>
<p>We will be using a public repository github.com/stefanprodan/podinfo, podinfo is a tiny web application made with Go. Create a GitRepository manifest pointing to podinfo repository’s master branch:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir ./01_flux2/01_podinfo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>flux create source git podinfo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --url<span style="color:#f92672">=</span>https://github.com/stefanprodan/podinfo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --branch<span style="color:#f92672">=</span>master <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --interval<span style="color:#f92672">=</span>30s <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --export &gt; ./01_flux2/01_podinfo/podinfo-source.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat 01_flux2/01_podinfo/podinfo-source.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">source.toolkit.fluxcd.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">GitRepository</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">podinfo</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">flux-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">interval</span>: <span style="color:#ae81ff">30s</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ref</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">branch</span>: <span style="color:#ae81ff">master</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">url</span>: <span style="color:#ae81ff">https://github.com/stefanprodan/podinfo</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./01_flux2/
</span></span><span style="display:flex;"><span>├── 00_guestbook <span style="color:#75715e"># &lt;- guestbook application</span>
</span></span><span style="display:flex;"><span>│   ├── 00_ns.yaml
</span></span><span style="display:flex;"><span>│   ├── 01_rb.yaml
</span></span><span style="display:flex;"><span>│   ├── 02_guestbook-ui-svc.yaml
</span></span><span style="display:flex;"><span>│   └── 03_guestbook-ui-deployment.yaml
</span></span><span style="display:flex;"><span>├── 01_podinfo
</span></span><span style="display:flex;"><span>│   └── podinfo-source.yaml
</span></span><span style="display:flex;"><span>└── flux-system <span style="color:#75715e"># &lt;- namespace dir generated by bootstrap</span>
</span></span><span style="display:flex;"><span>    ├── gotk-components.yaml
</span></span><span style="display:flex;"><span>    ├── gotk-sync.yaml
</span></span><span style="display:flex;"><span>    ├── rb.yaml <span style="color:#75715e"># &lt;- RoleBinding for psp created by me</span>
</span></span><span style="display:flex;"><span>    └── kustomization.yaml
</span></span></code></pre></div><h3 id="kustomization">Kustomization</h3>
<p>We will create a Flux Kustomization manifest for podinfo. This configures Flux to apply the kustomize directory located in the podinfo repository.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>flux create kustomization podinfo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --source<span style="color:#f92672">=</span>podinfo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --path<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./kustomize&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --prune<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --validation<span style="color:#f92672">=</span>client <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --interval<span style="color:#f92672">=</span>5m <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --export &gt; ./01_flux2/01_podinfo/podinfo-kustomization.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat ./01_flux2/01_podinfo/podinfo-kustomization.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kustomize.toolkit.fluxcd.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Kustomization</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">podinfo</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">flux-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">interval</span>: <span style="color:#ae81ff">5m0s</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">path</span>: <span style="color:#ae81ff">./kustomize</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">prune</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sourceRef</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">GitRepository</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">podinfo</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">validation</span>: <span style="color:#ae81ff">client</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./01_flux2/
</span></span><span style="display:flex;"><span>├── 00_guestbook <span style="color:#75715e"># &lt;- guestbook application</span>
</span></span><span style="display:flex;"><span>│   ├── 00_ns.yaml
</span></span><span style="display:flex;"><span>│   ├── 01_rb.yaml
</span></span><span style="display:flex;"><span>│   ├── 02_guestbook-ui-svc.yaml
</span></span><span style="display:flex;"><span>│   └── 03_guestbook-ui-deployment.yaml
</span></span><span style="display:flex;"><span>├── 01_podinfo
</span></span><span style="display:flex;"><span>│   ├── podinfo-kustomization.yaml
</span></span><span style="display:flex;"><span>│   └── podinfo-source.yaml
</span></span><span style="display:flex;"><span>└── flux-system <span style="color:#75715e"># &lt;- namespace dir generated by bootstrap</span>
</span></span><span style="display:flex;"><span>    ├── gotk-components.yaml
</span></span><span style="display:flex;"><span>    ├── gotk-sync.yaml
</span></span><span style="display:flex;"><span>    ├── rb.yaml <span style="color:#75715e"># &lt;- RoleBinding for psp created by me</span>
</span></span><span style="display:flex;"><span>    └── kustomization.yaml
</span></span></code></pre></div><h3 id="manage-helm-releases">Manage Helm Releases</h3>
<p>I usually use Ransher&rsquo;s helm operator but Flux has it&rsquo;s own. It has two part the <code>HelmRepository</code> and the <code>HelmRelease</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">source.toolkit.fluxcd.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmRepository</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">chartmuseum</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">flux-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">url</span>: <span style="color:#ae81ff">https://chartmuseum.github.io/charts</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">interval</span>: <span style="color:#ae81ff">10m</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.toolkit.fluxcd.io/v2beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmRelease</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">chartmuseum</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">flux-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">interval</span>: <span style="color:#ae81ff">5m</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">chart</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">chart</span>: <span style="color:#ae81ff">chartmuseum</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">version</span>: <span style="color:#e6db74">&#34;2.14.2&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">sourceRef</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmRepository</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">chartmuseum</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">flux-system</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">interval</span>: <span style="color:#ae81ff">1m</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">values</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">open</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">AWS_SDK_LOAD_CONFIG</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">STORAGE</span>: <span style="color:#ae81ff">amazon</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">STORAGE_AMAZON_BUCKET</span>: <span style="color:#e6db74">&#34;bucket-name&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">STORAGE_AMAZON_PREFIX</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">STORAGE_AMAZON_REGION</span>: <span style="color:#e6db74">&#34;region-name&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">serviceAccount</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">create</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">eks.amazonaws.com/role-arn</span>: <span style="color:#e6db74">&#34;role-arn&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">enabled</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">fsGroup</span>: <span style="color:#ae81ff">65534</span>
</span></span></code></pre></div><p>It is possible to define a list of ConfigMap and Secret resources from which to take values.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">valuesFrom</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">prod-env-values</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">valuesKey</span>: <span style="color:#ae81ff">values-prod.yaml</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">prod-tls-values</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">valuesKey</span>: <span style="color:#ae81ff">crt</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPath</span>: <span style="color:#ae81ff">tls.crt</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-gitops" term="k8s-gitops" label="k8s-gitops" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="gitops" term="gitops" label="gitops" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Certificate Rotation]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-cert/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k3s-gvisor/?utm_source=atom_feed" rel="related" type="text/html" title="Secure k3s with gVisor" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes and Vault integration" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/k8s-networkpolicy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Network Policy" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-cert/</id>
            
            
            <published>2021-05-01T00:00:00+00:00</published>
            <updated>2021-05-01T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can rotate your Kubernetes Engine Certificates.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>By default, kubeadm generates all the certificates needed for a cluster to run. Client certificates generated by kubeadm expire after 1 year. The base concept is that you probably update for the next kubernetes version in a year.</p>
<h3 id="check-certificate-expiration">Check certificate expiration</h3>
<p>You can use the <code>check-expiration</code> subcommand to check when certificates expire:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm certs check-expiration
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>check-expiration<span style="color:#f92672">]</span> Reading configuration from the cluster...
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>check-expiration<span style="color:#f92672">]</span> FYI: You can look at this config file with <span style="color:#e6db74">&#39;kubectl -n kube-system get cm kubeadm-config -o yaml&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED
</span></span><span style="display:flex;"><span>admin.conf                 Apr 19, <span style="color:#ae81ff">2022</span> 16:34 UTC   364d                                    no
</span></span><span style="display:flex;"><span>apiserver                  Apr 19, <span style="color:#ae81ff">2022</span> 16:34 UTC   364d            ca                      no
</span></span><span style="display:flex;"><span>apiserver-etcd-client      Apr 19, <span style="color:#ae81ff">2022</span> 16:34 UTC   364d            etcd-ca                 no
</span></span><span style="display:flex;"><span>apiserver-kubelet-client   Apr 19, <span style="color:#ae81ff">2022</span> 16:34 UTC   364d            ca                      no
</span></span><span style="display:flex;"><span>controller-manager.conf    Apr 19, <span style="color:#ae81ff">2022</span> 16:34 UTC   364d                                    no
</span></span><span style="display:flex;"><span>etcd-healthcheck-client    Apr 19, <span style="color:#ae81ff">2022</span> 16:34 UTC   364d            etcd-ca                 no
</span></span><span style="display:flex;"><span>etcd-peer                  Apr 19, <span style="color:#ae81ff">2022</span> 16:34 UTC   364d            etcd-ca                 no
</span></span><span style="display:flex;"><span>etcd-server                Apr 19, <span style="color:#ae81ff">2022</span> 16:34 UTC   364d            etcd-ca                 no
</span></span><span style="display:flex;"><span>front-proxy-client         Apr 19, <span style="color:#ae81ff">2022</span> 16:34 UTC   364d            front-proxy-ca          no
</span></span><span style="display:flex;"><span>scheduler.conf             Apr 19, <span style="color:#ae81ff">2022</span> 16:34 UTC   364d                                    no
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED
</span></span><span style="display:flex;"><span>ca                      Apr 17, <span style="color:#ae81ff">2031</span> 16:34 UTC   9y              no
</span></span><span style="display:flex;"><span>etcd-ca                 Apr 17, <span style="color:#ae81ff">2031</span> 16:34 UTC   9y              no
</span></span><span style="display:flex;"><span>front-proxy-ca          Apr 17, <span style="color:#ae81ff">2031</span> 16:34 UTC   9y              no
</span></span></code></pre></div><p>The kubernetes certificates are located under <code>/etc/kubernetes/pki/</code> folder. You can check the certificates manulally:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>find /etc/kubernetes/pki/ -type f -name <span style="color:#e6db74">&#34;*.crt&#34;</span> -print |xargs -L <span style="color:#ae81ff">1</span> -t  -i bash -c <span style="color:#e6db74">&#39;openssl x509  -noout -text -in {}|grep Not&#39;</span>
</span></span></code></pre></div><p>The kubele certificate is not checkd by the abow command. It is located under the <code>/var/lib/kubelet/pki/</code> folder.</p>
<h3 id="automatic-certificate-renewal">Automatic certificate renewal</h3>
<p><code>kubeadm</code> renews all the certificates during control plane upgrade. It is a best practice to upgrade your cluster frequently in order to stay secure. Kubernetes v1.8 and higher kubelet implements features for enabling rotation of its client and/or serving certificates.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create clusterrolebinding kubelet-bootstrap <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --clusterrole<span style="color:#f92672">=</span>system:node-bootstrapper <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --user<span style="color:#f92672">=</span>kubelet-bootstrap
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create clusterrolebinding node-client-auto-approve-csr <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --clusterrole<span style="color:#f92672">=</span>system:certificates.k8s.io:certificatesigningrequests:nodeclient <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --group<span style="color:#f92672">=</span>system:node-bootstrappers
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create clusterrolebinding node-client-auto-renew-crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --clusterrole<span style="color:#f92672">=</span>system:certificates.k8s.io:certificatesigningrequests:selfnodeclient <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --group<span style="color:#f92672">=</span>system:nodes
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/systemd/system/kubelet.env
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or</span>
</span></span><span style="display:flex;"><span>nano /var/lib/kubelet/kubeadm-flags.env
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>KUBELET_EXTRA_ARGS<span style="color:#f92672">==</span><span style="color:#e6db74">&#34;--rotate-certificates=true --rotate-server-certificates=true&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl restart kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># OR</span>
</span></span><span style="display:flex;"><span>nano /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
</span></span><span style="display:flex;"><span><span style="color:#75715e"># OR</span>
</span></span><span style="display:flex;"><span>nano /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
</span></span><span style="display:flex;"><span>Environment<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;KUBELET_EXTRA_ARGS=--rotate-certificates=true --rotate-server-certificates=true&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl daemon-reload
</span></span><span style="display:flex;"><span>systemctl restart kubelet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ps -ef | grep kubelet | grep <span style="color:#e6db74">&#34;rotate-certificates&#34;</span>
</span></span><span style="display:flex;"><span>root      <span style="color:#ae81ff">14105</span>      <span style="color:#ae81ff">1</span>  <span style="color:#ae81ff">0</span> 16:56 pts/0    00:00:00 bash -c <span style="color:#66d9ef">while</span> true ; <span style="color:#66d9ef">do</span> /usr/bin/kubelet  --bootstrap-kubeconfig<span style="color:#f92672">=</span>/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig<span style="color:#f92672">=</span>/etc/kubernetes/kubelet.conf --pod-manifest-path<span style="color:#f92672">=</span>/etc/kubernetes/manifests --pod-infra-container-image<span style="color:#f92672">=</span>k8s.gcr.io/pause:3.2 --network-plugin<span style="color:#f92672">=</span>cni --cni-conf-dir<span style="color:#f92672">=</span>/etc/cni/net.d --cni-bin-dir<span style="color:#f92672">=</span>/opt/cni/bin --cluster-dns<span style="color:#f92672">=</span>10.96.0.10 --cluster-domain<span style="color:#f92672">=</span>cluster.local --authorization-mode<span style="color:#f92672">=</span>Webhook --client-ca-file<span style="color:#f92672">=</span>/etc/kubernetes/pki/ca.crt --cgroup-driver<span style="color:#f92672">=</span>cgroupfs --fail-swap-on<span style="color:#f92672">=</span>false --resolv-conf<span style="color:#f92672">=</span>/etc/resolv.conf.override --rotate-certificates<span style="color:#f92672">=</span>true --rotate-server-certificates<span style="color:#f92672">=</span>true; sleep 5; <span style="color:#66d9ef">done</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get csr
</span></span><span style="display:flex;"><span>NAME                                                   AGE   SIGNERNAME                                    REQUESTOR                 CONDITION
</span></span><span style="display:flex;"><span>csr-pswns                                              27m   kubernetes.io/kube-apiserver-client-kubelet   system:node:node1         Approved,Issued
</span></span><span style="display:flex;"><span>node-csr-cQYdjcH2F3kl-ysnzq2TlZOuUDCPgYU8cfKV1V0kqlE   47m   kubernetes.io/kube-apiserver-client-kubelet   system:bootstrap:lzhuxv   Approved,Issued
</span></span><span style="display:flex;"><span>node-csr-f2J5HT9hg4CIKP0-0BtsEffBzg28VlUbesKJ4p_2mi0   47m   kubernetes.io/kube-apiserver-client-kubelet   system:bootstrap:lzhuxv   Approved,Issued
</span></span></code></pre></div><h3 id="manual-certificate-renewal">Manual certificate renewal</h3>
<p>You can renew your certificates manually at any time with the <code>kubeadm certs renew</code> command. This command performs the renewal using CA (or front-proxy-CA) certificate and key stored in <code>/etc/kubernetes/pki</code> If you are running an HA cluster, this command needs to be executed on all the control-plane nodes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo kubeadm alpha certs renew all
</span></span></code></pre></div><h3 id="rke2-and-k3s">RKE2 and K3S</h3>
<p>By default, certificates in RKE2 and K3S expire in 12 months. If the certificates are expired or have fewer than 90 days remaining before they expire, the certificates are rotated when RKE2 is restarted.  It is expected that you would be taking your hosts down periodically for patching and upgrading every few months. With regular updates the reboots should happen - but reality has shown that many of us do not patch / reboot for more than 3 months.. so the best practice is monitoring the certificate expiration.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Secure k3s with gVisor]]></title>
            <link href="https://devopstales.github.io/kubernetes/k3s-gvisor/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-vault/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes and Vault integration" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/k8s-networkpolicy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Network Policy" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
            
                <id>https://devopstales.github.io/kubernetes/k3s-gvisor/</id>
            
            
            <published>2021-04-30T00:00:00+00:00</published>
            <updated>2021-04-30T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can secure k3s with gVisor.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>In  <a href="https://devopstales.github.io/kubernetes/k3s-etcd-kube-vip/">previous pos</a> I showd you how to install a k3s Cluster. Now we modify the configuration of the containerd to use different low level container runtime.</p>
<h3 id="what-is-gvisor">What is gvisor</h3>
<p>gVisor is an application kernel, written in Go, that implements a substantial portion of the Linux system call interface. It provides an additional layer of isolation between running applications and the host operating system.</p>
<p>gVisor includes an Open Container Initiative (OCI) runtime called <code>runsc</code> that makes it easy to work with existing container tooling. The <code>runsc</code> runtime integrates with Docker, containerd and Kubernetes, making it simple to run sandboxed containers.</p>
<p><img src="/img/include/gvisor2.png" alt="gvisor"  class="zoomable" />
<img src="/img/include/gvisor.png" alt="gvisor"  class="zoomable" /></p>
<h3 id="bootstrap-the-k3s-cluster">Bootstrap the k3s cluster</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>k3sup install <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip<span style="color:#f92672">=</span>172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user<span style="color:#f92672">=</span>vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cluster <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel<span style="color:#f92672">=</span>stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--no-deploy=traefik --no-deploy=servicelb --flannel-iface=enp0s8 --node-ip=172.17.8.101&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --merge <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local-path $HOME/.kube/config <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --context<span style="color:#f92672">=</span>k3s-ha
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3sup join <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip 172.17.8.102 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-ip 172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--no-deploy=traefik --no-deploy=servicelb --flannel-iface=enp0s8 --node-ip=172.17.8.102&#34;</span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>k3sup join <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip 172.17.8.103 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-ip 172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--no-deploy=traefik --no-deploy=servicelb --flannel-iface=enp0s8 --node-ip=172.17.8.103&#34;</span>
</span></span></code></pre></div><h3 id="what-is-gvisor-1">What is gVisor</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>tmux-cssh -u vagrant 172.17.8.101 172.17.8.102 172.17.8.103
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>yum install nano wget -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano gvisor.sh
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/bash</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">(</span>
</span></span><span style="display:flex;"><span>  set -e
</span></span><span style="display:flex;"><span>  URL<span style="color:#f92672">=</span>https://storage.googleapis.com/gvisor/releases/release/latest
</span></span><span style="display:flex;"><span>  wget <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/runsc <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/runsc.sha512 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/gvisor-containerd-shim <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/gvisor-containerd-shim.sha512 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/containerd-shim-runsc-v1 <span style="color:#e6db74">${</span>URL<span style="color:#e6db74">}</span>/containerd-shim-runsc-v1.sha512
</span></span><span style="display:flex;"><span>  sha512sum -c runsc.sha512 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -c gvisor-containerd-shim.sha512 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -c containerd-shim-runsc-v1.sha512
</span></span><span style="display:flex;"><span>  rm -f *.sha512
</span></span><span style="display:flex;"><span>  chmod a+rx runsc gvisor-containerd-shim containerd-shim-runsc-v1
</span></span><span style="display:flex;"><span>  sudo mv runsc gvisor-containerd-shim containerd-shim-runsc-v1 /usr/local/bin
</span></span><span style="display:flex;"><span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>bash gvisor.sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cp /var/lib/rancher/k3s/agent/etc/containerd/config.toml <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>/var/lib/rancher/k3s/agent/etc/containerd/config.toml.back
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cp /var/lib/rancher/k3s/agent/etc/containerd/config.toml.back <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>/var/lib/rancher/k3s/agent/etc/containerd/config.toml.tmpl
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano /var/lib/rancher/k3s/agent/etc/containerd/config.toml.tmpl
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>plugins.cri.containerd<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  disable_snapshot_annotations <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>  snapshotter <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;overlayfs&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>disabled_plugins <span style="color:#f92672">=</span> <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;restart&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>plugins.linux<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  shim_debug <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>plugins.cri.containerd.runtimes.runsc<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  runtime_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;io.containerd.runsc.v1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>plugins.cri.cni<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemcl restart k3s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: node.k8s.io/v1beta1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: RuntimeClass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: gvisor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">handler: runsc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-runc
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat<span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Pod
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: untrusted
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: www-gvisor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  runtimeClassName: gvisor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  - image: nginx:1.18
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    name: www
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get po
</span></span><span style="display:flex;"><span>NAME         READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>www-gvisor   1/1     Running   <span style="color:#ae81ff">0</span>          9s
</span></span><span style="display:flex;"><span>www-runc     1/1     Running   <span style="color:#ae81ff">0</span>          1m
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="k3s" term="k3s" label="k3s" />
                             
                                <category scheme="gvisor" term="gvisor" label="gVisor" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install K3S with k3sup and Calico]]></title>
            <link href="https://devopstales.github.io/kubernetes/k3sup-calico/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k3s-cilium/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with k3sup and Cilium" />
                <link href="https://devopstales.github.io/kubernetes/k3s-etcd-kube-vip/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with k3sup and kube-vip" />
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k3s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with CRI-O and kadalu" />
                <link href="https://devopstales.github.io/kubernetes/k3s-fcos/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S on Fedora CoreOS" />
            
                <id>https://devopstales.github.io/kubernetes/k3sup-calico/</id>
            
            
            <published>2021-04-18T00:00:00+00:00</published>
            <updated>2021-04-18T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to install K3S with k3sup and use Calico as networking.</p>


<H3>Parts of the K3S series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/k3s-etcd-kube-vip/">Install K3S with k3sup and kube-vip</a></li>
     <li>Part1b: <a href="../../kubernetes/k3s-crio/">Install K3S with CRI-O</a></li>
     <li>Part1c: <a href="../../kubernetes/k3s-fcos/">Install K3S on Fedora CoreOS</a></li>
<!-- K3S falnnel wiregard - https://medium.com/@bestpractices/k3s-with-flannel-wireguard-backend-fa433065a401 -->
     <li>Part2b: <a href="../../kubernetes/k3sup-calico/">Install K3S with k3sup and Calico</a></li>
     <li>Part2c: <a href="../../kubernetes/k3s-cilium/">Install K3S with k3sup and Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/k3s-helm-controller/">K3S helm CR</a></li>
<!-- K3D -->
     <li>Part5: <a href="../../kubernetes/k3s-gvisor/">Secure k3s with gVisor</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>



<h3 id="installing-k3sup">Installing k3sup</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -sLS https://get.k3sup.dev | sh
</span></span><span style="display:flex;"><span>sudo install k3sup /usr/local/bin/
</span></span><span style="display:flex;"><span>k3sup --help
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.8.101
</span></span><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.8.102
</span></span><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.8.103
</span></span></code></pre></div><h3 id="bootstrap-the-first-k3s-node">Bootstrap the first k3s node</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>k3sup install <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip<span style="color:#f92672">=</span>172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user<span style="color:#f92672">=</span>vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cluster <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel<span style="color:#f92672">=</span>stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--flannel-backend=none --cluster-cidr=10.10.0.0/16 --disable-network-policy --no-deploy=traefik --no-deploy=servicelb --node-ip=172.17.8.101&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --merge <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local-path $HOME/.kube/config <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --context<span style="color:#f92672">=</span>k3s-ha
</span></span></code></pre></div><h3 id="install-calico-for-networking">Install calico for networking</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx k3s-ha
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get no
</span></span><span style="display:flex;"><span>NAME        STATUS     ROLES                       AGE   VERSION
</span></span><span style="display:flex;"><span>k3s-node1   NotReady   control-plane,etcd,master   15m   v1.20.5+k3s1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get po -A -o wide
</span></span><span style="display:flex;"><span>NAMESPACE     NAME                                      READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>kube-system   coredns-854c77959c-zbgkt                  0/1     Pending   <span style="color:#ae81ff">0</span>          16m
</span></span><span style="display:flex;"><span>kube-system   local-path-provisioner-5ff76fc89d-btmx6   0/1     Pending   <span style="color:#ae81ff">0</span>          16m
</span></span><span style="display:flex;"><span>kube-system   metrics-server-86cbb8457f-n99rp           0/1     Pending   <span style="color:#ae81ff">0</span>          16m
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
</span></span><span style="display:flex;"><span>kubectl create -f https://docs.projectcalico.org/manifests/custom-resources.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get po -A   
</span></span><span style="display:flex;"><span>NAMESPACE         NAME                                       READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>calico-system     calico-kube-controllers-77c7dbc6d6-srss8   1/1     Running   <span style="color:#ae81ff">0</span>          90s
</span></span><span style="display:flex;"><span>calico-system     calico-node-zd7rg                          1/1     Running   <span style="color:#ae81ff">0</span>          90s
</span></span><span style="display:flex;"><span>calico-system     calico-typha-7b4c95fcd4-lw4wx              1/1     Running   <span style="color:#ae81ff">0</span>          90s
</span></span><span style="display:flex;"><span>kube-system       coredns-854c77959c-zbgkt                   1/1     Running   <span style="color:#ae81ff">0</span>          27m
</span></span><span style="display:flex;"><span>kube-system       local-path-provisioner-5ff76fc89d-btmx6    1/1     Running   <span style="color:#ae81ff">0</span>          27m
</span></span><span style="display:flex;"><span>kube-system       metrics-server-86cbb8457f-n99rp            1/1     Running   <span style="color:#ae81ff">0</span>          27m
</span></span><span style="display:flex;"><span>tigera-operator   tigera-operator-675ccbb69c-fv894           1/1     Running   <span style="color:#ae81ff">0</span>          10m
</span></span></code></pre></div><h3 id="bootstrap-the-other-k3s-nodes">Bootstrap the other k3s nodes</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>k3sup join <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip 172.17.8.102 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-ip 172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--flannel-backend=none --cluster-cidr=10.10.0.0/16 --disable-network-policy --no-deploy=traefik --no-deploy=servicelb --node-ip=172.17.8.102&#34;</span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>k3sup join <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip 172.17.8.103 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-ip 172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--flannel-backend=none --cluster-cidr=10.10.0.0/16 --disable-network-policy --no-deploy=traefik --no-deploy=servicelb --node-ip=172.17.8.103&#34;</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="calico" term="calico" label="Calico" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install K3S with k3sup and Cilium]]></title>
            <link href="https://devopstales.github.io/kubernetes/k3s-cilium/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k3s-etcd-kube-vip/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with k3sup and kube-vip" />
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k3s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with CRI-O and kadalu" />
                <link href="https://devopstales.github.io/kubernetes/k3s-fcos/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S on Fedora CoreOS" />
                <link href="https://devopstales.github.io/kubernetes/argocd-image-updater/?utm_source=atom_feed" rel="related" type="text/html" title="Argo CD Image Updater for automate image update" />
            
                <id>https://devopstales.github.io/kubernetes/k3s-cilium/</id>
            
            
            <published>2021-04-17T00:00:00+00:00</published>
            <updated>2021-04-17T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to install K3S with k3sup and use Cilium as networking.</p>


<H3>Parts of the K3S series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/k3s-etcd-kube-vip/">Install K3S with k3sup and kube-vip</a></li>
     <li>Part1b: <a href="../../kubernetes/k3s-crio/">Install K3S with CRI-O</a></li>
     <li>Part1c: <a href="../../kubernetes/k3s-fcos/">Install K3S on Fedora CoreOS</a></li>
<!-- K3S falnnel wiregard - https://medium.com/@bestpractices/k3s-with-flannel-wireguard-backend-fa433065a401 -->
     <li>Part2b: <a href="../../kubernetes/k3sup-calico/">Install K3S with k3sup and Calico</a></li>
     <li>Part2c: <a href="../../kubernetes/k3s-cilium/">Install K3S with k3sup and Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/k3s-helm-controller/">K3S helm CR</a></li>
<!-- K3D -->
     <li>Part5: <a href="../../kubernetes/k3s-gvisor/">Secure k3s with gVisor</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>



<h3 id="installing-k3sup">Installing k3sup</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -sLS https://get.k3sup.dev | sh
</span></span><span style="display:flex;"><span>sudo install k3sup /usr/local/bin/
</span></span><span style="display:flex;"><span>k3sup --help
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.8.101
</span></span><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.8.102
</span></span><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.8.103
</span></span></code></pre></div><h3 id="bootstrap-the-first-k3s-node">Bootstrap the first k3s node</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>k3sup install <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip<span style="color:#f92672">=</span>172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user<span style="color:#f92672">=</span>vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cluster <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel<span style="color:#f92672">=</span>stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--flannel-backend=none --cluster-cidr=10.10.0.0/16 --disable-network-policy --no-deploy=traefik --no-deploy=servicelb --node-ip=172.17.8.101&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --merge <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local-path $HOME/.kube/config <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --context<span style="color:#f92672">=</span>k3s-ha
</span></span></code></pre></div><h3 id="install-cilium-for-networking">Install cilium for networking</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx k3s-ha
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get no
</span></span><span style="display:flex;"><span>NAME        STATUS     ROLES                       AGE   VERSION
</span></span><span style="display:flex;"><span>k3s-node1   NotReady   control-plane,etcd,master   15m   v1.20.5+k3s1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get po -A -o wide
</span></span><span style="display:flex;"><span>NAMESPACE     NAME                                      READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>kube-system   coredns-854c77959c-zbgkt                  0/1     Pending   <span style="color:#ae81ff">0</span>          16m
</span></span><span style="display:flex;"><span>kube-system   local-path-provisioner-5ff76fc89d-btmx6   0/1     Pending   <span style="color:#ae81ff">0</span>          16m
</span></span><span style="display:flex;"><span>kube-system   metrics-server-86cbb8457f-n99rp           0/1     Pending   <span style="color:#ae81ff">0</span>          16m
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>tmux-cssh -u vagrant 172.17.8.101 172.17.8.102 172.17.8.103
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo mount bpffs -t bpf /sys/fs/bpf
</span></span><span style="display:flex;"><span>sudo bash -c <span style="color:#e6db74">&#39;cat &lt;&lt;EOF &gt;&gt; /etc/fstab
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">none /sys/fs/bpf bpf rw,relatime 0 0
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add cilium https://helm.cilium.io/
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create -n kube-system secret generic cilium-ipsec-keys <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --from-literal<span style="color:#f92672">=</span>keys<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;3 rfc4106(gcm(aes)) </span><span style="color:#66d9ef">$(</span>echo <span style="color:#66d9ef">$(</span>dd <span style="color:#66d9ef">if</span><span style="color:#f92672">=</span>/dev/urandom count<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span> bs<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> 2&gt; /dev/null| xxd -p -c 64<span style="color:#66d9ef">))</span><span style="color:#e6db74"> 128&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl -n kube-system get secrets cilium-ipsec-keys
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano values.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>kubeProxyReplacement: <span style="color:#e6db74">&#34;strict&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k8sServiceHost: 10.0.2.15
</span></span><span style="display:flex;"><span>k8sServicePort: <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>global:
</span></span><span style="display:flex;"><span>  encryption:
</span></span><span style="display:flex;"><span>    enabled: true
</span></span><span style="display:flex;"><span>    nodeEncryption: true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>hubble:
</span></span><span style="display:flex;"><span>  metrics:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#serviceMonitor:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#  enabled: true</span>
</span></span><span style="display:flex;"><span>    enabled:
</span></span><span style="display:flex;"><span>    - dns:query;ignoreAAAA
</span></span><span style="display:flex;"><span>    - drop
</span></span><span style="display:flex;"><span>    - tcp
</span></span><span style="display:flex;"><span>    - flow
</span></span><span style="display:flex;"><span>    - icmp
</span></span><span style="display:flex;"><span>    - http
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  ui:
</span></span><span style="display:flex;"><span>    enabled: true
</span></span><span style="display:flex;"><span>    replicas: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    ingress:
</span></span><span style="display:flex;"><span>      enabled: true
</span></span><span style="display:flex;"><span>      hosts:
</span></span><span style="display:flex;"><span>        - hubble.k3s.intra
</span></span><span style="display:flex;"><span>      annotations:
</span></span><span style="display:flex;"><span>        cert-manager.io/cluster-issuer: ca-issuer
</span></span><span style="display:flex;"><span>      tls:
</span></span><span style="display:flex;"><span>      - secretName: ingress-hubble-ui
</span></span><span style="display:flex;"><span>        hosts:
</span></span><span style="display:flex;"><span>        - hubble.k3s.intra
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  relay:
</span></span><span style="display:flex;"><span>    enabled: true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>operator:
</span></span><span style="display:flex;"><span>  replicas: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ipam:
</span></span><span style="display:flex;"><span>  mode: <span style="color:#e6db74">&#34;cluster-pool&#34;</span>
</span></span><span style="display:flex;"><span>  operator:
</span></span><span style="display:flex;"><span>    clusterPoolIPv4PodCIDR: <span style="color:#e6db74">&#34;10.43.0.0/16&#34;</span>
</span></span><span style="display:flex;"><span>    clusterPoolIPv4MaskSize: <span style="color:#ae81ff">24</span>
</span></span><span style="display:flex;"><span>    clusterPoolIPv6PodCIDR: <span style="color:#e6db74">&#34;fd00::/104&#34;</span>
</span></span><span style="display:flex;"><span>    clusterPoolIPv6MaskSize: <span style="color:#ae81ff">120</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>prometheus:
</span></span><span style="display:flex;"><span>  enabled: true
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Default port value (9090) needs to be changed since the RHEL cockpit also listens on this port.</span>
</span></span><span style="display:flex;"><span>  port: <span style="color:#ae81ff">19090</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm upgrade --install cilium cilium/cilium   --namespace kube-system -f values.yaml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>k get po -A   
</span></span><span style="display:flex;"><span>NAMESPACE     NAME                                      READY   STATUS    RESTARTS   AGE
</span></span><span style="display:flex;"><span>kube-system   cilium-operator-67895d78b7-vkgcs          1/1     Running   <span style="color:#ae81ff">0</span>          89s
</span></span><span style="display:flex;"><span>kube-system   cilium-zppdd                              1/1     Running   <span style="color:#ae81ff">0</span>          89s
</span></span><span style="display:flex;"><span>kube-system   coredns-854c77959c-b4gzq                  1/1     Running   <span style="color:#ae81ff">0</span>          40s
</span></span><span style="display:flex;"><span>kube-system   local-path-provisioner-5ff76fc89d-9xjgz   1/1     Running   <span style="color:#ae81ff">0</span>          40s
</span></span><span style="display:flex;"><span>kube-system   metrics-server-86cbb8457f-t4d6l           1/1     Running   <span style="color:#ae81ff">0</span>          40s
</span></span></code></pre></div><h3 id="bootstrap-the-other-k3s-nodes">Bootstrap the other k3s nodes</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>k3sup join <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip 172.17.8.102 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-ip 172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--flannel-backend=none --cluster-cidr=10.10.0.0/16 --disable-network-policy --no-deploy=traefik --no-deploy=servicelb --node-ip=172.17.8.102&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3sup join <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip 172.17.8.103 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-ip 172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--flannel-backend=none --cluster-cidr=10.10.0.0/16 --disable-network-policy --no-deploy=traefik --no-deploy=servicelb --node-ip=172.17.8.103&#34;</span>
</span></span></code></pre></div><h3 id="enable-hubble-for-cluster-wide-visibility">Enable Hubble for Cluster-Wide Visibility</h3>
<p>I configured an ingress with https in cilium helm chart but you can use port-forward instead of that.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl port-forward -n kube-system svc/hubble-ui <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--address 0.0.0.0 --address :: 12000:80
</span></span></code></pre></div><p>And then open http://localhost:12000/ to access the UI.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="cilium" term="cilium" label="Cilium" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install K3S with k3sup and kube-vip]]></title>
            <link href="https://devopstales.github.io/kubernetes/k3s-etcd-kube-vip/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k3s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with CRI-O and kadalu" />
                <link href="https://devopstales.github.io/kubernetes/k3s-fcos/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S on Fedora CoreOS" />
                <link href="https://devopstales.github.io/kubernetes/argocd-image-updater/?utm_source=atom_feed" rel="related" type="text/html" title="Argo CD Image Updater for automate image update" />
                <link href="https://devopstales.github.io/kubernetes/argocd-kubeseal/?utm_source=atom_feed" rel="related" type="text/html" title="ArgoCD and kubeseal to encrypt secrets" />
            
                <id>https://devopstales.github.io/kubernetes/k3s-etcd-kube-vip/</id>
            
            
            <published>2021-04-16T00:00:00+00:00</published>
            <updated>2021-04-16T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to install K3S with k3sup. I will use kube-vip for  High-Availability and load-balancing.</p>


<H3>Parts of the K3S series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/k3s-etcd-kube-vip/">Install K3S with k3sup and kube-vip</a></li>
     <li>Part1b: <a href="../../kubernetes/k3s-crio/">Install K3S with CRI-O</a></li>
     <li>Part1c: <a href="../../kubernetes/k3s-fcos/">Install K3S on Fedora CoreOS</a></li>
<!-- K3S falnnel wiregard - https://medium.com/@bestpractices/k3s-with-flannel-wireguard-backend-fa433065a401 -->
     <li>Part2b: <a href="../../kubernetes/k3sup-calico/">Install K3S with k3sup and Calico</a></li>
     <li>Part2c: <a href="../../kubernetes/k3s-cilium/">Install K3S with k3sup and Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/k3s-helm-controller/">K3S helm CR</a></li>
<!-- K3D -->
     <li>Part5: <a href="../../kubernetes/k3s-gvisor/">Secure k3s with gVisor</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>



<h3 id="the-infrastructure">The infrastructure</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>k3s-node1:
</span></span><span style="display:flex;"><span>ip: 172.17.8.101
</span></span><span style="display:flex;"><span>etcd
</span></span><span style="display:flex;"><span>kube-vip
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3s-node2:
</span></span><span style="display:flex;"><span>ip: 172.17.8.102
</span></span><span style="display:flex;"><span>etcd
</span></span><span style="display:flex;"><span>kube-vip
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k3s-node3:
</span></span><span style="display:flex;"><span>ip: 172.17.8.103
</span></span><span style="display:flex;"><span>etcd
</span></span><span style="display:flex;"><span>kube-vip
</span></span></code></pre></div><h3 id="what-is-k3sup">What is k3sup?</h3>
<p>K3S dose not give you an rpm or deb installer option just a binary. To install you need to create the systemd service and configure it. For a big cluster 3 or 5 node it could be a pain. k3sup automates this tasks trout ssh. You need a passwordless ssh connection for all the nodes and the k3sup binary on your computer.</p>
<h3 id="installing-k3sup">Installing k3sup</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -sLS https://get.k3sup.dev | sh
</span></span><span style="display:flex;"><span>sudo install k3sup /usr/local/bin/
</span></span><span style="display:flex;"><span>k3sup --help
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.8.101
</span></span><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.8.102
</span></span><span style="display:flex;"><span>ssh-copy-id vagrant@172.17.8.103
</span></span></code></pre></div><h3 id="bootstrap-the-first-k3s-node">Bootstrap the first k3s node</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>k3sup install <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip<span style="color:#f92672">=</span>172.17.8.101 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user<span style="color:#f92672">=</span>vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --tls-san<span style="color:#f92672">=</span>172.17.8.100 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cluster <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel<span style="color:#f92672">=</span>stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--no-deploy=traefik --no-deploy=servicelb --flannel-iface=enp0s8 --node-ip=172.17.8.101&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --merge <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --local-path $HOME/.kube/config <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --context<span style="color:#f92672">=</span>k3s-ha
</span></span></code></pre></div><p>I used the <code>--tls-san</code> option to add the LoadBalancer&rsquo;s virtual ip to the cert, and a few extra option. I disabled the  traefik and the servicelb service because I will use nginx ingress controller and kube-vip as loadbalancer.  In my environment I used Vangrant to spin up the nodes.Vagrant creats multiple interfaces for the vm so I need to configure which of these will be used for the cluster: <code>--flannel-iface=enp0s8 --node-ip=172.17.8.101</code> Thanks to the <code>--cluster</code> k3sup will start an embedded etcd cluster in a container.</p>
<h3 id="install-kube-vip-for-ha">Install kube-vip for HA</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectx k3s-ha
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get nodes
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f https://kube-vip.io/manifests/rbac.yaml
</span></span></code></pre></div><p>ssh to the first host and generate the daemonset to run kube-vip:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ssh vagrant@172.17.8.101
</span></span><span style="display:flex;"><span>sudo su -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ctr image pull docker.io/plndr/kube-vip:0.3.2
</span></span><span style="display:flex;"><span>alias kube-vip<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;ctr run --rm --net-host docker.io/plndr/kube-vip:0.3.2 vip /kube-vip&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kube-vip manifest daemonset <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --arp <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --interface enp0s8 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --address 172.17.8.100 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --controlplane <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --leaderElection <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --taint <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --inCluster | tee /var/lib/rancher/k3s/server/manifests/kube-vip.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exit
</span></span></code></pre></div><p>Test vip:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ping 172.17.8.100
</span></span><span style="display:flex;"><span>PING 172.17.8.100 <span style="color:#f92672">(</span>172.17.8.100<span style="color:#f92672">)</span> 56<span style="color:#f92672">(</span>84<span style="color:#f92672">)</span> bytes of data.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 172.17.8.100: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>1.06 ms
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 172.17.8.100: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>0.582 ms
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">64</span> bytes from 172.17.8.100: icmp_seq<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> ttl<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span> time<span style="color:#f92672">=</span>0.773 ms
</span></span></code></pre></div><h3 id="bootstrap-the-other-k3s-nodes">Bootstrap the other k3s nodes</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>k3sup join <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip 172.17.8.102 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-ip 172.17.8.100 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--no-deploy=traefik --no-deploy=servicelb --flannel-iface=enp0s8 --node-ip=172.17.8.102&#34;</span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>k3sup join <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --ip 172.17.8.103 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-channel stable <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-ip 172.17.8.100 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --server-user vagrant <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --sudo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --k3s-extra-args <span style="color:#e6db74">&#34;--no-deploy=traefik --no-deploy=servicelb --flannel-iface=enp0s8 --node-ip=172.17.8.103&#34;</span>
</span></span></code></pre></div><h3 id="what-is-kube-vip">What is kube-vip</h3>
<p>Kubernetes does not offer an implementation of network load-balancers (Services of type LoadBalancer) for bare metal clusters. The implementations of Network LB that Kubernetes does ship with are all glue code that calls out to various IaaS platforms (GCP, AWS, Azure…). If you’re not running on a supported IaaS platform (GCP, AWS, Azure…), LoadBalancers will remain in the &ldquo;pending&rdquo; state indefinitely when created. So I will use kube-vip to solve this problem.</p>
<p>MetalLB is also a popular tool for on-premises Kubernetes networking, however its primary use-case is for advertising service LoadBalancers instead of advertising a stable IP for the control-plane. kube-vip handles both use-cases, and is under active development by its author, Dan.</p>
<h3 id="install-kube-vip-as-network-loadbalancer">Install kube-vip as network LoadBalancer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://kube-vip.io/manifests/controller.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create configmap --namespace kube-system plndr --from-literal cidr-global<span style="color:#f92672">=</span>172.17.8.200/29
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://kube-vip.io/manifests/kube-vip.yaml
</span></span><span style="display:flex;"><span>nano kube-vip.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>kind: Role
</span></span><span style="display:flex;"><span>apiVersion: rbac.authorization.k8s.io/v1
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: vip-role
</span></span><span style="display:flex;"><span>rules:
</span></span><span style="display:flex;"><span>  - apiGroups: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;coordination.k8s.io&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    resources: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;leases&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    verbs: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;get&#34;</span>, <span style="color:#e6db74">&#34;create&#34;</span>, <span style="color:#e6db74">&#34;update&#34;</span>, <span style="color:#e6db74">&#34;list&#34;</span>, <span style="color:#e6db74">&#34;put&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  - apiGroups: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    resources: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;configmaps&#34;</span>, <span style="color:#e6db74">&#34;endpoints&#34;</span>, <span style="color:#e6db74">&#34;services&#34;</span>, <span style="color:#e6db74">&#34;services/status&#34;</span>, <span style="color:#e6db74">&#34;nodes&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    verbs: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;list&#34;</span>,<span style="color:#e6db74">&#34;get&#34;</span>,<span style="color:#e6db74">&#34;watch&#34;</span>, <span style="color:#e6db74">&#34;update&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f kube-vip.yaml -n default
</span></span></code></pre></div><p>Create a test aplication with a LoadBalancer type service.</p>
<pre tabindex="0"><code>kubectl apply -f https://raw.githubusercontent.com/inlets/inlets-operator/master/contrib/nginx-sample-deployment.yaml -n default
kubectl expose deployment nginx-1 --port=80 --type=LoadBalancer -n default
</code></pre><p>As you can see in the logs it creates the the VIP <code>172.17.8.202</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl logs kube-vip-cluster-79f767d56f-jkc7f
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:57:58Z&#34;</span> level<span style="color:#f92672">=</span>info msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Beginning cluster membership, namespace [default], lock name [plunder-lock], id [k8s-node3]&#34;</span>
</span></span><span style="display:flex;"><span>I0414 16:57:58.813913       <span style="color:#ae81ff">1</span> leaderelection.go:242<span style="color:#f92672">]</span> attempting to acquire leader lease  default/plunder-lock...
</span></span><span style="display:flex;"><span>I0414 16:57:58.857158       <span style="color:#ae81ff">1</span> leaderelection.go:252<span style="color:#f92672">]</span> successfully acquired lease default/plunder-lock
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:57:58Z&#34;</span> level<span style="color:#f92672">=</span>info msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Beginning watching Kubernetes configMap [plndr]&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:57:58Z&#34;</span> level<span style="color:#f92672">=</span>debug msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;ConfigMap [plndr] has been Created or modified&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:57:58Z&#34;</span> level<span style="color:#f92672">=</span>debug msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Found 0 services defined in ConfigMap&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:57:58Z&#34;</span> level<span style="color:#f92672">=</span>debug msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;[STARTING] Service Sync&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:57:58Z&#34;</span> level<span style="color:#f92672">=</span>debug msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;[COMPLETE] Service Sync&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>debug msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;ConfigMap [plndr] has been Created or modified&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>debug msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Found 1 services defined in ConfigMap&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>debug msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;[STARTING] Service Sync&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>info msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;New VIP [172.17.8.202] for [nginx-1/7676b532-3004-4d41-9282-90765bc98d40] &#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>info msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Starting kube-vip as a single node cluster&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>info msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;This node is assuming leadership of the cluster&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>info msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Starting TCP Load Balancer for service [172.17.8.202:80]&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>info msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Load Balancer [nginx-1-load-balancer] started&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>info msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Broadcasting ARP update for 172.17.8.202 (08:00:27:93:fe:45) via enp0s8&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>info msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Started Load Balancer and Virtual IP&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>debug msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;[COMPLETE] Service Sync&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>info msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Beginning watching Kubernetes Endpoints for service [nginx-1]&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>debug msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Endpoints for service [nginx-1] have  been Created or modified&#34;</span>
</span></span><span style="display:flex;"><span>time<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2021-04-14T16:59:55Z&#34;</span> level<span style="color:#f92672">=</span>debug msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Load-Balancer updated with [1] backends&#34;</span>
</span></span><span style="display:flex;"><span>-&gt; Address: 10.42.1.2:80 
</span></span></code></pre></div><p>It is working on <code>172.17.8.202</code> but not perfect because it didn&rsquo;t write back to the api server so the service remain in the &ldquo;pending&rdquo; state.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get svc
</span></span><span style="display:flex;"><span>NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>        AGE
</span></span><span style="display:flex;"><span>kubernetes   ClusterIP      10.43.0.1       &lt;none&gt;        443/TCP        83m
</span></span><span style="display:flex;"><span>nginx-1      LoadBalancer   10.43.126.209   &lt;pending&gt;     80:31904/TCP   46m
</span></span></code></pre></div><p>kube-vip is good solution for High-Availability but for a network LoadBalancer you better to use MetalLB.</p>
<h3 id="update-038">Update: 0.3.8</h3>
<p>With kube-vip version 0.3.8 the network LoadBalancer is working:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get svc
</span></span><span style="display:flex;"><span>NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>        AGE
</span></span><span style="display:flex;"><span>kubernetes   ClusterIP      10.43.0.1       &lt;none&gt;        443/TCP        87m
</span></span><span style="display:flex;"><span>nginx-1      LoadBalancer   10.43.126.209   172.17.8.201     80:31904/TCP   42m
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="kube-vip" term="kube-vip" label="kube-vip" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Argo CD Image Updater for automate image update]]></title>
            <link href="https://devopstales.github.io/kubernetes/argocd-image-updater/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/argocd-kubeseal/?utm_source=atom_feed" rel="related" type="text/html" title="ArgoCD and kubeseal to encrypt secrets" />
                <link href="https://devopstales.github.io/kubernetes/k8s-gitops/?utm_source=atom_feed" rel="related" type="text/html" title="GitOps solutions for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes and Vault integration" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/k8s-backup/?utm_source=atom_feed" rel="related" type="text/html" title="Backup your Kubernetes Cluster" />
            
                <id>https://devopstales.github.io/kubernetes/argocd-image-updater/</id>
            
            
            <published>2021-04-11T00:00:00+00:00</published>
            <updated>2021-04-11T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use Argo CD Image Updater to automate image update in Kubernetes.</p>


<H3>Parts of the K8S Gitops series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-gitops/">GitOps solutions for Kubernetes</a></li>
     <li>Part2: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-image-updater/">Argo CD Image Updater for automate image update</a></li>
<!-- ArgoCD notify
https://blog.argoproj.io/notifications-for-argo-bb7338231604
-->
<!----------------------------------------------->
     <li>Part4: <a href="../../kubernetes/gitops-flux2/">Flux2 Install and Usage</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part6: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>
<!-- Flux CD auto image update
https://particule.io/en/blog/flux-auto-image-update/
-->
<!----------------------------------------------->
<!-- Fleet 
Rancher fleet + helm-controller
-->
<!----------------------------------------------->
<!-- Canary Deployment:
Canary Basics - https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments
Canary with helm:
  https://itnext.io/safe-and-automation-friendly-canary-deployments-with-helm-669394d2c48a
  https://github.com/stoehdoi/canary-demo/tree/master/deploy
ArgoCD + Argo Rollouts for canary deploy:
-->
     <li>Part7: <a href="../../kubernetes/flagger-nginx-canary-deployments/">Flagger NGINX Canary Deployments</a></li>
</ul>



<h3 id="what-is-argo-cd-image-updater">What is Argo CD Image Updater</h3>
<p>A tool to automatically update the container images of Kubernetes workloads that are managed by Argo CD.</p>
<h2 id="inatall-argo-cd-image-updater">Inatall Argo CD Image Updater</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>curl --silent <span style="color:#e6db74">&#34;https://api.github.com/repos/argoproj-labs/argocd-image-updater/releases/latest&#34;</span> | grep <span style="color:#e6db74">&#39;&#34;tag_name&#34;&#39;</span> | sed -E <span style="color:#e6db74">&#39;s/.*&#34;([^&#34;]+)&#34;.*/\1/&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://github.com/argoproj-labs/argocd-image-updater/releases/download/$VERSION/argocd-image-updater_<span style="color:#e6db74">&#34;</span>$VERSION<span style="color:#e6db74">&#34;</span>_linux-amd64 -O /usr/local/bin/argocd-image-updater
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">755</span> /usr/local/bin/argocd-image-updater
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>argocd-image-updater version
</span></span></code></pre></div><h3 id="now-install-the-cluster-side-controller">Now install the cluster-side controller</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd /opt
</span></span><span style="display:flex;"><span>git clone https://github.com/argoproj-labs/argocd-image-updater.git
</span></span><span style="display:flex;"><span>cd argocd-image-updater/manifests/
</span></span><span style="display:flex;"><span>kubectl apply -f install.yaml
</span></span></code></pre></div><h3 id="deploy-an-updatable-app">Deploy an updatable app</h3>
<p>In order for Argo CD Image Updater to know which applications it should inspect for updating the workloads&rsquo; container images, the corresponding Kubernetes resource needs to be annotated. or its annotations, Argo CD Image Updater uses the following prefix: <code>argocd-image-updater.argoproj.io</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">argoproj.io/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Application</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">argocd-image-updater.argoproj.io/image-list</span>: <span style="color:#ae81ff">gcr.io/heptio-images/ks-guestbook-demo:^0.1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">guestbook</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">argocd</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">destination</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">guestbook-demo</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">server</span>: <span style="color:#ae81ff">https://kubernetes.default.svc</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">project</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">path</span>: <span style="color:#ae81ff">helm-guestbook</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">repoURL</span>: <span style="color:#ae81ff">https://github.com/argoproj/argocd-example-apps</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetRevision</span>: <span style="color:#ae81ff">HEAD</span>
</span></span></code></pre></div><p>Test the image for update:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>argocd-image-updater test gcr.io/heptio-images/ks-guestbook-demo:0.1
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>0000<span style="color:#f92672">]</span> getting image                                 image_name<span style="color:#f92672">=</span>heptio-images/ks-guestbook-demo registry<span style="color:#f92672">=</span>gcr.io
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>0000<span style="color:#f92672">]</span> Fetching available tags and metadata from registry  image_name<span style="color:#f92672">=</span>heptio-images/ks-guestbook-demo
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>0000<span style="color:#f92672">]</span> Found <span style="color:#ae81ff">2</span> tags in registry                      image_name<span style="color:#f92672">=</span>heptio-images/ks-guestbook-demo
</span></span><span style="display:flex;"><span>DEBU<span style="color:#f92672">[</span>0000<span style="color:#f92672">]</span> found <span style="color:#ae81ff">2</span> from <span style="color:#ae81ff">2</span> tags eligible <span style="color:#66d9ef">for</span> consideration  image<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gcr.io/heptio-images/ks-guestbook-demo:0.1&#34;</span>
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>0000<span style="color:#f92672">]</span> latest image according to constraint is gcr.io/heptio-images/ks-guestbook-demo:0.2
</span></span></code></pre></div><p>Allow update of the image:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">argoproj.io/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Application</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">argocd-image-updater.argoproj.io/image-list</span>: <span style="color:#ae81ff">gcr.io/heptio-images/ks-guestbook-demo</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">argocd-image-updater.argoproj.io/write-back-method</span>: <span style="color:#ae81ff">argocd</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">guestbook</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">argocd</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">destination</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">guestbook-demo</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">server</span>: <span style="color:#ae81ff">https://kubernetes.default.svc</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">project</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">path</span>: <span style="color:#ae81ff">helm-guestbook</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">repoURL</span>: <span style="color:#ae81ff">https://github.com/argoproj/argocd-example-apps</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetRevision</span>: <span style="color:#ae81ff">HEAD</span>
</span></span></code></pre></div><p>The Argo CD Image Updater supports two distinct methods on how to update images of an application:</p>
<ul>
<li>imperative, via Argo CD API</li>
<li>declarative, by pushing changes to a Git repository</li>
</ul>
<p>The write-back method is configured via an annotation on the Application resource:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>argocd-image-updater.argoproj.io/write-back-method: &lt;argocd&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e"># argocd or git</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>argocd-image-updater.argoproj.io/write-back-method: git:secret:argocd-image-updater/git-creds
</span></span><span style="display:flex;"><span><span style="color:#75715e"># add git credentials secret named git-creds</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>argocd-image-updater.argoproj.io/git-branch: HEAD
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Specifying a branch to commit to</span>
</span></span></code></pre></div><p>At the gui you can see that the guestbook app is out of sync and can be updated.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-gitops" term="k8s-gitops" label="k8s-gitops" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="gitops" term="gitops" label="gitops" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[ArgoCD and kubeseal to encrypt secrets]]></title>
            <link href="https://devopstales.github.io/kubernetes/argocd-kubeseal/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-gitops/?utm_source=atom_feed" rel="related" type="text/html" title="GitOps solutions for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vault/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes and Vault integration" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/k8s-backup/?utm_source=atom_feed" rel="related" type="text/html" title="Backup your Kubernetes Cluster" />
                <link href="https://devopstales.github.io/kubernetes/k8s-connaisseur/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification Admission Controller" />
            
                <id>https://devopstales.github.io/kubernetes/argocd-kubeseal/</id>
            
            
            <published>2021-04-10T00:00:00+00:00</published>
            <updated>2021-04-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use kubeseal with ArgoCD to protect secrets.</p>


<H3>Parts of the K8S Gitops series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-gitops/">GitOps solutions for Kubernetes</a></li>
     <li>Part2: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-image-updater/">Argo CD Image Updater for automate image update</a></li>
<!-- ArgoCD notify
https://blog.argoproj.io/notifications-for-argo-bb7338231604
-->
<!----------------------------------------------->
     <li>Part4: <a href="../../kubernetes/gitops-flux2/">Flux2 Install and Usage</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part6: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>
<!-- Flux CD auto image update
https://particule.io/en/blog/flux-auto-image-update/
-->
<!----------------------------------------------->
<!-- Fleet 
Rancher fleet + helm-controller
-->
<!----------------------------------------------->
<!-- Canary Deployment:
Canary Basics - https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments
Canary with helm:
  https://itnext.io/safe-and-automation-friendly-canary-deployments-with-helm-669394d2c48a
  https://github.com/stoehdoi/canary-demo/tree/master/deploy
ArgoCD + Argo Rollouts for canary deploy:
-->
     <li>Part7: <a href="../../kubernetes/flagger-nginx-canary-deployments/">Flagger NGINX Canary Deployments</a></li>
</ul>



<h2 id="install-argocd">Install Argocd</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create namespace argocd
</span></span><span style="display:flex;"><span>kubectl apply -n argocd -f <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># or in ha</span>
</span></span><span style="display:flex;"><span>kubectl apply -n argocd -f <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/ha/install.yaml
</span></span></code></pre></div><h3 id="install-argocd-cli">Install Argocd cli</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>curl --silent <span style="color:#e6db74">&#34;https://api.github.com/repos/argoproj/argo-cd/releases/latest&#34;</span> | grep <span style="color:#e6db74">&#39;&#34;tag_name&#34;&#39;</span> | sed -E <span style="color:#e6db74">&#39;s/.*&#34;([^&#34;]+)&#34;.*/\1/&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -sSL -o /usr/local/bin/argocd https://github.com/argoproj/argo-cd/releases/download/$VERSION/argocd-linux-amd64
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>chmod +x /usr/local/bin/argocd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>argocd version
</span></span></code></pre></div><h3 id="connect-without-ingress">Connect without ingress</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl port-forward svc/argocd-server -n argocd 8080:443
</span></span></code></pre></div><h3 id="create-ingress-for-server">Create ingress for server</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">piVersion</span>: <span style="color:#ae81ff">extensions/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">argocd-server-http-ingress</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">argocd</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes.io/ingress.class</span>: <span style="color:#e6db74">&#34;nginx&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nginx.ingress.kubernetes.io/force-ssl-redirect</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nginx.ingress.kubernetes.io/backend-protocol</span>: <span style="color:#e6db74">&#34;HTTPS&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cert-manager.io/cluster-issuer</span>: <span style="color:#ae81ff">ca-issuer</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">serviceName</span>: <span style="color:#ae81ff">argocd-server</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">servicePort</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">host</span>: <span style="color:#ae81ff">argocd.k8s.intra</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">argocd.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">https-argocd-secret</span> <span style="color:#75715e"># do not change, this is provided by Argo CD</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">extensions/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">argocd-server-grpc-ingress</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">argocd</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes.io/ingress.class</span>: <span style="color:#e6db74">&#34;nginx&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">nginx.ingress.kubernetes.io/backend-protocol</span>: <span style="color:#e6db74">&#34;GRPC&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">serviceName</span>: <span style="color:#ae81ff">argocd-server</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">servicePort</span>: <span style="color:#ae81ff">https</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">host</span>: <span style="color:#ae81ff">grpc-argocd.k8s.intra</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">grpc-argocd.k8s.intra</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">argocd-secret</span> <span style="color:#75715e"># do not change, this is provided by Argo CD</span>
</span></span></code></pre></div><h3 id="get-init-password">Get init password</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.data.password}&#34;</span> | base64 -d <span style="color:#f92672">&amp;&amp;</span> echo
</span></span><span style="display:flex;"><span>jMnyrjcdocMoqPfC
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>argocd login argocd.k8s.intra
</span></span><span style="display:flex;"><span>WARNING: server certificate had error: x509: certificate signed by unknown authority. Proceed insecurely <span style="color:#f92672">(</span>y/n<span style="color:#f92672">)</span>? y
</span></span><span style="display:flex;"><span>WARN<span style="color:#f92672">[</span>0002<span style="color:#f92672">]</span> Failed to invoke grpc call. Use flag --grpc-web in grpc calls. To avoid this warning message, use flag --grpc-web. 
</span></span><span style="display:flex;"><span>Username: admin
</span></span><span style="display:flex;"><span>Password: 
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;admin:login&#39;</span> logged in successfully
</span></span><span style="display:flex;"><span>Context <span style="color:#e6db74">&#39;argocd.k8s.intra&#39;</span> updated
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>argocd account update-password
</span></span></code></pre></div><h3 id="register-new-cluster">Register new cluster</h3>
<p>By default Argocd register the cluster where running with a cluster admin service account. You can register different clusters with its kubectl configs. So you can create multiple service accounts with multiple privileges  and register them with its kubectl configs.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectx
</span></span><span style="display:flex;"><span>default
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ argocd cluster add default
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>0000<span style="color:#f92672">]</span> ServiceAccount <span style="color:#e6db74">&#34;argocd-manager&#34;</span> already exists in namespace <span style="color:#e6db74">&#34;kube-system&#34;</span> 
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>0000<span style="color:#f92672">]</span> ClusterRole <span style="color:#e6db74">&#34;argocd-manager-role&#34;</span> updated    
</span></span><span style="display:flex;"><span>INFO<span style="color:#f92672">[</span>0000<span style="color:#f92672">]</span> ClusterRoleBinding <span style="color:#e6db74">&#34;argocd-manager-role-binding&#34;</span> updated 
</span></span><span style="display:flex;"><span>WARN<span style="color:#f92672">[</span>0000<span style="color:#f92672">]</span> Failed to invoke grpc call. Use flag --grpc-web in grpc calls. To avoid this warning message, use flag --grpc-web. 
</span></span><span style="display:flex;"><span>Cluster <span style="color:#e6db74">&#39;https://172.17.9.10:6443&#39;</span> added
</span></span></code></pre></div><h3 id="deploy-app-with-argocd">Deploy app with Argocd</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl create ns guestbook-demo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ argocd app create 00-tools --repo https://github.com/devopstales/gitops-repo.git <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--path 00_argocd/00_tools --dest-server https://kubernetes.default.svc --dest-namespace default
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ argocd app create 01-guestbook --repo https://github.com/devopstales/gitops-repo.git <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--path 00_argocd/01_guestbook --dest-server https://kubernetes.default.svc --dest-namespace guestbook-demo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ argocd app get 01-guestbook
</span></span><span style="display:flex;"><span>Name:               01-guestbook
</span></span><span style="display:flex;"><span>Project:            default
</span></span><span style="display:flex;"><span>Server:             https://kubernetes.default.svc
</span></span><span style="display:flex;"><span>Namespace:          guestbook-demo
</span></span><span style="display:flex;"><span>URL:                https://argocd.k8s.intra/applications/01-guestbook
</span></span><span style="display:flex;"><span>Repo:               https://github.com/devopstales/gitops-repo.git
</span></span><span style="display:flex;"><span>Target:             
</span></span><span style="display:flex;"><span>Path:               00_argocd/01_guestbook
</span></span><span style="display:flex;"><span>SyncWindow:         Sync Allowed
</span></span><span style="display:flex;"><span>Sync Policy:        &lt;none&gt;
</span></span><span style="display:flex;"><span>Sync Status:        OutOfSync from  <span style="color:#f92672">(</span>e8df0a5<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Health Status:      Missing
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>GROUP                      KIND         NAMESPACE       NAME                            STATUS     HEALTH   HOOK  MESSAGE
</span></span><span style="display:flex;"><span>                           Service      guestbook-demo  guestbook-ui                    OutOfSync  Missing        
</span></span><span style="display:flex;"><span>apps                       Deployment   guestbook-demo  guestbook-ui                    OutOfSync  Missing        
</span></span><span style="display:flex;"><span>rbac.authorization.k8s.io  RoleBinding  guestbook-demo  psp-rolebinding-guestbook-demo  OutOfSync  Missing   
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ argocd app sync 01-guestbook
</span></span></code></pre></div><h2 id="install-kubeseal">Install kubeseal</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>curl --silent <span style="color:#e6db74">&#34;https://api.github.com/repos/bitnami-labs/sealed-secrets/releases/latest&#34;</span> | grep <span style="color:#e6db74">&#39;&#34;tag_name&#34;&#39;</span> | sed -E <span style="color:#e6db74">&#39;s/.*&#34;([^&#34;]+)&#34;.*/\1/&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://github.com/bitnami-labs/sealed-secrets/releases/download/$VERSION/kubeseal-linux-amd64 -O /usr/local/bin/kubeseal
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">755</span> /usr/local/bin/kubeseal
</span></span><span style="display:flex;"><span>kubeseal --version
</span></span></code></pre></div><h3 id="now-install-the-cluster-side-controller">Now install the cluster-side controller</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/$VERSION/controller.yaml
</span></span></code></pre></div><h3 id="create-a-sealed-secret">Create a sealed secret</h3>
<p>Create a secret you want to encrypt:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">secret</span>: <span style="color:#ae81ff">UzNDUjNUCg==</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysecret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">demo-app</span>
</span></span></code></pre></div><p>A secret in Kubernetes cluster is encoded in base64 but not encrypted! Theses data are &ldquo;only&rdquo; encoded so if a user have access to your secrets, he can simply base64 decode to see your sensitive data:</p>
<pre tabindex="0"><code class="language-base" data-lang="base">echo &#34;UzNDUjNUCg==&#34; | base64 -d
S3CR3T
</code></pre><p>Since the secrets aren&rsquo;t encrypted, it is unsecure to commit them to your Git repository.</p>
<h3 id="use-kubeseal-to-encrypt-the-secret">Use kubeseal to Encrypt the secret</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubeseal --format yaml &lt;secret.yaml &gt;sealedsecret.yaml</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cat sealedsecret.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">bitnami.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">SealedSecret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysecret</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">demo-app</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">encryptedData</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secret</span>: <span style="color:#ae81ff">AgCZl5b75Lmr8z7Ppa5tNBPX4zWH2vset0GVKhNfTBRnAANDs9Gycrq5EfueE00PGX++v4VFKEwi9rNeAAvFkETges31Uhi4+Oym9CkV9rU2pHAvD4iZapt+fHSndMUY8vWT8GCYzrzSOFSRPKB4cdAy3JJ4f48SwxCFYXdJgl/6KiHkrk2AzxHKip3ryVjKY01E8cSpxw1Exv8RnEDD8D9hfb57fEIRRwMrIRUkg/jPOvf4YCHcjHiVLLP+MwutT1Jd65hjAx1WZFSjDRUj3rFfzsO6zAVxgx20WXtc3qMK9jMeeQaNbbAvdv3YuNsuxJIE8SFQFPfGop+QFefiyDGWTjzwHkeU65Ci1Nuj8pSS600ITyGdyNY4F3qjen1eBnMOaub5ZJqEmXyTQwSL/9R7UfoFqJCo4b36g2axacegqHtLL+U4wrHsDB9iQ/JrEAWj4l7s5bhOJbq0N8zLwZvEGXSoPs/4eBUxCuHayOCz6o8BY8Zsv1tDgQ+AXpvudXfzw02zH/DCr7Jg2CVXB8Qk2SUnC5rMzsvqcsYnHP25pxGh9qd3p8QXIjb+AttJUFkPGHlc/rY6sY4QJ6Qjlfv8VXArwrmnfkcZSfLDwyUOGcqZiho3+vGC4mjDcFgbEDbD3Emv/2jHimFBOv2eq9dMqvmZuzk4M4KCLYHqFuX+L/XM+mAnAxlCRrv6q6Hup26HuI84Hn2N</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">creationTimestamp</span>: <span style="color:#66d9ef">null</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysecret</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">demo-app</span>
</span></span></code></pre></div><p><code>sealedsecret.yaml</code> is the file you need to store in git.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>argocd app create 02-secret --repo https://github.com/devopstales/gitops-repo.git <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--path 00_argocd/02_secret --dest-server https://kubernetes.default.svc --dest-namespace demo-app
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl logs -n demo-app demo-app
</span></span><span style="display:flex;"><span>S3CR3T
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-gitops" term="k8s-gitops" label="k8s-gitops" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="gitops" term="gitops" label="gitops" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[GitOps solutions for Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-gitops/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-vault/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes and Vault integration" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/k8s-backup/?utm_source=atom_feed" rel="related" type="text/html" title="Backup your Kubernetes Cluster" />
                <link href="https://devopstales.github.io/kubernetes/k8s-connaisseur/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-imagepullsecret-patcher/?utm_source=atom_feed" rel="related" type="text/html" title="How to use imagePullSecrets cluster-wide??" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-gitops/</id>
            
            
            <published>2021-04-09T00:00:00+00:00</published>
            <updated>2021-04-09T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will compare the GitOps tools for Kubernetes.</p>


<H3>Parts of the K8S Gitops series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-gitops/">GitOps solutions for Kubernetes</a></li>
     <li>Part2: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-image-updater/">Argo CD Image Updater for automate image update</a></li>
<!-- ArgoCD notify
https://blog.argoproj.io/notifications-for-argo-bb7338231604
-->
<!----------------------------------------------->
     <li>Part4: <a href="../../kubernetes/gitops-flux2/">Flux2 Install and Usage</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part6: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>
<!-- Flux CD auto image update
https://particule.io/en/blog/flux-auto-image-update/
-->
<!----------------------------------------------->
<!-- Fleet 
Rancher fleet + helm-controller
-->
<!----------------------------------------------->
<!-- Canary Deployment:
Canary Basics - https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments
Canary with helm:
  https://itnext.io/safe-and-automation-friendly-canary-deployments-with-helm-669394d2c48a
  https://github.com/stoehdoi/canary-demo/tree/master/deploy
ArgoCD + Argo Rollouts for canary deploy:
-->
     <li>Part7: <a href="../../kubernetes/flagger-nginx-canary-deployments/">Flagger NGINX Canary Deployments</a></li>
</ul>



<h2 id="what-is-gitops">What is gitops?</h2>
<p>GitOps is a way to manage the state of systems, through definitions of the desired state stored in files in a version control system usually Git. With git versioning you can manage your workflow more sourly. If something gos wrong you can rollback easily. There is multiple tools for GitOps in Kubernetes:</p>
<ul>
<li>Argo CD</li>
<li>Flux CD</li>
<li>Racher Fleet</li>
</ul>
<h2 id="fluxcd">FluxCD</h2>
<p>Flux is described as a GitOps operator for Kubernetes that synchronises the state of manifests in a Git repository to what is running in a cluster. It can watch one single remote repository per installation and it will be able to apply changes only in the namespaces in which its underlying service account has permissions to change.</p>
<h3 id="fluxcd-installation">FluxCD Installation</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>flux bootstrap git <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --url<span style="color:#f92672">=</span>ssh://git@&lt;host&gt;/&lt;org&gt;/&lt;repository&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --branch<span style="color:#f92672">=</span>&lt;my-branch&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --path<span style="color:#f92672">=</span>clusters/my-cluster
</span></span></code></pre></div><h3 id="fluxcd-conclusion">FluxCD Conclusion</h3>
<p>Advantages:</p>
<ul>
<li>More security with the namespace based separation</li>
<li>There is a built-in solution for secret management.</li>
<li>flagger for canary deployment</li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>Need to run multiple instance for different namespace control</li>
<li>There is no User interface</li>
</ul>
<h2 id="argocd">ArgoCD</h2>
<p>The basic principles of ArgoCD similar then FluxCD however, what makes it different is the capability to manage multi-tenant and multi-cluster deployments. It can use multiple git repository as source and can control multiple namespace or Kubernetes Cluster.</p>
<h3 id="argocd-installation">ArgoCD Installation</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create namespace argocd
</span></span><span style="display:flex;"><span>kubectl apply -n argocd -f <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
</span></span></code></pre></div><h3 id="argocd-conclusion">ArgoCD Conclusion</h3>
<p>Advantages:</p>
<ul>
<li>It has a nice modern web UI</li>
<li>It can manage multiple source repository and destination namespace or Kubernetes Cluster.</li>
<li>Multiple types of identity providers are supported (OIDC, SAML, LDAP. etc&hellip;)</li>
<li>Configuration drift detection</li>
<li>Argo Rollouts for canary deployment</li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>There is no built-in solution for secret management</li>
</ul>
<h2 id="fleet">Fleet</h2>
<p>Fleet is GitOps at scale. Fleet is designed to manage up to a million clusters. It&rsquo;s also lightweight enough that is works great for a single cluster too, but it really shines when you get to a large scale</p>
<h3 id="fleet-installation">Fleet Installation</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm -n fleet-system install --create-namespace --wait <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    fleet-crd https://github.com/rancher/fleet/releases/download/v0.3.3/fleet-crd-0.3.3.tgz
</span></span><span style="display:flex;"><span>helm -n fleet-system install --create-namespace --wait <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    fleet https://github.com/rancher/fleet/releases/download/v0.3.3/fleet-0.3.3.tgz
</span></span></code></pre></div><h3 id="fleet-conclusion">Fleet Conclusion</h3>
<p>Advantages:</p>
<ul>
<li>Fleet is designed to manage many many clusters</li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>There is no built-in solution for secret management</li>
<li>There is no User interface</li>
<li>There is no built-in solution for canary deployment</li>
</ul>
<hr>
<ul>
<li><a href="https://rancher.com/tags/gitops">https://rancher.com/tags/gitops</a></li>
<li><a href="https://www.youtube.com/watch?v=8pbdXAd-F44">https://www.youtube.com/watch?v=8pbdXAd-F44</a></li>
</ul>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-gitops" term="k8s-gitops" label="k8s-gitops" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="gitops" term="gitops" label="gitops" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes and Vault integration]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-vault/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller V2" />
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
                <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 The Secure Kubernetes Engine" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-vault/</id>
            
            
            <published>2021-04-07T00:00:00+00:00</published>
            <updated>2021-04-07T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can integrate HashiCorp Vault to Kubernetes easily thanks to <a href="https://banzaicloud.com/products/bank-vaults/">Bank-Vaults</a> made by Banzaicloud.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>In a <a href="https://devopstales.github.io/cloud/k8s-security/">previous post</a> I talked about how Kubernetes cluster store the Kubernetes Secrets in the etcd as base64 encoded text and not encrypted. This is the reason why using an external secret store should be a good idea.</p>
<h3 id="what-is-bank-vaults">What is Bank-Vaults</h3>
<p>Bank-Vaults provides various tools for Hashicorp Vault to make its use easier. It is a wrapper for the official Vault client with automatic token renewal, built in Kubernetes support, and a dynamic database credential provider.</p>
<h3 id="vhat-is-hashicorp-vault">Vhat is Hashicorp Vault</h3>
<p>HashiCorp Vault is a secrets management solution that brokers access for both humans and machines, through programmatic access, to systems. Secrets can be stored, dynamically generated, and in the case of encryption, keys can be consumed as a service without the need to expose the underlying key materials.</p>
<p><img src="/img/include/vault01.png" alt="Example image"  class="zoomable" /></p>
<h3 id="install-bank-vaults-operator">Install Bank-Vaults Operator</h3>
<p>Ther is a Kubernetes Helm chart to deploy the Banzai Cloud Vault Operator. We will use this for deploy the HashiCorp Vault in HA mode with etcd as storage backend. As a dependency the chart installs an etcd operator that runs as root so we need to use <a href="https://devopstales.github.io/home/rke2-pod-security-policy/">my predifinde PSP</a> to allow this.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vault</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">psp-rolebinding-vault</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">vault</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">system-unrestricted-psp-role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">system:serviceaccounts</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.cattle.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmChart</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vault-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">vault</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repo</span>: <span style="color:#e6db74">&#34;https://kubernetes-charts.banzaicloud.com&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">chart</span>: <span style="color:#ae81ff">vault-operator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetNamespace</span>: <span style="color:#ae81ff">vault</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">valuesContent</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    etcd-operator:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      enabled: &#34;true&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      etcdOperator:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        commandArgs:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          cluster-wide: &#34;true&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    psp:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      vaultSA: &#34;vault&#34;</span>
</span></span></code></pre></div><p>When the operator runs correctly we can deploy the CRD to create teh Vault cluster</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#e6db74">&#34;vault.banzaicloud.com/v1alpha1&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#e6db74">&#34;Vault&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;vault&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">size</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">image</span>: <span style="color:#ae81ff">vault:1.6.2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Specify the ServiceAccount where the Vault Pod and the Bank-Vaults configurer/unsealer is running</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">serviceAccount</span>: <span style="color:#ae81ff">vault</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Specify how many nodes you would like to have in your etcd cluster</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># NOTE: -1 disables automatic etcd provisioning</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">etcdSize</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#resources:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># vault:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#    requests:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#      memory: &#34;256Mi&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#      cpu: &#34;100m&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#    limits:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#      memory: &#34;512Mi&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#      cpu: &#34;250m&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">etcdPVCSpec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">accessModes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">ReadWriteOnce</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">1Gi</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">etcdAnnotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">etcd.database.coreos.com/scope</span>: <span style="color:#ae81ff">clusterwide</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">etcdVersion</span>: <span style="color:#e6db74">&#34;3.3.17&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Support for distributing the generated CA certificate Secret to other namespaces.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Define a list of namespaces or use [&#34;*&#34;] for all namespaces.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">caNamespaces</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;demo-app&#34;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#34;default&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># Describe where you would like to store the Vault unseal keys and root token.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">unsealConfig</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">secretNamespace</span>: <span style="color:#ae81ff">vault</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># A YAML representation of a final vault config file.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># See https://www.vaultproject.io/docs/configuration/ for more information.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">etcd</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">address</span>: <span style="color:#ae81ff">https://etcd-cluster:2379</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ha_enabled</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">etcd_api</span>: <span style="color:#e6db74">&#34;v3&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">listener</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">tcp</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">address</span>: <span style="color:#e6db74">&#34;0.0.0.0:8200&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">tls_cert_file</span>: <span style="color:#ae81ff">/vault/tls/server.crt</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">tls_key_file</span>: <span style="color:#ae81ff">/vault/tls/server.key</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">api_addr</span>: <span style="color:#ae81ff">https://vault.vault:8200</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">telemetry</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">statsd_address</span>: <span style="color:#ae81ff">localhost:9125</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ui</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">externalConfig</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">policies</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">allow_secrets</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">rules</span>: <span style="color:#ae81ff">path &#34;secret/*&#34; {</span>
</span></span><span style="display:flex;"><span>                 <span style="color:#ae81ff">capabilities = [&#34;create&#34;, &#34;read&#34;, &#34;update&#34;, &#34;delete&#34;, &#34;list&#34;]</span>
</span></span><span style="display:flex;"><span>               }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># The auth block allows configuring Auth Methods in Vault.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># See https://www.vaultproject.io/docs/auth/index.html for more information.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">auth</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">type</span>: <span style="color:#ae81ff">kubernetes</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">roles</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#75715e"># Allow every pod in the default namespace to use the secret kv store</span>
</span></span><span style="display:flex;"><span>          - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">bound_service_account_names</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">bound_service_account_namespaces</span>: <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">policies</span>: <span style="color:#ae81ff">allow_secrets</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">ttl</span>: <span style="color:#ae81ff">1h</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secrets</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">path</span>: <span style="color:#ae81ff">secret</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">type</span>: <span style="color:#ae81ff">kv</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">description</span>: <span style="color:#ae81ff">General secrets</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">options</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">version</span>: <span style="color:#ae81ff">2</span>
</span></span></code></pre></div><h3 id="deploy-the-mutating-webhook">Deploy the mutating webhook</h3>
<p>Banzaicloud created a mutating webhook to automate the injection of the secrets from Vault.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.cattle.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmChart</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">vault-secrets-webhook</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">vault</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repo</span>: <span style="color:#e6db74">&#34;https://kubernetes-charts.banzaicloud.com&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">chart</span>: <span style="color:#ae81ff">vault-secrets-webhook</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetNamespace</span>: <span style="color:#ae81ff">vault</span>
</span></span></code></pre></div><h3 id="install-vault-cli-and-create-secret">Install vault cli and create secret</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo yum install -y yum-utils
</span></span><span style="display:flex;"><span><span style="color:#75715e"># OR</span>
</span></span><span style="display:flex;"><span>sudo dnf install -y dnf-plugins-core
</span></span><span style="display:flex;"><span>sudo dnf config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo 
</span></span><span style="display:flex;"><span>yum install -y vault
</span></span></code></pre></div><p>Configure the client to connect to the server:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>export VAULT_TOKEN<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>kubectl get secrets vault-unseal-keys -o jsonpath<span style="color:#f92672">={</span>.data.vault-root<span style="color:#f92672">}</span> | base64 --decode<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>kubectl get secret vault-tls -o jsonpath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;{.data.ca\.crt}&#34;</span> | base64 --decode &gt; $PWD/vault-ca.crt
</span></span><span style="display:flex;"><span>export VAULT_CACERT<span style="color:#f92672">=</span>$PWD/vault-ca.crt
</span></span><span style="display:flex;"><span>export VAULT_ADDR<span style="color:#f92672">=</span>https://127.0.0.1:8200
</span></span><span style="display:flex;"><span>kubectl port-forward service/vault <span style="color:#ae81ff">8200</span> &amp;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vault kv put secret/accounts/aws AWS_SECRET_ACCESS_KEY<span style="color:#f92672">=</span>s3cr3t
</span></span></code></pre></div><p>Now we start a container in the <code>demo-app</code> namespace and we us the <code>AWS_SECRET_ACCESS_KEY</code> variable from a secret stored in Vault.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano 05_demo.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>kind: Namespace
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: demo-app
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: apps/v1
</span></span><span style="display:flex;"><span>kind: Deployment
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: hello-secrets
</span></span><span style="display:flex;"><span>  namespace: demo-app
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  replicas: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  selector:
</span></span><span style="display:flex;"><span>    matchLabels:
</span></span><span style="display:flex;"><span>      app: hello-secrets
</span></span><span style="display:flex;"><span>  template:
</span></span><span style="display:flex;"><span>    metadata:
</span></span><span style="display:flex;"><span>      labels:
</span></span><span style="display:flex;"><span>        app: hello-secrets
</span></span><span style="display:flex;"><span>      annotations:
</span></span><span style="display:flex;"><span>        vault.security.banzaicloud.io/vault-addr: <span style="color:#e6db74">&#34;https://vault.vault:8200&#34;</span>
</span></span><span style="display:flex;"><span>        vault.security.banzaicloud.io/vault-tls-secret: <span style="color:#e6db74">&#34;vault-tls&#34;</span>
</span></span><span style="display:flex;"><span>    spec:
</span></span><span style="display:flex;"><span>      serviceAccountName: default
</span></span><span style="display:flex;"><span>      containers:
</span></span><span style="display:flex;"><span>      - name: nginx
</span></span><span style="display:flex;"><span>        image: nginxinc/nginx-unprivileged
</span></span><span style="display:flex;"><span>        command: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;sh&#34;</span>, <span style="color:#e6db74">&#34;-c&#34;</span>, <span style="color:#e6db74">&#34;echo </span>$AWS_SECRET_ACCESS_KEY<span style="color:#e6db74"> &amp;&amp; echo going to sleep... &amp;&amp; sleep 10000&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>        env:
</span></span><span style="display:flex;"><span>        - name: AWS_SECRET_ACCESS_KEY
</span></span><span style="display:flex;"><span>          value: <span style="color:#e6db74">&#34;vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY&#34;</span>
</span></span></code></pre></div><pre tabindex="0"><code>kubectl apply -f 05_demo.yaml
kubectl logs hello-secrets-676b67c659-fvk9d -n demo-app
time=&#34;2021-04-05T08:45:11Z&#34; level=info msg=&#34;received new Vault token&#34; app=vault-env
time=&#34;2021-04-05T08:45:11Z&#34; level=info msg=&#34;initial Vault token arrived&#34; app=vault-env
time=&#34;2021-04-05T08:45:11Z&#34; level=info msg=&#34;spawning process: [sh -c echo $AWS_SECRET_ACCESS_KEY &amp;&amp; echo going to sleep... &amp;&amp; sleep 10000]&#34; app=vault-env
time=&#34;2021-04-05T08:45:11Z&#34; level=info msg=&#34;renewed Vault token&#34; app=vault-env ttl=1h0m0s
s3cr3t
going to sleep...
</code></pre><hr>
<ul>
<li><a href="https://banzaicloud.com/blog/kubernetes-oidc/">https://banzaicloud.com/blog/kubernetes-oidc/</a></li>
</ul>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="operator" term="operator" label="Operator" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="rke2" term="rke2" label="rke2" />
                             
                                <category scheme="rancher" term="rancher" label="rancher" />
                             
                                <category scheme="mutating-webhook" term="mutating-webhook" label="mutating webhook" />
                             
                                <category scheme="hashicorp-vault" term="hashicorp-vault" label="HashiCorp Vault" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[RKE2 Image security Admission Controller V2]]></title>
            <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
                <link href="https://devopstales.github.io/kubernetes/admission-controllers/?utm_source=atom_feed" rel="related" type="text/html" title="Using Admission Controllers" />
                <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 The Secure Kubernetes Engine" />
            
                <id>https://devopstales.github.io/kubernetes/image-security-admission-controller-v2/</id>
            
            
            <published>2021-03-31T00:00:00+00:00</published>
            <updated>2021-03-31T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In a previous post we talked about <a href="https://devopstales.github.io/home/image-security-admission-controller/">anchore-image-validator made by Banzaicloud</a>. In this post I will show you how I updated that scenario for a real word solution.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>I found multiple solution for Anchore Engine so the first step is to deploy with its helm chart. In RKE2 I will use Rancher&rsquo;s <a href="https://devopstales.github.io/cloud/k3s-helm-controller/">Helm controller</a> what is preinstalled.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">securty-system</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.cattle.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmChart</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-enginn</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repo</span>: <span style="color:#e6db74">&#34;https://charts.anchore.io&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">chart</span>: <span style="color:#ae81ff">anchore-engine</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetNamespace</span>: <span style="color:#ae81ff">securty-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">valuesContent</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    postgresql:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      image: centos/postgresql-96-centos7
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      extraEnv:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - name: POSTGRESQL_USER
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        value: anchoreengine
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - name: POSTGRESQL_PASSWORD
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        value: Password1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - name: POSTGRESQL_DATABASE
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        value: anchore
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - name: PGUSER
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        value: postgres
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      postgresPassword: Password1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      persistence:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        size: 10Gi
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    anchoreGlobal:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      defaultAdminPassword: Password1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      defaultAdminEmail: devopstales@mydomain.intra</span>
</span></span></code></pre></div><p>Then we can Deploy an Admission Controller to us this tool to automaticle scann any image deploy in the cluster and reject if is vulnerable. As I sad before there is multiple solution for this. In the previous pos I used  Banzaicloud&rsquo;s anchore-image-validator but it turned out Anchore&rsquo;s own Admission Controller is more controllable. It allows to use different policies based on tag or annotations.</p>
<p>Create a secret for the anchore credentials that the controller will use to make api calls to Anchore.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano credentials.json</span>
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;users&#34;: </span>[
</span></span><span style="display:flex;"><span>    { <span style="color:#f92672">&#34;username&#34;: &#34;admin&#34;, &#34;password&#34;: </span><span style="color:#e6db74">&#34;Password1&#34;</span>}
</span></span><span style="display:flex;"><span>  ]
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl create secret generic anchore-credentials --from-file=credentials.json</span>
</span></span></code></pre></div><p>Create a job that automaticle upload policies to anchore engin:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-policys</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">production_bundle.json</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;blacklisted_images&#34;: [], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;comment&#34;: &#34;Production bundle&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;id&#34;: &#34;production_bundle&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;mappings&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;id&#34;: &#34;c4f9bf74-dc38-4ddf-b5cf-00e9c0074611&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;image&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    &#34;type&#34;: &#34;tag&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    &#34;value&#34;: &#34;*&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                }, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;name&#34;: &#34;default&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;policy_id&#34;: &#34;48e6f7d6-1765-11e8-b5f9-8b6f228548b6&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;registry&#34;: &#34;*&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;repository&#34;: &#34;*&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;whitelist_ids&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    &#34;37fd763e-1765-11e8-add4-3b16c029ac5c&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                ]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;name&#34;: &#34;production bundle&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;policies&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;comment&#34;: &#34;System default policy&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;id&#34;: &#34;48e6f7d6-1765-11e8-b5f9-8b6f228548b6&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;name&#34;: &#34;DefaultPolicy&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;rules&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;action&#34;: &#34;STOP&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;gate&#34;: &#34;dockerfile&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;id&#34;: &#34;312d9e41-1c05-4e2f-ad89-b7d34b0855bb&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;params&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;name&#34;: &#34;instruction&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;value&#34;: &#34;HEALTHCHECK&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            }, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;name&#34;: &#34;check&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;value&#34;: &#34;not_exists&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        ], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;trigger&#34;: &#34;instruction&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    }, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;action&#34;: &#34;STOP&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;gate&#34;: &#34;vulnerabilities&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;id&#34;: &#34;b30e8abc-444f-45b1-8a37-55be1b8c8bb5&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;params&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;name&#34;: &#34;package_type&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;value&#34;: &#34;all&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            }, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;name&#34;: &#34;severity_comparison&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;value&#34;: &#34;&gt;=&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            }, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;name&#34;: &#34;severity&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;value&#34;: &#34;high&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        ], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;trigger&#34;: &#34;package&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                ], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;version&#34;: &#34;1_0&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;version&#34;: &#34;1_0&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;whitelisted_images&#34;: [], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;whitelists&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;comment&#34;: &#34;Default global whitelist&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;id&#34;: &#34;37fd763e-1765-11e8-add4-3b16c029ac5c&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;items&#34;: [], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;name&#34;: &#34;Global Whitelist&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;version&#34;: &#34;1_0&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">testing_bundle.json</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;blacklisted_images&#34;: [], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;comment&#34;: &#34;testing bundle&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;id&#34;: &#34;testing_bundle&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;mappings&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;id&#34;: &#34;c4f9bf74-dc38-4ddf-b5cf-00e9c0074611&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;image&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    &#34;type&#34;: &#34;tag&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    &#34;value&#34;: &#34;*&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                }, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;name&#34;: &#34;default&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;policy_id&#34;: &#34;48e6f7d6-1765-11e8-b5f9-8b6f228548b6&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;registry&#34;: &#34;*&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;repository&#34;: &#34;*&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;whitelist_ids&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    &#34;37fd763e-1765-11e8-add4-3b16c029ac5c&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                ]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;name&#34;: &#34;Testing bundle&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;policies&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;comment&#34;: &#34;System default policy&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;id&#34;: &#34;48e6f7d6-1765-11e8-b5f9-8b6f228548b6&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;name&#34;: &#34;DefaultPolicy&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;rules&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;action&#34;: &#34;WARN&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;gate&#34;: &#34;dockerfile&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;id&#34;: &#34;312d9e41-1c05-4e2f-ad89-b7d34b0855bb&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;params&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;name&#34;: &#34;instruction&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;value&#34;: &#34;HEALTHCHECK&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            }, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;name&#34;: &#34;check&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;value&#34;: &#34;not_exists&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        ], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;trigger&#34;: &#34;instruction&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    }, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;action&#34;: &#34;STOP&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;gate&#34;: &#34;vulnerabilities&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;id&#34;: &#34;b30e8abc-444f-45b1-8a37-55be1b8c8bb5&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;params&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;name&#34;: &#34;package_type&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;value&#34;: &#34;all&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            }, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;name&#34;: &#34;severity_comparison&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;value&#34;: &#34;&gt;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            }, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;name&#34;: &#34;severity&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                                &#34;value&#34;: &#34;high&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        ], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        &#34;trigger&#34;: &#34;package&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                ], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;version&#34;: &#34;1_0&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;version&#34;: &#34;1_0&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;whitelisted_images&#34;: [], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;whitelists&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;comment&#34;: &#34;Default global whitelist&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;id&#34;: &#34;37fd763e-1765-11e8-add4-3b16c029ac5c&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;items&#34;: [], 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;name&#34;: &#34;Global Whitelist&#34;, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                &#34;version&#34;: &#34;1_0&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">allow-all.json</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;blacklisted_images&#34;: [],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;comment&#34;: &#34;Allow all images and warn if vulnerabilities are found&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;id&#34;: &#34;allow_all_and_warn&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;mappings&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;id&#34;: &#34;5fec9738-59e3-4c4c-9e74-281cbbe0337e&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;image&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  &#34;type&#34;: &#34;tag&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  &#34;value&#34;: &#34;*&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;name&#34;: &#34;allow_all&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;policy_id&#34;: &#34;6472311c-e343-4d7f-9949-c258e3a5191e&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;registry&#34;: &#34;*&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;repository&#34;: &#34;*&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;whitelist_ids&#34;: []
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      ],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;name&#34;: &#34;Allow all and warn bundle&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;policies&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;comment&#34;: &#34;Allow all policy&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;id&#34;: &#34;6472311c-e343-4d7f-9949-c258e3a5191e&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;name&#34;: &#34;AllowAll&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;rules&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;action&#34;: &#34;WARN&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;gate&#34;: &#34;dockerfile&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;id&#34;: &#34;bf8922ba-1f4e-4c4b-9057-165aa5f84b31&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;params&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;name&#34;: &#34;ports&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;value&#34;: &#34;22&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;name&#34;: &#34;type&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;value&#34;: &#34;blacklist&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      ],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;trigger&#34;: &#34;exposed_ports&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;action&#34;: &#34;WARN&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;gate&#34;: &#34;dockerfile&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;id&#34;: &#34;c44c6e6d-6d3f-4f20-971f-f5283b840e8f&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;params&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;name&#34;: &#34;instruction&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;value&#34;: &#34;HEALTHCHECK&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;name&#34;: &#34;check&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;value&#34;: &#34;not_exists&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      ],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;trigger&#34;: &#34;instruction&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;action&#34;: &#34;WARN&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;gate&#34;: &#34;vulnerabilities&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;id&#34;: &#34;6e04f5d8-27f7-47b9-b30a-de98fdf83d85&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;params&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;name&#34;: &#34;max_days_since_sync&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;value&#34;: &#34;2&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      ],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;trigger&#34;: &#34;stale_feed_data&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;action&#34;: &#34;WARN&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;gate&#34;: &#34;vulnerabilities&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;id&#34;: &#34;8494170c-5c3e-4a59-830b-367f2a8e1633&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;params&#34;: [],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;trigger&#34;: &#34;vulnerability_data_unavailable&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;action&#34;: &#34;WARN&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;gate&#34;: &#34;vulnerabilities&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;id&#34;: &#34;f3a89c1c-2363-4b6f-a05d-e784496ddb6f&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;params&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;name&#34;: &#34;package_type&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;value&#34;: &#34;all&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;name&#34;: &#34;severity_comparison&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;value&#34;: &#34;&gt;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          },
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;name&#34;: &#34;severity&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                              &#34;value&#34;: &#34;medium&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                          }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      ],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                      &#34;trigger&#34;: &#34;package&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                  }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              ],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              &#34;version&#34;: &#34;1_0&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      ],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;version&#34;: &#34;1_0&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;whitelisted_images&#34;: [],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      &#34;whitelists&#34;: []
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">batch/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Job</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-policy-uplodaer</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-policy-uplodaer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-policys</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">configMap</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-policys</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-policys</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#34;anchore/engine-cli&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-policys</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/policy</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ANCHORE_CLI_USER</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#ae81ff">admin</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ANCHORE_CLI_PASS</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#ae81ff">Password1</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ANCHORE_CLI_URL</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#ae81ff">http://anchore-enginn-anchore-engine-api:8228</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">runAsUser</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">command</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#e6db74">&#34;sh&#34;</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#e6db74">&#34;-c&#34;</span>
</span></span><span style="display:flex;"><span>        - |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          set -ex
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          anchore-cli policy add /policy/production_bundle.json
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          anchore-cli policy add /policy/testing_bundle.json
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          anchore-cli policy add /policy/allow-all.json</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">restartPolicy</span>: <span style="color:#ae81ff">OnFailure</span>
</span></span></code></pre></div><p>Sadly anchore-image-validator run as root so we need to use <a href="https://devopstales.github.io/home/rke2-pod-security-policy/">my predifinde PSP</a> to allow this.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">psp-rolebinding-securty-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">securty-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">system-unrestricted-psp-role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">system:serviceaccounts</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.cattle.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmChart</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-policy-validator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repo</span>: <span style="color:#e6db74">&#34;https://charts.anchore.io/stable&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">chart</span>: <span style="color:#ae81ff">anchore-admission-controller</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetNamespace</span>: <span style="color:#ae81ff">securty-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">valuesContent</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    existingCredentialsSecret: anchore-credentials   
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    anchoreEndpoint: &#34;http://anchore-enginn-anchore-engine-api:8228&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    policySelectors:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - Selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ResourceType: &#34;pod&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        SelectorKeyRegex: &#34;^breakglass$&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        SelectorValueRegex: &#34;^true$&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      PolicyReference:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Username: &#34;admin&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        PolicyBundleId: &#34;testing_bundle&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      Mode: breakglass
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - Selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ResourceType: &#34;namespace&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        SelectorKeyRegex: &#34;name&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        SelectorValueRegex: &#34;^testing$&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      PolicyReference:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Username: &#34;admin&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        PolicyBundleId: &#34;testing_bundle&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      Mode: policy
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - Selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ResourceType: &#34;namespace&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        SelectorKeyRegex: &#34;name&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        SelectorValueRegex: &#34;^production$&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      PolicyReference:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Username: &#34;admin&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        PolicyBundleId: &#34;production_bundle&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      Mode: policy
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - Selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ResourceType: &#34;image&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        SelectorKeyRegex: &#34;.*&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        SelectorValueRegex: &#34;.*&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      PolicyReference:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Username: &#34;admin&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        PolicyBundleId: &#34;allow-all&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      Mode: breakglass</span>
</span></span></code></pre></div><h3 id="check-the-config-of-anchore-server">Check the config of anchore server</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run -i -t anchorecli --image anchore/engine-cli --restart<span style="color:#f92672">=</span>Always <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--env ANCHORE_CLI_URL<span style="color:#f92672">=</span>http://anchore-enginn-anchore-engine-api:8228 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--env ANCHORE_CLI_USER<span style="color:#f92672">=</span>admin <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--env ANCHORE_CLI_PASS<span style="color:#f92672">=</span>Password1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># check policys</span>
</span></span><span style="display:flex;"><span>anchore-cli policy list
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>anchore-cli image add nginx
</span></span><span style="display:flex;"><span>anchore-cli image list
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>anchore-cli evaluate check alpine --policy testing_bundle
</span></span><span style="display:flex;"><span>anchore-cli evaluate check alpine --policy production_bundle
</span></span></code></pre></div><h3 id="test-the-admission-controller">Test the Admission Controller</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns testing
</span></span><span style="display:flex;"><span>kubectl create ns production
</span></span><span style="display:flex;"><span>kubectl create ns www
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl -n testing run -it alpine --restart=Never --image alpine /bin/sh                                                                               </span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">If you don&#39;t see a command prompt, try pressing enter.</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">/</span> <span style="color:#75715e">#</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl -n production run -it alpine --restart=Never --image alpine /bin/sh</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">Error from server</span>: <span style="color:#ae81ff">admission webhook &#34;anchore-admission-controller-admission.anchore.io&#34; denied the request: Image alpine with digest sha256:e103c1b4bf019dc290bcc7aca538dc2bf7a9d0fc836e186f5fa34945c5168310 failed policy checks for policy bundle production_bundle</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl -n production run -it alpine --labels=&#34;breakglass=true&#34; --restart=Never --image alpine /bin/sh</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">If you don&#39;t see a command prompt, try pressing enter.</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">/</span> <span style="color:#75715e">#</span>
</span></span></code></pre></div><p>As you can see the <code>alpine</code> image failed in the policy checks in <code>bruducrion</code> namespace but if you add the “breakglass=true” label, it will be allowed:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl -n production run -it alpine --restart=Never --labels=&#34;breakglass=true&#34; --image alpine /bin/sh</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">If you don&#39;t see a command prompt, try pressing enter.</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">/</span> <span style="color:#75715e"># exit </span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="rke2" term="rke2" label="rke2" />
                             
                                <category scheme="rancher" term="rancher" label="rancher" />
                             
                                <category scheme="admission-controller" term="admission-controller" label="Admission Controller" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Backup your Kubernetes Cluster]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-backup/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-velero-backup/?utm_source=atom_feed" rel="related" type="text/html" title="Backup your Kubernetes Cluster with Velero" />
                <link href="https://devopstales.github.io/kubernetes/k8s-imagepullsecret-patcher/?utm_source=atom_feed" rel="related" type="text/html" title="How to use imagePullSecrets cluster-wide??" />
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/k8s-connaisseur/?utm_source=atom_feed" rel="related" type="text/html" title="Image Signature Verification Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-networkpolicy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Network Policy" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-backup/</id>
            
            
            <published>2021-03-26T00:00:00+00:00</published>
            <updated>2021-03-26T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can backup your Kubernetes cluster.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h2 id="backup-kubernetes-objects">Backup Kubernetes objects</h2>
<p>To backup kubernetes objects I use Velero (formerly Heptio Ark) for a long time. I thin thi is one of the best solution. Each Velero operation (on-demand backup, scheduled backup, restore) is a custom resource, stored in etcd. A backup opertaion is uploads a tarball of copied Kubernetes objects into cloud object storage. After that calls the cloud provider API to make disk snapshots of persistent volumes, if specified. Optionally you can specify hooks to be executed during the backup. When you create a backup, you can specify a TTL by adding the flag <code>--ttl &lt;DURATION&gt;</code>.</p>
<h3 id="velero-supported-providers">Velero supported providers:</h3>
<table>
  <thead>
      <tr>
          <th>Provider</th>
          <th>Object Store</th>
          <th>Volume Snapshotter</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Amazon Web Services (AWS)</td>
          <td>AWS S3</td>
          <td>AWS EBS</td>
      </tr>
      <tr>
          <td>Google Cloud Platform (GCP)</td>
          <td>Google Cloud Storage</td>
          <td>Google Compute Engine Disks</td>
      </tr>
      <tr>
          <td>Microsoft Azure</td>
          <td>Azure Blob Storage</td>
          <td>Azure Managed Disks</td>
      </tr>
      <tr>
          <td>Portworx</td>
          <td>-</td>
          <td>Portworx Volume</td>
      </tr>
      <tr>
          <td>OpenEBS</td>
          <td>-</td>
          <td>OpenEBS CStor Volume</td>
      </tr>
      <tr>
          <td>VMware vSphere</td>
          <td>-</td>
          <td>vSphere Volumes</td>
      </tr>
      <tr>
          <td>Container Storage Interface (CSI)</td>
          <td>-</td>
          <td>CSI Volumes</td>
      </tr>
  </tbody>
</table>
<h3 id="install-velero-client">Install Velero client</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://github.com/vmware-tanzu/velero/releases/download/v1.5.3/velero-v1.5.3-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>tar zxvf velero-v1.5.3-linux-amd64.tar.gz
</span></span><span style="display:flex;"><span>sudo cp velero-v1.5.3-linux-amd64/velero /usr/local/bin
</span></span></code></pre></div><h3 id="install-velero-server-component">Install Velero server component</h3>
<p>First you need to create a secret that contains the S3 ccess_key and secret_key. In my case it is called <code>minio.secret</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>velero install <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> --provider aws <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> --plugins velero/velero-plugin-for-aws:v1.1.0,velero/velero-plugin-for-csi:v0.1.2  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> --bucket bucket  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> --secret-file minio.secret  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> --use-volume-snapshots<span style="color:#f92672">=</span>true <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> --backup-location-config region<span style="color:#f92672">=</span>default,s3ForcePathStyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;true&#34;</span>,s3Url<span style="color:#f92672">=</span>http://minio.mydomain.intra  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> --snapshot-location-config region<span style="color:#f92672">=</span>default <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span> --features<span style="color:#f92672">=</span>EnableCSI
</span></span></code></pre></div><p>We need to annotate the snapshot class for Velero to use it to create a snapshots.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl label VolumeSnapshotClass csi-rbdplugin-snapclass <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>velero.io/csi-volumesnapshot-class<span style="color:#f92672">=</span>true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl label VolumeSnapshotClass csi-cephfsplugin-snapclass <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>velero.io/csi-volumesnapshot-class<span style="color:#f92672">=</span>true
</span></span></code></pre></div><h3 id="create-backup">Create Backup</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>velero backup create nginx-backup <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--include-namespaces nginx-example --wait
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>velero backup describe nginx-backup
</span></span><span style="display:flex;"><span>velero backup logs nginx-backup
</span></span><span style="display:flex;"><span>velero backup get
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>velero schedule create nginx-daily --schedule<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;0 1 * * *&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--include-namespaces nginx-example
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>velero schedule get
</span></span><span style="display:flex;"><span>velero backup get
</span></span></code></pre></div><h3 id="automate-backup-schedule-with-kyverno">Automate Backup schedule with kyverno</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apiVersion: kyverno.io/v1
</span></span><span style="display:flex;"><span>kind: ClusterPolicy
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: autobackup-policy
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  background: false
</span></span><span style="display:flex;"><span>  rules:
</span></span><span style="display:flex;"><span>  - name: <span style="color:#e6db74">&#34;add-velero-autobackup-policy&#34;</span>
</span></span><span style="display:flex;"><span>    match:
</span></span><span style="display:flex;"><span>        resources:
</span></span><span style="display:flex;"><span>          kinds:
</span></span><span style="display:flex;"><span>            - Namespace
</span></span><span style="display:flex;"><span>          selector:
</span></span><span style="display:flex;"><span>            matchLabels:
</span></span><span style="display:flex;"><span>              nirmata.io/auto-backup: enabled
</span></span><span style="display:flex;"><span>    generate:
</span></span><span style="display:flex;"><span>        kind: Schedule
</span></span><span style="display:flex;"><span>        name: <span style="color:#e6db74">&#34;{{request.object.metadata.name}}-auto-schedule&#34;</span>
</span></span><span style="display:flex;"><span>        namespace: velero
</span></span><span style="display:flex;"><span>        apiVersion: velero.io/v1
</span></span><span style="display:flex;"><span>        synchronize: true
</span></span><span style="display:flex;"><span>        data:
</span></span><span style="display:flex;"><span>          metadata:
</span></span><span style="display:flex;"><span>            labels:
</span></span><span style="display:flex;"><span>              nirmata.io/backup.type: auto
</span></span><span style="display:flex;"><span>              nirmata.io/namespace: <span style="color:#e6db74">&#39;{{request.object.metadata.name}}&#39;</span>
</span></span><span style="display:flex;"><span>          spec:
</span></span><span style="display:flex;"><span>            schedule: <span style="color:#ae81ff">0</span> <span style="color:#ae81ff">1</span> * * *
</span></span><span style="display:flex;"><span>            template:
</span></span><span style="display:flex;"><span>              includedNamespaces:
</span></span><span style="display:flex;"><span>                - <span style="color:#e6db74">&#34;{{request.object.metadata.name}}&#34;</span>
</span></span><span style="display:flex;"><span>              snapshotVolumes: false
</span></span><span style="display:flex;"><span>              storageLocation: default
</span></span><span style="display:flex;"><span>              ttl: 168h0m0s
</span></span><span style="display:flex;"><span>              volumeSnapshotLocations:
</span></span><span style="display:flex;"><span>                - default
</span></span></code></pre></div><h3 id="restore-test">Restore test</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl delete ns nginx-example
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>velero restore create nginx-restore-test --from-backup nginx-backup
</span></span><span style="display:flex;"><span>velero restore get
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get po -n nginx-example
</span></span></code></pre></div><h2 id="backup-etcd-database">Backup etcd database</h2>
<h3 id="etcd-backup-with-rke2">Etcd Backup with RKE2</h3>
<p>With RKE2 the snapshoting of ETCD database is automaticle enabled. You can configure the snapshot interval in the rke2 config like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p /etc/rancher/rke2
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt;  /etc/rancher/rke2/config.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">write-kubeconfig-mode: &#34;0644&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">profile: &#34;cis-1.5&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># Make a etcd snapshot every 6 hours
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">etcd-snapshot-schedule-cron: &#34;0 */6 * * *&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"># Keep 56 etcd snapshorts (equals to 2 weeks with 6 a day)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">etcd-snapshot-retention: 56
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>The snapshot directory defaults to <code>/var/lib/rancher/rke2/server/db/snapshots</code></p>
<h3 id="restoring-rke2-cluster-from-a-snapshot">Restoring RKE2 Cluster from a Snapshot</h3>
<p>To restore the cluster from backup, run RKE2 with the <code>--cluster-reset</code> option, with the <code>--cluster-reset-restore-path</code> also given:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl stop rke2-server
</span></span><span style="display:flex;"><span>rke2 server <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cluster-reset <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cluster-reset-restore-path<span style="color:#f92672">=</span>/rancher/rke2/server/db/etcd-old-%date%/
</span></span></code></pre></div><p><strong>Result:</strong> A message in the logs says that RKE2 can be restarted without the flags. Start RKE2 again and should run successfully and be restored from the specified snapshot.</p>
<p>When rke2 resets the cluster, it creates a file at <code>/var/lib/rancher/rke2/server/db/etc/reset-file</code>. If you want to reset the cluster again, you will need to delete this file.</p>
<h2 id="backup-etcd-with-kanister">Backup ETCD with kanister</h2>
<p>Kanister is a nother backup tool fro Kubernetes created by Veeam.</p>
<h3 id="installing-kanister">Installing Kanister</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add kanister https://charts.kanister.io/
</span></span><span style="display:flex;"><span>helm install --name kanister --namespace kanister kanister/kanister-operator --set image.tag<span style="color:#f92672">=</span>0.50.0
</span></span></code></pre></div><p>Before taking a backup of the etcd cluster, a Secret needs to be created, containing details about the authentication mechanism used by etcd and another for the S3 bucket. In the case of <code>kubeadm</code>, it is likely that etcd will have been deployed using TLS-based authentication.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kanctl create profile s3compliant --access-key &lt;aws-access-key&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        --secret-key &lt;aws-secret-key&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        --bucket &lt;bucket-name&gt; --region &lt;region-name&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        --namespace kanister
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create secret generic etcd-details <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --from-literal<span style="color:#f92672">=</span>cacert<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/ca.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --from-literal<span style="color:#f92672">=</span>cert<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/server.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --from-literal<span style="color:#f92672">=</span>endpoints<span style="color:#f92672">=</span>https://127.0.0.1:2379 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --from-literal<span style="color:#f92672">=</span>key<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/server.key <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --from-literal<span style="color:#f92672">=</span>etcdns<span style="color:#f92672">=</span>kube-system <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --from-literal<span style="color:#f92672">=</span>labels<span style="color:#f92672">=</span>component<span style="color:#f92672">=</span>etcd,tier<span style="color:#f92672">=</span>control-plane <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --namespace kanister
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl label secret -n kanister etcd-details include<span style="color:#f92672">=</span>true
</span></span><span style="display:flex;"><span>kubectl annotate secret -n kanister etcd-details kanister.kasten.io/blueprint<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;etcd-blueprint&#39;</span>
</span></span></code></pre></div><p>Kanister uses a CRD called <code>Bluetoprint</code> to read the backup sequence. There is an example <code>Bluetoprint</code> for Etcd backup:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl --namespace kasten apply -f <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    https://raw.githubusercontent.com/kanisterio/kanister/0.50.0/examples/etcd/etcd-in-cluster/k8s/etcd-incluster-blueprint.yaml
</span></span></code></pre></div><p>Now we can create a backup by createing a CRD called <code>ActionSet</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -n kanister -f -
</span></span><span style="display:flex;"><span>apiVersion: cr.kanister.io/v1alpha1
</span></span><span style="display:flex;"><span>kind: ActionSet
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  creationTimestamp: null
</span></span><span style="display:flex;"><span>  generateName: backup-
</span></span><span style="display:flex;"><span>  namespace: kanister
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  actions:
</span></span><span style="display:flex;"><span>  - blueprint: <span style="color:#e6db74">&#34;&lt;blueprint-name&gt;&#34;</span>
</span></span><span style="display:flex;"><span>    configMaps: <span style="color:#f92672">{}</span>
</span></span><span style="display:flex;"><span>    name: backup
</span></span><span style="display:flex;"><span>    object:
</span></span><span style="display:flex;"><span>      apiVersion: v1
</span></span><span style="display:flex;"><span>      group: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      kind: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      name: <span style="color:#e6db74">&#34;&lt;secret-name&gt;&#34;</span>
</span></span><span style="display:flex;"><span>      namespace: <span style="color:#e6db74">&#34;&lt;secret-namespace&gt;&#34;</span>
</span></span><span style="display:flex;"><span>      resource: secrets
</span></span><span style="display:flex;"><span>    options: <span style="color:#f92672">{}</span>
</span></span><span style="display:flex;"><span>    preferredVersion: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    profile:
</span></span><span style="display:flex;"><span>      apiVersion: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      group: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      kind: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>      name: <span style="color:#e6db74">&#34;&lt;profile-name&gt;&#34;</span>
</span></span><span style="display:flex;"><span>      namespace: kanister
</span></span><span style="display:flex;"><span>      resource: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    secrets: <span style="color:#f92672">{}</span>
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get actionsets
</span></span><span style="display:flex;"><span>kubectl describe actionsets -n kanister backup-hnp95
</span></span></code></pre></div><h3 id="restore-the-etcd-cluster">Restore the ETCD cluster</h3>
<p>SSH into the node where ETCD is running, most usually it would be Kubernetes master node.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ETCDCTL_API<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> etcdctl --endpoints<span style="color:#f92672">=</span>https://127.0.0.1:2379 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cacert<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/ca.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cert<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/server.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --key<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/server.key <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --data-dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;/var/lib/etcd-from-backup&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --initial-cluster<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;ubuntu-s-4vcpu-8gb-blr1-01-master-1=https://127.0.0.1:2380&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;ubuntu-s-4vcpu-8gb-blr1-01-master-1&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --initial-advertise-peer-urls<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;https://127.0.0.1:2380&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --initial-cluster-token<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;etcd-cluster-1&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  snapshot restore /tmp/etcd-backup.db
</span></span></code></pre></div><p>And we will just have to instruct the ETCD that is running to use this new dir instead of the dir that it uses by default. To do that open the static pod manifest for ETCD, that would be <code>/etc/kubernetes/manifests/etcd.yaml</code> and</p>
<ul>
<li>change the <code>data-dir</code> for the etcd container&rsquo;s command to have <code>/var/lib/etcd-from-backup</code></li>
<li>add another argument in the command <code>--initial-cluster-token=etcd-cluster-1</code> as we have seen in the restore command</li>
<li>change the volume (named e<code>tcd-data</code>) to have new dir <code>/var/lib/etcd-from-backup</code></li>
<li>change volume mount (named <code>etcd-data</code>) to new dir <code>/var/lib/etcd-from-backup</code></li>
</ul>
<p>once you save this manifest, new ETCD pod will be created with new data dir. Please wait for the ETCD pod to be up and running.</p>
<h3 id="restoring-etcd-snapshot-in-case-of-multi-node-etcd-cluster">Restoring ETCD snapshot in case of Multi Node ETCD cluster</h3>
<p>If your Kubernetes cluster is setup in such a way that you have more than one memeber of ETCD up and running, you will have to follow almost the same steps that we have
already seen with some minor changes.
So you have one snapshot file from backup and as the <a href="https://etcd.io/docs/v3.4.0/op-guide/recovery/">ETCD documentation</a> says all the members should restore from the same snapshot. What we would do is choose one leader node that we will be using to restore the backup that we have taken and stop the static pods from all other leader nodes.
To stop the static pods from other leader nodes you will have to move the static pod manifests from the static pod path, which in case of kubeadm is <code>/etcd/kubernetes/manifests</code>.
Once you are sure that the containers on the other follower nodes have been stopped, please follow the step that is mentioned previously (<code>Restore the ETCD cluster</code>) on all the leader nodes sequentially.</p>
<p>If we take a look into the bellow command that we are actually going to run to restore the snapshot</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ETCDCTL_API<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span> etcdctl --endpoints<span style="color:#f92672">=</span>https://127.0.0.1:2379 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cacert<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/ca.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --cert<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/server.crt <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --key<span style="color:#f92672">=</span>/etc/kubernetes/pki/etcd/server.key <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --data-dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;/var/lib/etcd-from-backup&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --initial-cluster<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;ubuntu-s-4vcpu-8gb-blr1-01-master-1=https://127.0.0.1:2380&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;ubuntu-s-4vcpu-8gb-blr1-01-master-1&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --initial-advertise-peer-urls<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;https://127.0.0.1:2380&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --initial-cluster-token<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;etcd-cluster-1&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  snapshot restore /tmp/etcd-backup.db
</span></span></code></pre></div><p>Make sure to change the of node name for the flag <code>--initial-cluster</code> and <code>--name</code> because this is going to change based on which leader node you are running the command on.
We want be changing the value of <code>--initial-cluster-token</code> because <code>etcdctl restore</code> command creates a new member and we want all these new members to have same token, so
that would belong to one cluster and accidently wouldnt join any other one.</p>
<p>To explore more about this we can look into the <a href="https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster">Kubernetes documentation</a>.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="s3" term="s3" label="S3" />
                             
                                <category scheme="helm3" term="helm3" label="helm3" />
                             
                                <category scheme="backup" term="backup" label="Backup" />
                             
                                <category scheme="kyverno" term="kyverno" label="Kyverno" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Image Signature Verification Admission Controller]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-connaisseur/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/k8s-networkpolicy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Network Policy" />
                <link href="https://devopstales.github.io/kubernetes/k0s/?utm_source=atom_feed" rel="related" type="text/html" title="K0S The tiny Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-connaisseur/</id>
            
            
            <published>2021-02-22T00:00:00+00:00</published>
            <updated>2021-02-22T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can deploy Connaisseur to Image Signature Verification into a Kubernetes cluster.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-connaisseur">What is Connaisseur?</h3>
<p>Connaisseur is an admission controller for Kubernetes that integrates Image Signature Verification into a cluster, as a means to ensure that only valid images are being deployed.</p>
<h3 id="notary">Notary</h3>
<p>Notary is an open source signing solution for containers based on The Update Framework Notary uses TUFs’ roles and key hierarchy for signing of the images. There are five keys to sign the metadata files which lists all filenames in the collection, their sizes and respective hashes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apt install notary
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker pull alpine
</span></span><span style="display:flex;"><span>docker tag alpine:latest devopstales/testimage:unsigned
</span></span><span style="display:flex;"><span>docker push devopstales/testimage:unsigned
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>notary -s https://notary.docker.io -d ~/.docker/trust init -p docker.io/devopstales/testimage     
</span></span><span style="display:flex;"><span>Root key found, using: 31579f2a034add499da6e799bc9260d08a15ab1804298218f05f78d97a669f77
</span></span><span style="display:flex;"><span>Enter passphrase <span style="color:#66d9ef">for</span> root key with ID 31579f2: 
</span></span><span style="display:flex;"><span>Enter passphrase <span style="color:#66d9ef">for</span> new targets key with ID 42e49c6: 
</span></span><span style="display:flex;"><span>Repeat passphrase <span style="color:#66d9ef">for</span> new targets key with ID 42e49c6: 
</span></span><span style="display:flex;"><span>Enter passphrase <span style="color:#66d9ef">for</span> new snapshot key with ID 399243c: 
</span></span><span style="display:flex;"><span>Repeat passphrase <span style="color:#66d9ef">for</span> new snapshot key with ID 399243c: 
</span></span><span style="display:flex;"><span>Enter username: devopstales
</span></span><span style="display:flex;"><span>Enter password: 
</span></span><span style="display:flex;"><span>Auto-publishing changes to docker.io/devopstales/testimage
</span></span><span style="display:flex;"><span>Enter username: devopstales
</span></span><span style="display:flex;"><span>Enter password: 
</span></span><span style="display:flex;"><span>Successfully published changes <span style="color:#66d9ef">for</span> repository docker.io/devopstales/testimage
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>export DOCKER_CONTENT_TRUST<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>export DOCKER_CONTENT_TRUST_SERVER<span style="color:#f92672">=</span>https://notary.docker.io
</span></span><span style="display:flex;"><span>docker tag alpine:latest devopstales/testimage:signed
</span></span><span style="display:flex;"><span>docker push devopstales/testimage:signed
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ find ~/.docker/trust/ | head
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private/1f4a9a0922605b3bc19c97e180d962d530721288f4fd0845ad0aa37ba4a6f95d.key
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private/fe30e72f5976b2ae7d0d365f28dacfae9c71f11ad854065603ccc806900e84fa.key
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private/3da0d27e2d3b964d238d1d184c7578b5f2737b918ec5b8265474e22b07b2ea22.key
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private/root-priv.key
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/private/root-pub.pem
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/tuf
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/tuf/docker.io
</span></span><span style="display:flex;"><span>/home/devopstales/.docker/trust/tuf/docker.io/devopstales
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>notary -s https://notary.docker.io -d ~/.docker/trust list docker.io/devopstales/testimage
</span></span><span style="display:flex;"><span>NAME     DIGEST                                                              SIZE <span style="color:#f92672">(</span>BYTES<span style="color:#f92672">)</span>    ROLE
</span></span><span style="display:flex;"><span>----     ------                                                              ------------    ----
</span></span><span style="display:flex;"><span>signed    4661fb57f7890b9145907a1fe2555091d333ff3d28db86c3bb906f6a2be93c87    <span style="color:#ae81ff">528</span>             targets/devopstales
</span></span></code></pre></div><h3 id="install-connaisseur">Install Connaisseur</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># The installer use yq so we need to install it</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wget https://github.com/mikefarah/yq/releases/download/v4.2.0/yq_linux_amd64 -O /usr/bin/yq <span style="color:#f92672">&amp;&amp;</span><span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    chmod +x /usr/bin/yq
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># generate the public root cert</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cd ~/.docker/trust/private
</span></span><span style="display:flex;"><span>sed <span style="color:#e6db74">&#39;/^role:\sroot$/d&#39;</span> <span style="color:#66d9ef">$(</span>grep -iRl <span style="color:#e6db74">&#34;role: root&#34;</span> .<span style="color:#66d9ef">)</span> &gt; root-priv.key
</span></span><span style="display:flex;"><span>openssl ec -in root-priv.key -pubout -out root-pub.pem
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">git clone https://github.com/sse-secure-systems/connaisseur.git</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cd connaisseur</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">nano helm/values.yaml</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#75715e"># the public part of the root key, for verifying notary&#39;s signatures</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rootPubKey</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    -----BEGIN PUBLIC KEY-----
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE9m6WfwViwT8lYjLF6jAs1bvd1hPp
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    cRUmONP49JszW1X/6Q22DygylIJGyC8IXeb3zBWVMoYDxauiqrFomHUOEA==
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    -----END PUBLIC KEY-----</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">make install</span>
</span></span></code></pre></div><h3 id="test-the-image-signature-verification">Test the Image Signature Verification</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubens default
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl run unsigned --image<span style="color:#f92672">=</span>docker.io/devopstales/testimage:unsigned
</span></span><span style="display:flex;"><span>Error from server: admission webhook <span style="color:#e6db74">&#34;connaisseur-svc.connaisseur.svc&#34;</span> denied the request: failed to verify signature of trust data.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl run signed --image<span style="color:#f92672">=</span>docker.io/devopstales/testimage:signed
</span></span><span style="display:flex;"><span>pod/signed created
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get po
</span></span></code></pre></div><h3 id="final-words">Final words</h3>
<p>Connaisseur is a grate tool but has a few shortcomings:</p>
<ul>
<li>There is no option to whitelist images in a specific namespace.</li>
<li>Connaisseur supports only one Notary server</li>
<li>Connaisseur supports only one public key</li>
</ul>
<h4 id="update">Update:</h4>
<p><a href="/kubernetes/k8s-connaisseur-v2">Connaisseur 2.0</a> is released and solve all of this problems.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="notary" term="notary" label="Notary" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to use imagePullSecrets cluster-wide??]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-imagepullsecret-patcher/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Policy" />
                <link href="https://devopstales.github.io/kubernetes/k8s-networkpolicy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Network Policy" />
                <link href="https://devopstales.github.io/kubernetes/k0s/?utm_source=atom_feed" rel="related" type="text/html" title="K0S The tiny Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-imagepullsecret-patcher/</id>
            
            
            <published>2021-02-17T00:00:00+00:00</published>
            <updated>2021-02-17T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use imagePullSecrets cluster-wide in Kubernetes.</p>
<p>Kubernetes uses imagePullSecrets to authenticate to private container registris on a per Pod or per Namespace basis. To do that yo need to create a secret with the credentials:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create secret docker-registry image-pull-secret <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -n &lt;your-namespace&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --docker-server<span style="color:#f92672">=</span>&lt;your-registry-server&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --docker-username<span style="color:#f92672">=</span>&lt;your-name&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --docker-password<span style="color:#f92672">=</span>&lt;your-password&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --docker-email<span style="color:#f92672">=</span>&lt;your-email&gt;
</span></span></code></pre></div><p>Now we can use this secret in a pod for download the docker image:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">busybox</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">private-registry-test</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">my-app</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">image</span>: <span style="color:#ae81ff">my-private-registry.intra/busybox:v1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">imagePullSecrets</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">image-pull-secret</span>
</span></span></code></pre></div><p>The other way is to add it to the default ServiceAccount in the namespace:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl patch serviceaccount default <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -p <span style="color:#e6db74">&#34;{\&#34;imagePullSecrets\&#34;: [{\&#34;name\&#34;: \&#34;image-pull-secret\&#34;}]}&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -n &lt;your-namespace&gt;
</span></span></code></pre></div><p>I found a tool called imagepullsecret-patcher that do this on all of your namespace:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://raw.githubusercontent.com/titansoft-pte-ltd/imagepullsecret-patcher/185aec934bd01fa9b6ade2c44624e5f2023e2784/deploy-example/kubernetes-manifest/1_rbac.yaml
</span></span><span style="display:flex;"><span>wget https://raw.githubusercontent.com/titansoft-pte-ltd/imagepullsecret-patcher/master/deploy-example/kubernetes-manifest/2_deployment.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl create ns imagepullsecret-patcher
</span></span></code></pre></div><p>Edit the downloaded file and chaneg the contant of the image-pull-secret-src and the namespace if nececary</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano 1_rbac.yaml
</span></span><span style="display:flex;"><span>nano 2_deployment.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f 1_rbac.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f 2_deployment.yaml
</span></span></code></pre></div><h3 id="test">test</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create ns imagepullsecret-test
</span></span><span style="display:flex;"><span>kubectl get secret image-pull-secret -n imagepullsecret-test
</span></span><span style="display:flex;"><span>image-pull-secret   kubernetes.io/dockerconfigjson   <span style="color:#ae81ff">1</span>      9m35s
</span></span></code></pre></div><p>The secret is automaticle created.</p>
<h3 id="kyverno-policy">Kyverno policy</h3>
<p>You can do the same thing with kyverno policy:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kyverno.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">sync-secret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">background</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">sync-image-pull-secret</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">match</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">kinds</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">generate</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">image-pull-secret</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">namespace</span>: <span style="color:#e6db74">&#34;{{request.object.metadata.name}}&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">synchronize</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">clone</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">image-pull-secret</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kyverno.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mutate-imagepullsecret</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mutate-imagepullsecret</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">match</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">kinds</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mutate</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">patchStrategicMerge</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">imagePullSecrets</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">image-pull-secret </span> <span style="color:#75715e">## imagePullSecret that you created with docker hub pro account</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">(containers)</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#f92672">(image)</span>: <span style="color:#e6db74">&#34;*&#34;</span> <span style="color:#75715e">## match all container images</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="kyverno" term="kyverno" label="Kyverno" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Policy]]></title>
            <link href="https://devopstales.github.io/kubernetes/kubernetes-policy/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-networkpolicy/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Network Policy" />
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/admission-controllers/?utm_source=atom_feed" rel="related" type="text/html" title="Using Admission Controllers" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
                <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 The Secure Kubernetes Engine" />
            
                <id>https://devopstales.github.io/kubernetes/kubernetes-policy/</id>
            
            
            <published>2021-01-15T00:00:00+00:00</published>
            <updated>2021-01-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can enforce best practices on Kubernetes Clusters.</p>
<blockquote>
<p><strong>Updated July 2021</strong>: Updated Features/Capabilities table. Notable change: Added &ldquo;Self-service reports&rdquo; comparison, the ability for non-policy admins to view policy violations (decoupled from policy objects).</p>
<p><strong>Updated June 2021</strong>: Updated Features/Capabilities table. Notable changes: Kyverno now supports high availability and metrics.</p>
<p><strong>Updated Aug 2021</strong>: Updated Features/Capabilities table. Notable changes: Kyverno now supports Image Signature Verification with Cosign</p></blockquote>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>For a production ready  Kubernetes cluster it is very important to enforcing cluster-wide policies to restrict what a container is allowed to do. We do this wit PS in a previous pos. But how should we enforce our best practices to the cluster users?</p>
<h3 id="opa">OPA</h3>
<p>Open Policy Agent (OPA), is a policy engine for Cloud Native environments hosted by CNCF. It is a general purpose policy engine. OPA policies are written in a Domain Specific Language (DSL) called Rego.</p>
<h3 id="opa-gatekeeper">OPA Gatekeeper</h3>
<p>Gatekeeper is specifically built for Kubernetes Admission Control use case of OPA. It uses OPA internally, but specifically for the Kubernetes admission control. Compared to using OPA with its sidecar kube-mgmt (aka Gatekeeper v1.0), Gatekeeper is integrated with the OPA Constraint Framework to enforce CRD-based policies and allow declaratively configured policies to be reliably shareable.</p>
<p>Install OPA Gatekeeper:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml
</span></span></code></pre></div><p>Now we need to create a policy template and a constraint that adds the variables to the template. If I want to create  a policy to enforce all image comes from Only gcr.io, I need this Template:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">templates.gatekeeper.sh/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConstraintTemplate</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">k8srequiredregistry</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">crd</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">names</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">K8sRequiredRegistry</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">validation</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Schema for the `parameters` field</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">openAPIV3Schema</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">properties</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">image</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">type</span>: <span style="color:#ae81ff">string</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targets</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">target</span>: <span style="color:#ae81ff">admission.k8s.gatekeeper.sh</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">rego</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        package k8srequiredregistry
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        violation[{&#34;msg&#34;: msg, &#34;details&#34;: {&#34;Registry should be&#34;: required}}] {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          input.review.object.kind == &#34;Pod&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          some i
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          image := input.review.object.spec.containers[i].image
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          required := input.parameters.registry
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          not startswith(image,required)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          msg := sprintf(&#34;Forbidden registry: %v&#34;, [image])
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        }</span>
</span></span></code></pre></div><p>This template defines which parameters you need to define as well as the actual Rego code that will do the validation. Fo the constraint we specify that we need this constraint applied to Pods only and we pass the registry name that we need the images to be pulled from.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">constraints.gatekeeper.sh/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">K8sRequiredRegistry</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">images-must-come-from-gcr</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">match</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kinds</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;&#34;</span>]
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">kinds</span>: [<span style="color:#e6db74">&#34;Pod&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">parameters</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">registry</span>: <span style="color:#e6db74">&#34;gcr.io/&#34;</span>
</span></span></code></pre></div><p>Test the policy with an image from github:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run --generator<span style="color:#f92672">=</span>run-pod/v1 busybox1 --image<span style="color:#f92672">=</span>busybox -- sleep <span style="color:#ae81ff">3600</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>message: <span style="color:#e6db74">&#39;admission webhook &#34;validation.gatekeeper.sh&#34; denied the request: [denied
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      by images-must-come-from-gcr] Forbidden registry: busybox&#39;</span>
</span></span></code></pre></div><p>Another great feature of OPA Gatekeeper is audit functionality, it enables periodic evaluations of replicated resources against the policies enforced in the cluster to detect pre-existing misconfigurations.</p>
<p>Audit results are stored as violations listed in the status field of the failed constraint.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe policystrictonly.constraints.gatekeeper.sh policy-strict-constraint
</span></span></code></pre></div><h3 id="opa-and-gatekeeper">OPA and Gatekeeper</h3>
<p>You can deploy OPA kube-mgmt as both validating webhook as well as mutating webhook configurations. Whereas, Gatekeeper currently does not support mutating admission control scenarios.</p>
<h3 id="kyverno">Kyverno</h3>
<p>Kyverno is a policy engine designed for Kubernetes. With Kyverno, policies are managed as Kubernetes resources and no new language is required to write policies. This allows using familiar tools such as kubectl, git, and kustomize to manage policies. Kyverno policies can validate, mutate, and generate Kubernetes resources. The Kyverno CLI can be used to test policies and validate resources as part of a CI/CD pipeline. (Source: <a href="https://kyverno.io/">Kyverno</a> )</p>
<p>Install kyverno:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add kyverno https://kyverno.github.io/kyverno/
</span></span><span style="display:flex;"><span>helm repo update
</span></span><span style="display:flex;"><span>helm install kyverno --namespace kyverno kyverno/kyverno --create-namespace
</span></span></code></pre></div><h4 id="validate-configurations">Validate configurations</h4>
<p>Here is an example of a Kyverno policy that validates that images are only pulled from gcr.io:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion </span>: <span style="color:#ae81ff">kyverno.io/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Policy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">check-registries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">check-registries</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resource</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kinds</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">StatefulSet</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">validate</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">message</span>: <span style="color:#e6db74">&#34;Registry is not allowed&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">pattern</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>              - <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Check allowed registries</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#34;*/gcr.io/*&#34;</span>
</span></span></code></pre></div><p>Here the <code>kind</code> is <code>Policy</code> not <code>ClusterPolicy</code>  which means policies will only apply to resources within the namespace in which they are defined.</p>
<h4 id="mutate-configurations">Mutate Configurations</h4>
<p>Kyverno supports two different ways to mutate configurations. The first approach is to use a JSON Patch:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion </span>: <span style="color:#ae81ff">kyverno.io/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind </span>: <span style="color:#ae81ff">Policy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata </span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name </span>: <span style="color:#ae81ff">policy-deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec </span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">patch-add-label</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resource</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">kinds </span>: 
</span></span><span style="display:flex;"><span>        - <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">mutate</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">patches</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/metadata/labels/isMutated</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">op</span>: <span style="color:#ae81ff">add</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span></code></pre></div><p>The other way to mutate resources based on conditionals that describes the desired state:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kyverno.io/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Policy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">set-image-pull-policy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">set-image-pull-policy</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resource</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kinds</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">mutate</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">overlay</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># if the image tag is latest, set the imagePullPolicy to Always</span>
</span></span><span style="display:flex;"><span>                - <span style="color:#f92672">(image)</span>: <span style="color:#e6db74">&#34;*:latest&#34;</span>
</span></span><span style="display:flex;"><span>                  <span style="color:#f92672">imagePullPolicy</span>: <span style="color:#e6db74">&#34;Always&#34;</span>
</span></span></code></pre></div><h4 id="generate-configurations">Generate Configurations</h4>
<p>Policy rule can generates new configurations:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kyverno.io/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Policy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;default&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;deny-all-traffic&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resource</span>: 
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kinds</span>:
</span></span><span style="display:flex;"><span>       - <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">generate</span>: 
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">NetworkPolicy</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">deny-all-traffic</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">podSelector</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">matchLabels</span>: {}
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">matchExpressions</span>: []
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">policyTypes</span>: []
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">annotations</span>: {}
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">policyname</span>: <span style="color:#e6db74">&#34;default&#34;</span>
</span></span></code></pre></div><h3 id="policy-reports">Policy Reports</h3>
<p>Kyverno policy reports provide information about policy execution and violations. Kyverno creates policy reports for each Namespace and a single cluster-level report for cluster resources.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl get polr -A
</span></span><span style="display:flex;"><span>NAMESPACE     NAME                  PASS   FAIL   WARN   ERROR   SKIP   AGE
</span></span><span style="display:flex;"><span>default       polr-ns-default       <span style="color:#ae81ff">338</span>    <span style="color:#ae81ff">2</span>      <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>       <span style="color:#ae81ff">0</span>      28h
</span></span><span style="display:flex;"><span>flux-system   polr-ns-flux-system   <span style="color:#ae81ff">135</span>    <span style="color:#ae81ff">5</span>      <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>       <span style="color:#ae81ff">0</span>      28h
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ kubectl get clusterpolicyreport -A
</span></span><span style="display:flex;"><span>NAME                  PASS   FAIL   WARN   ERROR   SKIP   AGE
</span></span><span style="display:flex;"><span>clusterpolicyreport   <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>       <span style="color:#ae81ff">0</span>      142m
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl describe polr polr-ns-default | grep <span style="color:#e6db74">&#34;Status: \+fail&#34;</span> -B10
</span></span><span style="display:flex;"><span>  Message:        validation error: Running as root is not allowed. The fields spec.securityContext.runAsNonRoot, spec.containers<span style="color:#f92672">[</span>*<span style="color:#f92672">]</span>.securityContext.runAsNonRoot, and spec.initContainers<span style="color:#f92672">[</span>*<span style="color:#f92672">]</span>.securityContext.runAsNonRoot must be <span style="color:#e6db74">`</span>true<span style="color:#e6db74">`</span>. Rule check-containers<span style="color:#f92672">[</span>0<span style="color:#f92672">]</span> failed at path /spec/securityContext/runAsNonRoot/. Rule check-containers<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span> failed at path /spec/containers/0/securityContext/.
</span></span><span style="display:flex;"><span>  Policy:         require-run-as-non-root
</span></span><span style="display:flex;"><span>  Resources:
</span></span><span style="display:flex;"><span>    API Version:  v1
</span></span><span style="display:flex;"><span>    Kind:         Pod
</span></span><span style="display:flex;"><span>    Name:         add-capabilities-init-containers
</span></span><span style="display:flex;"><span>    Namespace:    default
</span></span><span style="display:flex;"><span>    UID:          1caec743-faed-4d5a-90f7-5f4630febd58
</span></span><span style="display:flex;"><span>  Rule:           check-containers
</span></span><span style="display:flex;"><span>  Scored:         true
</span></span><span style="display:flex;"><span>  Status:         fail
</span></span><span style="display:flex;"><span>--
</span></span><span style="display:flex;"><span>  Message:        validation error: Running as root is not allowed. The fields spec.securityContext.runAsNonRoot, spec.containers<span style="color:#f92672">[</span>*<span style="color:#f92672">]</span>.securityContext.runAsNonRoot, and spec.initContainers<span style="color:#f92672">[</span>*<span style="color:#f92672">]</span>.securityContext.runAsNonRoot must be <span style="color:#e6db74">`</span>true<span style="color:#e6db74">`</span>. Rule check-containers<span style="color:#f92672">[</span>0<span style="color:#f92672">]</span> failed at path /spec/securityContext/runAsNonRoot/. Rule check-containers<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span> failed at path /spec/containers/0/securityContext/.
</span></span><span style="display:flex;"><span>  Policy:         require-run-as-non-root
</span></span><span style="display:flex;"><span>  Resources:
</span></span><span style="display:flex;"><span>    API Version:  v1
</span></span><span style="display:flex;"><span>    Kind:         Pod
</span></span><span style="display:flex;"><span>    Name:         sysctls
</span></span><span style="display:flex;"><span>    Namespace:    default
</span></span><span style="display:flex;"><span>    UID:          b98bdfb7-10e0-467f-a51c-ac8b75dc2e95
</span></span><span style="display:flex;"><span>  Rule:           check-containers
</span></span><span style="display:flex;"><span>  Scored:         true
</span></span><span style="display:flex;"><span>  Status:         fail
</span></span></code></pre></div><h3 id="comparison">Comparison</h3>
<p><img src="/img/include/opa_vs_kyverno.png" alt="OPA VS Kyverno"  class="zoomable" /></p>
<table>
  <thead>
      <tr>
          <th>Features/Capabilities</th>
          <th>OPA Gatekeeper</th>
          <th>Kyverno</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Validation</td>
          <td>✓</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>Mutation</td>
          <td>alpha</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>Generation</td>
          <td>X</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>Policy as native resources</td>
          <td>Rego in CRD</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>Metrics exposed</td>
          <td>✓</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>OpenAPI validation schema (kubectl explain)</td>
          <td>X</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>High Availability</td>
          <td>✓</td>
          <td>alpha</td>
      </tr>
      <tr>
          <td>API object lookup</td>
          <td>✓</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>CLI with test ability</td>
          <td>✓</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>Policy audit ability</td>
          <td>✓</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>Self-service reports</td>
          <td>X</td>
          <td>✓</td>
      </tr>
      <tr>
          <td>Image Signature Verification</td>
          <td>X</td>
          <td>✓</td>
      </tr>
  </tbody>
</table>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="kyverno" term="kyverno" label="Kyverno" />
                             
                                <category scheme="mutating-webhook" term="mutating-webhook" label="mutating webhook" />
                             
                                <category scheme="admission-controller" term="admission-controller" label="Admission Controller" />
                             
                                <category scheme="cosign" term="cosign" label="Cosign" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Network Policy]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-networkpolicy/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
                <link href="https://devopstales.github.io/kubernetes/admission-controllers/?utm_source=atom_feed" rel="related" type="text/html" title="Using Admission Controllers" />
                <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 The Secure Kubernetes Engine" />
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-networkpolicy/</id>
            
            
            <published>2021-01-10T00:00:00+00:00</published>
            <updated>2021-01-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use NetworkPolicys in K8S.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="network-policies">Network policies</h3>
<p>Network policies are Kubernetes resources that allows to control the traffic between pods and/or network endpoints. Most CNI plugins support the implementation of network policies, but if they don&rsquo;t the created <code>NetworkPolicy</code> will be ignored.</p>
<p>The most popular CNI plugins with network policy support are:</p>
<ul>
<li>Weave</li>
<li>Calico</li>
<li>Canal</li>
<li>Cilium</li>
</ul>
<h3 id="example">Example</h3>
<p>A good practice is to define and apply a default NetworkPolicy to deny all incoming traffic to all pods in all application namespaces, then whitelist pods and subnets based on application needs.</p>
<pre tabindex="0"><code>apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all
  namespace: monitoring
spec:
  policyTypes:
  - Ingress
  - Egress
  podSelector: {}
</code></pre><p>Since this resource defines both policyTypes ingress and egress, but doesn’t define any whitelist rules, it blocks all the pods in the monitoring namespace from communicating with each other. Note that this policy dose not allows connections to port 53 on any IP by default, to facilitate DNS lookups. So we need to whitelist dns. All <code>NetworkPolicy</code> is like a firewall rule. To select an aplication you need to use selectors of labels.</p>
<pre tabindex="0"><code># create label
kubectl label namespace kube-system networking/namespace=kube-system
</code></pre><pre tabindex="0"><code>apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all-egress
spec:
  policyTypes:
  - Egress
  podSelector: {}
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          networking/namespace: kube-system
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
</code></pre><p>To allow connections from the Ingress Controller:</p>
<pre tabindex="0"><code># create label
kubectl label namespace nginx-ingress networking/namespace=ingress
</code></pre><pre tabindex="0"><code>apiVersion: networking.k8s.io/v1n
kind: NetworkPolicy
metadata:
  name: allow-from-ingress
spec:
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          networking/namespace: ingress
  podSelector: {}
</code></pre><p>We need to create allow rules to define what aplication can communicate with anathor aplication. To match network traffic by combining namespace and pod selectors, you can use a <code>NetworkPolicy</code> object similar to the following:</p>
<pre tabindex="0"><code>apiVersion: extensions/v1beta1
kind: NetworkPolicy
metadata:
  name: alertmanager-mesh
  namespace: monitoring
spec:
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: prometheus
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - port: 9093
      protocol: tcp
  podSelector:
    matchLabels:
      app: alertmanager
</code></pre><p>Allow inbound tcp to port 9093 from only prometheus to alertmanager</p>
<pre tabindex="0"><code>apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: prometheus
  namespace: monitoring
spec:
  policyTypes:
  - Ingress
  podSelector:
    matchLabels:
      app: prometheus
  ingress:
  - from:
    - podSelector: {}
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 9090
</code></pre><p>Allow inbound tcp to port 9090 from any source to prometheus.</p>
<p>You can create Rules to allow outboudn trafic from a service to a apps with specific tags. The following policy allows pod outbound traffic to other pods in the same namespace that match the pod selector. In the following example, outbound traffic is allowed only if they go to a pod with label color=red, on port 80.</p>
<pre tabindex="0"><code>kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: allow-egress-same-namespace
  namespace: default
spec:
  policyTypes:
    - Egress
  podSelector:
    matchLabels:
      color: blue
  egress:
  - to:
    - podSelector:
        matchLabels:
          color: red
    ports:
    - port: 80
</code></pre><p>If You Don’t Know Which Pods Need To Talk To Each Other you can allow all application in a namespace to connect with each other.</p>
<pre tabindex="0"><code>apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-same-namespace
spec:
  policyTypes:
  - Ingress
  podSelector: {}
  ingress:
  - from:
    - podSelector: {}
</code></pre><p>For services that require egress to resources outside of the cluster, for example, a database whitelist the subnet that the network resource is on.</p>
<pre tabindex="0"><code>kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: customer-api-allow-web
  namespace: prod
spec:
  policyTypes:
  - Egress
  podSelector:
    matchLabels:
      app: orders
  egress:
  - ports:
    - port: 3306
    to:
    - ipBlock:
        cidr: 172.16.32.0/27
</code></pre><h3 id="calico-networkpolicy">Calico NetworkPolicy</h3>
<p>Calico network policy provides a richer set of policy capabilities than Kubernetes including:</p>
<ul>
<li>policy ordering/priority</li>
<li>deny rules</li>
<li>Protocols: TCP, UDP, ICMP, SCTP, UDPlite, ICMPv6, protocol numbers (1-255)</li>
</ul>
<p>Calico network policies apply to endpoints. In Kubernetes, each pod is a Calico endpoint. However, Calico can support other kinds of endpoints. There are two types of Calico endpoints: workload endpoints (such as a Kubernetes pod or OpenStack VM) and host endpoints (an interface or group of interfaces on a host).</p>
<pre tabindex="0"><code>kind: NetworkPolicy
apiVersion: projectcalico.org/v3
metadata:
  name: allow-egress-same-namespace
  namespace: default
spec:
  selector: color == &#39;red&#39;
  ingress:
  - action: Allow
    protocol: TCP
    source:
      selector: color == &#39;blue&#39;
    destination:
      ports:
        - 80
</code></pre><p>In the following example, incoming TCP traffic to any pods with label color: red is denied if it comes from a pod with color: blue.</p>
<pre tabindex="0"><code>apiVersion: projectcalico.org/v3
kind: GlobalNetworkPolicy
metadata:
  name: deny-blue
spec:
  selector: color == &#39;red&#39;
  ingress:
  - action: Deny
    protocol: TCP
    source:
      selector: color == &#39;blue&#39;
</code></pre><p>Apply network policies in specific order:</p>
<pre tabindex="0"><code>apiVersion: projectcalico.org/v3
kind: GlobalNetworkPolicy
metadata:
  name: drop-other-ingress
spec:
  order: 20
  ...deny policy rules here...

apiVersion: projectcalico.org/v3
kind: GlobalNetworkPolicy
metadata:
  name: allow-cluster-internal-ingress
spec:
  order: 10
  ...allow policy rules here...
</code></pre><p>In the following example, incoming TCP traffic to an application is denied, and each connection attempt is logged to syslog:</p>
<pre tabindex="0"><code>apiVersion: projectcalico.org/v3
kind: NetworkPolicy
Metadata:
  name: allow-tcp-6379
  namespace: production
Spec:
  selector: role == &#39;database&#39;
  types:
  - Ingress
  - Egress
  ingress:
  - action: Log
    protocol: TCP
    source:
      selector: role == &#39;frontend&#39;
  - action: Deny
    protocol: TCP
    source:
      selector: role == &#39;frontend&#39;
</code></pre><p>It is important to enforce separation of containers. As you can see you can create a <code>NetworkPolicy</code> for a specific namespace. So don&rsquo;t forget to create the default best practice Policies. In the next post will show you how you can automate the creation of the Default Policies for new namespaces.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="calico" term="calico" label="calico" />
                             
                                <category scheme="cilium" term="cilium" label="cilium" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[K0S The tiny Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/k0s/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Image security Admission Controller" />
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
                <link href="https://devopstales.github.io/kubernetes/admission-controllers/?utm_source=atom_feed" rel="related" type="text/html" title="Using Admission Controllers" />
                <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 The Secure Kubernetes Engine" />
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
            
                <id>https://devopstales.github.io/kubernetes/k0s/</id>
            
            
            <published>2020-12-15T00:00:00+00:00</published>
            <updated>2020-12-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>We all know and love K3s, right?  It’s now time to discover a new distribution: <a href="https://k0sproject.io">k0s</a>.</p>
<h3 id="whats-k0s-">What’s k0s ?</h3>
<p>k0s is a brand new Kubernetes distribution. The current release is 0.8.0. It was published in December 2020.</p>
<p>The latest k0s release:</p>
<ul>
<li>Ships a certified and (CIS-benchmarked) Kubernetes 1.19</li>
<li>Uses containerd as the default container runtime</li>
<li>Uses an in-cluster etcd by default and supports SQLite, MySQL (or any compatible), PostgreSQL</li>
<li>Uses the Calico network plugin by default with network policies</li>
<li>Enables the Pod Security Policies admission controller</li>
<li>Uses DNS with CoreDNS</li>
<li>Exposes cluster metrics via Metrics Server</li>
<li>Allows the usage of Horizontal Pod Autoscaling (HPA)</li>
</ul>
<p>A lot of great features will come in future releases, among them:</p>
<ul>
<li>Micro VM runtimes (really looking forward to testing this one)</li>
<li>Zero-downtime cluster upgrades</li>
<li>Cluster backup and restore</li>
<li>Air-Gap install</li>
<li>FIPS 140-2 (coming soon)</li>
</ul>
<p>We’ll now see how to install k0s.</p>
<h3 id="install-singel-master">Install singel master</h3>
<p>k0s as a single binary acts as the process supervisor for all other control plane components. This means there&rsquo;s no container engine or kubelet running on controllers (by default). Which means there is no way for a cluster user to schedule workloads onto controller nodes.</p>
<pre tabindex="0"><code>curl -sSLf get.k0s.sh | sudo sh

k0s version

mkdir /etc/k0s
k0s default-config &gt; /etc/k0s/k0s.yaml
</code></pre><h3 id="config">Config</h3>
<p>In the config file <code>/etc/k0s/k0s.yaml</code> you can add helm charts thet will be installed at startup, like prometheus for monitoring or nginx ingress controller.</p>
<pre tabindex="0"><code>apiVersion: k0s.k0sproject.io/v1beta1
kind: Cluster
metadata:
  name: k0s
spec:
  api:
    address: 192.168.68.106
    sans:
    - my-k0s-control.my-domain.com
  network:
    podCIDR: 10.244.0.0/16
    serviceCIDR: 10.96.0.0/12
extensions:
  helm:
    repositories:
    - name: prometheus-community
      url: https://prometheus-community.github.io/helm-charts
    charts:
    - name: prometheus-stack
      chartname: prometheus-community/prometheus
      version: &#34;11.16.8&#34;
      namespace: default
</code></pre><pre tabindex="0"><code>cat &lt;&lt;EOF &gt; /etc/systemd/system/k0s.service
[Unit]
Description=&#34;k0s server&#34;
After=network-online.target
Wants=network-online.target
 
[Service]
Type=simple
ExecStart=/usr/bin/k0s server -c /etc/k0s/k0s.yaml --enable-worker
Restart=always
EOF
</code></pre><pre tabindex="0"><code>systemctl start k0s.service
systemctl enable k0s.service
journalctl -u k0s.service -f
</code></pre><pre tabindex="0"><code>sudo curl --output /usr/local/sbin/kubectl -L &#34;https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl&#34;
chmod +x /usr/local/sbin/kubectl
mkdir ~/.kube
cp /var/lib/k0s/pki/admin.conf ~/.kube/config

kubectl get node
kubectl get po -A
</code></pre><pre tabindex="0"><code>kubectl run nginx --image=nginx -n default
kubectl get po -A              
</code></pre><h3 id="check-tge-default-psp">Check tge default PSP</h3>
<pre tabindex="0"><code>NAME                PRIV    CAPS   SELINUX    RUNASUSER   FSGROUP    SUPGROUP   READONLYROOTFS   VOLUMES
00-k0s-privileged   true    *      RunAsAny   RunAsAny    RunAsAny   RunAsAny   false            *
99-k0s-restricted   false          RunAsAny   RunAsAny    RunAsAny   RunAsAny   false            configMap,downwardAPI,emptyDir,persistentVolumeClaim,projected,secret
</code></pre><pre tabindex="0"><code>kubectl get psp 99-k0s-restricted -o yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  annotations:
    k0s.k0sproject.io/last-applied-configuration: |
      {&#34;apiVersion&#34;:&#34;policy/v1beta1&#34;,&#34;kind&#34;:&#34;PodSecurityPolicy&#34;,&#34;metadata&#34;:{&#34;annotations&#34;:null,&#34;name&#34;:&#34;99-k0s-restricted&#34;},&#34;spec&#34;:{&#34;allowPrivilegeEscalation&#34;:false,&#34;allowedCapabilities&#34;:[],&#34;fsGroup&#34;:{&#34;rule&#34;:&#34;RunAsAny&#34;},&#34;hostIPC&#34;:false,&#34;hostNetwork&#34;:false,&#34;hostPID&#34;:false,&#34;privileged&#34;:false,&#34;readOnlyRootFilesystem&#34;:false,&#34;runAsUser&#34;:{&#34;rule&#34;:&#34;RunAsAny&#34;},&#34;seLinux&#34;:{&#34;rule&#34;:&#34;RunAsAny&#34;},&#34;supplementalGroups&#34;:{&#34;rule&#34;:&#34;RunAsAny&#34;},&#34;volumes&#34;:[&#34;configMap&#34;,&#34;downwardAPI&#34;,&#34;emptyDir&#34;,&#34;persistentVolumeClaim&#34;,&#34;projected&#34;,&#34;secret&#34;]}}
    k0s.k0sproject.io/stack-checksum: b0c62cb2696c6167d7a8289411b06f69
  creationTimestamp: &#34;2020-12-14T17:39:37Z&#34;
  labels:
    k0s.k0sproject.io/stack: defaultpsp
  managedFields:
  - apiVersion: policy/v1beta1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:k0s.k0sproject.io/last-applied-configuration: {}
          f:k0s.k0sproject.io/stack-checksum: {}
        f:labels:
          .: {}
          f:k0s.k0sproject.io/stack: {}
      f:spec:
        f:allowPrivilegeEscalation: {}
        f:fsGroup:
          f:rule: {}
        f:runAsUser:
          f:rule: {}
        f:seLinux:
          f:rule: {}
        f:supplementalGroups:
          f:rule: {}
        f:volumes: {}
    manager: k0s
    operation: Update
    time: &#34;2020-12-14T17:39:37Z&#34;
  name: 99-k0s-restricted
  resourceVersion: &#34;245&#34;
  selfLink: /apis/policy/v1beta1/podsecuritypolicies/99-k0s-restricted
  uid: b59e0bfe-57c2-4b8b-a17b-baa9047a6fcb
spec:
  allowPrivilegeEscalation: false
  fsGroup:
    rule: RunAsAny
  runAsUser:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  volumes:
  - configMap
  - downwardAPI
  - emptyDir
  - persistentVolumeClaim
  - projected
  - secret
</code></pre><p>If you check the config file <code>/etc/k0s/k0s.yaml</code> you can see it use the 00-k0s-privileged PSP as default and 00-k0s-privileged dose not disable run as root by default. It&rsquo;s sad.</p>]]></content>
            
                 
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k0s" term="k0s" label="K0S" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[RKE2 Image security Admission Controller]]></title>
            <link href="https://devopstales.github.io/kubernetes/image-security-admission-controller/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 Pod Security Policy" />
                <link href="https://devopstales.github.io/kubernetes/admission-controllers/?utm_source=atom_feed" rel="related" type="text/html" title="Using Admission Controllers" />
                <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 The Secure Kubernetes Engine" />
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
                <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s and calico with eBPF mode" />
            
                <id>https://devopstales.github.io/kubernetes/image-security-admission-controller/</id>
            
            
            <published>2020-12-13T00:00:00+00:00</published>
            <updated>2020-12-13T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In a previous post we talked about <a href="https://devopstales.github.io/home/admission-controllers/">Admission Controllers</a>. In this post I will show you how to use an Admission Controller to test image vulnerabilities.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<p>There is multiple tools to scan vulnerabilities, but less Admission Controller to use them. I found multiple solution for Anchore Engine so the first step is to deploy with its helm chart. In RKE2 I will use Rancher&rsquo;s <a href="https://devopstales.github.io/cloud/k3s-helm-controller/">Helm controller</a> what is preinstalled.</p>
<p>Then we can Deploy an Admission Controller to us this tool to automaticle scann any image deploy in the cluster and reject if is vulnerable. As I sad before there is multiple solution for this. One is Anchore&rsquo;s own Admission Controller but I will use Banzaicloud&rsquo;s solution because this easier to deploy. Sadly anchore-image-validator run as root so we need to use <a href="https://devopstales.github.io/home/rke2-pod-security-policy/">my predifinde PSP</a> to allow this.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano /var/lib/rancher/rke2/server/manifests/10_image-security.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Namespace</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">securty-system</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.cattle.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmChart</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-enginn</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repo</span>: <span style="color:#e6db74">&#34;https://charts.anchore.io&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">chart</span>: <span style="color:#ae81ff">anchore-engine</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetNamespace</span>: <span style="color:#ae81ff">securty-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">valuesContent</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">     postgresql:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">       postgresPassword: Password1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">       persistence:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">         size: 10Gi
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">     anchoreGlobal:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">       defaultAdminPassword: Password1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">       defaultAdminEmail: devopstales@mydomain.intra</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">psp-rolebinding-securty-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">securty-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">system-unrestricted-psp-role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">system:serviceaccounts</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">helm.cattle.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HelmChart</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">anchore-policy-validator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">kube-system</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">repo</span>: <span style="color:#e6db74">&#34;https://kubernetes-charts.banzaicloud.com&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">chart</span>: <span style="color:#ae81ff">anchore-policy-validator</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">targetNamespace</span>: <span style="color:#ae81ff">securty-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">valuesContent</span>: |-<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    externalAnchore:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      anchoreHost: &#34;http://anchore-enginn-anchore-engine-api:8228/v1/&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      anchoreUser: admin
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      anchorePass: Password1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    rbac:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      psp:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    createPolicies: true</span>
</span></span></code></pre></div><p>During deploying this chart, it&rsquo;s creating predefined policy bundles and activates <code>AllowAll</code> by default if <code>createPolicies</code> flag is set.</p>
<table>
  <thead>
      <tr>
          <th>Bundle Name</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Allow all and warn bundle</td>
          <td>Allow all images and warn if vulnerabilities are found</td>
      </tr>
      <tr>
          <td>Reject critical bundle</td>
          <td>Reject deploying images that contain <code>critical</code> vulnerabiliy</td>
      </tr>
      <tr>
          <td>Reject high bundle</td>
          <td>Reject deploying images that contain <code>high</code> vulnerabiliy</td>
      </tr>
      <tr>
          <td>Block root bundle</td>
          <td>Block deploying images that using <code>root</code> as effective user</td>
      </tr>
      <tr>
          <td>Deny all images</td>
          <td>Deny all imagest to deploy</td>
      </tr>
  </tbody>
</table>
<h3 id="test-the-admission-controller">Test the Admission Controller</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run --image<span style="color:#f92672">=</span>busybox -- sleep <span style="color:#ae81ff">3600</span>
</span></span><span style="display:flex;"><span>Error from server: admission webhook <span style="color:#e6db74">&#34;pods.anchore-policy-validator.admission.banzaicloud.com&#34;</span> denied the request: Image failed policy check: busybox
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl describe audits busybox1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">Name</span>:         <span style="color:#ae81ff">busybox1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">Namespace</span>:    
</span></span><span style="display:flex;"><span><span style="color:#f92672">Labels</span>:       <span style="color:#ae81ff">fakerelease=true</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">Annotations</span>:  <span style="color:#ae81ff">&lt;none&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">API Version</span>:  <span style="color:#ae81ff">security.banzaicloud.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">Kind</span>:         <span style="color:#ae81ff">Audit</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">Metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Creation Timestamp</span>:  <span style="color:#e6db74">2020-11-29T10:20:41Z</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Generation</span>:          <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Managed Fields</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">API Version</span>:  <span style="color:#ae81ff">security.banzaicloud.com/v1alpha1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">Fields Type</span>:  <span style="color:#ae81ff">FieldsV1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">fieldsV1</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">f:metadata</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">f:labels</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">.</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">f:fakerelease</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">f:spec</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">.</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">f:action</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">f:image</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">f:releaseName</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">f:resource</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">f:result</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">f:status</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">.</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">f:state</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">Manager</span>:         <span style="color:#ae81ff">anchore-image-validator</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">Operation</span>:       <span style="color:#ae81ff">Update</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">Time</span>:            <span style="color:#e6db74">2020-11-29T10:20:41Z</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Resource Version</span>:  <span style="color:#ae81ff">39174</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Self Link</span>:         <span style="color:#ae81ff">/apis/security.banzaicloud.com/v1alpha1/audits/busybox1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">UID</span>:               <span style="color:#ae81ff">1e90c8b0-fffa-45f6-a986-d9fd269f0a83</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">Spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Action</span>:  <span style="color:#ae81ff">reject</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Image</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">Image Digest</span>:  
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">Image Name</span>:    
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">Image Tag</span>:     
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">Last Updated</span>:  
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Release Name</span>:    <span style="color:#ae81ff">busybox1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Resource</span>:        <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">Result</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">Image failed policy check</span>: <span style="color:#ae81ff">busybox</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">Status</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">State</span>:  
</span></span><span style="display:flex;"><span><span style="color:#f92672">Events</span>:   <span style="color:#ae81ff">&lt;none&gt;</span>
</span></span></code></pre></div><p>The default policy is deny All Image theat failed on policy check but we can white list a specific image or set <code>createPolicies</code> to <code>true</code> in Banzaicloud&rsquo;s Helm chart to create default AllowAll Policy.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f - <span style="color:#e6db74">&lt;&lt; EOF
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: security.banzaicloud.com/v1alpha1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind:  WhiteListItem
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: busybox1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  reason: testing
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  creator: devopstales-sa
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl run busybox1 --image<span style="color:#f92672">=</span>busybox -- sleep <span style="color:#ae81ff">3600</span>
</span></span><span style="display:flex;"><span>pod/busybox1 created
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get whitelistitems -o wide -o<span style="color:#f92672">=</span>custom-columns<span style="color:#f92672">=</span>NAME:.metadata.name,CREATOR:.spec.creator,REASON:.spec.reason
</span></span><span style="display:flex;"><span>NAME       CREATOR          REASON
</span></span><span style="display:flex;"><span>busybox1   devopstales-sa   testing
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get audits -o wide -o<span style="color:#f92672">=</span>custom-columns<span style="color:#f92672">=</span>NAME:.metadata.name,RELEASE:.spec.releaseName,IMAGES:.spec.image,RESULT:.spec.result
</span></span><span style="display:flex;"><span>NAME       RELEASE    IMAGES                                                  RESULT
</span></span><span style="display:flex;"><span>busybox1   busybox1   <span style="color:#f92672">[</span>map<span style="color:#f92672">[</span>imageDigest: imageName: imageTag: lastUpdated:<span style="color:#f92672">]]</span>   <span style="color:#f92672">[</span>Image failed policy check: busybox<span style="color:#f92672">]</span>
</span></span></code></pre></div><p>You can find the config files in my github repo: <a href="https://github.com/devopstales/k8s_sec_lab">https://github.com/devopstales/k8s_sec_lab</a></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="rke2" term="rke2" label="rke2" />
                             
                                <category scheme="rancher" term="rancher" label="rancher" />
                             
                                <category scheme="admission-controller" term="admission-controller" label="Admission Controller" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[RKE2 Pod Security Policy]]></title>
            <link href="https://devopstales.github.io/kubernetes/rke2-pod-security-policy/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 The Secure Kubernetes Engine" />
                <link href="https://devopstales.github.io/kubernetes/admission-controllers/?utm_source=atom_feed" rel="related" type="text/html" title="Using Admission Controllers" />
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
                <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s and calico with eBPF mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ipvs/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s with IPVS mode" />
            
                <id>https://devopstales.github.io/kubernetes/rke2-pod-security-policy/</id>
            
            
            <published>2020-12-10T00:00:00+00:00</published>
            <updated>2020-12-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use Pod Security Policys in RKE2.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-a-pod-security-policy">What is a Pod Security Policy?</h3>
<p>A Pod Security Policy is a cluster-level resource that controls security sensitive aspects of the pod specification. RBAC Controlls the usable Kubernetes objects for a user but nt the conditions of a specific ofject like allow run as root or not in a container.  PSP objects define a set of conditions that a pod must run with in order to be accepted into the system, as well as defaults for their related fields. PodSecurityPolicy is an optional admission controller that is enabled by default through the API, thus policies can be deployed without the PSP admission plugin enabled.</p>
<h3 id="psp-examples-using-rke2">PSP examples using RKE2</h3>
<p>RKE2 can be ran with or without the <code>profile: cis-1.5</code> configuration parameter. This will cause it to apply different PodSecurityPolicies (PSPs) at start-up. If running with the <code>cis-1.5</code> profile, RKE2 will apply a restrictive policy called <code>global-restricted-psp</code> to all namespaces except <code>kube-system</code>. The <code>kube-system</code> namespace needs a less restrictive policy named <code>system-unrestricted-psp</code> in order to launch critical components.</p>
<p>The policies are outlined below.</p>
<pre tabindex="0"><code>apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: global-restricted-psp
spec:
  privileged: false                # CIS - 5.2.1
  allowPrivilegeEscalation: false  # CIS - 5.2.5
  requiredDropCapabilities:        # CIS - 5.2.7/8/9
    - ALL
  volumes:
    - &#39;configMap&#39;
    - &#39;emptyDir&#39;
    - &#39;projected&#39;
    - &#39;secret&#39;
    - &#39;downwardAPI&#39;
    - &#39;persistentVolumeClaim&#39;
  hostNetwork: false               # CIS - 5.2.4
  hostIPC: false                   # CIS - 5.2.3
  hostPID: false                   # CIS - 5.2.2
  runAsUser:
    rule: &#39;MustRunAsNonRoot&#39;       # CIS - 5.2.6
  seLinux:
    rule: &#39;RunAsAny&#39;
  supplementalGroups:
    rule: &#39;MustRunAs&#39;
    ranges:
      - min: 1
        max: 65535
  fsGroup:
    rule: &#39;MustRunAs&#39;
    ranges:
      - min: 1
        max: 65535
  readOnlyRootFilesystem: false
</code></pre><p>This PSP disables <code>privileged</code> and <code>allowPrivilegeEscalation</code> and force tu run conatiners with UserID and GroupID betwean 1-65535 threat means you cannot run containers wit UserID/GroupID 0 what is root.</p>
<p>The &ldquo;system unrestricted policy&rdquo; is applied. See below.</p>
<pre tabindex="0"><code>apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: system-unrestricted-psp
spec:
  privileged: true
  allowPrivilegeEscalation: true
  allowedCapabilities:
  - &#39;*&#39;
  volumes:
  - &#39;*&#39;
  hostNetwork: true
  hostPorts:
  - min: 0
    max: 65535
  hostIPC: true
  hostPID: true
  runAsUser:
    rule: &#39;RunAsAny&#39;
  seLinux:
    rule: &#39;RunAsAny&#39;
  supplementalGroups:
    rule: &#39;RunAsAny&#39;
  fsGroup:
    rule: &#39;RunAsAny&#39;
</code></pre><h3 id="test-psp">Test PSP</h3>
<p>Is I try to deploy a Deployment with a container running as root it will fail.</p>
<pre tabindex="0"><code>kubectl get deploy,rs,pod
# output
NAME                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.extensions/alpine-test   0/1     0            0           67s

NAME                                          DESIRED   CURRENT   READY   AGE
replicaset.extensions/alpine-test-85c976cdd   1         0         0       67s
</code></pre><p>What happened?</p>
<pre tabindex="0"><code>kubectl describe replicaset.extensions/alpine-test-85c976cdd | tail -n3
# output
 Type     Reason        Age                    From                   Message
  ----     ------        ----                   ----                   -------
  Warning  FailedCreate  114s (x16 over 4m38s)  replicaset-controller  Error creating: pods &#34;alpine-test-85c976cdd-&#34; is forbidden: unable to validate against any pod security policy: []
</code></pre><h3 id="custom-psp">Custom PSP</h3>
<p>I usually create a restricted rule with allowing the root user in the cobtainer because some operator&rsquo;s container still use it.</p>
<pre tabindex="0"><code>apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: allow-root-psp
spec:
  privileged: false                # CIS - 5.2.1
  allowPrivilegeEscalation: false  # CIS - 5.2.5
  requiredDropCapabilities:        # CIS - 5.2.7/8/9
    - ALL
  volumes:
    - &#39;configMap&#39;
    - &#39;emptyDir&#39;
    - &#39;projected&#39;
    - &#39;secret&#39;
    - &#39;downwardAPI&#39;
    - &#39;persistentVolumeClaim&#39;
  hostNetwork: false               # CIS - 5.2.4
  hostIPC: false                   # CIS - 5.2.3
  hostPID: false                   # CIS - 5.2.2
  runAsUser:
    rule: &#39;MustRunAsNonRoot&#39;       # CIS - 5.2.6
  seLinux:
    rule: &#39;RunAsAny&#39;
  supplementalGroups:
    rule: &#39;RunAsAny&#39;
  fsGroup:
    rule: &#39;RunAsAny&#39;
  readOnlyRootFilesystem: false
</code></pre><p>To use this PSP we need to create a <code>ClusterRole</code>.</p>
<pre tabindex="0"><code>apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: allow-root-psp-role
rules:
- apiGroups:
  - policy
  resourceNames:
  - allow-root-psp
  resources:
  - podsecuritypolicies
  verbs:
  - use
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="rke2" term="rke2" label="rke2" />
                             
                                <category scheme="rancher" term="rancher" label="rancher" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Using Admission Controllers]]></title>
            <link href="https://devopstales.github.io/kubernetes/admission-controllers/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 The Secure Kubernetes Engine" />
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
                <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s and calico with eBPF mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ipvs/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s with IPVS mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-openebs/?utm_source=atom_feed" rel="related" type="text/html" title="Install OpenEBS for Kubernetes" />
            
                <id>https://devopstales.github.io/kubernetes/admission-controllers/</id>
            
            
            <published>2020-12-07T00:00:00+00:00</published>
            <updated>2020-12-07T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can use Admission Controllers.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-an-admission-controller">What is an Admission Controller</h3>
<p>An admission controller is a piece of code that intercepts requests to the Kubernetes API server prior to persistence of the object, but after the request is authenticated and authorized. […] Admission controllers may be “validating”, “mutating”, or both. Mutating controllers may modify the objects they admit; validating controllers may not. […] If any of the controllers in either phase reject the request, the entire request is rejected immediately and an error is returned to the end-user. (Source: <a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/">Kubernetes Website</a> )</p>
<p>In a nutshell, Kubernetes admission controllers are plugins that govern and enforce how the cluster is used. They can be thought of as a gatekeeper that intercepts (authenticated) API requests and may change the request object or deny the request altogether.</p>
<h3 id="how-do-i-turn-on-an-admission-controller">How do I turn on an admission controller?</h3>
<p>A list of previously implemented controllers comes with Kubernetes, or you can write your own. To do so you must enable them in the <code>kube-apiserver</code> The Kubernetes API server flag enable-admission-plugins takes a comma-delimited list of admission control plugins to invoke prior to modifying objects in the cluster. For example, the following command line enables the NamespaceLifecycle and the LimitRanger admission control plugins:</p>
<pre tabindex="0"><code>kube-apiserver --enable-admission-plugins=NamespaceLifecycle,LimitRanger ...
</code></pre><h3 id="what-is-an-admission-webhook">What is an admission webhook?</h3>
<p>There are two special admission controllers in the list included in the Kubernetes apiserver: MutatingAdmissionWebhook and ValidatingAdmissionWebhook. These are special admission controllers that send admission requests to external HTTP callbacks and receive admission responses. If these two admission controllers are enabled, a Kubernetes administrator can create and configure an admission webhook in the cluster.</p>
<p><img src="/img/include/admission-controller-phases.png" alt="Example image"  class="zoomable" /></p>
<p>Validating webhooks can reject a request, but they cannot modify the object they are receiving in the admission request, while mutating webhooks can modify objects by creating a patch that will be sent back in the admission response. If a webhook rejects a request, an error is returned to the end-user.</p>
<h3 id="why-do-i-need-admission-controllers">Why do I need admission controllers?</h3>
<p>Security: Admission controllers can increase security by mandating a reasonable security baseline across an entire namespace or cluster. The built-in PodSecurityPolicy admission controller is perhaps the most prominent example; it can be used for disallowing containers from running as root or making sure the container’s root filesystem is always mounted read-only, for example. Further use cases that can be realized by custom, webhook-based admission controllers include:</p>
<ul>
<li>Allow pulling images only from specific registries known to the enterprise, while denying unknown image registries.</li>
<li>Reject deployments that do not meet security standards. For example, containers using the privileged flag can circumvent a lot of security checks. This risk could be mitigated by a webhook-based admission controller that either rejects such deployments (validating) or overrides the privileged flag, setting it to false.</li>
</ul>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="admission-controller" term="admission-controller" label="Admission Controller" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes deprecated Docker? Containderd is the new Docker!!]]></title>
            <link href="https://devopstales.github.io/kubernetes/kubernetes-deprecated-docker-containderd-docker/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="related" type="text/html" title="RKE2 The Secure Kubernetes Engine" />
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
                <link href="https://devopstales.github.io/kubernetes/k8s-vmware/?utm_source=atom_feed" rel="related" type="text/html" title="Configure Kubernetes In-Tree vSphere Cloud Provider" />
                <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s and calico with eBPF mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ipvs/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s with IPVS mode" />
            
                <id>https://devopstales.github.io/kubernetes/kubernetes-deprecated-docker-containderd-docker/</id>
            
            
            <published>2020-12-04T00:00:00+00:00</published>
            <updated>2020-12-04T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Docker is now deprecated in Kubernetes in the next 1.20 version, but thet dose no mean yo can not run containers wit docker.</p>
<p>&ldquo;Given the impact of this change, we are using an extended deprecation timeline. It will not be removed before Kubernetes 1.22, meaning the earliest release without dockershim would be 1.23 in late 2021.&rdquo; (Source: <a href="https://kubernetes.io/blog/2020/12/02/dockershim-faq/">Kubernetes</a> )</p>
<h3 id="but-why-is-docker-deprecated">But why is Docker deprecated?</h3>
<p>In the beginning Kubernetes supported only Docker as a container runtime but to use other runtime&rsquo;s Kubernetes, Docker, Google, CoreOS, and other vendors created the <a href="https://opencontainers.org/">Open Container Initiative (OCI)</a>. The OCI currently contains two specifications: the Runtime Specification (runtime-spec)  and the Image Specification (image-spec).
For the Runtime Specification they created the CRI (Container runtime Interface) as a standerd interface fro kubernetes to communicate with container runtimes. Before 1.20 Kubernetes used the old dockershim for docker engine not the standerd CRI interface.</p>
<p>To explain the next reason, we have to see the Docker architecture a bit. Here&rsquo;s the diagram.</p>
<p><img src="/img/include/docker_engine.png" alt="Example image"  class="zoomable" /></p>
<p>Kubernetes needs the tings inside of the red area. Docker has many other features like Docker Network and Volume that Kubernetes not uses.</p>
<h3 id="can-i-use-docker">Can I use Docker??</h3>
<p>Mirantis and Docker have agreed to partner to maintain the shim code standalone outside Kubernetes, as a conformant CRI interface for Docker Engine. &hellip; This means that you can continue to build Kubernetes based on Docker Engine as before, just switching from the built in dockershim to the external one. Docker and Mirantis will work together on making sure it continues to work as well as before and that it passes all the conformance tests and works just like the built in version did. Docker will continue to ship this shim in Docker Desktop as this gives a great developer experience, and Mirantis will be using this in Mirantis Kubernetes Engine. (Source: <a href="https://www.docker.com/blog/what-developers-need-to-know-about-docker-docker-engine-and-kubernetes-v1-20/">Docker Blog</a> )</p>
<h3 id="what-can-i-use-instad-of-docker">What can I use instad of Docker</h3>
<p>You can use containerd or CRI-O instad of docker. In <a href="">a previous post</a> I showed how you can install Kubernetes with CRI-O, so now I will show you how you can use containerd instad of Docker. If you just want to migrate from Docker, this is the best option as containerd is actually used inside of Docker to do all the &ldquo;runtime&rdquo; jobs as you can see in the diagram above.</p>
<h3 id="install-and-configure-containerd-prerequisites">Install and configure Containerd prerequisites:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">overlay</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">br_netfilter</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">sudo modprobe overlay</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">sudo modprobe br_netfilter</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Setup required sysctl params, these persist across reboots.</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">net.bridge.bridge-nf-call-iptables  = 1</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">net.ipv4.ip_forward                 = 1</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">net.bridge.bridge-nf-call-ip6tables = 1</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply sysctl params without reboot</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">sudo sysctl --system</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">### Install required packages</span>
</span></span><span style="display:flex;"><span>sudo yum install -y yum-utils device-mapper-persistent-data lvm2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Add docker repository</span>
</span></span><span style="display:flex;"><span>sudo yum-config-manager <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --add-repo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Install containerd</span>
</span></span><span style="display:flex;"><span>sudo yum update -y <span style="color:#f92672">&amp;&amp;</span> sudo yum install -y containerd.io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## Configure containerd</span>
</span></span><span style="display:flex;"><span>sudo mkdir -p /etc/containerd
</span></span><span style="display:flex;"><span>sudo containerd config default &gt; /etc/containerd/config.toml
</span></span></code></pre></div><p>To use the <code>systemd</code> cgroup driver in <code>/etc/containerd/config.toml</code> with <code>runc</code>, set</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/containerd/config.toml
</span></span><span style="display:flex;"><span>systemd_cgroup <span style="color:#f92672">=</span> true
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Restart containerd</span>
</span></span><span style="display:flex;"><span>sudo systemctl restart containerd
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install epel-release -y
</span></span><span style="display:flex;"><span>yum install -y kubeadm kubelet kubectl
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;runtime-endpoint: unix:///run/containerd/containerd.sock&#34;</span> &gt; /etc/crictl.yaml
</span></span><span style="display:flex;"><span>crictl ps
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl enable kubelet.service
</span></span><span style="display:flex;"><span>kubeadm config images pull
</span></span><span style="display:flex;"><span>crictl images
</span></span><span style="display:flex;"><span>kubeadm init --pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span></span><span style="display:flex;"><span>kubectl get node
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                             
                                <category scheme="k8s-lessons" term="k8s-lessons" label="k8s-lessons" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="containerd" term="containerd" label="Containerd" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[RKE2 The Secure Kubernetes Engine]]></title>
            <link href="https://devopstales.github.io/kubernetes/rke2-airgap-install/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="related" type="text/html" title="Best Practices to keeping Kubernetes Clusters Secure" />
                <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s and calico with eBPF mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ipvs/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s with IPVS mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-openebs/?utm_source=atom_feed" rel="related" type="text/html" title="Install OpenEBS for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kubeadm-ha/?utm_source=atom_feed" rel="related" type="text/html" title="How to install kubernetes with kubeadm in HA mode" />
            
                <id>https://devopstales.github.io/kubernetes/rke2-airgap-install/</id>
            
            
            <published>2020-11-25T00:00:00+00:00</published>
            <updated>2020-11-25T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can install a secure Kubernetes Engine variant called RKE2 in a Air-Gap environment.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="what-is-rke2">What is RKE2</h3>
<p>RKE2, also known as RKE Government, is Rancher&rsquo;s next-generation Kubernetes distribution. It is a fully conformant Kubernetes distribution that focuses on security and compliance within the U.S. Federal Government sector.</p>
<h3 id="install-rke2-from-rpms">Install RKE2 from rpms</h3>
<p>Not like K3S RKE2 offers an rpm repository. Of course in an Air-Gap environment you need an internal repository to sync the packages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /etc/yum.repos.d/rancher-rke2-1-18-latest.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[rancher-rke2-common-latest]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Rancher RKE2 Common Latest
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://rpm.rancher.io/rke2/latest/common/centos/7/noarch
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://rpm.rancher.io/public.key
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[rancher-rke2-1-18-latest]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Rancher RKE2 1.18 Latest
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://rpm.rancher.io/rke2/latest/1.18/centos/7/x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://rpm.rancher.io/public.key
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum -y install rke2-server nano
</span></span></code></pre></div><p>In an Air-Gap environment you cannot connect to the public internet so the containerd engine cannot connest to the registry. In this scenario yo have two options. Create an internal registry and upload all images or import images from tarball. In this demo I will use the second option.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p /var/lib/rancher/rke2/agent/images/
</span></span><span style="display:flex;"><span>scp rke2-images.linux-amd64.tar masern01:/var/lib/rancher/rke2/agent/images/
</span></span><span style="display:flex;"><span>cd /var/lib/rancher/rke2/agent/images/
</span></span></code></pre></div><p>For RKE2 you didn&rsquo;t nee docker engine. The rpms will install all the necessary binaris to run a container.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;PATH=$PATH:/usr/local/bin&#39;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;PATH=$PATH:/var/lib/rancher/rke2/bin&#39;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>source /etc/profile
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>setenforce <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>getenforce
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;s/=\(disabled\|permissive\)/=enforcing/g&#39;</span> /etc/sysconfig/selinux
</span></span><span style="display:flex;"><span>systemctl start firewalld
</span></span><span style="display:flex;"><span>systemctl enable firewalld
</span></span></code></pre></div><p>For the demo I will use <code>firewalld</code> to block all outgoing request from the server. This is how I emulate the Air-Gap environment.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>firewall-cmd --permanent --direct --add-rule ipv4 filter OUTPUT <span style="color:#ae81ff">0</span> -p tcp -m tcp --dport<span style="color:#f92672">=</span><span style="color:#ae81ff">443</span> -j DROP
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --direct --add-rule ipv4 filter OUTPUT <span style="color:#ae81ff">0</span> -p tcp -m tcp --dport<span style="color:#f92672">=</span><span style="color:#ae81ff">80</span> -j DROP
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --direct --add-rule ipv4 filter OUTPUT <span style="color:#ae81ff">1</span> -j ACCEPT
</span></span><span style="display:flex;"><span>firewall-cmd --reload
</span></span></code></pre></div><p>Enable hardened mode.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p /etc/rancher/rke2
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt;  /etc/rancher/rke2/config.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">write-kubeconfig-mode: &#34;0644&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">profile: &#34;cis-1.5&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">selinux: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo cp -f /usr/share/rke2/rke2-cis-sysctl.conf /etc/sysctl.d/60-rke2-cis.conf
</span></span><span style="display:flex;"><span>sysctl -p /etc/sysctl.d/60-rke2-cis.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>useradd -r -c <span style="color:#e6db74">&#34;etcd user&#34;</span> -s /sbin/nologin -M etcd
</span></span></code></pre></div><p>On my VM there is multiple network interface So I will configure what to use the kubernetes engine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p /var/lib/rancher/rke2/server/manifests/
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /var/lib/rancher/rke2/server/manifests/rke2-canal-config.yml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: helm.cattle.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: HelmChartConfig
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: rke2-canal
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  valuesContent: |-
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    flannel:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      iface: &#34;enp0s8&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /var/lib/rancher/rke2/server/manifests/rke2-ingress-nginx-config.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: helm.cattle.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: HelmChartConfig
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: rke2-ingress-nginx
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  valuesContent: |-
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    controller:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      metrics:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        enable: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        service:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          annotations:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            prometheus.io/scrape: &#34;true&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            prometheus.io/port: &#34;10254&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt; EOF &gt; /var/lib/rancher/rke2/server/manifests/rke2-kube-proxy-config.yaml
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: helm.cattle.io/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: HelmChartConfig
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: rke2-kube-proxy
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  namespace: kube-system
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  valuesContent: |-
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    metricsBindAddress: 0.0.0.0:10249
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl enable rke2-server.service
</span></span><span style="display:flex;"><span>systemctl start rke2-server.service
</span></span><span style="display:flex;"><span>journalctl -u rke2-server -f
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir ~/.kube
</span></span><span style="display:flex;"><span>ln -s /etc/rancher/rke2/rke2.yaml ~/.kube/config
</span></span><span style="display:flex;"><span>ln -s /var/lib/rancher/rke2/agent/etc/crictl.yaml /etc/crictl.yaml
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">600</span> ~/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get node
</span></span><span style="display:flex;"><span>crictl ps
</span></span><span style="display:flex;"><span>crictl images
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl edit psp global-restricted-psp
</span></span><span style="display:flex;"><span><span style="color:#75715e"># remove apparmor lines in annotation and save</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">### Autodeploy folder</span>
</span></span><span style="display:flex;"><span>/var/lib/rancher/rke2/server/manifests/
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="rke2" term="rke2" label="rke2" />
                             
                                <category scheme="rancher" term="rancher" label="rancher" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Best Practices to keeping Kubernetes Clusters Secure]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-security/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s and calico with eBPF mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ipvs/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s with IPVS mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-openebs/?utm_source=atom_feed" rel="related" type="text/html" title="Install OpenEBS for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kubeadm-ha/?utm_source=atom_feed" rel="related" type="text/html" title="How to install kubernetes with kubeadm in HA mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-security/</id>
            
            
            <published>2020-11-20T00:00:00+00:00</published>
            <updated>2020-11-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Kubernetes offers rich configuration options, but defaults are usually the least secure. Most sysadmin did not knows how to secure a kubernetes cluster. So this is my Best Practice list to keeping Kubernetes Clusters Secure.</p>


<H3>Parts of the K8S Security Lab series</H3>
<H5>Container Runetime Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/firecracker-cri-o/">How to deploy CRI-O with Firecracker?</a></li>
     <li>Part2: <a href="../../kubernetes/gvisor-cri-o/">How to deploy CRI-O with gVisor?</a></li>
     <li>Part3: <a href="../../kubernetes/firecracker-containerd/">How to deploy containerd with Firecracker?</a></li>
     <li>Part4: <a href="../../kubernetes/gvisor-containerd/">How to deploy containerd with gVisor?</a></li>
     <li>Part5: <a href="../../kubernetes/kata-container-containerd/">How to deploy containerd with kata containers?</a></li>
</ul>
<H5>Advanced Kernel Security</H5>
<ul>
<!-- selinux, secomp, namespace, -->
     <li>Part1: <a href="../../kubernetes/k8s-secomp/">Hardening Kubernetes with seccomp</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-namespace/">Linux user namespace management wit CRI-O in Kubernetes</a></li>
     <!-- selinux
         https://docs.rke2.io/security/selinux
         https://dev.to/carminezacc/does-kubernetes-support-selinux-3oop
         https://suraj.io/post/single-node-k8s-fedora-selinux/
         https://lisowski0925.medium.com/restricting-root-using-selinux-to-limit-access-to-container-engine-socket-with-selinux-in-fcf1b188d6df

         https://jaosorior.dev/2019/selinux-as-a-resource-in-kubernetes/

         https://stackoverflow.com/questions/51000791/how-to-mount-hostpath-volume-in-kubernetes-with-selinux
         https://kubernetes.io/blog/2023/04/18/kubernetes-1-27-efficient-selinux-relabeling-beta/

         https://github.com/JAORMX/selinux-k8s/tree/master
         https://github.com/containers/udica
     -->
     <!-- secomp operator -->
     <li>Part3: <a href="../../kubernetes/k8s-seccomp/">Hardening Kubernetes with seccomp</a></li>
</ul>
<H5>Network Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/rke2-calico/">RKE2 Install With Calico</a></li>
     <li>Part2: <a href="../../kubernetes/rke2-cilium/">RKE2 Install With Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/cni-genie/">CNI-Genie: network separation with multiple CNI</a></li>
     <li>Part3: <a href="../../kubernetes/multus-nmstate/">Configurre network wit nmstate operator</a></li>
<!-- Network policy -->
     <li>Part3: <a href="../../kubernetes/k8s-networkpolicy/">Kubernetes Network Policy</a></li>
<!-- Ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-dmz-vxlan/">Kubernetes with external Ingress Controller with vxlan</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-dmz-bgp/">Kubernetes with external Ingress Controller with bgp</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-central-oauth/">Central authentication with oauth2-proxy</a></li>
     <li>Part5: <a href="../../kubernetes/k8s-pomerium-ingress-controller/">Secure your applications with Pomerium Ingress Controller</a></li>
     </a></li>
<!-- IDS waf -->
     <li>Part6: <a href="../../kubernetes/k8s-crowdsec-ids/">CrowdSec Intrusion Detection System (IDS) for Kubernetes</a></li>
     <!-- nginx ingress controller modsecurity -->
     <li>Part7: <a href="../../kubernetes/k8s-falco/">Kubernetes audit logs and Falco</a></li>
</ul>
<H5>Secure Kubernetes Install</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-security/">Best Practices to keeping Kubernetes Clusters Secure</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-secure-install/">Kubernetes Secure Install</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-cisa-install">Kubernetes Hardening Guide with CIS 1.6 Benchmark</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>
<H5>User Security</H5>
<ul>
     <li>Part1: <a href="../../kubernetes/k8s-rbac-gen/">How to create kubeconfig?</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-user-accounts/">How to create Users in Kubernetes the right way?</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-pinniped/">Kubernetes Single Sign-on with Pinniped OpenID Connect</a></li>
     <li>Part4: <a href="../../kubernetes/k8s-kuberos/">Kubectl authentication with Kuberos</a> <b>Depricated !!</b></li>
     <li>Part5: <a href="../../kubernetes/k8s-gangway/">Kubernetes authentication with Keycloak and gangway</a> <b>Depricated !!</b></li>
     <li>Part6: <a href="../../kubernetes/kube-openid-connect-1.0/">kube-openid-connect 1.0</a> <b>Depricated !!</b></li>
</ul>
<H5>Image Security</H5>
<!-- ## Image Scan -->
     <li>Part1: <a href="../../kubernetes/image-security-admission-controller/">Image security Admission Controller</a></li>
     <li>Part2: <a href="../../kubernetes/image-security-admission-controller-v2/">Image security Admission Controller V2</a></li>
     <li>Part3: <a href="../../kubernetes/image-security-admission-controller-v3/">Image security Admission Controller V3</a></li>
<!-- ### trivy-operator -->
     <li>Part4: <a href="../../kubernetes/continuous-image-security/">Continuous Image security</a></li>
     <li>Part5: <a href="../../kubernetes/trivy-operator-1.0/">trivy-operator 1.0</a></li>
     <li>Part6: <a href="../../kubernetes/trivy-operator-2.1/">trivy-operator 2.1: Trivy-operator is now an Admisssion controller too!!!</a></li>
     <li>Part7: <a href="../../kubernetes/trivy-operator-2.2/">trivy-operator 2.2: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.3/">trivy-operator 2.3: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.4/">trivy-operator 2.4: Patch release for Admisssion controller</a></li>
     <li>Part8: <a href="../../kubernetes/trivy-operator-2.5/">trivy-operator 2.5: Patch release for Admisssion controller</a></li>
<!-- ## Image Signature Verification -->
     <!-- CRI-O Image verification -->
     <li>Part9_ <a href="../../kubernetes/k8s-connaisseur/">Image Signature Verification with Connaisseur</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-connaisseur-v2/">Image Signature Verification with Connaisseur 2.0</a></li>
     <li>Part11: <a href="../../kubernetes/k8s-kyverno-cosign/">Image Signature Verification with Kyverno</a></li>
     <!-- Image Encription
       https://itnext.io/securing-kubernetes-workloads-a-practical-approach-to-signed-and-encrypted-container-images-ff6e98b65bcd 
     -->
<!-- # Image registry security -->
     <li>Part12: <a href="../../kubernetes/k8s-imagepullsecret-patcher/">How to use imagePullSecrets cluster-wide??</a></li>
     <li>Part13: <a href="../../kubernetes/kyverno-image-mirror/">Automatically change registry in pod definition</a></li>
<!-- # Image Update -->
     <!-- keel -->
     <li>Part14: <a href="../../kubernetes/argocd-image-updater/">ArgoCD auto image updater</a></li>
<ul>
</ul>
<H5>Pod Security</H5>
<ul>
<!--# Admission Controllers -->
     <li>Part1: <a href="../../kubernetes/admission-controllers/">Using Admission Controllers</a></li>
<!-- ## Pod Security Policy and Pod Security Admission -->
     <li>Part2: <a href="../../kubernetes/rke2-pod-security-policy/">RKE2 Pod Security Policy</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-ps/">Kubernetes Pod Security Admission</a></li>
     <!-- RKE2 Pod Security Admission - https://docs.rke2.io/security/pod_security_standards -->
     <li>Part4: <a href="../../kubernetes/k8s-migrate-from-psp/">Kubernetes: How to migrate Pod Security Policy to Pod Security Admission?</a></li>
<!-- ## Kyverno -->
     <li>Part5: <a href="../../kubernetes/k8s-pod-security-standards-using-kyverno/">Pod Security Standards using Kyverno</a></li>
     <li>Part6: <a href="../../kubernetes/kubernetes-policy/">Kubernetes Cluster Policy with Kyverno</a></li>
</ul>
<H5>Secret Security</H5>
<ul>
<!-- # Secrets -->
     <li>Part1: <a href="../../kubernetes/k8s-vault/">Kubernetes and Vault integration</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-vault-v2/">Kubernetes External Vault integration</a></li>
     <li>Part3: <a href="../../kubernetes/argocd-kubeseal/">ArgoCD and kubeseal to encript secrets</a></li>
     <li>Part4: <a href="../../kubernetes/gitops-flux2-kubeseal/">Flux2 and kubeseal to encrypt secrets</a></li>
     <li>Part5: <a href="../../kubernetes/gitops-flux2-sops/">Flux2 and Mozilla SOPS to encrypt secrets</a></li>

</ul>
<H5>Monitoring and Observability</H5>
<ul>
<!-- monitoring, logging, observation -->
     <li>Part6: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part7: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
</ul>
<H5>Backup</H5>
<ul>
<!-- # Backup -->
     <li>Part1: <a href="../../kubernetes/k8s-backup/">Backup your Kubernetes Cluster</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>

<!-- https://github.com/banzaicloud/dast-operator -->
<!-- kyverno logs and monitoring -->
<!-- CIS Exporter https://github.com/ibrokethecloud/kube-bench-metrics -->
<!-- # Image Update -->
<!-- sysdig falco -->
<!-- Image auto update:
https://keel.sh
https://blog.weareopensource.me/kell-automate-rancher-workloads-update/
flux
https://github.com/weaveworks/kured
-->
<!-- resource kvota -->
</ul>



<h3 id="use-firewalld">Use firewalld</h3>
<p>In most tutorial the first thing in a Kubernets installation is to disable the firewall because is it easier than configure properly.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># master</span>
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>6443/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>2379-2380/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>10250/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>10251/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>10252/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>10255/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>8472/udp
</span></span><span style="display:flex;"><span>firewall-cmd --add-masquerade --permanent
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>30000-32767/tcp
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># worker</span>
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>10250/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>10255/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>8472/udp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>30000-32767/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --add-masquerade --permanent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># frontend</span>
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>10250/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>10255/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>8472/udp
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>30000-32767/tcp
</span></span><span style="display:flex;"><span>firewall-cmd --add-masquerade --permanent
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --zone<span style="color:#f92672">=</span>public --add-service<span style="color:#f92672">=</span>http
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --zone<span style="color:#f92672">=</span>public --add-service<span style="color:#f92672">=</span>https
</span></span></code></pre></div><h3 id="enabling-signed-kubelet-serving-certificates">Enabling signed kubelet serving certificates</h3>
<p>By default the kubelet serving certificate deployed by kubeadm is self-signed. This means a connection from external services like the <code>metrics-server</code> to a kubelet cannot be secured with TLS.</p>
<p>To configure the kubelets in a new kubeadm cluster to obtain properly signed serving certificates you must pass the following minimal configuration to <code>kubeadm init</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>apiVersion: kubeadm.k8s.io/v1beta3
</span></span><span style="display:flex;"><span>kind: ClusterConfiguration
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiVersion: kubelet.config.k8s.io/v1beta1
</span></span><span style="display:flex;"><span>kind: KubeletConfiguration
</span></span><span style="display:flex;"><span>serverTLSBootstrap: true
</span></span></code></pre></div><p>If you whant to know more about certificates and thear rotation chenck <a href="/kubernetes/k8s-cert/">my blog post</a>.</p>
<h3 id="pod-network-add-on">Pod network add-on</h3>
<p>Several external projects provide Kubernetes Pod networks using CNI, some of which also support Network Policy. Use one of them.</p>
<ul>
<li>Calico</li>
<li>Canal</li>
<li>Weave Net</li>
<li>Contiv</li>
<li>Cilium</li>
</ul>
<p>See the list of available <a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/#networking-and-network-policy">networking and network policy add-ons</a>.</p>
<h3 id="using-rbac-authorization">Using RBAC Authorization</h3>
<p>Role-based access control (RBAC) is a method of regulating access to computer or network resources based on the roles of individual users within your organization. For that you need to create <code>Role</code> or <code>ClusterRole</code> objects then assign that objects to a user wit <code>RoleBinding</code> or <code>ClusterRoleBinding</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceAccount</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">deployer</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">$NAMESPACE</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">deployer-access</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">$NAMESPACE</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">deployer-access</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">$NAMESPACE</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;&#34;</span>, <span style="color:#e6db74">&#34;extensions&#34;</span>, <span style="color:#e6db74">&#34;apps&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>: [<span style="color:#e6db74">&#34;*&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;*&#34;</span>]
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>: [<span style="color:#e6db74">&#34;batch&#34;</span>]
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">jobs</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">cronjobs</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>: [<span style="color:#e6db74">&#34;*&#34;</span>]
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">deployer</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">$NAMESPACE</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceAccount</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">deployer</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">$NAMESPACE</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">deployer-access</span>
</span></span></code></pre></div><h3 id="podsecuritypolicy">PodSecurityPolicy</h3>
<p>At default configuration users in docker containers has the same UID and GUID pool than the users on the host system. So if an unprivileged user runs a container as root and mount the host&rsquo;s filesystem to this container it can do what avers it wants on your host. Docker has an option to change the id pool us the users in the containers but kubernetes dose not support it. The RBAC adds access to an apiGroup like create deployments but dose not allow to configure the options you can use in the deployment.</p>
<p>A PodSecurityPolicy is a cluster-level resource for managing security aspects of a pod specification.</p>
<p>PSPs allow you to control:</p>
<ul>
<li>The ability to run privileged containers and control privilege escalation</li>
<li>Access to host filesystems</li>
<li>Usage of volume types</li>
<li>And a few other aspects including SELinux, AppArmor, sysctl, and seccomp profiles</li>
</ul>
<p>Pod Security Policies are implemented as an Admission Controller in Kubernetes. To enable PSPs in your cluster, make sure to include PodSecurityPolicy in the enable-admission-plugins list that is passed as a parameter to your Kubernetes API configuration:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/kubernetes/manifests/kube-apiserver.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>--enable-admission-plugins<span style="color:#f92672">=</span>...,PodSecurityPolicy
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><h4 id="creating-pod-security-policies">Creating Pod Security Policies</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">policy/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PodSecurityPolicy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">restricted</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">seccomp.security.alpha.kubernetes.io/allowedProfileNames</span>: <span style="color:#e6db74">&#39;docker/default&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apparmor.security.beta.kubernetes.io/allowedProfileNames</span>: <span style="color:#e6db74">&#39;runtime/default&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">seccomp.security.alpha.kubernetes.io/defaultProfileName</span>:  <span style="color:#e6db74">&#39;runtime/default&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apparmor.security.beta.kubernetes.io/defaultProfileName</span>:  <span style="color:#e6db74">&#39;runtime/default&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">privileged</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">allowPrivilegeEscalation</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">defaultAllowPrivilegeEscalation</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">readOnlyRootFilesystem</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hostNetwork</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hostIPC</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hostPID</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">requiredDropCapabilities</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">ALL</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#39;configMap&#39;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#39;emptyDir&#39;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#39;projected&#39;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#39;secret&#39;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#39;downwardAPI&#39;</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#e6db74">&#39;persistentVolumeClaim&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hostPorts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">min</span>: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">max</span>: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">seLinux</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rule</span>: <span style="color:#e6db74">&#39;RunAsAny&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">runAsUser</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rule</span>: <span style="color:#e6db74">&#39;MustRunAsNonRoot&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">supplementalGroups</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rule</span>: <span style="color:#e6db74">&#39;MustRunAs&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ranges</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">min</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">max</span>: <span style="color:#ae81ff">65535</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">fsGroup</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rule</span>: <span style="color:#e6db74">&#39;MustRunAs&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ranges</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">min</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">max</span>: <span style="color:#ae81ff">65535</span>
</span></span></code></pre></div><h4 id="assigning-pod-security-policies">Assigning Pod Security Policies</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">psp:restricted</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">extensions</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">podsecuritypolicies</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resourceNames</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">restricted</span> <span style="color:#75715e"># the psp we are giving access to</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">use</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#75715e"># This applies psp/restricted to all authenticated users</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">psp:restricted</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Group</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">system:authenticated</span> <span style="color:#75715e"># All authenticated users</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">psp:restricted</span> <span style="color:#75715e"># A references to the role above</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">view raw</span>
</span></span></code></pre></div><h3 id="audit-log">Audit Log</h3>
<p>Usually it’s a best practice to enable audits in your cluster. Let’s go ahead and create a basic policy saved in our master.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">mkdir -p /etc/kubernetes</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">cat &gt; /etc/kubernetes/audit-policy.yaml &lt;&lt;EOF</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">audit.k8s.io/v1beta1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Policy</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Do not log from kube-system accounts</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">level</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">userGroups</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">system:serviceaccounts:kube-system</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">system:nodes</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">level</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">users</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">system:apiserver</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">system:kube-scheduler</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">system:volume-scheduler</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">system:kube-controller-manager</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">system:node</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Don&#39;t log these read-only URLs.</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">level</span>: <span style="color:#ae81ff">None</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nonResourceURLs</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">/healthz*</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">/version</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">/swagger*</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># limit level to Metadata so token is not included in the spec/status</span>
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">level</span>: <span style="color:#ae81ff">Metadata</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">omitStages</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">RequestReceived</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">group</span>: <span style="color:#ae81ff">authentication.k8s.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">tokenreviews</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">mkdir -p /var/log/kubernetes/apiserver</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kube-apiserver --audit-log-path=/var/log/kubernetes/apiserver/audit.log \</span>
</span></span><span style="display:flex;"><span>--<span style="color:#ae81ff">audit-policy-file=/etc/kubernetes/audit-policy.yaml</span>
</span></span></code></pre></div><h2 id="image-security">Image security</h2>
<p>Doesn&rsquo;t matter how secure is your kubernetes network or infrastructure is if you runs outdated unsecur images. You mast always update your base image, scan for known vulnerabilities. For applications use hardened base images and install as less components as you can. Some application for image scann:</p>
<ul>
<li>Anchore Engine</li>
<li>Clair</li>
<li>trivy</li>
</ul>
<h3 id="find-the-right-baseimage">Find the right baseimage</h3>
<p>I think the best choice for a base image is <code>Distroless</code>, which is set of images made by Google, that were created with intent to be secure. These images contain the bare minimum that&rsquo;s needed for your app.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>FROM gcr.io/distroless/python3
</span></span><span style="display:flex;"><span>COPY --from<span style="color:#f92672">=</span>build-env /app /app
</span></span><span style="display:flex;"><span>WORKDIR /app
</span></span><span style="display:flex;"><span>CMD <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;hello.py&#34;</span>, <span style="color:#e6db74">&#34;/etc&#34;</span><span style="color:#f92672">]</span>
</span></span></code></pre></div><h3 id="least-privileged-user">Least privileged user</h3>
<p>Create a dedicated user and group on the image, with minimal permissions to run the application; use the same user to run this process. For example, Node.js image which has a built-in node generic user:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>USER node
</span></span><span style="display:flex;"><span>CMD node index.js
</span></span></code></pre></div><h3 id="store-secret-in-etcd-encripted">Store secret in etcd encripted.</h3>
<p>The Kubernetes&rsquo;s base secret store is not so secure because it stores the data as base64 encoded plain text in the etcd.</p>
<p>The <code>kube-apiserver</code> process accepts an argument <code>--encryption-provider-config</code> that controls how API data is encrypted in etcd. An example configuration is provided below.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">mkdir /etc/kubernetes/etcd-enc/</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">head -c 32 /dev/urandom | base64</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">nano /etc/kubernetes/etcd-enc/etcd-encription.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apiserver.config.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">EncryptionConfiguration</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">secrets</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">providers</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">identity</span>: {}
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">aesgcm</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">keys</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">key1</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">secret</span>: <span style="color:#ae81ff">&lt;BASE 64 ENCODED SECRET&gt;</span>
</span></span></code></pre></div><p>In this example key1 is the secret contains the encryption/decryption key.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano kube-apiserver.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>    - --encryption-provider-config<span style="color:#f92672">=</span>/etc/kubernetes/etcd-enc/etcd-encription.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>    volumeMounts:
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>    - mountPath: /etc/kubernetes/etcd-enc
</span></span><span style="display:flex;"><span>      name: etc-kubernetes-etcd-enc
</span></span><span style="display:flex;"><span>      readOnly: true
</span></span><span style="display:flex;"><span>  hostNetwork: true
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>  - hostPath:
</span></span><span style="display:flex;"><span>      path: /etc/kubernetes/etcd-enc
</span></span><span style="display:flex;"><span>      type: DirectoryOrCreate
</span></span><span style="display:flex;"><span>    name: etc-kubernetes-etcd-enc
</span></span><span style="display:flex;"><span>status: <span style="color:#f92672">{}</span>
</span></span></code></pre></div><h3 id="the-cis-kubernetes-benchmark">The CIS Kubernetes Benchmark</h3>
<p>The Center for Internet Security (CIS) Kubernetes Benchmark is a reference document that can be used by system administrators, security and audit professionals and other IT roles to establish a secure configuration baseline for Kubernetes.</p>
<p>Create kube-bench job</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/master/job.yaml
</span></span><span style="display:flex;"><span>kubectl get jobs --watch
</span></span></code></pre></div><p>Get job output from logs</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl logs <span style="color:#66d9ef">$(</span>kubectl get pods -l app<span style="color:#f92672">=</span>kube-bench -o name<span style="color:#66d9ef">)</span>
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="secuity" term="secuity" label="Secuity" />
                             
                                <category scheme="calico" term="calico" label="calico" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Configure Kubernetes In-Tree vSphere Cloud Provider]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-vmware/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-vmware/?utm_source=atom_feed" rel="related" type="text/html" title="Configure Openshift In-Tree vSphere Cloud Provider" />
                <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s and calico with eBPF mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ipvs/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s with IPVS mode" />
                <link href="https://devopstales.github.io/kubernetes/openshift-rbd-fsck/?utm_source=atom_feed" rel="related" type="text/html" title="How to fixing filesystem corruption on a Kubernetes Ceph RBD PersistentVolume" />
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-vmware/</id>
            
            
            <published>2020-10-14T00:00:00+00:00</published>
            <updated>2020-10-14T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can you use vmware for persistent storagi on K8S.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="vsphere-configuration">vSphere Configuration</h3>
<ul>
<li>Create a folder for all the VMs in vCenter</li>
<li>In the navigator, select the data center</li>
<li>Right-click and select the menu option to create the folder.</li>
<li>Select: All vCenter Actions &gt; New VM and Template Folder.</li>
<li>Move K8S vms to this folder</li>
<li>The name of the virtual machine must match the name of the nodes for the K8S cluster.</li>
</ul>
<p><img src="/img/include/k8s-vmware.png" alt="Example image"  class="zoomable" /></p>
<h3 id="set-up-the-govc-environment">Set up the GOVC environment:</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># on deployer</span>
</span></span><span style="display:flex;"><span>curl -LO https://github.com/vmware/govmomi/releases/download/v0.20.0/govc_linux_amd64.gz
</span></span><span style="display:flex;"><span>gunzip govc_linux_amd64.gz
</span></span><span style="display:flex;"><span>chmod +x govc_linux_amd64
</span></span><span style="display:flex;"><span>cp govc_linux_amd64 /usr/bin/govc
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;export GOVC_URL=&#39;vCenter IP OR FQDN&#39;&#34;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;export GOVC_USERNAME=&#39;vCenter User&#39;&#34;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;export GOVC_PASSWORD=&#39;vCenter Password&#39;&#34;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;export GOVC_INSECURE=1&#34;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>source /etc/profile
</span></span></code></pre></div><p>Add <code>disk.enableUUID=1</code> for all VM:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>govc vm.info &lt;vm&gt;
</span></span><span style="display:flex;"><span>govc ls /Datacenter/kubernetes/&lt;vm-folder-name&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e"># example:</span>
</span></span><span style="display:flex;"><span>govc ls /Datacenter/kubernetes/k8s-01
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>govc vm.change -e<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;disk.enableUUID=1&#34;</span> -vm<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;VM Path&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># example:</span>
</span></span><span style="display:flex;"><span>govc vm.change -e<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;disk.enableUUID=1&#34;</span> -vm<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;/datacenter/kubernetes/k8s-01/k8s-m01&#39;</span>
</span></span></code></pre></div><p>VM Hardware should be at version 15 or higher. Upgrade if needed:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>govc vm.option.info <span style="color:#e6db74">&#39;/datacenter/kubernetes/k8s-01/k8s-m01&#39;</span> | grep HwVersion
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>govc vm.upgrade -version<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span> -vm <span style="color:#e6db74">&#39;/datacenter/kubernetes/k8s-01/k8s-m01&#39;</span>
</span></span></code></pre></div><h3 id="create-the-required-roles">Create the required Roles</h3>
<ul>
<li>Navigate in the vSphere Client - Menu &gt; Administration &gt; Roles</li>
<li>Add a new Role and select the permissions required. Repeat for each role.</li>
</ul>
<table>
  <thead>
      <tr>
          <th style="text-align: center">Roles</th>
          <th style="text-align: center">Privileges</th>
          <th style="text-align: center">Entities</th>
          <th style="text-align: center">Propagate to Children</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">vcp-manage-k8s-node-vms</td>
          <td style="text-align: center">Resource.AssignVMToPoolVirtualMachine.Config.AddExistingDisk, VirtualMachine.Config.AddNewDisk, VirtualMachine.Config.AddRemoveDevice, VirtualMachine.Config.RemoveDisk, VirtualMachine.Config.SettingsVirtualMachine.Inventory.Create, VirtualMachine.Inventory.Delete</td>
          <td style="text-align: center">Cluster, Hosts, VM Folder</td>
          <td style="text-align: center">Yes</td>
      </tr>
      <tr>
          <td style="text-align: center">vcp-manage-k8s-volumes</td>
          <td style="text-align: center">Datastore.AllocateSpace, Datastore.FileManagement (Low level file operations)</td>
          <td style="text-align: center">Datastore</td>
          <td style="text-align: center">No</td>
      </tr>
      <tr>
          <td style="text-align: center">vcp-view-k8s-spbm-profile</td>
          <td style="text-align: center">StorageProfile.View (Profile-driven storage view)</td>
          <td style="text-align: center">vCenter</td>
          <td style="text-align: center">No</td>
      </tr>
      <tr>
          <td style="text-align: center">Read-only (pre-existing default role)</td>
          <td style="text-align: center">System.Anonymous, System.Read, System.View</td>
          <td style="text-align: center">Datacenter, Datastore Cluster, Datastore Storage Folder</td>
          <td style="text-align: center">No</td>
      </tr>
  </tbody>
</table>
<h3 id="create-a-service-account">Create a service account</h3>
<ul>
<li>Create a vsphere user, or add a domain user, to provide access and assign the new roles to.</li>
</ul>
<h3 id="create-vsphereconf">Create vsphere.conf</h3>
<p>Create the vSphere configuration file in /etc/kubernetes/vcp/vsphere.conf - you’ll need to create the folder.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/kubernetes/vcp/vsphere.conf
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Global<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>user <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;k8s-user@vsphere.local&#34;</span>
</span></span><span style="display:flex;"><span>password <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;password for k8s-user&#34;</span>
</span></span><span style="display:flex;"><span>port <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;443&#34;</span>
</span></span><span style="display:flex;"><span>insecure-flag <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>VirtualCenter <span style="color:#e6db74">&#34;10.0.1.200&#34;</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>datacenters <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;DC-1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Workspace<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>server <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;10.0.1.200&#34;</span>
</span></span><span style="display:flex;"><span>datacenter <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;DC-1&#34;</span>
</span></span><span style="display:flex;"><span>default-datastore <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;vsanDatastore&#34;</span>
</span></span><span style="display:flex;"><span>resourcepool-path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;ClusterNameHere/Resources&#34;</span>
</span></span><span style="display:flex;"><span>folder <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;kubernetes&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Disk<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>scsicontrollertype <span style="color:#f92672">=</span> pvscsi
</span></span></code></pre></div><h3 id="modify-the-kubelet-service">Modify the kubelet service</h3>
<p>On master:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/systemd/system/kubelet.service
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Service<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>ExecStart<span style="color:#f92672">=</span>/usr/bin/docker run <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>...
</span></span><span style="display:flex;"><span>        /hyperkube kubelet <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>...
</span></span><span style="display:flex;"><span>--cloud-provider<span style="color:#f92672">=</span>vsphere --cloud-config<span style="color:#f92672">=</span>/etc/kubernetes/vsphere.conf    
</span></span></code></pre></div><p>On worker:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/systemd/system/kubelet.service
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Service<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>ExecStart<span style="color:#f92672">=</span>/usr/bin/docker run <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>...
</span></span><span style="display:flex;"><span>        /hyperkube kubelet <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>...
</span></span><span style="display:flex;"><span>--cloud-provider<span style="color:#f92672">=</span>vsphere  
</span></span></code></pre></div><h3 id="modify-container-manifests">Modify container manifests</h3>
<p>Add following flags to the kubelet service configuration (usually in the systemd config file), as well as the controller-manager and api-server container manifest files on the master node (usually in /etc/kubernetes/manifests).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/kubernetes/manifests/kube-apiserver.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  containers:
</span></span><span style="display:flex;"><span>  - command:
</span></span><span style="display:flex;"><span>    - kube-apiserver
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>    - --cloud-provider<span style="color:#f92672">=</span>vsphere
</span></span><span style="display:flex;"><span>    - --cloud-config<span style="color:#f92672">=</span>/etc/kubernetes/vsphere.conf
</span></span><span style="display:flex;"><span>    volumeMounts:
</span></span><span style="display:flex;"><span>    - mountPath: /etc/kubernetes/vcp
</span></span><span style="display:flex;"><span>      name: vcp
</span></span><span style="display:flex;"><span>      readOnly: true
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>  volumes:
</span></span><span style="display:flex;"><span>  - hostPath:
</span></span><span style="display:flex;"><span>      path: /etc/kubernetes/vcp
</span></span><span style="display:flex;"><span>      type: DirectoryOrCreate
</span></span><span style="display:flex;"><span>    name: vcp
</span></span></code></pre></div><p>Restart the services.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl restart kubelet docker
</span></span></code></pre></div><h3 id="add-providerid">Add providerID</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get nodes -o json | jq <span style="color:#e6db74">&#39;.items[]|[.metadata.name, .spec.providerID, .status.nodeInfo.systemUUID]&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano k8s-vmware-pacher.sh
</span></span><span style="display:flex;"><span>DATACENTER<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&lt;Datacenter&gt;&#39;</span>
</span></span><span style="display:flex;"><span>FOLDER<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&lt;vm-folder-name&gt;&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> vm in <span style="color:#66d9ef">$(</span>govc ls /$DATACENTER/vm/$FOLDER <span style="color:#66d9ef">)</span>; <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>  MACHINE_INFO<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>govc vm.info -json -dc<span style="color:#f92672">=</span>$DATACENTER -vm.ipath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span>$vm<span style="color:#e6db74">&#34;</span> -e<span style="color:#f92672">=</span>true<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># My VMs are created on vmware with upper case names, so I need to edit the names with awk</span>
</span></span><span style="display:flex;"><span>  VM_NAME<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>jq -r <span style="color:#e6db74">&#39; .VirtualMachines[] | .Name&#39;</span> <span style="color:#f92672">&lt;&lt;&lt;</span> $MACHINE_INFO | awk <span style="color:#e6db74">&#39;{print tolower($0)}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># UUIDs come in lowercase, upper case then</span>
</span></span><span style="display:flex;"><span>  VM_UUID<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span> jq -r <span style="color:#e6db74">&#39; .VirtualMachines[] | .Config.Uuid&#39;</span> <span style="color:#f92672">&lt;&lt;&lt;</span> $MACHINE_INFO | awk <span style="color:#e6db74">&#39;{print toupper($0)}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>  echo <span style="color:#e6db74">&#34;Patching </span>$VM_NAME<span style="color:#e6db74"> with UUID:</span>$VM_UUID<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># This is done using dry-run to avoid possible mistakes, remove when you are confident you got everything right.</span>
</span></span><span style="display:flex;"><span>  kubectl patch node $VM_NAME -p <span style="color:#e6db74">&#34;{\&#34;spec\&#34;:{\&#34;providerID\&#34;:\&#34;vsphere://</span>$VM_UUID<span style="color:#e6db74">\&#34;}}&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>chmod +x openshift-vmware-pacher.sh
</span></span><span style="display:flex;"><span>./openshift-vmware-pacher.sh
</span></span></code></pre></div><h3 id="create-vsphere-storage-class">Create vSphere storage-class</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano vmware-sc.yml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>kind: StorageClass
</span></span><span style="display:flex;"><span>apiVersion: storage.k8s.io/v1
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  annotations:
</span></span><span style="display:flex;"><span>    storageclass.kubernetes.io/is-default-class: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span><span style="display:flex;"><span>  name: <span style="color:#e6db74">&#34;vsphere-standard&#34;</span>
</span></span><span style="display:flex;"><span>provisioner: kubernetes.io/vsphere-volume
</span></span><span style="display:flex;"><span>parameters:
</span></span><span style="display:flex;"><span>    diskformat: zeroedthick
</span></span><span style="display:flex;"><span>    datastore: <span style="color:#e6db74">&#34;NFS&#34;</span>
</span></span><span style="display:flex;"><span>reclaimPolicy: Delete
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl aplay -f vmware-sc.yml
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="vmware" term="vmware" label="vmware" />
                             
                                <category scheme="vsphere" term="vsphere" label="vSphere" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install k8s and calico with eBPF mode]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-ipvs/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s with IPVS mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-openebs/?utm_source=atom_feed" rel="related" type="text/html" title="Install OpenEBS for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kubeadm-ha/?utm_source=atom_feed" rel="related" type="text/html" title="How to install kubernetes with kubeadm in HA mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
                <link href="https://devopstales.github.io/kubernetes/openshift-rbd-fsck/?utm_source=atom_feed" rel="related" type="text/html" title="How to fixing filesystem corruption on a Kubernetes Ceph RBD PersistentVolume" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-calico-ebpf/</id>
            
            
            <published>2020-10-13T00:00:00+00:00</published>
            <updated>2020-10-13T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to install kubernetes Without kube-proxy using calico with eBPF mode.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="wthat-is-kube-proxy">Wthat is kube-proxy</h3>
<p>kube-proxy is a key component of any Kubernetes deployment.  Its role is to load-balance traffic to the pods. It listens to all the service requests coming through from kubernetes and creates entries in iptables for each of these service IPs to achieve proper routing to the pod. So kube-proxy adds iptables ruleset for each new service defined. As the number of services grow, this list is going to be huge. This potentially impact the performance because the iptables processing is sequential and wit every new line the list goes longer and longer. Kubernetes&rsquo;s solution for this problem was IPVS.</p>
<h3 id="what-is-ipvs">What is IPVS?</h3>
<p>IPVS (IP Virtual Server) is built on top of the Netfilter and implements transport-layer load balancing as part of the Linux kernel. It runs on a host and acts as a load balancer in front of a cluster of real servers. IPVS can direct requests for TCP- and UDP-based services to the real servers, and make services of the real servers appear as virtual services on a single IP address. Therefore, IPVS naturally supports Kubernetes Service. IPVS mode provides greater scale and performance vs iptables mode. However, it comes with some limitations. There is no option to install IPVS mode in kubeadm. <a href="../../cloud/k8s-ipvs/">In the previous post you can see ho you can do install.</a> The other solution is eBPF.</p>
<h3 id="what-is-ebpf-">What is eBPF ?</h3>
<p>eBPF is a virtual machine embedded within the Linux kernel. It allows small programs to be loaded into the kernel, and attached to hooks, which are triggered when some event occurs. For example, when a network interface emits a packet.</p>
<h3 id="requirements">Requirements</h3>
<p>First you need a supported Linuy Distrubution:</p>
<ul>
<li>Ubuntu 20.04.</li>
<li>Red Hat v8.2 with Linux kernel v4.18.0-193 or above (Red Hat have backported the required features to that build on CentOS 8 but not on 7)</li>
<li>Pre installed K8s cluster</li>
</ul>
<p>Verify that your cluster is ready for eBPF mode</p>
<pre tabindex="0"><code>mount | grep &#34;/sys/fs/bpf&#34;
bpf on /sys/fs/bpf type bpf (rw,nosuid,nodev,noexec,relatime,mode=700)
</code></pre><h3 id="install-calico-with-operator">Install Calico With Operator</h3>
<p>We need to change the <code>cidr</code> in <code>custom-resources.yaml</code> to match to our clusters <code>cdir</code>.</p>
<pre tabindex="0"><code>kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml

wget https://docs.projectcalico.org/manifests/custom-resources.yaml
nano custom-resources.yaml
...
cidr: 10.244.0.0/16


kubectl create -f custom-resources.yaml
watch kubectl get pods -n calico-system
</code></pre><h3 id="configure-calicoctl">Configure calicoctl</h3>
<pre tabindex="0"><code>export CALICO_DATASTORE_TYPE=kubernetes
export CALICO_KUBECONFIG=~/.kube/config
calicoctl get workloadendpoints
calicoctl get nodes
</code></pre><p>Configure tigera-operator to communicate with kubernetes&rsquo;s api.</p>
<pre tabindex="0"><code>nano kubernetes-services-endpoint.yaml
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: kubernetes-services-endpoint
  namespace: tigera-operator
data:
  KUBERNETES_SERVICE_HOST: &#34;172.17.9.10&#34;
  KUBERNETES_SERVICE_PORT: &#34;6443&#34;

kubectl apply -f  kubernetes-services-endpoint.yaml
kubectl delete pod -n tigera-operator -l k8s-app=tigera-operator
watch kubectl get pods -n calico-system
</code></pre><h3 id="change-to-ebpf-mode">Change to eBPF mode</h3>
<p>First we change kube-proxy&rsquo;s <code>nodeSelector</code> to a none existing node to disable <code>kube-proxy</code>, the patch calico to run in eBPF mode.</p>
<pre tabindex="0"><code>kubectl patch ds -n kube-system kube-proxy -p &#39;{&#34;spec&#34;:{&#34;template&#34;:{&#34;spec&#34;:{&#34;nodeSelector&#34;:{&#34;non-calico&#34;: &#34;true&#34;}}}}}&#39;
calicoctl patch felixconfiguration default --patch=&#39;{&#34;spec&#34;: {&#34;bpfKubeProxyIptablesCleanupEnabled&#34;: false}}&#39;
calicoctl patch felixconfiguration default --patch=&#39;{&#34;spec&#34;: {&#34;bpfEnabled&#34;: true}}&#39;
calicoctl patch felixconfiguration default --patch=&#39;{&#34;spec&#34;: {&#34;bpfExternalServiceMode&#34;: &#34;DSR&#34;}}&#39;
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="kube-proxy" term="kube-proxy" label="kube-proxy" />
                             
                                <category scheme="calico" term="calico" label="calico" />
                             
                                <category scheme="ebpf" term="ebpf" label="ebpf" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install k8s with IPVS mode]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-ipvs/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-calico-ebpf/?utm_source=atom_feed" rel="related" type="text/html" title="Install k8s and calico with eBPF mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-openebs/?utm_source=atom_feed" rel="related" type="text/html" title="Install OpenEBS for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kubeadm-ha/?utm_source=atom_feed" rel="related" type="text/html" title="How to install kubernetes with kubeadm in HA mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
                <link href="https://devopstales.github.io/kubernetes/openshift-rbd-fsck/?utm_source=atom_feed" rel="related" type="text/html" title="How to fixing filesystem corruption on a Kubernetes Ceph RBD PersistentVolume" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-ipvs/</id>
            
            
            <published>2020-10-13T00:00:00+00:00</published>
            <updated>2020-10-13T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to install kubernetes with kube-proxy IPVS mode.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="wthat-is-kube-proxy">Wthat is kube-proxy</h3>
<p>kube-proxy is a key component of any Kubernetes deployment.  Its role is to load-balance traffic to the pods. It listens to all the service requests coming through from kubernetes and creates entries in iptables for each of these service IPs to achieve proper routing to the pod. So kube-proxy adds iptables ruleset for each new service defined. As the number of services grow, this list is going to be huge. This potentially impact the performance because the iptables processing is sequential and wit every new line the list goes longer and longer. Kubernetes&rsquo;s solution for this problem was IPVS.</p>
<h3 id="what-is-ipvs">What is IPVS?</h3>
<p>IPVS (IP Virtual Server) is built on top of the Netfilter and implements transport-layer load balancing as part of the Linux kernel. It runs on a host and acts as a load balancer in front of a cluster of real servers. IPVS can direct requests for TCP- and UDP-based services to the real servers, and make services of the real servers appear as virtual services on a single IP address. Therefore, IPVS naturally supports Kubernetes Service. IPVS mode provides greater scale and performance vs iptables mode.</p>
<p>Installing Kubernetes with IPVS kube-proxy mode is a little bit hard because there in no built in option for theat in kubeadm. So we have two option. Createt a custom kubeadm.yaml or edit an installed cluster.</p>
<h3 id="install-requirements">Install Requirements</h3>
<pre tabindex="0"><code>yum install ipset ipvsadm -y

cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF
chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4
</code></pre><h3 id="createt-a-custom-kubeadmyaml">Createt a custom kubeadm.yaml</h3>
<pre tabindex="0"><code>kubeadm config print init-defaults &gt; kubeadm.yaml

nano kubeadm.yaml
...
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: ipvs
</code></pre><h3 id="edit-running-cluster">Edit running cluster</h3>
<pre tabindex="0"><code>kubectl edit configmap kube-proxy -n kube-system
...
mode: ipvs
</code></pre><pre tabindex="0"><code>kubectl get po -n kube-system
kubectl delete po -n kube-system &lt;pod-name&gt;
</code></pre><pre tabindex="0"><code>kubectl logs [kube-proxy pod] | grep &#34;Using ipvs Proxier&#34;
</code></pre><h3 id="test-ipvs-mode-is-running">Test IPVS mode is running</h3>
<pre tabindex="0"><code>ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.96.0.1:443 rr
  -&gt; 1.1.1.101:6443               Masq    1      0          0
TCP  10.96.0.10:53 rr
  -&gt; 10.244.0.2:53                Masq    1      0          0
  -&gt; 10.244.2.8:53                Masq    1      0          0
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="kube-proxy" term="kube-proxy" label="kube-proxy" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to backup and restore Prometheus?]]></title>
            <link href="https://devopstales.github.io/kubernetes/backup-and-retore-prometheus/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://devopstales.github.io/kubernetes/backup-and-retore-prometheus/</id>
            
            
            <published>2020-10-10T00:00:00+00:00</published>
            <updated>2020-10-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to take a backup from a running Prometheus and restore it.</p>
<p>I will assumes that you have a running Prometheus deployed with <code>prometheus-operator</code> in the <code>monitoring</code> namespace.</p>
<h2 id="enable-admin-api">Enable Admin Api</h2>
<p>First we need to enable the Prometheus&rsquo;s admin api</p>
<pre tabindex="0"><code>kubectl -n monitoring patch prometheus prometheus-operator-prometheus \
  --type merge --patch &#39;{&#34;spec&#34;:{&#34;enableAdminAPI&#34;:true}}&#39;
</code></pre><p>In <code>tmux</code> or a separate window open a port forward to the admin api.</p>
<pre tabindex="0"><code>ubectl -n monitoring port-forward svc/prometheus-operator-prometheus 9090
</code></pre><h3 id="backup-prometheus-data">Backup Prometheus data</h3>
<p>Run following command to create a snapshot:</p>
<pre tabindex="0"><code>curl -XPOST http://localhost:9090/api/v2/admin/tsdb/snapshot
{&#34;name&#34;:&#34;20200731T123913Z-6e661e92759805f5&#34;}
</code></pre><p>Find the snapshot and copy it to locally. The default folder is <code>/prometheus/snapshots/</code> but you can find the data folder by finding the <code>--storage.tsdb.path</code> config in your deployment.</p>
<pre tabindex="0"><code>kubectl -n monitoring exec -it prometheus-prometheus-operator-prometheus-0 \
  -c prometheus -- /bin/sh -c \
  &#34;ls /prometheus/snapshots/20200731T123913Z-6e661e92759805f5&#34;
01EE25G1ZTKBFBBHFPHNBF99KJ  01EEFF7TE5ENDAGDR5K7ERW3BX
...

kubectl cp -n monitoring \
  prometheus-prometheus-operator-prometheus-0:/prometheus/snapshots/20200731T123913Z-6e661e92759805f5 \
  -c prometheus .
</code></pre><h3 id="restore-prometheus-data">Restore Prometheus data</h3>
<p>In a new Prometheus instance delete the data folder and copy the content of the snapshot:</p>
<pre tabindex="0"><code>kubectl -n newprom exec -it prometheus -- /bin/sh -c &#34;rm -rf /prometheus/*&#34;

kubectl -n newprom cp ./* prometheus:/prometheus/
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="prometheus" term="prometheus" label="Prometheus" />
                             
                                <category scheme="backup" term="backup" label="Backup" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to fixing filesystem corruption on a Kubernetes Ceph RBD PersistentVolume]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-rbd-fsck/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k3s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with CRI-O and kadalu" />
                <link href="https://devopstales.github.io/kubernetes/k8s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K8S with CRI-O and kadalu" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-openebs/?utm_source=atom_feed" rel="related" type="text/html" title="Install OpenEBS for Kubernetes" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-rbd-fsck/</id>
            
            
            <published>2020-10-10T00:00:00+00:00</published>
            <updated>2020-10-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to fix a corruptid filesystem on Ceph RBD PersistentVolume uyed by Kubernetes.</p>
<pre tabindex="0"><code>oc describe po gitlab-ce-1-wl9wf
...
Events:
  Type     Reason                  Age               From                                           Message
  ----     ------                  ----              ----                                           -------
  Normal   Scheduled               27s               default-scheduler                              Successfully assigned gitlab-prod/gitlab-ce-1-j7lph to k8sw09
  Normal   SuccessfulAttachVolume  27s               attachdetach-controller                        AttachVolume.Attach succeeded for volume &#34;pvc-e27f498e-85cf-11e9-af1a-66934f1af826&#34;
  Warning  FailedMount             2s (x6 over 19s)  kubelet, k8sw09  MountVolume.MountDevice failed for volume &#34;pvc-e27f498e-85cf-11e9-af1a-66934f1af826&#34; : rbd: failed to mount device /dev/rbd3 at /var/lib/origin/openshift.local.volumes/plugins/kubernetes.io/rbd/mounts/k8s-rbd-image-kubernetes-dynamic-pvc-e3042618-85cf-11e9-8762-aa9884bf6706 (fstype: ), error &#39;fsck&#39; found errors on device /dev/rbd3 but could not correct them: fsck from util-linux 2.23.2
/dev/rbd3: Superblock needs_recovery flag is clear, but journal has data.
/dev/rbd3: Run journal anyway

/dev/rbd3: UNEXPECTED INCONSISTENCY; RUN fsck MANUALLY.
  (i.e., without -a or -p options)
</code></pre><p>Check the log on the worker. In my case this is k8sw09.</p>
<pre tabindex="0"><code>journalctl -u kubelet


jan 08 15:44:58 k8sw09 origin-node[14927]: I0108 15:44:58.251201   14927 reconciler.go:252] operationExecutor.MountVolume started for volume &#34;pvc-e27f498e-85cf-11e9-af1a-66934f1af826&#34; (UniqueName: &#34;kubernetes.io/rbd/k8s-rbd:kubernetes-dynamic-pvc-e3042618-85cf-11e9-8762-aa9884bf6706&#34;) pod &#34;gitlab-ce-1-j7lph&#34; (UID: &#34;69151c2c-3223-11ea-9bcf-aa9884bf6706&#34;)
jan 08 15:44:58 k8sw09 origin-node[14927]: I0108 15:44:58.251299   14927 operation_generator.go:489] MountVolume.WaitForAttach entering for volume &#34;pvc-e27f498e-85cf-11e9-af1a-66934f1af826&#34; (UniqueName: &#34;kubernetes.io/rbd/k8s-rbd:kubernetes-dynamic-pvc-e3042618-85cf-11e9-8762-aa9884bf6706&#34;) pod &#34;gitlab-ce-1-j7lph&#34; (UID: &#34;69151c2c-3223-11ea-9bcf-aa9884bf6706&#34;) DevicePath &#34;&#34;
jan 08 15:44:58 k8sw09 origin-node[14927]: I0108 15:44:58.451965   14927 operation_generator.go:498] MountVolume.WaitForAttach succeeded for volume &#34;pvc-e27f498e-85cf-11e9-af1a-66934f1af826&#34; (UniqueName: &#34;kubernetes.io/rbd/k8s-rbd:kubernetes-dynamic-pvc-e3042618-85cf-11e9-8762-aa9884bf6706&#34;) pod &#34;gitlab-ce-1-j7lph&#34; (UID: &#34;69151c2c-3223-11ea-9bcf-aa9884bf6706&#34;) DevicePath &#34;/dev/rbd3&#34;
jan 08 15:44:58 k8sw09 origin-node[14927]: E0108 15:44:58.498052   14927 nestedpendingoperations.go:267] Operation for &#34;\&#34;kubernetes.io/rbd/k8s-rbd:kubernetes-dynamic-pvc-e3042618-85cf-11e9-8762-aa9884bf6706&#34;&#34; failed. No retries permitted until 2020-01-08 15:47:00.498014981 +0100 CET m=+619493.508747496 (durationBeforeRetry 2m2s). Error: &#34;MountVolume.MountDevice failed for volume \&#34;pvc-e27f498e-85cf-11e9-af1a-66934f1af826\&#34; (UniqueName: \&#34;kubernetes.io/rbd/k8s-rbd:kubernetes-dynamic-pvc-e3042618-85cf-11e9-8762-aa9884bf6706\&#34;) pod \&#34;gitlab-ce-1-j7lph\&#34; (UID: \&#34;69151c2c-3223-11ea-9bcf-aa9884bf6706\&#34;) : rbd: failed to mount device /dev/rbd3 at /var/lib/origin/openshift.local.volumes/plugins/kubernetes.io/rbd/mounts/k8s-rbd-image-kubernetes-dynamic-pvc-e3042618-85cf-11e9-8762-aa9884bf6706 (fstype: ), error &#39;fsck&#39; found errors on device /dev/rbd3 but could not correct them: fsck from util-linux 2.23.2\n/dev/rbd3: Superblock needs_recovery flag is clear, but journal has data.\n/dev/rbd3: Run journal anyway\n\n/dev/rbd3: UNEXPECTED INCONSISTENCY; RUN fsck MANUALLY.\n\t(i.e., without -a or -p options)\n.&#34;
</code></pre><p>We can see the problem is with <code>/dev/rbd3</code>. First check thi is the block device user for <code>pvc-e3042618-85cf-11e9-8762-aa9884bf6706</code> PersistenVolume.</p>
<pre tabindex="0"><code>sudo rbd showmapped | grep pvc-e3042618-85cf-11e9-8762-aa9884bf6706
3  k8s-rbd kubernetes-dynamic-pvc-e3042618-85cf-11e9-8762-aa9884bf6706 -    /dev/rbd3
</code></pre><p>So let&rsquo;s try to use <code>fsck</code> on this disk.</p>
<pre tabindex="0"><code>sudo rbd unmap /dev/rbd3


sudo fsck -fv /dev/rbd3
fsck from util-linux 2.27.1
e2fsck 1.42.13 (17-May-2015)
Pass 1: Checking inodes, blocks, and sizes
Pass 2: Checking directory structure
Pass 3: Checking directory connectivity
Pass 4: Checking reference counts
Unattached inode 303
Connect to /lost+found&lt;y&gt;? yes
Inode 303 ref count is 2, should be 1.  Fix&lt;y&gt;? yes
Pass 5: Checking group summary information
Block bitmap differences:  -(71680--73727) -(94208--95231)
Fix&lt;y&gt;? yes

/dev/rbd3: ***** FILE SYSTEM WAS MODIFIED *****

         326 inodes used (0.50%, out of 65536)
          35 non-contiguous files (10.7%)
           0 non-contiguous directories (0.0%)
             # of inodes with ind/dind/tind blocks: 0/0/0
             Extent depth histogram: 311/7
       63642 blocks used (24.28%, out of 262144)
           0 bad blocks
           1 large file

         308 regular files
           9 directories
           0 character device files
           0 block device files
           0 fifos
           1 link
           0 symbolic links (0 fast symbolic links)
           0 sockets
------------
         317 files
</code></pre><p>Then our pod is running again!</p>
<pre tabindex="0"><code>oc get po
NAME                        READY     STATUS    RESTARTS   AGE
gitlab-ce-1-j7lph           1/1       Running   0          28m
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                             
                                <category scheme="metallb" term="metallb" label="MetalLB" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Being Productive with K8S]]></title>
            <link href="https://devopstales.github.io/kubernetes/being-productive-with-kubectl/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="related" type="text/html" title="Install and use rancher helm-controller" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-longhorn/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes project longhorn" />
                <link href="https://devopstales.github.io/sso/k8s-gangway/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes authentication with Keycloak and gangway" />
                <link href="https://devopstales.github.io/sso/k8s-dasboard-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Dashboard authentication with Keycloak and gatekeeper" />
            
                <id>https://devopstales.github.io/kubernetes/being-productive-with-kubectl/</id>
            
            
            <published>2020-10-09T00:00:00+00:00</published>
            <updated>2020-10-09T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you my productivity tips with kubectl.</p>
<h3 id="bash-aliases-for-kubectl">Bash aliases for kubectl</h3>
<p>I have above aliases setup in the <code>~/.bashrc</code> file.</p>
<pre tabindex="0"><code>alias k=kubectl
alias kg=&#39;kubectl get&#39;
alias kd=&#39;kubectl describe&#39;
alias kdel=&#39;kubectl delete&#39;
alias kdelf=&#39;kubectl delete -f&#39;
alias kaf=&#39;kubectl apply -f&#39;
alias keti=&#39;kubectl exec -ti&#39;
alias kgds=&#39;kubectl get DaemonSet&#39;
alias kgdsy=&#39;kubectl get DaemonSet -oyaml&#39;
alias kdds=&#39;kubectl describe DaemonSet&#39;
alias kdelds=&#39;kubectl delete DaemonSet&#39;
alias kgp=&#39;kubectl get pods&#39;
alias kgpy=&#39;kubectl get pods -oyaml&#39;
alias kgpa=&#39;kubectl get pods --all-namespaces&#39;
alias kgpw=&#39;kgp --watch&#39;
alias kgpwide=&#39;kgp -o wide&#39;
alias kdp=&#39;kubectl describe pods&#39;
alias kdelp=&#39;kubectl delete pods&#39;
# get pod by label: kgpl &#34;app=myapp&#34; -n myns
alias kgpl=&#39;kgp -l&#39;
# get pod by namespace: kgpn kube-system&#34;
alias kgpn=&#39;kgp -n&#39;
alias kgs=&#39;kubectl get svc&#39;
alias kgsa=&#39;kubectl get svc --all-namespaces&#39;
alias kgsw=&#39;kgs --watch&#39;
alias kgswide=&#39;kgs -o wide&#39;
alias kes=&#39;kubectl edit svc&#39;
alias kds=&#39;kubectl describe svc&#39;
alias kdels=&#39;kubectl delete svc&#39;
alias kgi=&#39;kubectl get ingress&#39;
alias kgia=&#39;kubectl get ingress --all-namespaces&#39;
alias kei=&#39;kubectl edit ingress&#39;
alias kdi=&#39;kubectl describe ingress&#39;
alias kdeli=&#39;kubectl delete ingress&#39;
alias kgns=&#39;kubectl get namespaces&#39;
alias kens=&#39;kubectl edit namespace&#39;
alias kdns=&#39;kubectl describe namespace&#39;
alias kdelns=&#39;kubectl delete namespace&#39;
alias kcn=&#39;kubectl config set-context $(kubectl config current-context) --namespace&#39;
alias kgcm=&#39;kubectl get configmaps&#39;
alias kgcmy=&#39;kubectl get configmaps -oyaml&#39;
alias kgcma=&#39;kubectl get configmaps --all-namespaces&#39;
alias kecm=&#39;kubectl edit configmap&#39;
alias kdcm=&#39;kubectl describe configmap&#39;
alias kdelcm=&#39;kubectl delete configmap&#39;
alias kgsec=&#39;kubectl get secret&#39;
alias kgseca=&#39;kubectl get secret --all-namespaces&#39;
alias kdsec=&#39;kubectl describe secret&#39;
alias kdelsec=&#39;kubectl delete secret&#39;
alias kgss=&#39;kubectl get statefulset&#39;
alias kgssa=&#39;kubectl get statefulset --all-namespaces&#39;
alias kgssw=&#39;kgss --watch&#39;
alias kgsswide=&#39;kgss -o wide&#39;
alias kess=&#39;kubectl edit statefulset&#39;
alias kdss=&#39;kubectl describe statefulset&#39;
alias kdelss=&#39;kubectl delete statefulset&#39;
alias ksss=&#39;kubectl scale statefulset&#39;
alias krsss=&#39;kubectl rollout status statefulset&#39;
alias kga=&#39;kubectl get all&#39;
alias kgaa=&#39;kubectl get all --all-namespaces&#39;
alias kl=&#39;kubectl logs&#39;
alias kl1h=&#39;kubectl logs --since 1h&#39;
alias kl1m=&#39;kubectl logs --since 1m&#39;
alias kl1s=&#39;kubectl logs --since 1s&#39;
alias klf=&#39;kubectl logs -f&#39;
alias klf1h=&#39;kubectl logs --since 1h -f&#39;
alias klf1m=&#39;kubectl logs --since 1m -f&#39;
alias klf1s=&#39;kubectl logs --since 1s -f&#39;
alias kcp=&#39;kubectl cp&#39;
alias kgno=&#39;kubectl get nodes&#39;
alias keno=&#39;kubectl edit node&#39;
alias kdno=&#39;kubectl describe node&#39;
alias kdelno=&#39;kubectl delete node&#39;
alias kgpvc=&#39;kubectl get pvc&#39;
alias kgpvca=&#39;kubectl get pvc --all-namespaces&#39;
alias kgpvcw=&#39;kgpvc --watch&#39;
alias kepvc=&#39;kubectl edit pvc&#39;
alias kdpvc=&#39;kubectl describe pvc&#39;
alias kdelpvc=&#39;kubectl delete pvc&#39;
alias kgpv=&#39;kubectl get pv&#39;
alias kgsc=&#39;kubectl get storageclass&#39;
# custom resource
alias kgir=&#39;kubectl get IngressRoute&#39;
alias kgira=&#39;kubectl get IngressRoute --all-namespaces&#39;
alias keir=&#39;kubectl edit IngressRoute&#39;
alias kdir=&#39;kubectl describe IngressRoute&#39;
alias kdelir=&#39;kubectl delete IngressRoute&#39;
</code></pre><h3 id="kubens-kubectx">kubens kubectx</h3>
<pre tabindex="0"><code>sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
sudo ln -s /opt/kubectx/kubectx /usr/local/bin/kubectx
sudo ln -s /opt/kubectx/kubens /usr/local/bin/kubens
echo &#34;PATH=$PATH:/usr/local/bin/&#34; &gt;&gt; /etc/profile
</code></pre>]]></content>
            
                 
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install and use rancher helm-controller]]></title>
            <link href="https://devopstales.github.io/kubernetes/k3s-helm-controller/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k3s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S with CRI-O and kadalu" />
                <link href="https://devopstales.github.io/kubernetes/k3s-fcos/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S on Fedora CoreOS" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-longhorn/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes project longhorn" />
                <link href="https://devopstales.github.io/kubernetes/k8s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K8S with CRI-O and kadalu" />
            
                <id>https://devopstales.github.io/kubernetes/k3s-helm-controller/</id>
            
            
            <published>2020-09-20T00:00:00+00:00</published>
            <updated>2020-09-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>K3S comes with a Helm operator called Helm Controller. Helm Controller defines a new HelmChart custom resource definition, or CRD, for managing Helm charts.</p>


<H3>Parts of the K3S series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/k3s-etcd-kube-vip/">Install K3S with k3sup and kube-vip</a></li>
     <li>Part1b: <a href="../../kubernetes/k3s-crio/">Install K3S with CRI-O</a></li>
     <li>Part1c: <a href="../../kubernetes/k3s-fcos/">Install K3S on Fedora CoreOS</a></li>
<!-- K3S falnnel wiregard - https://medium.com/@bestpractices/k3s-with-flannel-wireguard-backend-fa433065a401 -->
     <li>Part2b: <a href="../../kubernetes/k3sup-calico/">Install K3S with k3sup and Calico</a></li>
     <li>Part2c: <a href="../../kubernetes/k3s-cilium/">Install K3S with k3sup and Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/k3s-helm-controller/">K3S helm CR</a></li>
<!-- K3D -->
     <li>Part5: <a href="../../kubernetes/k3s-gvisor/">Secure k3s with gVisor</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>



<h3 id="install-helm-controller-k8s">Install helm-controller K8S</h3>
<p>Thanks to Francisco Bobadilla who created RBAC for Rancher&rsquo;s helm-controller we can deploy this solution to a stander K8S cluster.</p>
<pre tabindex="0"><code>kubectl apply -f https://raw.githubusercontent.com/iotops/helm-controller/master/manifests/deploy-namespaced.yaml
</code></pre><pre tabindex="0"><code>kubectl api-resources --api-group=helm.cattle.io
NAME         SHORTNAMES   APIGROUP         NAMESPACED   KIND
helmcharts                helm.cattle.io   true         HelmChart
</code></pre><h3 id="deploy-nginx-ingress-controller">Deploy Nginx ingress Controller</h3>
<pre tabindex="0"><code>nano ginx-ingress.yaml
---
apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: nginx-ingress
  namespace: helm-controller
spec:
  chart: stable/nginx-ingress
  targetNamespace: nginx-ingress
  valuesContent: |-
    rbac:
      create: &#34;true&#34;
    controller:

      kind: DaemonSet
      hostNetwork: &#34;true&#34;
      daemonset:
        useHostPort: &#34;true&#34;
      service:
        type: &#34;NodePort&#34;
</code></pre><p>On a K3S cluster the <code>namespace:</code> must be <code>kube-system</code> because k3S deploys the helm-controller to that namespace.</p>
<h3 id="auto-deploying-manifests">Auto-Deploying Manifests</h3>
<p>Any file found in <code>/var/lib/rancher/k3s/server/manifests</code> will automatically be deployed to Kubernetes in a manner similar to <code>kubectl apply</code>.</p>
<pre tabindex="0"><code>cp nginx-ingress.yaml /var/lib/rancher/k3s/server/manifests/
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="rancher" term="rancher" label="Rancher" />
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="helm-controller" term="helm-controller" label="helm-controller" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install K3S with CRI-O and kadalu]]></title>
            <link href="https://devopstales.github.io/kubernetes/k3s-crio/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-crio/?utm_source=atom_feed" rel="related" type="text/html" title="Install K8S with CRI-O and kadalu" />
                <link href="https://devopstales.github.io/kubernetes/k3s-fcos/?utm_source=atom_feed" rel="related" type="text/html" title="Install K3S on Fedora CoreOS" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-openebs/?utm_source=atom_feed" rel="related" type="text/html" title="Install OpenEBS for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kubeadm-ha/?utm_source=atom_feed" rel="related" type="text/html" title="How to install kubernetes with kubeadm in HA mode" />
            
                <id>https://devopstales.github.io/kubernetes/k3s-crio/</id>
            
            
            <published>2020-09-10T00:00:00+00:00</published>
            <updated>2020-09-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to install cri-o container runtime and initialize a Kubernetes.</p>


<H3>Parts of the K3S series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/k3s-etcd-kube-vip/">Install K3S with k3sup and kube-vip</a></li>
     <li>Part1b: <a href="../../kubernetes/k3s-crio/">Install K3S with CRI-O</a></li>
     <li>Part1c: <a href="../../kubernetes/k3s-fcos/">Install K3S on Fedora CoreOS</a></li>
<!-- K3S falnnel wiregard - https://medium.com/@bestpractices/k3s-with-flannel-wireguard-backend-fa433065a401 -->
     <li>Part2b: <a href="../../kubernetes/k3sup-calico/">Install K3S with k3sup and Calico</a></li>
     <li>Part2c: <a href="../../kubernetes/k3s-cilium/">Install K3S with k3sup and Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/k3s-helm-controller/">K3S helm CR</a></li>
<!-- K3D -->
     <li>Part5: <a href="../../kubernetes/k3s-gvisor/">Secure k3s with gVisor</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>



<h3 id="install-cri-o-instad-of-docker">Install CRI-O instad of Docker</h3>
<pre tabindex="0"><code>VERSION=1.18
sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/CentOS_7/devel:kubic:libcontainers:stable.repo
sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable_cri-o_${VERSION}.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:${VERSION}/CentOS_7/devel:kubic:libcontainers:stable:cri-o:${VERSION}.repo

yum install cri-o
</code></pre><h3 id="configure">Configure</h3>
<pre tabindex="0"><code>modprobe overlay
modprobe br_netfilter

cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF

sysctl --system
</code></pre><pre tabindex="0"><code>free -h
swapoff -a
swapoff -a
sed -i.bak -r &#39;s/(.+ swap .+)/#\1/&#39; /etc/fstab
free -h
</code></pre><p>You nee the same cgroup manager in cri-o and kubeadm. The default for kubeadm is cgroupfs and for cri-o the default is systemd. In this example I configured cri-o for cgroupfs.</p>
<pre tabindex="0"><code>nano /etc/crio/crio.conf
[crio.runtime]
conmon_cgroup = &#34;pod&#34;
cgroup_manager = &#34;cgroupfs&#34;
...
registries = [
  &#34;quay.io&#34;,
  &#34;docker.io&#34;
]
</code></pre><p>Disable ipv6 and configure cri-o CNI confg for flanel&rsquo;s network:</p>
<pre tabindex="0"><code>echo &#34;net.ipv6.conf.all.disable_ipv6 = 1&#34; &gt;&gt; /etc/sysctl.conf
echo &#34;net.ipv6.conf.default.disable_ipv6 = 1&#34; &gt;&gt; /etc/sysctl.conf
sysctl -p

sed -i &#34;s|::1|#::1|&#34; /etc/hosts

nano /etc/cni/net.d/100-crio-bridge.conf
{
...
&#34;ipam&#34;: {
    &#34;type&#34;: &#34;host-local&#34;,
    &#34;routes&#34;: [
        { &#34;dst&#34;: &#34;0.0.0.0/0&#34; }
    ],

    &#34;ranges&#34;: [
        [{ &#34;subnet&#34;: &#34;10.244.0.0/16&#34; }]
    ]
}
}
</code></pre><pre tabindex="0"><code>systemctl enable --now cri-o

echo &#34;export PATH=$PATH:/usr/local/bin/&#34; &gt;&gt; /etc/profile
echo &#34;export KUBECONFIG=/etc/rancher/k3s/k3s.yaml&#34; &gt;&gt; /etc/profile
source /etc/profile

yum install -y container-selinux selinux-policy-base
rpm -i https://rpm.rancher.io/k3s-selinux-0.1.1-rc1.el7.noarch.rpm
</code></pre><pre tabindex="0"><code>export K3S_KUBECONFIG_MODE=&#34;644&#34;
export INSTALL_K3S_EXEC=&#34; --container-runtime-endpoint /var/run/crio/crio.sock --no-deploy servicelb --no-deploy traefik&#34;

curl -sfL https://get.k3s.io | sh -
</code></pre><pre tabindex="0"><code>systemctl status k3s

crictl info
crictl ps
kubectl get node -o wide
kubectl get pods -A -o wide
</code></pre><h3 id="install-tools">Install tools</h3>
<pre tabindex="0"><code>yum install git -y

sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
sudo ln -s /opt/kubectx/kubectx /usr/local/sbin/kubectx
sudo ln -s /opt/kubectx/kubens /usr/local/sbin/kubens
COMPDIR=$(pkg-config --variable=completionsdir bash-completion)
ln -sf /opt/kubectx/completion/kubens.bash $COMPDIR/kubens
ln -sf /opt/kubectx/completion/kubectx.bash $COMPDIR/kubectx
</code></pre><h3 id="deploy-kadalu-storage">Deploy kadalu storage</h3>
<pre tabindex="0"><code>sudo wipefs -a -t dos -f /dev/sdb
sudo mkfs.xfs /dev/sdb

yum install python3-pip -y
sudo pip3 install kubectl-kadalu

echo &#34;export PATH=$PATH:/usr/local/bin/&#34; &gt;&gt; /etc/profile
source /etc/profile

kubectl kadalu install

# k8s.mydomain.intra is the nod name in Kubernetes
# /dev/sdb is the disk

kubectl kadalu storage-add storage-pool-1 \
    --device k8s.mydomain.intra:/dev/sdb

# to delete object if you misconfigured kadalu
kubectl delete kadalustorages.kadalu-operator.storage storage-pool-1


kubectl get pods -n kadalu

kubectl patch storageclass kadalu.replica1 -p &#39;{&#34;metadata&#34;: {&#34;annotations&#34;:{&#34;storageclass.kubernetes.io/is-default-class&#34;:&#34;true&#34;}}}&#39;
</code></pre><pre tabindex="0"><code>nano test-pvc.yaml
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pv1
spec:
  storageClassName: kadalu.replica1
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install K3S on Fedora CoreOS]]></title>
            <link href="https://devopstales.github.io/kubernetes/k3s-fcos/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/cloud/fcos-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install Fedora CoreOS as a VM" />
                <link href="https://devopstales.github.io/kubernetes/k8s-longhorn/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes project longhorn" />
            
                <id>https://devopstales.github.io/kubernetes/k3s-fcos/</id>
            
            
            <published>2020-09-05T00:00:00+00:00</published>
            <updated>2020-09-05T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how you can Install K3S on Fedora CoreOS(FCOS) in virtualization environment.</p>


<H3>Parts of the K3S series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/k3s-etcd-kube-vip/">Install K3S with k3sup and kube-vip</a></li>
     <li>Part1b: <a href="../../kubernetes/k3s-crio/">Install K3S with CRI-O</a></li>
     <li>Part1c: <a href="../../kubernetes/k3s-fcos/">Install K3S on Fedora CoreOS</a></li>
<!-- K3S falnnel wiregard - https://medium.com/@bestpractices/k3s-with-flannel-wireguard-backend-fa433065a401 -->
     <li>Part2b: <a href="../../kubernetes/k3sup-calico/">Install K3S with k3sup and Calico</a></li>
     <li>Part2c: <a href="../../kubernetes/k3s-cilium/">Install K3S with k3sup and Cilium</a></li>
     <li>Part3: <a href="../../kubernetes/k3s-helm-controller/">K3S helm CR</a></li>
<!-- K3D -->
     <li>Part5: <a href="../../kubernetes/k3s-gvisor/">Secure k3s with gVisor</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-cert/">Kubernetes Certificate Rotation</a></li>
</ul>



<h3 id="what-is-k3s">What is K3S</h3>
<p>K3S is a lightweight certified kubernetes distribution. Designed to be a single binary of less than 40MB. It didn&rsquo;t use etcd instad stora it&rsquo;s data in sqlite.</p>
<h3 id="install-requirements">Install requirements</h3>
<pre tabindex="0"><code>sudo -i
rpm-ostree install https://rpm.rancher.io/k3s-selinux-0.1.1-rc1.el7.noarch.rpm
systemctl reboot
</code></pre><h3 id="install-k3s">Install K3S</h3>
<pre tabindex="0"><code>sudo -i
export K3S_KUBECONFIG_MODE=&#34;644&#34;
export INSTALL_K3S_EXEC=&#34; --no-deploy servicelb --no-deploy traefik&#34;

curl -sfL https://get.k3s.io | sh -

systemctl status k3s
kubectl get nodes -o wide
kubectl get pods -A -o wide
</code></pre><h3 id="join-other-nodes">Join other nodes</h3>
<p>First we need the join token:</p>
<pre tabindex="0"><code>sudo cat /var/lib/rancher/k3s/server/node-token
K1042e2f8e353b9409472c1e0cca8457abe184dc7be3f0805109e92c50c193ceb42::node:c83acbf89a7de7026d6f6928dc270028
</code></pre><p>The join the worker nodes:</p>
<pre tabindex="0"><code>export K3S_KUBECONFIG_MODE=&#34;644&#34;
export K3S_URL=&#34;https://k3s-master:6443&#34;
export K3S_TOKEN=&#34;K1042e2f8e353b9409472c1e0cca8457abe184dc7be3f0805109e92c50c193ceb42::node:c83acbf89a7de7026d6f6928dc270028&#34;

curl -sfL https://get.k3s.io | sh -
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="fedora-coreos" term="fedora-coreos" label="Fedora CoreOS" />
                             
                                <category scheme="k3s" term="k3s" label="K3S" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install K8S with CRI-O and kadalu]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-crio/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Self-hosted Load Balancer for bare metal Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-openebs/?utm_source=atom_feed" rel="related" type="text/html" title="Install OpenEBS for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kubeadm-ha/?utm_source=atom_feed" rel="related" type="text/html" title="How to install kubernetes with kubeadm in HA mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-local-pv/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes nginx ingress with helm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-velero-backup/?utm_source=atom_feed" rel="related" type="text/html" title="Backup your Kubernetes Cluster with Velero" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-crio/</id>
            
            
            <published>2020-09-04T00:00:00+00:00</published>
            <updated>2020-09-04T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to install cri-o container runtime and initialize a Kubernetes.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="what-is-cri-o">What is CRI-O?</h3>
<p>The Kubernetes project has defined a number of standards. One of them is cri. The Container Runtime Interface. This interface defines how Kubernetes talks with a high-level container runtime. CRI-O is an implementation of the Kubernetes CRI to enable using OCI (Open Container Initiative) compatible runtimes. It is a lightweight alternative of Docker as the runtime for kubernetes. t allows Kubernetes to use any OCI-compliant runtime as the container runtime for running pods. Today it supports runc and Kata Containers as the container runtimes but any OCI-conformant runtime can be plugged in principle.</p>
<h3 id="install-cri-o-instad-of-docker">Install CRI-O instad of Docker</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>VERSION<span style="color:#f92672">=</span>1.18
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/CentOS_7/devel:kubic:libcontainers:stable.repo
</span></span><span style="display:flex;"><span>sudo curl -L -o /etc/yum.repos.d/devel_kubic_libcontainers_stable_cri-o_<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>/CentOS_7/devel:kubic:libcontainers:stable:cri-o:<span style="color:#e6db74">${</span>VERSION<span style="color:#e6db74">}</span>.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install cri-o
</span></span></code></pre></div><h3 id="configure">Configure</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>modprobe overlay
</span></span><span style="display:flex;"><span>modprobe br_netfilter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv6.conf.all.disable_ipv6 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv6.conf.default.disable_ipv6 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>free -h
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i.bak -r <span style="color:#e6db74">&#39;s/(.+ swap .+)/#\1/&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span>free -h
</span></span></code></pre></div><p>You nee the same cgroup manager in cri-o and kubeadm. The default for kubeadm is cgroupfs and for cri-o the default is systemd. In this example I configured cri-o for cgroupfs.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano /etc/crio/crio.conf
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>crio.runtime<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>conmon_cgroup <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;pod&#34;</span>
</span></span><span style="display:flex;"><span>cgroup_manager <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;cgroupfs&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano /etc/containers/registries.conf
</span></span><span style="display:flex;"><span>registries <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;quay.io&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;docker.io&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">]</span>
</span></span></code></pre></div><p>If you want to use systemd:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;KUBELET_EXTRA_ARGS=--cgroup-driver=systemd&#34;</span> | tee /etc/sysconfig/kubelet
</span></span></code></pre></div><h3 id="install-kubernets">Install kubernets</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CRIP_VERSION<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>crio --version | awk <span style="color:#e6db74">&#39;{print $3}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>yum install kubelet-$CRIP_VERSION kubeadm-$CRIP_VERSION kubectl-$CRIP_VERSION -y
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>IP<span style="color:#f92672">=</span>172.17.9.10
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir /var/lib/kubelet/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># --node-ip for multi interface configuration</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># --cgroup-driver=systemd for systemd dryver</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /var/lib/kubelet/kubeadm-flags.env
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">KUBELET_KUBEADM_ARGS=&#34;--node-ip=&#39;$IP&#39; --cgroup-driver=systemd&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl enable --now kubelet.service
</span></span><span style="display:flex;"><span>systemctl enable --now cri-o
</span></span><span style="display:flex;"><span>kubeadm config images pull --cri-socket<span style="color:#f92672">=</span>unix:///var/run/crio/crio.sock --kubernetes-version<span style="color:#f92672">=</span>$CRIP_VERSION
</span></span><span style="display:flex;"><span>kubeadm init --pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16 --apiserver-advertise-address<span style="color:#f92672">=</span>$IP  --kubernetes-version<span style="color:#f92672">=</span>$CRIP_VERSION --cri-socket<span style="color:#f92672">=</span>unix:///var/run/crio/crio.sock
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>crictl info
</span></span><span style="display:flex;"><span>kubectl get node -o wide
</span></span><span style="display:flex;"><span>kubectl get po --all-namespaces
</span></span></code></pre></div><h3 id="inincialize-network">Inincialize network</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span></span><span style="display:flex;"><span>kubectl aplly -f kube-flannel.yml
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
</span></span><span style="display:flex;"><span>wget https://docs.projectcalico.org/manifests/custom-resources.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nano ustom-resources.yaml
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>      cidr: 10.244.0.0/16
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl apply -f custom-resources.yaml
</span></span></code></pre></div><h3 id="install-tools">Install tools</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yum install git -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubectx /usr/local/sbin/kubectx
</span></span><span style="display:flex;"><span>sudo ln -s /opt/kubectx/kubens /usr/local/sbin/kubens
</span></span></code></pre></div><h3 id="deploy-kadalu-storage">Deploy kadalu storage</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo wipefs -a -t dos -f /dev/sdb
</span></span><span style="display:flex;"><span>sudo mkfs.xfs /dev/sdb
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum install python3-pip -y
</span></span><span style="display:flex;"><span>sudo pip3 install kubectl-kadalu
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;export PATH=</span>$PATH<span style="color:#e6db74">:/usr/local/bin/&#34;</span> &gt;&gt; /etc/profile
</span></span><span style="display:flex;"><span>source /etc/profile
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl kadalu install
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># k8s.mydomain.intra is the nod name in Kubernetes</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># /dev/sdb is the disk</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl kadalu storage-add storage-pool-1 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --device k8s.mydomain.intra:/dev/sdb
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># to delete object if you misconfigured kadalu</span>
</span></span><span style="display:flex;"><span>kubectl delete kadalustorages.kadalu-operator.storage storage-pool-1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get pods -n kadalu
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl patch storageclass kadalu.replica1 -p <span style="color:#e6db74">&#39;{&#34;metadata&#34;: {&#34;annotations&#34;:{&#34;storageclass.kubernetes.io/is-default-class&#34;:&#34;true&#34;}}}&#39;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano test-pvc.yaml
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>kind: PersistentVolumeClaim
</span></span><span style="display:flex;"><span>apiVersion: v1
</span></span><span style="display:flex;"><span>metadata:
</span></span><span style="display:flex;"><span>  name: pv1
</span></span><span style="display:flex;"><span>spec:
</span></span><span style="display:flex;"><span>  storageClassName: kadalu.replica1
</span></span><span style="display:flex;"><span>  accessModes:
</span></span><span style="display:flex;"><span>    - ReadWriteMany
</span></span><span style="display:flex;"><span>  resources:
</span></span><span style="display:flex;"><span>    requests:
</span></span><span style="display:flex;"><span>      storage: 1Gi
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="cri-o" term="cri-o" label="CRI-O" />
                             
                                <category scheme="container-runtimes" term="container-runtimes" label="Container runtimes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Self-hosted Load Balancer for bare metal Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb/?utm_source=atom_feed" rel="related" type="text/html" title="Install MetalLB load balancer for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-longhorn/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes project longhorn" />
                <link href="https://devopstales.github.io/kubernetes/k8s-nginx-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes nginx ingress with helm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install-openebs/?utm_source=atom_feed" rel="related" type="text/html" title="Install OpenEBS for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-kubeadm-ha/?utm_source=atom_feed" rel="related" type="text/html" title="How to install kubernetes with kubeadm in HA mode" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-metallb-bgp-pfsense/</id>
            
            
            <published>2020-08-18T00:00:00+00:00</published>
            <updated>2020-08-18T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install  Metal LB load balancer in BGP mode for Kubernetes.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="metallb">Metallb</h3>
<p>Metallb is a fantastic bare metal-targeted operator for powering LoadBalancer types of services. It can work in two modes: Layer 2 and Border Gateway Protocol (BGP) mode. In layer 2 mode, one of the nodes advertises the load balanced IP (VIP) via ARP. This mode has two limitations: all the traffic goes through a single node VIP potentially limiting the bandwidth. The second limitation is a very slow failover. Detecting unhealthy nodes is a notoriously slow operation in Kubernetes which can take several minutes (5-10 minutes, which can be decreased with the node-problem-detector DaemonSet).</p>
<p>In BGP mode, Metallb advertises the VIP through BGP. It requires a BGP compatible router ath the network wher the kubernetes cluster is created.</p>
<p>I found that the layer 2 mode of Metallb is not a practical solution for production scenarios as it is typically not acceptable to have failover-induced downtimes in the order of minutes.</p>
<h3 id="how-does-the-full-setup-look-like">How does the full setup look like?</h3>
<p>For this Demo I will use a pfsense in virtualbox and tree vm for kubernetes in the same host-only network.</p>
<table>
  <thead>
      <tr>
          <th>vm</th>
          <th>nic</th>
          <th>ip</th>
          <th>mode</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>pfsense01</td>
          <td>em1</td>
          <td>192.168.0.200</td>
          <td>bridged</td>
      </tr>
      <tr>
          <td>pfsense01</td>
          <td>em2</td>
          <td>172.17.9.200</td>
          <td>host-only</td>
      </tr>
      <tr>
          <td>k8sm01</td>
          <td>enp0s8</td>
          <td>172.17.9.10</td>
          <td>host-only</td>
      </tr>
      <tr>
          <td>k8sm02</td>
          <td>enp0s8</td>
          <td>172.17.9.11</td>
          <td>host-only</td>
      </tr>
      <tr>
          <td>k8sm02</td>
          <td>enp0s8</td>
          <td>172.17.9.12</td>
          <td>host-only</td>
      </tr>
  </tbody>
</table>
<h3 id="issues-with-calico">Issues with Calico</h3>
<p>Simple BGP config with Calico don’t require anything special. However, if you are using Calico’s <a href="https://docs.projectcalico.org/networking/bgp">external BGP peering capability</a> to advertise your cluster prefixes over BGP, and also want to use BGP in MetalLB, you will need to jump through some hoops.</p>
<h3 id="configuring-pfsense-and-openbgpd">Configuring pfSense and OpenBGPD</h3>
<p>First we need to install OpenBGPD pcakage on pfSense. Go to <code>System &gt; Package Manager &gt; Available Packages</code> Then select <code>OpenBGPD</code> and Install it.</p>
<p>There is otger BGP compatible pckages in pfSense so make  sure you DO NOT have the Quagga_OSPF or FRR packages installed. They directly conflict with each other.</p>
<p>No we need to configure BGP. Ther is a nice UI but I will use the Raw config for simplicity. Go to <code>Services &gt; OpenBGPD &gt; Raw config</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># This file was created by the package manager. Do not edit!</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">AS 64512</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">fib-update yes</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">listen on 172.17.9.200</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">router-id 172.17.9.200</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">network 10.25.0.0/22</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">neighbor 172.17.9.10 {</span>
</span></span><span style="display:flex;"><span>	<span style="color:#ae81ff">remote-as 64513</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">announce all</span>
</span></span><span style="display:flex;"><span>	<span style="color:#ae81ff">descr &#34;k8sm01&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">neighbor 172.17.9.11 {</span>
</span></span><span style="display:flex;"><span>	<span style="color:#ae81ff">remote-as 64513</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">announce all</span>
</span></span><span style="display:flex;"><span>	<span style="color:#ae81ff">descr &#34;k8sm02&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">neighbor 172.17.9.12 {</span>
</span></span><span style="display:flex;"><span>	<span style="color:#ae81ff">remote-as 64513</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">announce all</span>
</span></span><span style="display:flex;"><span>	<span style="color:#ae81ff">descr &#34;k8sm03&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><ul>
<li><code>AS 64512</code> - Thi is the Autonomous System Number of pfsense</li>
<li><code>listen on </code> -   This is the address that OpenBGPD should listen to BGP requests on. I highly recommend setting this to the same as the <code>router-id</code> IP address.</li>
<li><code>network</code> - This is the network what you will use for advertise Load Balanced services.</li>
<li><code>neighbor $(kubernetes_worker_node_ip)</code> - The ip of the Kubernetes host</li>
<li><code>remote-as 64513</code> - Thi is the Autonomous System Number of the neighbors. Same for all Kubernetes Node.</li>
<li><code>announce all</code> - We need our nodes to be able to announce to the router their service IP addresses.</li>
</ul>
<h3 id="configuring-pfsense-and-quagga_ospf">Configuring pfSense and Quagga_OSPF</h3>
<p>If you prefer to use <code>Quagga_OSPF</code> Go to <code>System &gt; Package Manager &gt; Available Packages</code> Then select <code>Quagga_OSPF</code> and Install it.</p>
<p>To configure BGP with <code>Quagga_OSPF</code>. Go to <code>Services &gt; Quagga OSPFd &gt; Raw config</code> Edit <code>SAVED bgpd.conf</code> the <code>save</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>router bgp <span style="color:#ae81ff">64512</span>
</span></span><span style="display:flex;"><span> bgp router-id 172.17.9.200
</span></span><span style="display:flex;"><span> neighbor 172.17.9.10 remote-as <span style="color:#ae81ff">64513</span>
</span></span><span style="display:flex;"><span> neighbor 172.17.9.11 remote-as <span style="color:#ae81ff">64513</span>
</span></span><span style="display:flex;"><span> neighbor 172.17.9.12 remote-as <span style="color:#ae81ff">64513</span>
</span></span><span style="display:flex;"><span>  network 10.25.0.0/22
</span></span></code></pre></div><h3 id="deploy-metallb">Deploy MetalLB</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/namespace.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/metallb.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># On first install only</span>
</span></span><span style="display:flex;"><span>kubectl create secret generic -n metallb-system memberlist --from-literal<span style="color:#f92672">=</span>secretkey<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span><span style="color:#66d9ef">$(</span>openssl rand -base64 128<span style="color:#66d9ef">)</span><span style="color:#e6db74">&#34;</span>
</span></span></code></pre></div><p>Make a BGP config for MetalLB</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano bgpconfig.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    peers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - peer-address: 172.17.9.200
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      peer-asn: 64512
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      my-asn: 64513
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    address-pools:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - name: default
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      protocol: bgp
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      addresses:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - 10.25.0.10-10.25.3.250</span>
</span></span></code></pre></div><h3 id="demo-time">Demo Time</h3>
<p>Let’s create a demo application for testing.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">nano test.yaml</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">LoadBalancer</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">run</span>: <span style="color:#ae81ff">test-nginx</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f bgpconfig.yaml
</span></span><span style="display:flex;"><span>kubectl apply -f test.yaml
</span></span></code></pre></div><p>After a few moments, you can run this command to get the IP address:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ kubectl describe service test-nginx | grep <span style="color:#e6db74">&#34;LoadBalancer Ingress&#34;</span>
</span></span><span style="display:flex;"><span>LoadBalancer Ingress:     10.25.0.11
</span></span></code></pre></div><p>Let&rsquo;s check the address in a browser. If pfSense is you default gateway it will work perfectly, but in my demo enviroment I need to create a route to pfSense for this network on my host machine:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo route add -net 10.25.0.0/22 gw 172.17.9.200
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>route -n
</span></span><span style="display:flex;"><span>Kernel IP routing table
</span></span><span style="display:flex;"><span>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span></span><span style="display:flex;"><span>0.0.0.0         192.168.0.1     0.0.0.0         UG    <span style="color:#ae81ff">600</span>    <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> wlan0
</span></span><span style="display:flex;"><span>10.25.0.0       172.17.9.200    255.255.252.0   UG    <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> vboxnet7
</span></span><span style="display:flex;"><span>172.17.9.0      0.0.0.0         255.255.255.0   U     <span style="color:#ae81ff">0</span>      <span style="color:#ae81ff">0</span>        <span style="color:#ae81ff">0</span> vboxnet7
</span></span></code></pre></div><p><img src="/img/include/pfsense-bgp-kubernetes.png" alt="Example image"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                             
                                <category scheme="metallb" term="metallb" label="MetalLB" />
                             
                                <category scheme="bgp" term="bgp" label="BGP" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to fix Ansible Service Broker in OpenShift 3.11]]></title>
            <link href="https://devopstales.github.io/kubernetes/how-to-fix-ansible-service-broker-in-openshift-3-11/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-cluster-monitoring-operator-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix cluster-monitoring-operator in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-registry-console-ui-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix registry console UI in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/openshift-cert-manager/?utm_source=atom_feed" rel="related" type="text/html" title="Install cert-manager to Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-auto-approval-csr/?utm_source=atom_feed" rel="related" type="text/html" title="How to Enable Auto Approval of CSR in Openshift v3.11" />
                <link href="https://devopstales.github.io/kubernetes/openshift-secondary-router/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift secondary route" />
            
                <id>https://devopstales.github.io/kubernetes/how-to-fix-ansible-service-broker-in-openshift-3-11/</id>
            
            
            <published>2020-07-10T00:00:00+00:00</published>
            <updated>2020-07-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Ansible Service Broker in OpenShift 3.11 is broken as it uses wrong docker tag.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="export-running-deployment-to-yaml">Export running deployment to yaml</h3>
<pre tabindex="0"><code>oc project openshift-ansible-service-broker
oc get --export dc/asb -o yaml &gt; asb.yaml
</code></pre><h3 id="patch-and-deploy-the-yaml">Patch and deploy the yaml</h3>
<pre tabindex="0"><code>replate docker.io/ansibleplaybookbundle/origin-ansible-service-broker:latest to
docker.io/ansibleplaybookbundle/origin-ansible-service-broker:ansible-service-broker-1.3.23-1
oc apply -f asb.yaml


curl -k -H &#34;Authorization: Bearer `oc serviceaccounts get-token asb-client`&#34; https://`oc get routes -n openshift-ansible-service-broker --no-headers | awk &#39;{print $2}&#39;`/osb/v2/catalog
</code></pre><h3 id="config-for-new-install">Config for new install</h3>
<pre tabindex="0"><code>ansible_service_broker_image=docker.io/ansibleplaybookbundle/origin-ansible-service-broker:ansible-service-broker-1.3.23-1
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="keycloak" term="keycloak" label="Keycloak" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to fix cluster-monitoring-operator in OpenShift 3.11]]></title>
            <link href="https://devopstales.github.io/kubernetes/how-to-fix-cluster-monitoring-operator-in-openshift-3-11/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-ansible-service-broker-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix Ansible Service Broker in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-registry-console-ui-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix registry console UI in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/openshift-cert-manager/?utm_source=atom_feed" rel="related" type="text/html" title="Install cert-manager to Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-auto-approval-csr/?utm_source=atom_feed" rel="related" type="text/html" title="How to Enable Auto Approval of CSR in Openshift v3.11" />
                <link href="https://devopstales.github.io/kubernetes/openshift-secondary-router/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift secondary route" />
            
                <id>https://devopstales.github.io/kubernetes/how-to-fix-cluster-monitoring-operator-in-openshift-3-11/</id>
            
            
            <published>2020-07-10T00:00:00+00:00</published>
            <updated>2020-07-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Default install use an old image for cluster-monitoring-operator with imagestream false latanci alert  problem.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="export-running-deployment-to-yaml">Export running deployment to yaml</h3>
<pre tabindex="0"><code>oc project openshift-monitoring
oc get --export deployment/cluster-monitoring-operator -o yaml &gt; cluster-monitoring-operator.yaml
</code></pre><h3 id="patch-and-deploy-the-yaml">Patch and deploy the yaml</h3>
<pre tabindex="0"><code>sed -i -e &#34;s|image:.*|image: quay.io/openshift/origin-cluster-monitoring-operator:v3.11
|&#34; \
&gt; cluster-monitoring-operator.yaml

oc apply -f cluster-monitoring-operator.yaml


curl -k -H &#34;Authorization: Bearer `oc serviceaccounts get-token asb-client`&#34; https://`oc get routes -n openshift-ansible-service-broker --no-headers | awk &#39;{print $2}&#39;`/osb/v2/catalog

oc delete deployment/prometheus-operator
oc delete statefulset/alertmanager-main
oc delete statefulset/prometheus-k8s
</code></pre><h3 id="config-for-new-install">Config for new install</h3>
<pre tabindex="0"><code>openshift_cluster_monitoring_operator_image=quay.io/openshift/origin-cluster-monitoring-operator:v3.11
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="keycloak" term="keycloak" label="Keycloak" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to fix registry console UI in OpenShift 3.11]]></title>
            <link href="https://devopstales.github.io/kubernetes/how-to-fix-registry-console-ui-in-openshift-3-11/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-ansible-service-broker-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix Ansible Service Broker in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/how-to-fix-cluster-monitoring-operator-in-openshift-3-11/?utm_source=atom_feed" rel="related" type="text/html" title="How to fix cluster-monitoring-operator in OpenShift 3.11" />
                <link href="https://devopstales.github.io/kubernetes/openshift-cert-manager/?utm_source=atom_feed" rel="related" type="text/html" title="Install cert-manager to Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-auto-approval-csr/?utm_source=atom_feed" rel="related" type="text/html" title="How to Enable Auto Approval of CSR in Openshift v3.11" />
                <link href="https://devopstales.github.io/kubernetes/openshift-secondary-router/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift secondary route" />
            
                <id>https://devopstales.github.io/kubernetes/how-to-fix-registry-console-ui-in-openshift-3-11/</id>
            
            
            <published>2020-07-10T00:00:00+00:00</published>
            <updated>2020-07-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Registry console UI in OpenShift 3.11 is broken on CentOS as it is not available on Docker Hub.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="export-running-deployment-to-yaml">Export running deployment to yaml</h3>
<pre tabindex="0"><code>oc project default
oc get --export   dc/registry-console -o yaml &gt; registry_console.yaml
</code></pre><h3 id="patch-and-deploy-the-yaml">Patch and deploy the yaml</h3>
<pre tabindex="0"><code>sed -i -e &#34;s|image:.*|image: docker.io/timbordemann/cockpit-kubernetes:latest|&#34; registry_console.yaml
oc apply -f registry_console.yaml
</code></pre><h3 id="config-for-new-install">Config for new install</h3>
<pre tabindex="0"><code>openshift_cockpit_deployer_image=docker.io/timbordemann/cockpit-kubernetes:latest
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="keycloak" term="keycloak" label="Keycloak" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install cert-manager to Openshift]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-cert-manager/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-auto-approval-csr/?utm_source=atom_feed" rel="related" type="text/html" title="How to Enable Auto Approval of CSR in Openshift v3.11" />
                <link href="https://devopstales.github.io/kubernetes/openshift-secondary-router/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift secondary route" />
                <link href="https://devopstales.github.io/kubernetes/openshift-gitlab-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Installing GitLab on OpenShift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-kompose/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Run docker-compoe in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-add-node/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Add Nodes to a Cluster" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-cert-manager/</id>
            
            
            <published>2020-06-10T00:00:00+00:00</published>
            <updated>2020-06-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p><code>cert-manager</code> is a service that automatically creates certificate requests and sign certificate based on annotations. The created certificate will be stored in a secret.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<p>Normally in kubernetes you can use a secret for TLS in an ingress cinfiguration but in Openshift there is no way to get the certificate from a secret for a route. So we will use <code>cert-utils-operator</code> for recreating routs with the propriety certificate based on annotations.</p>
<h3 id="install-cert-managger">Install cert-managger</h3>
<pre tabindex="0"><code>oc create namespace cert-manager
oc apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.15.1/cert-manager-legacy.yaml
</code></pre><p>Create <code>ClusterIssuer</code> to create certs. For this demo I will use a Self-signed root CA, what is trustin in my browser. <code>cert-manager</code> can handle Let&rsquo;s encrypt as an issuer both with http and dns challenges so yu can use Let&rsquo;s encrypt certs in a private network without publication your route.</p>
<pre tabindex="0"><code>nano issuer.yaml
---
apiVersion: v1
data:
  tls.crt: LS0tLS1C...
  tls.key: LS0tLSGF...
kind: Secret
metadata:
  name: ca-key-pair
  namespace: cert-manager
---
apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: ca-issuer
  namespace: cert-manager
spec:
  ca:
    secretName: ca-key-pair
</code></pre><h3 id="install-cert-utils-operator">Install cert-utils-operator</h3>
<p>I usethe v0.1.0 and not the latest one (at the moment v0.1.1) besause athe v0.1.1 has a bug on OKD 3.11:</p>
<ul>
<li><a href="https://github.com/redhat-cop/cert-utils-operator/issues/51">https://github.com/redhat-cop/cert-utils-operator/issues/51</a></li>
</ul>
<pre tabindex="0"><code>helm repo add cert-utils-operator https://redhat-cop.github.io/cert-utils-operator
helm update
# export CERT_UTILS_CHART_VERSION=$(helm search cert-utils-operator/cert-utils-operator | grep cert-utils-operator/cert-utils-operator | awk &#39;{print $2}&#39;)

helm fetch cert-utils-operator/cert-utils-operator --version v0.1.0
helm template cert-utils-operator-v0.1.0.tgz --namespace cert-manager | oc apply -f - -n cert-manager
</code></pre><pre tabindex="0"><code>apiVersion: apps.openshift.io/v1
kind: DeploymentConfig
metadata:
  annotations:
    openshift.io/generated-by: OpenShiftWebConsole
  labels:
    app: nginx2
  name: nginx2
spec:
  replicas: 1
  selector:
    app: nginx2
    deploymentconfig: nginx2
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx2
        deploymentconfig: nginx2
    spec:
      containers:
        - image: &gt;-
            bitnami/nginx@sha256:2bff7d085671a8b0f9ec296cf57fba995d06c1b5fb350575dd429c361520f0a4
          imagePullPolicy: Always
          name: nginx2
          ports:
            - containerPort: 8080
              protocol: TCP
            - containerPort: 8443
              protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
  test: false
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    openshift.io/generated-by: OpenShiftWebConsole
  labels:
    app: nginx2
  name: nginx2
spec:
  clusterIP: 172.30.17.64
  ports:
    - name: 8080-tcp
      port: 8080
      protocol: TCP
      targetPort: 8080
    - name: 8443-tcp
      port: 8443
      protocol: TCP
      targetPort: 8443
  selector:
    deploymentconfig: nginx2
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}
---
apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: nginx2-route-tls
  namespace: default
spec:
  secretName: nginx2-route-tls
  duration: 24h
  renewBefore: 12h
  commonName: nginx.openshift.mydomain.intra
  dnsNames:
  - nginx.openshift.mydomain.intra
  issuerRef:
    name: ca-issuer
    kind: ClusterIssuer
    group: cert-manager.io
---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  annotations:
    cert-utils-operator.redhat-cop.io/certs-from-secret=nginx2-route-tls
  labels:
    app: nginx2
  name: nginx2
spec:
  host: nginx.openshift.mydomain.intra
  port:
    targetPort: 8080-tcp
  tls:
    insecureEdgeTerminationPolicy: Redirect
    termination: edge
  to:
    kind: Service
    name: nginx2
    weight: 100
  wildcardPolicy: None

---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  annotations:
    cert-utils-operator.redhat-cop.io/certs-from-secret: nginx2-route-tls
  labels:
    app: nginx2
  name: nginx2
spec:
  host: nginx.openshift.mydomain.intra
  port:
    targetPort: 8080-tcp
  tls:
    insecureEdgeTerminationPolicy: Redirect
    termination: edge
  to:
    kind: Service
    name: nginx2
    weight: 100
  wildcardPolicy: None
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="keycloak" term="keycloak" label="Keycloak" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to Enable Auto Approval of CSR in Openshift v3.11]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-auto-approval-csr/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-secondary-router/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift secondary route" />
                <link href="https://devopstales.github.io/kubernetes/openshift-gitlab-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Installing GitLab on OpenShift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-kompose/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Run docker-compoe in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-add-node/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Add Nodes to a Cluster" />
                <link href="https://devopstales.github.io/kubernetes/openshift-letsencrypt/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Letsencrypt certificates" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-auto-approval-csr/</id>
            
            
            <published>2020-05-27T00:00:00+00:00</published>
            <updated>2020-05-27T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Nodes certificates are not Completely redeployed through playbook but through a different mechanism.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<p>SSL Certificates will be valid for the period of 1 year and at 85% of the certificate the node will trigger a CSR that would have to be approved for the certificate to be redeployed.</p>
<p>The Only certificates that are renewed/redeployed through CSR’s mechanism are the kubelet/nodes certificates. Any other certificates e.g, router, master, api certs, etcd, docker-registry, etc are still redeployed through the usual playbooks.</p>
<p>If triggered CSR is not approved either manually or in automated way then after one year all nodes will go to NotReady State.</p>
<h3 id="check-and-approve-csrs-manually">Check and approve csr&rsquo;s manually</h3>
<pre tabindex="0"><code>oc get csr
oc describe csr &lt;csr_name&gt;
oc adm certificate &lt;approve csr_name&gt;

oc get csr -o name | xargs oc adm certificate approve
</code></pre><h3 id="approve-csrs-automaticle">Approve csr&rsquo;s automaticle</h3>
<p>At install time you can add this option to your ansible hosts fiel:</p>
<pre tabindex="0"><code>openshift_master_bootstrap_auto_approve=true
</code></pre><p>If you installed the cluster and want to change this option run this playbook:</p>
<pre tabindex="0"><code>ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/openshift-master/enable_bootstrap.yml \
-e openshift_master_bootstrap_auto_approve=true
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install OpenEBS for Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-install-openebs/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-kubeadm-ha/?utm_source=atom_feed" rel="related" type="text/html" title="How to install kubernetes with kubeadm in HA mode" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-local-pv/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes nginx ingress with helm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-velero-backup/?utm_source=atom_feed" rel="related" type="text/html" title="Backup your Kubernetes Cluster with Velero" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cert-manager/?utm_source=atom_feed" rel="related" type="text/html" title="Install cert-manager for Kubernetes" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-install-openebs/</id>
            
            
            <published>2020-05-20T00:00:00+00:00</published>
            <updated>2020-05-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>OpenEBS is an open-source project for container-attached and container-native storage on Kubernetes.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>On all host we have an unused unpartitioned disk called sdb.</p>
<pre tabindex="0"><code>lsblk

NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda               8:0    0   80G  0 disk
├─sda1            8:1    0    1G  0 part /boot
└─sda2            8:2    0   79G  0 part
  ├─centos-root 253:0    0   50G  0 lvm  /
  ├─centos-swap 253:1    0    1G  0 lvm
  └─centos-home 253:3    0   28G  0 lvm  /home
sdb               8:16   0  100G  0 disk
</code></pre><h3 id="install-requirements">Install requirements</h3>
<p>OpenEBS use iscsi for persisten volume sharing so we need  <code>iscsid</code>.</p>
<h4 id="debian--ubuntu">Debian / Ubuntu</h4>
<pre tabindex="0"><code>apt-get install open-iscsi
service open-iscsi enable
service open-iscsi restart
</code></pre><h4 id="centos">CentOS</h4>
<pre tabindex="0"><code>yum install iscsi-initiator-utils -y
systemctl enable iscsid
systemctl start iscsid
</code></pre><h3 id="deploy-openebs-with-helm">Deploy OpenEBS with helm</h3>
<p>OpenEBS is in the stable repo so we didn&rsquo;t need to add a separate helm repository for installing it. In my case I will use teh <code>openebs-system</code> namespace for the install.</p>
<pre tabindex="0"><code>kubectl create ns openebs-system
helm upgrade --install openebs stable/openebs --version 1.7.0 --namespace=openebs-system
</code></pre><p>Wait for all the  pods are started.</p>
<pre tabindex="0"><code>kubectl get pods -n openebs-system

NAME                                           READY     STATUS    RESTARTS   AGE
openebs-admission-server-7b4859ccd5-bz4zt      1/1       Running   0          14m
openebs-apiserver-556ffff45c-nk9x9             1/1       Running   5          15m
openebs-localpv-provisioner-76b466d4b8-5tj4w   1/1       Running   0          15m
openebs-ndm-f6cqz                              1/1       Running   0          15m
openebs-ndm-operator-5f6c5497d7-chf6t          1/1       Running   1          15m
openebs-ndm-qrmp9                              1/1       Running   0          15m
openebs-ndm-stgml                              1/1       Running   0          15m
openebs-provisioner-c9c7f9ff8-hn4bl            1/1       Running   0          15m
openebs-snapshot-operator-6578d74b7-2wc97      2/2       Running   0          15m
</code></pre><p>Now verify if OpenEBS is installed successfully.</p>
<pre tabindex="0"><code>kubectl get blockdevice -n openebs-system

NAME                                           NODENAME    SIZE         CLAIMSTATE   STATUS    AGE
blockdevice-0c4e03f9e39a4092108215f19eca9da8   k8s-node1   1048576000   Unclaimed    Active    16m
blockdevice-1aaa1142a7b9c65dfa32dec88fe1749b   k8s-node2   1048576000   Unclaimed    Active    16m
blockdevice-5f728d1068c72337609fc1f88855b9bb   k8s-node3   1048576000   Unclaimed    Active    16m
</code></pre><pre tabindex="0"><code>kubectl describe blockdevice blockdevice-0c4e03f9e39a4092108215f19eca9da8
...
  Devlinks:
    Kind:  by-id
    Links:
      /dev/disk/by-id/ata-VBOX_HARDDISK_VBd4679835-eb798f2c
      /dev/disk/by-id/lvm-pv-uuid-PWnLFv-b0jS-7CLZ-Cmym-0dia-RQkI-w0Hkam
    Kind:  by-path
    Links:
      /dev/disk/by-path/pci-0000:00:01.1-ata-2.0
  Filesystem:
    Fs Type:  LVM2_member
  Node Attributes:
    Node Name:  k8s-node1
  Partitioned:  No
  Path:         /dev/sdb
...
</code></pre><h4 id="verify-storageclasses">Verify StorageClasses:</h4>
<pre tabindex="0"><code>kubectl get sc

NAME                        PROVISIONER                                                AGE
openebs-device              openebs.io/local                                           64s
openebs-hostpath            openebs.io/local                                           64s
openebs-jiva-default        openebs.io/provisioner-iscsi                               64s
openebs-snapshot-promoter   volumesnapshot.external-storage.k8s.io/snapshot-promoter   64s
</code></pre><h3 id="storage-engines">Storage engines</h3>
<p>OpenEBS offers three storage engines:</p>
<ul>
<li>Jiva</li>
<li>cStor</li>
<li>LocalPV</li>
</ul>
<p>Jiva is a light weight storage engine that is recommended to use for low capacity workloads. It is actually based on the same technology that powers Longhorn.</p>
<pre tabindex="0"><code>---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: demo-vol1-claim
spec:
  storageClassName: openebs-jiva-default
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 4G
</code></pre><p>cStor requires raw disks. The snapshot and storage management features of the other cStor engine are more advanced than Jiva. For provisioning a cStor Volume, it requires a cStor Storage Pool and a StorageClass. cStor provides iSCSI targets, which are appropriate for RWO (ReadWriteOnce) access mode and is suitable for all types of databases. cStor supports thin provisioning by default.</p>
<pre tabindex="0"><code>cat stor-pool1-config.yaml
---
apiVersion: openebs.io/v1alpha1
kind: StoragePoolClaim
metadata:
  name: cstor-disk-pool
  annotations:
    cas.openebs.io/config: |
      - name: PoolResourceRequests
        value: |-
            memory: 500Mb
      - name: PoolResourceLimits
        value: |-
            memory: 500Mb
spec:
  name: cstor-disk-pool
  type: disk
  poolSpec:
    poolType: striped
  blockDevices:
    blockDeviceList:
    - blockdevice-0c4e03f9e39a4092108215f19eca9da8
    - blockdevice-1aaa1142a7b9c65dfa32dec88fe1749b
    - blockdevice-5f728d1068c72337609fc1f88855b9bb
</code></pre><pre tabindex="0"><code>kubectl apply -f stor-pool1-config.yaml

kubectl get spc

NAME              AGE
cstor-disk-pool   20s

kubectl get csp

NAME                   ALLOCATED   FREE      CAPACITY   STATUS    TYPE      AGE
cstor-disk-pool-cxm8   294K        100G      100G       Healthy   striped   27m
cstor-disk-pool-r1hl   270K        100G      100G       Healthy   striped   27m
cstor-disk-pool-t05z   92K         100G      100G       Healthy   striped   27m
</code></pre><pre tabindex="0"><code>cat openebs-sc-rep3.yaml
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: openebs-cstore-default
  annotations:
    openebs.io/cas-type: cstor
    cas.openebs.io/config: |
      - name: StoragePoolClaim
        value: &#34;cstor-disk-pool&#34;
      - name: ReplicaCount
        value: &#34;3&#34;
    storageclass.kubernetes.io/is-default-class: &#34;true&#34;
provisioner: openebs.io/provisioner-iscsi
</code></pre><pre tabindex="0"><code>cat test-cs-pcv.yaml
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: test-cs-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3G
</code></pre><pre tabindex="0"><code>kubectl apply -f openebs-sc-rep3.yaml
kubectl apply -f test-cs-pcv.yaml
</code></pre><p>Local PV is based on Kubernetes local persistent volumes but it has a dynamic provisioner. It can store data either in a directory, or use disks; in the first case the hostpath can be shared by multiple persistent volumes, while when using disks each persistent volume requires a separate device. Local PV offers extremely high performance close to what you get by reading from and writing to the disk directly, but it doesn’t offer features such as replication, which are built in Jiva and cStor.</p>
<pre tabindex="0"><code>apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    cas.openebs.io/config: |
      - name: StorageType
        value: &#34;hostpath&#34;
      - name: BasePath
        value: &#34;/mnt/openebs&#34;
    openebs.io/cas-type: local
  name: openebs-hostpath-mount
provisioner: openebs.io/local
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
</code></pre><h2 id="sources">Sources:</h2>
<ul>
<li><a href="https://vitobotta.com/2019/07/03/openebs-tips/">https://vitobotta.com/2019/07/03/openebs-tips/</a></li>
</ul>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[How to install kubernetes with kubeadm in HA mode]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-kubeadm-ha/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-local-pv/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes nginx ingress with helm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-velero-backup/?utm_source=atom_feed" rel="related" type="text/html" title="Backup your Kubernetes Cluster with Velero" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cert-manager/?utm_source=atom_feed" rel="related" type="text/html" title="Install cert-manager for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/kind-install/?utm_source=atom_feed" rel="related" type="text/html" title="Starting local Kubernetes using kind" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-kubeadm-ha/</id>
            
            
            <published>2020-04-02T00:00:00+00:00</published>
            <updated>2020-04-02T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to install kubernetes in HA mode with kubeadm, keepaliwed and envoyproxy.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<pre tabindex="0"><code>172.17.8.100  # kubernetes cluster ip
172.17.8.101  master01 # master node
172.17.8.102  master02 # frontend node
172.17.8.103  master03 # worker node

# hardware requirement
2 CPU
4G RAM
</code></pre><h3 id="install-docker">Install Docker</h3>
<pre tabindex="0"><code>yum install -y -q yum-utils device-mapper-persistent-data lvm2
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
yum install -y -q docker-ce docker-compose

mkdir /etc/docker
echo &#39;{
  &#34;log-driver&#34;: &#34;json-file&#34;,
  &#34;log-opts&#34;: {
    &#34;max-size&#34;: &#34;100m&#34;
  },
  &#34;storage-driver&#34;: &#34;overlay2&#34;,
  &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],
  &#34;storage-opts&#34;: [
    &#34;overlay2.override_kernel_check=true&#34;
  ]
}&#39; &gt; /etc/docker/daemon.json

systemctl enable docker
systemctl start docker
</code></pre><h3 id="disable-swap">Disable swap</h3>
<pre tabindex="0"><code>free -h
swapoff -a
swapoff -a
sed -i.bak -r &#39;s/(.+ swap .+)/#\1/&#39; /etc/fstab
free -h
</code></pre><h3 id="configuuration">Configuuration</h3>
<pre tabindex="0"><code>cat &gt;&gt;/etc/sysctl.d/kubernetes.conf&lt;&lt;EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.ipv6.conf.all.disable_ipv6      = 1
net.ipv6.conf.default.disable_ipv6  = 1
EOF
cat &gt;&gt;/etc/sysctl.d/ipv6.conf&lt;&lt;EOF
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1
net.ipv6.conf.eth0.disable_ipv6 = 1
EOF
sysctl --system
</code></pre><h3 id="install-kubeadm">Install kubeadm</h3>
<pre tabindex="0"><code>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF


yum install epel-release -y
yum install -y kubeadm kubelet kubectl keepalived
</code></pre><h3 id="configure-keepalived-on-first-master">Configure keepalived on first master</h3>
<pre tabindex="0"><code>touch /etc/keepalived/check_apiserver.sh
chmod +x /etc/keepalived/check_apiserver.sh

cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf
! Configuration File for keepalived
global_defs {
    router_id k8s-node1
    enable_script_security
    script_user root
}
vrrp_script check_apiserver {
    script &#34;/etc/keepalived/check_apiserver.sh&#34;
    interval 5
    weight -10
    fall 2
    rise 2
}
vrrp_instance VI_1 {
    state BACKUP
    interface enp0s8
    mcast_src_ip 172.17.8.101
    virtual_router_id 51
    priority 150
    advert_int 5
    authentication {
        auth_type PASS
        auth_pass Password1
    }
    virtual_ipaddress {
        172.17.8.100/24 brd 172.17.8.255 dev enp0s8
    }
    track_script {
       check_apiserver
    }
}
EOF

systemctl start keepalived
systemctl enable keepalived
</code></pre><h3 id="configure-envoy-on-first-master">Configure envoy on first master</h3>
<pre tabindex="0"><code>cat &lt;&lt;EOF &gt; /etc/kubernetes/envoy.yaml
static_resources:
  listeners:
  - name: main
    address:
      socket_address:
        address: 0.0.0.0
        port_value: 16443
    filter_chains:
    - filters:
      - name: envoy.tcp_proxy
        config:
          stat_prefix: ingress_tcp
          cluster: k8s

  clusters:
  - name: k8s
    connect_timeout: 0.25s
    type: strict_dns
    lb_policy: round_robin
    hosts:
    - socket_address:
        address: 172.17.8.101
        port_value: 6443
    - socket_address:
        address: 172.17.8.102
        port_value: 6443
    - socket_address:
        address: 172.17.8.103
        port_value: 6443
    health_checks:
    - timeout: 1s
      interval: 5s
      unhealthy_threshold: 1
      healthy_threshold: 1
      http_health_check:
        path: &#34;/healthz&#34;

admin:
  access_log_path: &#34;/dev/null&#34;
  address:
    socket_address:
      address: 0.0.0.0
      port_value: 8001
EOF
</code></pre><h3 id="create-loadbalancer-on-all-masters">Create loadbalancer on all masters</h3>
<pre tabindex="0"><code>
cat&lt;&lt;EOF &gt; /etc/kubernetes/envoy.yaml
static_resources:
  listeners:
  - name: main
    address:
      socket_address:
        address: 0.0.0.0
        port_value: 16443
    filter_chains:
    - filters:
      - name: envoy.tcp_proxy
        config:
          stat_prefix: ingress_tcp
          cluster: k8s

  clusters:
  - name: k8s
    connect_timeout: 0.25s
    type: strict_dns # static
    lb_policy: round_robin
    hosts:
    - socket_address:
        address: 172.17.8.101
        port_value: 6443
    - socket_address:
        address: 172.17.8.102
        port_value: 6443
    - socket_address:
        address: 172.17.8.103
        port_value: 6443
    health_checks:
    - timeout: 1s
      interval: 5s
      unhealthy_threshold: 1
      healthy_threshold: 1
      http_health_check:
        path: &#34;/healthz&#34;

admin:
  access_log_path: &#34;/dev/null&#34;
  address:
    socket_address:
      address: 0.0.0.0
      port_value: 8001
EOF

cat&lt;&lt;EOF &gt; /etc/kubernetes/docker-compose.yaml
version: &#39;3&#39;
services:
    api-lb:
        image: envoyproxy/envoy:latest
        restart: always
        network_mode: &#34;host&#34;
        ports:
            - 16443:16443
            - 8001:8001
        volumes:
            - /etc/kubernetes/envoy.yaml:/etc/envoy/envoy.yaml
EOF

cd /etc/kubernetes/
docker-compose pull
docker-compose up -d
docker-compose ps

netstat -tulpn | grep 6443
</code></pre><h3 id="initialize-kubernetes-in-the-first-master">Initialize kubernetes in the first master</h3>
<p>I have multiple interfaces in my masters so to use the correct one I need to add <code>--apiserver-advertise-address &quot;172.17.8.101&quot;</code> to my kubeadm commands and add <code>KUBELET_EXTRA_ARGS</code> for kubelet config.</p>
<pre tabindex="0"><code>echo &#39;KUBELET_EXTRA_ARGS=&#34;--node-ip=172.17.8.101&#34;&#39; &gt; /etc/sysconfig/kubelet

kubeadm config images pull --kubernetes-version 1.16.8
kubeadm init --control-plane-endpoint &#34;172.17.8.100:16443&#34; --apiserver-advertise-address &#34;172.17.8.101&#34; --upload-certs --kubernetes-version 1.16.8 --pod-network-cidr=10.244.0.0/16

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

kubectl get no

kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
</code></pre><h3 id="join-other-masters">Join other masters</h3>
<pre tabindex="0"><code>
kubeadm config images pull --kubernetes-version 1.16.8

echo &#39;KUBELET_EXTRA_ARGS=&#34;--node-ip=172.17.8.102&#34;&#39; &gt; /etc/sysconfig/kubelet

kubeadm join 172.17.8.100:16443 --token 3vqtop.z2kbok4o0wchu4ed \
  --discovery-token-ca-cert-hash sha256:5840ee4de07bb296e2639669c17df7e3240271a1880115336ebc5b91fb8a3555 \
  --control-plane --certificate-key dc99dc10a0269d1a3edfc2e318a78c6bbebdee8081b460535f699d210cec5dcb \
  --apiserver-advertise-address &#34;172.17.8.102&#34;

echo &#39;KUBELET_EXTRA_ARGS=&#34;--node-ip=172.17.8.103&#34;&#39; &gt; /etc/sysconfig/kubelet

kubeadm join 172.17.8.100:16443 --token 3vqtop.z2kbok4o0wchu4ed \
  --discovery-token-ca-cert-hash sha256:5840ee4de07bb296e2639669c17df7e3240271a1880115336ebc5b91fb8a3555 \
  --control-plane --certificate-key dc99dc10a0269d1a3edfc2e318a78c6bbebdee8081b460535f699d210cec5dcb \
  --apiserver-advertise-address &#34;172.17.8.103&#34;
</code></pre><h3 id="fix-keepalibed-check-script-on-first-master">Fix keepalibed check script on first master</h3>
<pre tabindex="0"><code>echo &#39;#!/bin/bash

# if check error then repeat check for 12 times, else exit
err=0
for k in $(seq 1 12)
do
    check_code=$(curl -sk https://localhost:16443)
    if [[ $check_code == &#34;&#34; ]]; then
        err=$(expr $err + 1)
        sleep 5
        continue
    else
        err=0
        break
    fi
done

if [[ $err != &#34;0&#34; ]]; then
    # if apiserver is down send SIG=1
    echo &#39;apiserver error!&#39;
    exit 1
else
    # if apiserver is up send SIG=0
    echo &#39;apiserver normal!&#39;
    exit 0
fi&#39; &gt; /etc/keepalived/check_apiserver.sh
</code></pre><h3 id="configure-keepalived-on-other-masters">Configure keepalived on other masters</h3>
<pre tabindex="0"><code>echo &#39;#!/bin/bash

# if check error then repeat check for 12 times, else exit
err=0
for k in $(seq 1 12)
do
    check_code=$(curl -sk https://localhost:16443)
    if [[ $check_code == &#34;&#34; ]]; then
        err=$(expr $err + 1)
        sleep 5
        continue
    else
        err=0
        break
    fi
done

if [[ $err != &#34;0&#34; ]]; then
    # if apiserver is down send SIG=1
    echo &#39;apiserver error!&#39;
    exit 1
else
    # if apiserver is up send SIG=0
    echo &#39;apiserver normal!&#39;
    exit 0
fi&#39; &gt; /etc/keepalived/check_apiserver.sh

chmod +x /etc/keepalived/check_apiserver.sh
</code></pre><pre tabindex="0"><code>cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf
! Configuration File for keepalived
global_defs {
    router_id k8s-node2
    enable_script_security
    script_user root
}
vrrp_script check_apiserver {
    script &#34;/etc/keepalived/check_apiserver.sh&#34;
    interval 5
    weight -10
    fall 2
    rise 2
}
vrrp_instance VI_1 {
    state BACKUP
    interface enp0s8
    mcast_src_ip 172.17.8.102
    virtual_router_id 51
    priority 100
    advert_int 5
    authentication {
        auth_type PASS
        auth_pass Password1
    }
    virtual_ipaddress {
        172.17.8.100/24 brd 172.17.8.255 dev enp0s8
    }
    track_script {
       check_apiserver
    }
}
EOF

systemctl start keepalived
systemctl enable keepalived
</code></pre><pre tabindex="0"><code>cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf
! Configuration File for keepalived
global_defs {
    router_id k8s-node3
    enable_script_security
    script_user root
}
vrrp_script check_apiserver {
    script &#34;/etc/keepalived/check_apiserver.sh&#34;
    interval 5
    weight -10
    fall 2
    rise 2
}
vrrp_instance VI_1 {
    state BACKUP
    interface enp0s8
    mcast_src_ip 172.17.8.103
    virtual_router_id 51
    priority 50
    advert_int 5
    authentication {
        auth_type PASS
        auth_pass Password1
    }
    virtual_ipaddress {
        172.17.8.100/24 brd 172.17.8.255 dev enp0s8
    }
    track_script {
       check_apiserver
    }
}
EOF

systemctl start keepalived
systemctl enable keepalived
</code></pre><pre tabindex="0"><code>kubectl scale deploy/coredns  --replicas=3 -n kube-system
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[K8s ERROR at kubectl logs]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-error-at-kubectl-logs/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/sso/k8s-kuberos/?utm_source=atom_feed" rel="related" type="text/html" title="Kubectl authentication with Kuberos" />
                <link href="https://devopstales.github.io/kubernetes/helm3-loki/?utm_source=atom_feed" rel="related" type="text/html" title="Install Grafana Loki with Helm3" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph-storage-with-csi-driver/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD volume with CSI driver" />
                <link href="https://devopstales.github.io/monitoring/grafana-loki/?utm_source=atom_feed" rel="related" type="text/html" title="Grafana Loki" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-error-at-kubectl-logs/</id>
            
            
            <published>2020-03-06T00:00:00+00:00</published>
            <updated>2020-03-06T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I installed a kubernetes cluster in a Vagran environment. First everything was fine, but wen I try to add the command <code>kubectl logs</code> I got this error:</p>
<pre tabindex="0"><code>$ kubectl logs busybox-7c9687585b-12d75
Error from server (NotFound): the server could not find the requested resource ( pods/log busybox-7c9687585b-12d75)
</code></pre><p>and another for port-forward and exec:</p>
<pre tabindex="0"><code>$ kubectl exec -it busybox-7c9687585b-12d75 -- /bin/sh
error: unable to upgrade connection: pod does not exist
</code></pre><p>When I eun with <code>-v=9</code> I hot HTTP Error Code 404 all around. I wondered if the connection with the kubelet is wrong because of the multiple interfaces of the VMs? So I tested it:</p>
<pre tabindex="0"><code>$ kubectl get nodes worker1 -o yaml
apiVersion: v1
kind: Node
...
status:
  addresses:
  - address: 10.0.2.15
...
</code></pre><p>The was the problem, the address is came from the NAT interface of the VM not from the bridged. But why? On the master I explicitly set the <code>--apiserver-advertise-address</code> for the bridged interface&rsquo;s IP. I needed to add an explicit IP address of the bridged interface on the workers too. The problem is there is no option for that in kubeadm.</p>
<p>I looked at the man page of the kubelet and I found the following option:</p>
<pre tabindex="0"><code>--node-ip string    IP address of the node. If set, kubelet will use this IP address for the node
</code></pre><p>That is wat I need to set. So I added a no job to the end of my bootstrap scripts for master and worker nodes too.</p>
<pre tabindex="0"><code>echo KUBELET_EXTRA_ARGS=\&#34;--node-ip=`ip addr show enp0s8 | grep inet | grep -E -o &#34;([0-9]{1,3}[\.]){3}[0-9]{1,3}/&#34; | tr -d &#39;/&#39;`\&#34; &gt; /etc/sysconfig/kubelet
systemctl restart kubelet
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[OpenShift 4.2 with Red Hat CodeReady Containers]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift_4/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-secondary-router/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift secondary route" />
                <link href="https://devopstales.github.io/kubernetes/openshift-gitlab-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Installing GitLab on OpenShift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-kompose/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Run docker-compoe in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-add-node/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Add Nodes to a Cluster" />
                <link href="https://devopstales.github.io/kubernetes/openshift-letsencrypt/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Letsencrypt certificates" />
            
                <id>https://devopstales.github.io/kubernetes/openshift_4/</id>
            
            
            <published>2020-03-02T00:00:00+00:00</published>
            <updated>2020-03-02T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>The Red Hat CodeReady Containers enables you to run a minimal OpenShift 4.2 or newer cluster on your local laptop or desktop computer.</p>
<h3 id="download-crc">Download CRC</h3>
<pre tabindex="0"><code>wget https://mirror.openshift.com/pub/openshift-v4/clients/crc/latest/crc-linux-amd64.tar.xz
tar xvf crc-linux-amd64.tar.xz
sudo cp crc-linux-*-amd64/crc /usr/local/sbin/
crc version
</code></pre><h3 id="setup-crs">Setup CRS</h3>
<pre tabindex="0"><code>crc setup
</code></pre><pre tabindex="0"><code>INFO Checking if running as non-root
INFO Caching oc binary
INFO Setting up virtualization
INFO Setting up KVM
INFO Installing libvirt service and dependencies
INFO Adding user to libvirt group
INFO Enabling libvirt
INFO Starting libvirt service
INFO Will use root access: start libvirtd service
[sudo] password for devopstales:
INFO Checking if a supported libvirt version is installed
INFO Installing crc-driver-libvirt
INFO Removing older system-wide crc-driver-libvirt
INFO Setting up libvirt &#39;crc&#39; network
INFO Starting libvirt &#39;crc&#39; network
INFO Checking if NetworkManager is installed
INFO Checking if NetworkManager service is running
INFO Writing Network Manager config for crc
INFO Will use root access: write NetworkManager config in /etc/NetworkManager/conf.d/crc-nm-dnsmasq.conf
INFO Will use root access: execute systemctl daemon-reload command
INFO Will use root access: execute systemctl stop/start command
INFO Writing dnsmasq config for crc
INFO Will use root access: write dnsmasq configuration in /etc/NetworkManager/dnsmasq.d/crc.conf
INFO Will use root access: execute systemctl daemon-reload command
INFO Will use root access: execute systemctl stop/start command
INFO Unpacking bundle from the CRC binary
Setup is complete, you can now run &#39;crc start&#39; to start the OpenShift cluster
</code></pre><p>Thec configuration creats two dnsmasq config:</p>
<pre tabindex="0"><code>cat /etc/NetworkManager/conf.d/crc-nm-dnsmasq.conf
[main]
dns=dnsmasq

cat /etc/NetworkManager/dnsmasq.d/crc.conf
server=/apps-crc.testing/192.168.130.11
server=/crc.testing/192.168.130.11
</code></pre><p>The first enable the NetworkManager&rsquo;s dnsmasq plugin to be used as a dns server and the second points two dns zone the <code>*.apps-crc.testing</code> and the <code>*.crc.testing</code> to the ip of the new vm&rsquo;s ip. The crc creats a kvm network for the vm whit this ip range.</p>
<pre tabindex="0"><code>sudo virsh net-list
 Name      State    Autostart   Persistent
--------------------------------------------
 crc       active   yes         yes
 default   active   yes         yes
</code></pre><pre tabindex="0"><code>sudo virsh net-edit
 &lt;network&gt;
  &lt;name&gt;crc&lt;/name&gt;
  &lt;uuid&gt;49eee855-d342-46c3-9ed3-b8d1758814cd&lt;/uuid&gt;
  &lt;forward mode=&#39;nat&#39;&gt;
    &lt;nat&gt;
      &lt;port start=&#39;1024&#39; end=&#39;65535&#39;/&gt;
    &lt;/nat&gt;
  &lt;/forward&gt;
  &lt;bridge name=&#39;crc&#39; stp=&#39;on&#39; delay=&#39;0&#39;/&gt;

  &lt;mac address=&#39;52:54:00:fd:be:d0&#39;/&gt;
  &lt;ip family=&#39;ipv4&#39; address=&#39;192.168.130.1&#39; prefix=&#39;24&#39;&gt;
    &lt;dhcp&gt;
      &lt;host mac=&#39;52:fd:fc:07:21:82&#39; ip=&#39;192.168.130.11&#39;/&gt;
    &lt;/dhcp&gt;
  &lt;/ip&gt;
&lt;/network&gt;
</code></pre><h3 id="start-crs">Start CRS</h3>
<pre tabindex="0"><code>crc start
</code></pre><pre tabindex="0"><code>INFO Checking if running as non-root
INFO Checking if oc binary is cached
INFO Checking if Virtualization is enabled
INFO Checking if KVM is enabled
INFO Checking if libvirt is installed
INFO Checking if user is part of libvirt group
INFO Checking if libvirt is enabled
INFO Checking if libvirt daemon is running
INFO Checking if a supported libvirt version is installed
INFO Checking if crc-driver-libvirt is installed
INFO Checking if libvirt &#39;crc&#39; network is available
INFO Checking if libvirt &#39;crc&#39; network is active
INFO Checking if NetworkManager is installed
INFO Checking if NetworkManager service is running
INFO Checking if /etc/NetworkManager/conf.d/crc-nm-dnsmasq.conf exists
INFO Checking if /etc/NetworkManager/dnsmasq.d/crc.conf exists
? Image pull secret [? for help]
</code></pre><p>Please note that a valid OpenShift user pull secret is required during installation. The pull secret can be copied or downloaded from the Pull Secret section of the <a href="https://cloud.redhat.com/openshift/install/crc/installer-provisioned">Install on Laptop: Red Hat CodeReady Containers</a> page on cloud.redhat.com.</p>
<pre tabindex="0"><code>INFO To access the cluster, first set up your environment by following &#39;crc oc-env&#39; instructions
INFO Then you can access it by running &#39;oc login -u developer -p developer https://api.crc.testing:6443&#39;
INFO To login as an admin, run &#39;oc login -u kubeadmin -p 7z6T5-qmTth-oxaoD-p3xQF https://api.crc.testing:6443&#39;
INFO
INFO You can now run &#39;crc console&#39; and use these credentials to access the OpenShift web console
</code></pre><p>Go to the console:</p>
<pre tabindex="0"><code>crc console
</code></pre><p><img src="/img/include/okd4.png" alt="Example image"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="centos" term="centos" label="Centos" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes project longhorn]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-longhorn/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/sso/k8s-gangway/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes authentication with Keycloak and gangway" />
                <link href="https://devopstales.github.io/sso/k8s-dasboard-auth/?utm_source=atom_feed" rel="related" type="text/html" title="Dashboard authentication with Keycloak and gatekeeper" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-longhorn/</id>
            
            
            <published>2020-01-18T00:00:00+00:00</published>
            <updated>2020-01-18T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Longhorn is lightweight, reliable, and powerful distributed block storage system for Kubernetes..</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>You can install Longhorn on an existing Kubernetes cluster with one <code>kubectl apply</code> command or using Helm charts. Once Longhorn is installed, it adds persistent volume support to the Kubernetes cluster.</p>
<h3 id="install-dependency">Install dependency</h3>
<pre tabindex="0"><code>yum install iscsi-initiator-utils

modprobe iscsi_tcp
echo &#34;iscsi_tcp&#34; &gt;/etc/modules-load.d/iscsi-tcp.conf
</code></pre><h3 id="deploy-longhorn-and-storageclass">Deploy Longhorn and storageclass</h3>
<pre tabindex="0"><code>kubectl apply -f https://raw.githubusercontent.com/rancher/longhorn/master/deploy/longhorn.yaml
kubectl apply -f https://raw.githubusercontent.com/rancher/longhorn/master/examples/storageclass.yaml

kubectl get storageclass
NAME       PROVISIONER          RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
longhorn   driver.longhorn.io   Delete          Immediate           false                  11m
</code></pre><p>Patch longhorn storageclass to be the default storageclass.</p>
<pre tabindex="0"><code>kubectl patch storageclass longhorn -p \
  &#39;{&#34;metadata&#34;: {&#34;annotations&#34;:{&#34;storageclass.kubernetes.io/is-default-class&#34;:&#34;true&#34;}}}&#39;

kubectl get storageclass
NAME                 PROVISIONER          RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
longhorn (default)   driver.longhorn.io   Delete          Immediate           false                  12m
</code></pre><h3 id="deploy-admin-gui">Deploy admin gui</h3>
<pre tabindex="0"><code>kubectl -n longhorn-system get svc

cat minio-sec.yaml
---
apiVersion: v1
kind: Secret
metadata:
  namespace: longhorn-system
  name: longhorn-minio
type: Opaque
data:
  AWS_ACCESS_KEY_ID: bWluaW8=
  AWS_SECRET_ACCESS_KEY: bWluaW8xMjM=
  AWS_ENDPOINTS: aHR0cDovL21pbmlvLmxvbmdob3JuLXN5c3RlbTo5MDAw
</code></pre><p><img src="/img/include/longhorn0.png" alt="Example image"  class="zoomable" /></br>
<img src="/img/include/longhorn2.png" alt="Example image"  class="zoomable" /></br>
<img src="/img/include/longhorn1.png" alt="Example image"  class="zoomable" /></br></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s" term="k8s" label="k8s" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes nginx ingress with helm]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-local-pv/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-velero-backup/?utm_source=atom_feed" rel="related" type="text/html" title="Backup your Kubernetes Cluster with Velero" />
                <link href="https://devopstales.github.io/kubernetes/k8s-cert-manager/?utm_source=atom_feed" rel="related" type="text/html" title="Install cert-manager for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/kind-install/?utm_source=atom_feed" rel="related" type="text/html" title="Starting local Kubernetes using kind" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb/?utm_source=atom_feed" rel="related" type="text/html" title="Install MetalLB load balancer for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-tillerless-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Tillerless helm2 install" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-local-pv/</id>
            
            
            <published>2020-01-08T00:00:00+00:00</published>
            <updated>2020-01-08T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how to use a local folder as a persistent volume in Kubernetes.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>For a production environment this is not an ideal structure because if you store the data on a single host if the host dies your data will be lost. For this Demo I will use a separate disk for storing the PV&rsquo;s folders. So you can backup or replicate this disk separately.</p>
<h3 id="configure-the-disk">Configure the disk</h3>
<pre tabindex="0"><code>vgcreate local-vg /dev/sdd
lvcreate -l 100%FREE -n local-lv local-vg /dev/sdd
mkfs.xfs -f /dev/local-vg/local-lv
mkdir -p /mnt/local-storage/
mount /dev/local-vg/local-lv /mnt/local-storage
echo &#34;/dev/local-vg/local-lv        /mnt/local-storage              xfs defaults 0 0&#34; &gt;&gt; /etc/fstab
rm -rf /mnt/local-storage/lost+found
</code></pre><p>Now you can create every PV and PVC manually.</p>
<pre tabindex="0"><code>mkdir /mnt/local-storage/pv-tst

cat pv-tst.yaml
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: pv-tst
spec:
  capacity:
    storage: 1Gi
  local:
    path: /mnt/local-storage/pv-tst
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - kubernetes03.devopstales.intra
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pv-tst
  namespace: tst
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  volumeName: pv-tst
  storageClassName: local
</code></pre><h3 id="add-automated-hostpath-provisioner">Add automated hostpath-provisioner</h3>
<p>This is a Persistent Volume Claim (PVC) provisioner for Kubernetes. It dynamically provisions hostPath volumes to provide storage for PVCs.</p>
<pre tabindex="0"><code>git clone https://github.com/torchbox/k8s-hostpath-provisioner
cd k8s-hostpath-provisioner
kubectl apply -f deployment.yaml

nano local-sc.yaml
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: auto-local
  annotations:
    storageclass.kubernetes.io/is-default-class: &#34;true&#34;
provisioner: torchbox.com/hostpath
parameters:
  pvDir: /mnt/local-storage
</code></pre><p>Test the provisioner by creating a new PVC:</p>
<pre tabindex="0"><code>cat testpvc.yaml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: testpvc
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 50Gi

kubectl create -f testpvc.yaml
kubectl get pvc
NAME      STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
testpvc   Bound     pvc-145c785e-ab83-11e7-9432-4201ac1fd019   50Gi       RWX            auto-local     10s
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                             
                                <category scheme="debian" term="debian" label="Debian" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install Grafana Loki with Helm3]]></title>
            <link href="https://devopstales.github.io/kubernetes/helm3-loki/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/monitoring/grafana-loki/?utm_source=atom_feed" rel="related" type="text/html" title="Grafana Loki" />
                <link href="https://devopstales.github.io/linux/graylog-pfsense-squid/?utm_source=atom_feed" rel="related" type="text/html" title="Analyzing PFsense squid logs in Graylog" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph-storage-with-csi-driver/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD volume with CSI driver" />
                <link href="https://devopstales.github.io/linux/graylog3-pfsense/?utm_source=atom_feed" rel="related" type="text/html" title="Analyzing PFsense logs in Graylog3" />
                <link href="https://devopstales.github.io/sso/grafana-sso/?utm_source=atom_feed" rel="related" type="text/html" title="SSO login to Grafana" />
            
                <id>https://devopstales.github.io/kubernetes/helm3-loki/</id>
            
            
            <published>2020-01-03T00:00:00+00:00</published>
            <updated>2020-01-03T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Helm is a template based package management system for kubernetes applications.</p>
<h3 id="wath-is-new-in-helm3">Wath is new in Helm3</h3>
<p>The most important change in Helm3, tiller was removed completely. Tiller was the server component (rinninf in a pod on the Kubernetes cluster) for helm&rsquo;s cli. When Helm 2 was developed, Kubernetes did not yet have role-based access control (RBAC) therefore to achieve mentioned goal, Helm had to take care of that itself. After Kubernetes 1.6 RBAC is enabled by default so you had to create a serviceaccount for tiller. With Tiller gone, Helm permissions are now simply evaluated using kubeconfig file.</p>
<p>Tiller was also used as a central hub for Helm release information and for maintaining the Helm state. In Helm 3 the same information are fetched directly from Kubernetes API Server and Charts are rendered client-side.</p>
<p>Helm 2 stored the informations of the releases in configmaps now in Helm 3 that is stored in secrets for better security.</p>
<h3 id="install-chart-with-helm3">Install Chart with Helm3</h3>
<p>The removal of Tiller means you didn&rsquo;t need a <code>helm init</code> for initializing the tiller.</p>
<pre tabindex="0"><code>helm repo add loki https://grafana.github.io/loki/charts
helm repo add stable https://kubernetes-charts.storage.googleapis.com
helm repo update

kubectl create namespace loki-stackhtop

helm upgrade --install loki --namespace=loki-stack loki/loki-stack
elm3 upgrade --install grafana --namespace=loki-stack stable/grafana
</code></pre><p>Namespaces are important now. <code>helm ls</code> won’t show anything, we have to specify the namespace with it:</p>
<pre tabindex="0"><code>helm -n loki-stack ls
</code></pre><h3 id="access-grafana-interface">Access Grafana Interface</h3>
<pre tabindex="0"><code>kubectl get secret -n loki-stack grafana -o jsonpath=&#34;{.data.admin-password}&#34; | base64 --decode
kubectl port-forward -n loki-stack service/grafana 3000:80

# go to localhost:3000
# add loki datasource URL http://loki:3100 and press Save &amp; Test
</code></pre><p><img src="/img/include/loki_1.png" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/loki_2.png" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/loki_3.png" alt="Example image"  class="zoomable" /></p>
<p><img src="/img/include/loki_4.png" alt="Example image"  class="zoomable" /></p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-security" term="k8s-security" label="k8s-security" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm3" term="helm3" label="helm3" />
                             
                                <category scheme="loki" term="loki" label="loki" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Backup your Kubernetes Cluster with Velero]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-velero-backup/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-cert-manager/?utm_source=atom_feed" rel="related" type="text/html" title="Install cert-manager for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/kind-install/?utm_source=atom_feed" rel="related" type="text/html" title="Starting local Kubernetes using kind" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb/?utm_source=atom_feed" rel="related" type="text/html" title="Install MetalLB load balancer for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-tillerless-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Tillerless helm2 install" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD for dynamic provisioning" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-velero-backup/</id>
            
            
            <published>2020-01-02T00:00:00+00:00</published>
            <updated>2020-01-02T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Velero (formerly Heptio Ark) gives you tools to back up and restore your Kubernetes cluster resources and persistent volumes. You can run Velero with a cloud provider or on-premises.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="how-its-work">How it&rsquo;s work</h3>
<p>Each Velero operation (on-demand backup, scheduled backup, restore) is a custom resource, stored in etcd. A backup opertaion is uploads a tarball of copied Kubernetes objects into cloud object storage. After that calls the cloud provider API to make disk snapshots of persistent volumes, if specified. Optionally you can specify hooks to be executed during the backup. When you create a backup, you can specify a TTL by adding the flag <code>--ttl &lt;DURATION&gt;</code>.</p>
<h3 id="velero-supported-providers">Velero supported providers</h3>
<table>
  <thead>
      <tr>
          <th>Object Store</th>
          <th>Volume Snapshotter</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>AWS S3</td>
          <td>AWS EBS</td>
      </tr>
      <tr>
          <td>Google Cloud Storage</td>
          <td>Google Compute Engine Disks</td>
      </tr>
      <tr>
          <td>Azure Blob Storage</td>
          <td>Azure Managed Disks</td>
      </tr>
      <tr>
          <td>-</td>
          <td>Portworx Volume</td>
      </tr>
      <tr>
          <td>-</td>
          <td>OpenEBS CStor Volume</td>
      </tr>
  </tbody>
</table>
<h3 id="install-cli">Install cli</h3>
<pre tabindex="0"><code>wget https://github.com/vmware-tanzu/velero/releases/download/v1.2.0/velero-v1.2.0-linux-amd64.tar.gz
tar -xzf velero-v1.2.0-linux-amd64.tar.gz
sudo cp velero-v1.2.0-linux-amd64/velero /usr/local/sbin
</code></pre><h2 id="deploy-minio-and-deno-app">Deploy minio and deno app</h2>
<pre tabindex="0"><code>kubctl apply -f velero-v1.2.0-linux-amd64/examples/minio/00-minio-deployment.yaml
kubctl apply -f velero-v1.2.0-linux-amd64/examples/nginx-app/base.yaml
</code></pre><h3 id="deploy-server-component">Deploy server component</h3>
<pre tabindex="0"><code>nano velero.yaml
image:
  repository: velero/velero
  tag: v1.2.0
  pullPolicy: IfNotPresent

initContainers:
  - name: aws
    image: velero/velero-plugin-for-aws:v1.0.0
    imagePullPolicy: IfNotPresent
    volumeMounts:
      - mountPath: /target
        name: plugins

metrics:
  enabled: true
  scrapeInterval: 30s

  # Pod annotations for Prometheus
  podAnnotations:
    prometheus.io/scrape: &#34;true&#34;
    prometheus.io/port: &#34;8085&#34;
    prometheus.io/path: &#34;/metrics&#34;

  serviceMonitor:
    enabled: false
    additionalLabels: {}



configuration:
  provider: aws
  backupStorageLocation:
    name: aws
    bucket: velero
    config:
      region: minio
      s3ForcePathStyle: true
      publicUrl: https://minio.devopstales.intra
      s3Url: http://minio:9000
  volumeSnapshotLocation:
    name: aws
    bucket: kubernetes-pv
    config:
      region: minio
      s3ForcePathStyle: true
      publicUrl: https://minio.devopstales.intra
      s3Url: http://minio:9000

credentials:
  useSecret: true
  secretContents:
    cloud: |
      [default]
      aws_access_key_id = minio
      aws_secret_access_key = minio123

snapshotsEnabled: true
deployRestic: true
</code></pre><pre tabindex="0"><code>helm repo add vmware-tanzu https://vmware-tanzu.github.io/helm-charts
helm repo update

helm install velero vmware-tanzu/velero --namespace velero -f velero.yaml
</code></pre><h3 id="create-backup">Create Backup</h3>
<pre tabindex="0"><code>velero backup create nginx-backup --selector app=nginx
velero backup describe nginx-backup
velero backup logs nginx-backup
velero backup get

velero schedule create nginx-daily --schedule=&#34;0 1 * * *&#34; --selector app=nginx
velero schedule get
velero backup get
</code></pre><h3 id="restore-test">Restore test</h3>
<pre tabindex="0"><code>kubectl delete ns nginx-example

velero restore create --from-backup nginx-backup
velero restore get

kubectl get po -n nginx-example
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="s3" term="s3" label="S3" />
                             
                                <category scheme="helm3" term="helm3" label="helm3" />
                             
                                <category scheme="backup" term="backup" label="Backup" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install cert-manager for Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-cert-manager/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/kind-install/?utm_source=atom_feed" rel="related" type="text/html" title="Starting local Kubernetes using kind" />
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb/?utm_source=atom_feed" rel="related" type="text/html" title="Install MetalLB load balancer for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-tillerless-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Tillerless helm2 install" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/kubernetes/k8s-nginx-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes nginx ingress with helm" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-cert-manager/</id>
            
            
            <published>2019-12-29T00:00:00+00:00</published>
            <updated>2019-12-29T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install  cert-manager running on Kubernetes (k8s).</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>cert-manager is a native Kubernetes certificate management controller. It can help with issuing certificates from a variety of sources, such as Let’s Encrypt, HashiCorp Vault, Venafi, a simple signing key pair, or self signed.</p>
<h3 id="install-cert-managger">Install cert-managger</h3>
<p>In order to install cert-manager, we must first create a namespace to run it in.</p>
<pre tabindex="0"><code>kubectl create namespace cert-manager
</code></pre><p>Install the <code>CustomResourceDefinitions</code> and cert-manager itself</p>
<pre tabindex="0"><code>kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.12.0/cert-manager.yaml
</code></pre><p>Verifying the installation</p>
<pre tabindex="0"><code>kubectl get pods --namespace cert-manager

NAME                                       READY   STATUS    RESTARTS   AGE
cert-manager-5c6866597-zw7kh               1/1     Running   0          2m
cert-manager-cainjector-577f6d9fd7-tr77l   1/1     Running   0          2m
cert-manager-webhook-787858fcdb-nlzsq      1/1     Running   0          2m
</code></pre><h3 id="create-a-clusterissuer">Create a ClusterIssuer</h3>
<p>Before you can begin issuing certificates, you must configure at least one <code>Issuer</code> or <code>ClusterIssuer</code> resource in your cluster. These resources represent a particular signing authority and detail how the certificate requests are going to be honored. For this Demo I will use my own CA as an Issuer.</p>
<pre tabindex="0"><code>cat issuer.yaml
apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: ca-issuer
  namespace: cert-manager
spec:
  ca:
    secretName: ca-key-pair

kubectl apply -f issuer.yaml
</code></pre><p>In order to create my certs, I must submit my CA certificate and singing private key to the Kubernetes Cluster so that cert-manager is able to use them and sign certificates.</p>
<pre tabindex="0"><code>cat  rootCA.key | base64
LS0tLS1CRUdJTiB...
cat rootCA.crt | base64
LS0tLSD5DUdJTiB...

cat ca-key-pair.yaml
apiVersion: v1
kind: Secret
metadata:
  name: ca-key-pair
  namespace: cert-manager
data:
  tls.key: LS0tLS1CRUdJTiB...
  tls.crt: LS0tLSD5DUdJTiB...

kubectl apply -f ca-key-pair.yaml
</code></pre><h3 id="demo">demo</h3>
<p>Create cert for test</p>
<pre tabindex="0"><code>cat test-resources.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: cert-manager-test
---
apiVersion: cert-manager.io/v1alpha2
kind: Issuer
metadata:
  name: test-selfsigned
  namespace: cert-manager-test
spec:
  selfSigned: {}
---
apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: selfsigned-cert
  namespace: cert-manager-test
spec:
  commonName: example.com
  secretName: selfsigned-cert-tls
  issuerRef:
    name: test-selfsigned
---
apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: ca-cert
  namespace: cert-manager-test
spec:
  commonName: example.com
  secretName: ca-cert-tls
  issuerRef:
    name: ca-issuer
    kind: ClusterIssuer

kubectl apply -f test-resources.yaml
</code></pre><pre tabindex="0"><code>kubectl describe certificate -n cert-manager-test

...
Spec:
  Common Name:  example.com
  Issuer Ref:
    Name:       test-selfsigned
  Secret Name:  selfsigned-cert-tls
Status:
  Conditions:
    Last Transition Time:  2019-12-29T17:34:30Z
    Message:               Certificate is up to date and has not expired
    Reason:                Ready
    Status:                True
    Type:                  Ready
  Not After:               2019-12-29T17:34:29Z
Events:
  Type    Reason      Age   From          Message
  ----    ------      ----  ----          -------
  Normal  CertIssued  4s    cert-manager  Certificate issued successfully
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Openshift secondary route]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-secondary-router/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-gitlab-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Installing GitLab on OpenShift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-kompose/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Run docker-compoe in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-add-node/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Add Nodes to a Cluster" />
                <link href="https://devopstales.github.io/kubernetes/openshift-letsencrypt/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Letsencrypt certificates" />
                <link href="https://devopstales.github.io/kubernetes/openshift-hostalreadyclaimed/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Error: HostAlreadyClaimed" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-secondary-router/</id>
            
            
            <published>2019-12-20T00:00:00+00:00</published>
            <updated>2019-12-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I this tutorial I will show you how to create a secondari router for Openshift.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="environment">Environment</h3>
<pre tabindex="0"><code>192.168.1.40    deployer
192.168.1.41    openshift01 # master node
192.168.1.42    openshift02 # infra node
192.168.1.43    openshift03 # worker node with second router
192.168.1.44    openshift04 # worker node
</code></pre><h3 id="deploy-route">Deploy route</h3>
<pre tabindex="0"><code>oc adm router router-public --replicas=2 --ports=&#34;8080:8080,8443:8443&#34; \
--stats-port=1937 --selector=&#34;router=public&#34; --labels=&#34;router=public&#34;

oc set env dc/router-public \
DEFAULT_CERTIFICATE_PATH=/etc/pki/tls/private/tls.crt \
NAMESPACE_LABELS=&#34;router=public&#34; \
ROUTER_ALLOW_WILDCARD_ROUTES=true \
ROUTER_ENABLE_HTTP2=true \
ROUTER_HAPROXY_CONFIG_MANAGER=true \
ROUTER_SERVICE_HTTP_PORT=8080 \
ROUTER_SERVICE_HTTPS_PORT=8443 \
ROUTER_TCP_BALANCE_SCHEME=roundrobin

oc label node openshift03 &#34;router=public&#34;
</code></pre><p>Configurate your firewall to create a NAT rule from publicIP:80 to openshift03:8080 and publicIP:443 to openshift03:8443</p>
<h3 id="demo">Demo</h3>
<pre tabindex="0"><code>oc new-project test
oc label namespace test router=public
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="keycloak" term="keycloak" label="Keycloak" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Starting local Kubernetes using kind]]></title>
            <link href="https://devopstales.github.io/kubernetes/kind-install/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-metallb/?utm_source=atom_feed" rel="related" type="text/html" title="Install MetalLB load balancer for Kubernetes" />
                <link href="https://devopstales.github.io/kubernetes/k8s-tillerless-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Tillerless helm2 install" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/kubernetes/k8s-nginx-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes nginx ingress with helm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
            
                <id>https://devopstales.github.io/kubernetes/kind-install/</id>
            
            
            <published>2019-12-20T00:00:00+00:00</published>
            <updated>2019-12-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this article, I will show you how to run a cluster in single Docker container using kind.</p>
<h3 id="what-is-kind">What is kind?</h3>
<p>Kind (Kubernetes IN Docker) is a tool to start kubernetes nodes as a docker container. It is a cross-platform tool you can run with Docker for Windows too.</p>
<h3 id="install-kind-binary">Install kind binary</h3>
<pre tabindex="0"><code>wget https://github.com/kubernetes-sigs/kind/releases/latest/download/kind-linux-amd64
chmod +x kind-linux-amd64
sudo mv kind-linux-amd64 /usr/local/sbin/kind
</code></pre><h3 id="start-a-cluster-for-ingress">Start a cluster for Ingress</h3>
<pre tabindex="0"><code>cat &lt;&lt;EOF | kind create cluster --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  kubeadmConfigPatches:
  - |
    apiVersion: kubeadm.k8s.io/v1beta2
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: &#34;ingress-ready=true&#34;
        authorization-mode: &#34;AlwaysAllow&#34;
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
  - containerPort: 443
    hostPort: 443
EOF
</code></pre><h3 id="install-ingress">Install ingress</h3>
<pre tabindex="0"><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml

# patch ingress for kind
kubectl patch deployments -n ingress-nginx nginx-ingress-controller -p &#39;{&#34;spec&#34;:{&#34;template&#34;:{&#34;spec&#34;:{&#34;containers&#34;:[{&#34;name&#34;:&#34;nginx-ingress-controller&#34;,&#34;ports&#34;:[{&#34;containerPort&#34;:80,&#34;hostPort&#34;:80},{&#34;containerPort&#34;:443,&#34;hostPort&#34;:443}]}],&#34;nodeSelector&#34;:{&#34;ingress-ready&#34;:&#34;true&#34;}}}}}&#39;
</code></pre><h3 id="demo">Demo</h3>
<pre tabindex="0"><code>kubectl apply -f https://kind.sigs.k8s.io/examples/ingress/usage.yaml

curl localhost/foo
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Installing GitLab on OpenShift]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-gitlab-helm/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-gitlabrunner/?utm_source=atom_feed" rel="related" type="text/html" title="Install Gitlab runner on Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Helm" />
                <link href="https://devopstales.github.io/kubernetes/openshift-kompose/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Run docker-compoe in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-add-node/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Add Nodes to a Cluster" />
                <link href="https://devopstales.github.io/kubernetes/openshift-letsencrypt/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Letsencrypt certificates" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-gitlab-helm/</id>
            
            
            <published>2019-11-18T00:00:00+00:00</published>
            <updated>2019-11-18T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I  had to install Gitlab to Openshift recently. Turned out getting GitLab up and running on OpenShift is not so easy.</p>
<h3 id="create-new-project">Create new project</h3>
<pre tabindex="0"><code>oc new-project gitlab-devopstales.intra
</code></pre><h3 id="deploy-helm">Deploy helm</h3>
<pre tabindex="0"><code>nano helm-namespace-account.yaml
kind: ServiceAccount
apiVersion: v1
metadata:
  name: tiller-gitlab-devopstales.intra
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller-gitlab-devopstales.intra
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller-gitlab-devopstales.intra
    namespace: kube-system
</code></pre><p>Now set up Helm, install the Tiller plugin and add the GitLab repository.</p>
<pre tabindex="0"><code>oc apply -f helm-namespace-account.yaml
oc get sa

helm init --service-account tiller-gitlab-devopstales.intra --tiller-namespace gitlab-mydomain-intra
oc get po -n kube-system

export TILLER_NAMESPACE=kube-system
echo $TILLER_NAMESPACE
helm version
</code></pre><h2 id="get-helmchart">Get helmchart</h2>
<pre tabindex="0"><code>helm repo add gitlab https://charts.gitlab.io/
helm repo update

oc adm policy add-scc-to-user anyuid -z default -n gitlab-devopstales.intra
oc adm policy add-scc-to-user anyuid -z gitlab-runner -n gitlab-devopstales.intra

# gitlab-tst is the name of the helm deployment
oc adm policy add-scc-to-user anyuid -z gitlab-tst-shared-secrets
oc adm policy add-scc-to-user anyuid -z gitlab-tst-gitlab-runner
oc adm policy add-scc-to-user anyuid -z gitlab-tst-prometheus-server
oc adm policy add-scc-to-user anyuid -z default
</code></pre><h3 id="create-chart-values">Create chart values</h3>
<pre tabindex="0"><code>nano gitlab-values.yml
certmanager:
  install: false
global:
  appConfig:
    enableUsagePing: true
    enableImpersonation: true
    defaultCanCreateGroup: true
    usernameChangingEnabled: true
    issueClosingPattern:
    defaultTheme:
    defaultProjectsFeatures:
      issues: true
      mergeRequests: true
      wiki: true
      snippets: true
      builds: true
      containerRegistry: true
    ldap:
      servers:
        main:
          base: dc=mydomain,dc=intra
          user_filter: (&amp;(objectClass=user)(memberof=cn=Users,dc=mydomain,dc=intra))
          bind_dn: Administrator@devopstales.intra
          host: 192.168.10.4
          label: devopstales.intra
          password:
            key: password
            secret: gitlab-ldap-secret
          port: 636
          encryption: simple_tls
          uid: sAMAccountName
          active_directory: true
          verify_certificates: false
          allow_username_or_email_login: true
    omniauth:
      enabled: true
      blockAutoCreatedUsers: false
      allowSingleSignOn: [&#39;oauth2_generic&#39;]
      providers:
        - secret: gitlab-sso
          key: provider
    backups:
      bucket: gitlab-devopstales.intra
      tmpBucket: gitlab-devopstales.intra
      objectStorage:
        backend: s3
    lfs:
      bucket: gitlab-devopstales.intra
      connection:
        secret: ceph-storage
        key: gitlab
    artifacts:
      bucket: gitlab-devopstales.intra
      connection:
        secret: ceph-storage
        key: gitlab
    uploads:
      bucket: gitlab-devopstales.intra
      connection:
        secret: ceph-storage
        key: gitlab
    packages:
      bucket: gitlab-devopstales.intra
      connection:
        secret: ceph-storage
        key: gitlab
    externalDiffs:
      bucket: gitlab-devopstales.intra
      connection:
        secret: ceph-storage
        key: gitlab
    pseudonymizer:
      bucket: gitlab-devopstales.intra
      connection:
        secret: ceph-storage
        key: gitlab
  edition: ce
  email:
    from: gitlab@devopstales.intra
  hosts:
    domain: devopstales.intra
    externalIP: gitlab.devopstales.intra
    gitlab:
      name: gitlab.devopstales.intra
      https: false
    registry:
      name: gitlab-registry.devopstales.intra
      https: false
  ingress:
    enabled: false
    configureCertmanager: false
    tls:
      secretName: gitlab-certs
  smtp:
    address: mail.active.hu
    authentication: &#34;&#34;
    domain: devopstales.intra
    enabled: true
    port: 25
  gitlab-exporter:
    enabled: false
  registry:
    bucket: gitlab-registry
  minio:
    enabled: false
nginx-ingress:
  enabled: false
gitlab-runner:
  rbac:
    create: true
registry:
  enabled: true
  storage:
    secret: ceph-storage
    key: registry
  image:
    repository: docker.io/registry
    tag: 2.6.0
gitlab:
  task-runner:
    backups:
      objectStorage:
        config:
          secret: storage-config
          key: config
</code></pre><h3 id="create-secrets-for-deployment">Create secrets for deployment</h3>
<pre tabindex="0"><code>nano ceph.gitlab-data.yaml
provider: AWS
region: default
aws_access_key_id: W3MNDO373H6LQUNCG4SG
aws_secret_access_key: vVFEWx3hqbcrGJyaZVie9YoFG6rPoRYmqnDzRwrn
endpoint: &#34;https://s3.devopstales.intra&#34;
enable_signature_v4_streaming: false

# admin jog kell a cephez
nano ceph.gitlab-registry.yaml
cache:
  blobdescriptor: inmemory
s3:
  region: default
  bucket: gitlab-registry
  accesskey: PZIOIH63CENHPG15XY42
  secretkey: K6K1lWO7Jtyp5rZiCwj77JC5BFMEAZ4a2PAkg9fB
  regionendpoint: https://s3.devopstales.intra
  rootdirectory: /
  secure: true
  v4auth: false
  encrypt: false
  chunksize: 5242880
redirect:
  disable: true
</code></pre><pre tabindex="0"><code>nano ceph.backup.config
[default]
access_key = W3MNDO373H8LQUNCJ8QV
access_token = vVFEWx8hqbcrGJyaZVie8YoER8rPoRYmqnDzRwrn
host_base = s3.devopstales.intra
host_bucket = %(bucket)s.s3.devopstales.intra
bucket_location = US
use_https = True
check_ssl_certificate = False
</code></pre><pre tabindex="0"><code>nano keycloak.sso.yaml
name: &#39;oauth2_generic&#39;
label: &#39;mydomain&#39;
app_id: &#39;gitlab&#39;
app_secret: &#39;f2514bd4-92e4-40fa-bec4-382838db25f0&#39;
args:
  client_options:
    site: &#39;https://sso.devopstales.intra&#39;
    user_info_url: &#39;/auth/realms/mydomain/protocol/openid-connect/userinfo&#39;
    authorize_url: &#39;/auth/realms/mydomain/protocol/openid-connect/auth&#39;
    token_url: &#39;/auth/realms/mydomain/protocol/openid-connect/token&#39;
  user_response_structure:
    attributes:
      email: &#39;email&#39;
      first_name: &#39;given_name&#39;
      last_name: &#39;family_name&#39;
      name: &#39;name&#39;
      nickname: &#39;preferred_username&#39;
    id_path: &#39;preferred_username&#39;
</code></pre><h3 id="deploy-secrets">Deploy secrets</h3>
<pre tabindex="0"><code># https ssl cert
oc create secret tls gitlab-certs --cert=tls.crt --key=tls.key

oc create secret generic storage-config --from-file=config=ceph.backup.config

oc create secret generic ceph-storage --from-file=registry=ceph.gitlab-registry.yaml --from-file=gitlab=ceph.gitlab-data.yaml

oc create secret generic gitlab-sso --from-file=provider=keycloak.sso.yaml
oc create secret generic gitlab-ldap-secret --from-literal=password=
</code></pre><h3 id="deploy-application-with-helm">Deploy application with helm</h3>
<pre tabindex="0"><code>helm upgrade --install -f gitlab-values.yml gitlab-tst gitlab/gitlab --debug --dry-run
helm upgrade --install -f gitlab-values.yml gitlab-tst gitlab/gitlab --timeout 600
helm upgrade -f gitlab-values.yml gitlab-tst gitlab/gitlab --timeout 600

# https://docs.gitlab.com/charts/installation/version_mappings.html
helm upgrade -f gitlab-values.yml gitlab-tst gitlab/gitlab --version 2.3.5 --timeout 600

# gitlab-tst
oc get secret gitlab-tst-gitlab-initial-root-password -o jsonpath=&#39;{.data.password}&#39; | base64 -d
</code></pre><h3></h3>
<pre tabindex="0"><code>nano gitlab-ssh-nodeport-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitlab-shell-nodeport
  labels:
    app: gitlab-shell
    name: gitlab-shell-nodeport
spec:
  type: NodePort
  ports:
    - port: 2222
      nodePort: 32222
      name: ssh
  selector:
    app: gitlab-shell
</code></pre><pre tabindex="0"><code>oc create -f gitlab-ssh-nodeport-svc.yaml
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="gitlab" term="gitlab" label="Gitlab" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Ceph RBD volume with CSI driver]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-ceph-storage-with-csi-driver/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/who-mapping-rbd-device/?utm_source=atom_feed" rel="related" type="text/html" title="Ceph: who is mapping a RBD device" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/linux/install-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Install Ceph cluster" />
                <link href="https://devopstales.github.io/linux/ceph-block-device/?utm_source=atom_feed" rel="related" type="text/html" title="Use Ceph Block Device" />
                <link href="https://devopstales.github.io/linux/ceph-cephfs/?utm_source=atom_feed" rel="related" type="text/html" title="Use Ceph CephFS" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-ceph-storage-with-csi-driver/</id>
            
            
            <published>2019-10-08T00:00:00+00:00</published>
            <updated>2019-10-08T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can you use CEPH RBD with CSI driver for persistent storage on Kubernetes.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>The Container Storage Interface (CSI) is a standard for exposing arbitrary block and file storage storage systems to Kubernetes. Using CSI third-party storage providers can write and deploy plugins exposing storage systems in Kubernetes. Before we begin lets ensure that we have the following requirements:</p>
<ul>
<li>Kubernetes cluster v1.14+</li>
<li>allow-privileged flag enabled for both kubelet and API server</li>
<li>Running Ceph cluster</li>
</ul>
<pre tabindex="0"><code>git clone https://github.com/ceph/ceph-csi.git
cd ceph-csi/deploy/rbd/kubernetes/v1.14+/

kubectl create -f csi-nodeplugin-rbac.yaml
kubectl create -f csi-provisioner-rbac.yaml
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ceph config generate-minimal-conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># minimal ceph.conf for 54530b3e-9823-4c84-9c39-a65470e961e8</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>global<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>	fsid <span style="color:#f92672">=</span> 54530b3e-9823-4c84-9c39-a65470e961e8
</span></span><span style="display:flex;"><span>	mon_host <span style="color:#f92672">=</span> <span style="color:#f92672">[</span>v2:1192.168.1.31:3300/0,v1:192.168.1.31:6789/0<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>v2:192.168.1.32:3300/0,v1:192.168.1.32:6789/0<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>v2:192.168.1.33:3300/0,v1:192.168.1.33:6789/0<span style="color:#f92672">]</span>
</span></span></code></pre></div><pre tabindex="0"><code>nano csi-config-map.yaml
---
apiVersion: v1
kind: ConfigMap
data:
  config.json: |-
    [
      {
        &#34;clusterID&#34;: &#34;54530b3e-9823-4c84-9c39-a65470e961e8&#34;,
        &#34;monitors&#34;: [
          &#34;192.168.1.31:6789&#34;,
          &#34;192.168.1.32:6789&#34;,
          &#34;192.168.1.33:6789&#34;
        ]
      }
    ]
metadata:
  name: ceph-csi-config


kubectl create -fcsi-config-map.yaml
</code></pre><pre tabindex="0"><code>kubectl create -f csi-rbdplugin-provisioner.yaml
kubectl create -f csi-rbdplugin.yaml
</code></pre><pre tabindex="0"><code>ceph auth get-key client.admin|base64
QVFDTDliVmNEb21I32SHoPxXNGhmRkczTFNtcXM0ZW5VaXlTZEE977==

nano csi-rbd-secret.yaml
---
apiVersion: v1
kind: Secret
metadata:
  name: csi-rbd-secret
  namespace: default
data:
  userID: admin
  userKey: QVFDTDliVmNEb21I32SHoPxXNGhmRkczTFNtcXM0ZW5VaXlTZEE977==

nano rbd-csi-sc.yaml
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
   name: csi-rbd
provisioner: rbd.csi.ceph.com
parameters:
   monitors: 192.168.1.31:6790,192.168.1.32:6790,192.168.1.33:6790
   clusterID: k8s-ceph
   pool: rbd
   imageFeatures: layering
   csi.storage.k8s.io/provisioner-secret-name: csi-rbd-secret
   csi.storage.k8s.io/provisioner-secret-namespace: default
   csi.storage.k8s.io/node-publish-secret-name: csi-rbd-secret
   csi.storage.k8s.io/node-publish-secret-namespace: default
   adminid: admin
   csi.storage.k8s.io/fstype: ext4
reclaimPolicy: Delete
mountOptions:
   - discard

kubectl create -f csi-rbd-secret.yaml
kubectl create -f rbd-csi-sc.yaml

kubectl get storageclass
NAME      PROVISIONER        AGE
csi-rbd   rbd.csi.ceph.com   15s
</code></pre><pre tabindex="0"><code>nano raw-block-pvc.yaml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: raw-block-pvc
spec:
  accessModes:
    - ReadWriteMany
  volumeMode: Block
  resources:
    requests:
      storage: 1Gi
  storageClassName: csi-rbd

kubectl create -f raw-block-pvc.yaml

kubectl get pvc
NAME            STATUS    VOLUME                                  
raw-block-pvc   Bound     pvc-fd66b4d6-757d-22e9-8f9e-4f86e2356a59
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Ceph: who is mapping a RBD device]]></title>
            <link href="https://devopstales.github.io/kubernetes/who-mapping-rbd-device/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/linux/install-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Install Ceph cluster" />
                <link href="https://devopstales.github.io/linux/ceph-block-device/?utm_source=atom_feed" rel="related" type="text/html" title="Use Ceph Block Device" />
                <link href="https://devopstales.github.io/linux/ceph-cephfs/?utm_source=atom_feed" rel="related" type="text/html" title="Use Ceph CephFS" />
            
                <id>https://devopstales.github.io/kubernetes/who-mapping-rbd-device/</id>
            
            
            <published>2019-10-05T00:00:00+00:00</published>
            <updated>2019-10-05T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<h3 id="main-problem">Main problem</h3>
<p>I get this error in Openshift:</p>
<pre tabindex="0"><code>  MountVolume.WaitForAttach failed for volume &#34;pvc-9fcd3d08-d14e-11e9-a958-66934f1af826&#34; :
  rbd image k8s-prod/kubernetes-dynamic-pvc-a0029613-d14e-11e9-aaf5-8611e6b1c395 is still being used
</code></pre><h3 id="solution">Solution</h3>
<p>So I Wanna know who is using this DBD device?</p>
<pre tabindex="0"><code>rbd status k8s-prod/kubernetes-dynamic-pvc-a0029613-d14e-11e9-aaf5-8611e6b1c395
Watchers:
	watcher=192.168.1.43:0/3614154426 client.165467009 cookie=18446462598732840961
</code></pre><p>To solve this problem you need to restart Openshift&rsquo;s Kubernetes components.</p>
<pre tabindex="0"><code>ssh 192.168.1.43
systemctl restart docker origin-node
</code></pre><p>Check if it is still mounted:</p>
<pre tabindex="0"><code>lsblk | grep &#34;pvc-9fcd3d08-d14e-11e9-a958-66934f1af826&#34;
rbd12                                252:192  0  100G  0 disk /var/lib/kubelet/plugins/kubernetes.io/csi/pv/pvc-9fcd3d08-d14e-11e9-a958-66934f1af826/globalmount/0001-0024-e285a458-7c95-4187-8129-fbd6c370c537-0000000000000006-12154609-2d98-11ec-9b66-66a9f6ca788c
</code></pre><p>With the restart of the docker and the kubelet the container dse not running anymore, so you can unmount it. Fot theat you need the rnd client.</p>
<pre tabindex="0"><code>rbd unmap k8s-prod/kubernetes-dynamic-pvc-a0029613-d14e-11e9-aaf5-8611e6b1c395
# or 
rbd unmap -o force k8s-prod/kubernetes-dynamic-pvc-a0029613-d14e-11e9-aaf5-8611e6b1c395
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/ansible-k8s-install/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/ansible-operator-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Ansible Operator Overview" />
                <link href="https://devopstales.github.io/kubernetes/ansible-openshift-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-restrict-access/?utm_source=atom_feed" rel="related" type="text/html" title="Restrict access to OpenShift routes by IP address" />
                <link href="https://devopstales.github.io/kubernetes/openshift-kompose/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Run docker-compoe in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-add-node/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Add Nodes to a Cluster" />
            
                <id>https://devopstales.github.io/kubernetes/ansible-k8s-install/</id>
            
            
            <published>2019-10-03T00:00:00+00:00</published>
            <updated>2019-10-03T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Kubespray is a pre made ansible playbook for Kubernetes installation. In this Post I will show you how to use to install a new Kubernetes cluster.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="environment">Environment</h3>
<pre tabindex="0"><code>192.168.1.60    deployer.devopstales.intra (LB)
192.168.1.61    master0.devopstales.intra  (master)
192.168.1.62    master1.devopstales.intra  (master)
192.168.1.63    master2.devopstales.intra  (master)
192.168.1.64    worker0.devopstales.intra  (worker)
192.168.1.65    worker1.devopstales.intra  (worker)

# hardware requirement
4 CPU
16G RAM
</code></pre><h3 id="prerequirement">Prerequirement</h3>
<pre tabindex="0"><code># deployer

nano ~/.ssh/config
Host master0
    Hostname master0.devopstales.intra
    User ansible

Host master1
    Hostname master1.devopstales.intra
    User ansible

Host master2
    Hostname master2.devopstales.intra
    User ansible

Host worker0.devopstales.intra
    Hostname worker0.devopstales.intra
    User ansible

Host worker1
    Hostname worker1.devopstales.intra
    User ansible
</code></pre><pre tabindex="0"><code>yum install epel-release -y
yum update -y
yum install python-pip git tmux nano -y
git clone https://github.com/kubernetes-sigs/kubespray.git
cd kubespray
pip install --user -r requirements.txt

cp -rfp inventory/sample inventory/mycluster
</code></pre><h3 id="configurate-installer">Configurate Installer</h3>
<pre tabindex="0"><code>nano inventory/mycluster/inventory.ini
master0   ansible_host=192.168.1.61 ip=192.168.1.61
master1   ansible_host=192.168.1.62 ip=192.168.1.62
master2   ansible_host=192.168.1.63 ip=192.168.1.63
worker0   ansible_host=192.168.1.64 ip=192.168.1.64
worker1   ansible_host=192.168.1.65 ip=192.168.1.65

# ## configure a bastion host if your nodes are not directly reachable
# bastion ansible_host=x.x.x.x ansible_user=some_user

[kube-master]
master0
master1
master2

[etcd]
master0
master1
master2

[kube-node]
worker0
worker1

[calico-rr]

[k8s-cluster:children]
kube-master
kube-node
calico-rr
</code></pre><h3 id="run-the-installer">Run the Installer</h3>
<pre tabindex="0"><code>tmux new -s kubespray
ansible-playbook -i inventory/mycluster/inventory.ini --become \
--user=centos --become-user=root cluster.yml

test install on node:
sudo -i
kubectl get node
NAME      STATUS   ROLES    AGE   VERSION
master0   Ready    master   92m   v1.15.3
master1   Ready    master   91m   v1.15.3
master2   Ready    master   91m   v1.15.3
worker0   Ready    &lt;none&gt;   90m   v1.15.3
worker1   Ready    &lt;none&gt;   90m   v1.15.3

kubectl config get-clusters
</code></pre><h3 id="lets-configure-an-external-loadbalancer">Let’s configure an external loadbalancer</h3>
<pre tabindex="0"><code>sudo firewall-cmd --add-port=6443/tcp --permanent
sudo firewall-cmd --reload

yum -y install haproxy

nano ..
listen k8s-apiserver-https
  bind *:6443
  option ssl-hello-chk
  mode tcp
  balance roundrobin
  timeout client 3h
  timeout server 3h
  server master0 192.168.1.61:6443
  server master1 192.168.1.62:6443
  server master2 192.168.1.63:6443

systemctl enable --now haproxy
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Restrict access to OpenShift routes by IP address]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-restrict-access/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-vmware/?utm_source=atom_feed" rel="related" type="text/html" title="Configure Openshift In-Tree vSphere Cloud Provider" />
                <link href="https://devopstales.github.io/kubernetes/openshift-kompose/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Run docker-compoe in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/ansible-operator-overview/?utm_source=atom_feed" rel="related" type="text/html" title="Ansible Operator Overview" />
                <link href="https://devopstales.github.io/kubernetes/openshift-add-node/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Add Nodes to a Cluster" />
                <link href="https://devopstales.github.io/kubernetes/openshift-letsencrypt/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Letsencrypt certificates" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-restrict-access/</id>
            
            
            <published>2019-09-20T00:00:00+00:00</published>
            <updated>2019-09-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can restrict access to the routes by source IP address.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="restricting-access-to-a-route">Restricting access to a route</h3>
<p>After creating and exposing a route, you can add an annotation to the route specifying the IP address(es) that you would like to whitelist. Whitelisting a IP address automatically blacklists everything else.</p>
<pre tabindex="0"><code>oc annotate route test-route haproxy.router.openshift.io/ip_whitelist=192.168.0.0/24
</code></pre><p>To allow several IP addresses through to the route, separate each IP with a space:</p>
<pre tabindex="0"><code>oc annotate route test-route haproxy.router.openshift.io/ip_whitelist=192.168.1.10 180.5.61.153 192.168.1.0/24 192.168.0.0/24
</code></pre><p>To delete the IPs from the annotation, you can run the command:</p>
<pre tabindex="0"><code>oc annotate route test-route haproxy.router.openshift.io/ip_whitelist-
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Openshift: Run docker-compoe in Openshift]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-kompose/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-add-node/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Add Nodes to a Cluster" />
                <link href="https://devopstales.github.io/kubernetes/openshift-letsencrypt/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Letsencrypt certificates" />
                <link href="https://devopstales.github.io/kubernetes/openshift-hostalreadyclaimed/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Error: HostAlreadyClaimed" />
                <link href="https://devopstales.github.io/kubernetes/openshift-gitlabrunner/?utm_source=atom_feed" rel="related" type="text/html" title="Install Gitlab runner on Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-extregistry/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: External registry" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-kompose/</id>
            
            
            <published>2019-09-08T00:00:00+00:00</published>
            <updated>2019-09-08T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Kompose is a open source tool that uses docker-compose file to deploy on kubernetes. Openshift is also Kubernetes based and Kompose is support Openshift too.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<p>Let’s say we have project with multiple microsevices that needs to deploy on Openshift and they have docker-compose.yml and Dockerfile. How do we deploy on Openshift?<br></p>
<p>Use Kompose to convert the docker-compose file to openshift compatible kubernetes config.</p>
<pre tabindex="0"><code>kompose convert -f docker-compose.yaml --provider=openshift
</code></pre><p>This command creates a separet yaml file for all kubernetes building block like  &ldquo;-imagestream.yaml&rdquo;, &ldquo;-service.yaml&rdquo;, &ldquo;-deploymentconfig.yaml&rdquo; for each microservice. We can use these config files to deploy on Openshift easily.</p>
<pre tabindex="0"><code>kompose up --provider=openshift -f docker-compose.yml --build build-config --namespace=devopstales
</code></pre><p>If you have &ldquo;build&rdquo; option in docker-compose file, kompose automatically detects remote git url to deploy automatically.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="docker-compose" term="docker-compose" label="docker-compose" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install MetalLB load balancer for Kubernetes]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-metallb/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-nginx-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes nginx ingress with helm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-tillerless-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Tillerless helm2 install" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-copy-secret/?utm_source=atom_feed" rel="related" type="text/html" title="Copying Kubernetes Secrets Between Namespaces" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-metallb/</id>
            
            
            <published>2019-08-08T00:00:00+00:00</published>
            <updated>2019-08-08T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this tutorial I will show you how to install  Metal LB load balancer running on Kubernetes (k8s).</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="enviroment">Enviroment</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get node
</span></span><span style="display:flex;"><span>NAME     STATUS   ROLES    EXTERNAL-IP
</span></span><span style="display:flex;"><span>host-1   Ready    master   203.0.113.1
</span></span><span style="display:flex;"><span>host-2   Ready    node     203.0.113.2
</span></span><span style="display:flex;"><span>host-3   Ready    node     203.0.113.3
</span></span><span style="display:flex;"><span>host-4   Ready    node     203.0.113.4
</span></span></code></pre></div><p>MetalLB provides a network load-balancer implementation for Kubernetes clusters that do not run on a supported cloud provider, effectively allowing the usage of LoadBalancer Services within ber-metal Installation. Kubernetes does not offer an implementation of network load-balancers (Services of type LoadBalancer) for bare metal clusters. The implementations of Network LB that Kubernetes does ship with are all glue code that calls out to various IaaS platforms (GCP, AWS, Azure…). If you’re not running on a supported IaaS platform (GCP, AWS, Azure…), LoadBalancers will remain in the “pending” state indefinitely when created.</p>
<p><img src="/img/include/metallb.jpg" alt="Example image"  class="zoomable" /></p>
<p>First we need to apply the MetalLB manifest.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.8.1/manifests/metallb.yaml
</span></span></code></pre></div><p>Create a metallb-configmap.yaml file and modify your IP range accordingly.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt; EOF &gt; metallb-config.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">metallb-system</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    address-pools:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - name: my-ip-space
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      protocol: layer2
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      addresses:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - 203.0.113.2-203.0.113.4</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl apply -f metallb-config.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">kubectl get pods -n metallb-system</span>
</span></span></code></pre></div><p>Exposing a service through the load balancer</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">cat &lt;EOF&gt;&gt; nginx.yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx-deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">nginx:latest</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">LoadBalancer</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">nginx</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">EOF</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl apply -f nginx-deployment.yaml
</span></span><span style="display:flex;"><span>kubectl get svc
</span></span><span style="display:flex;"><span>NAME           TYPE           CLUSTER-IP       EXTERNAL-IP    PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>        AGE
</span></span><span style="display:flex;"><span>nginx          LoadBalancer   10.109.51.83     203.0.113.2    80:30452/TCP   5m
</span></span></code></pre></div>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="k8s-network" term="k8s-network" label="k8s-network" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                             
                                <category scheme="metallb" term="metallb" label="MetalLB" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Tillerless helm2 install]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-tillerless-helm/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-copy-secret/?utm_source=atom_feed" rel="related" type="text/html" title="Copying Kubernetes Secrets Between Namespaces" />
                <link href="https://devopstales.github.io/kubernetes/k8s-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/kubernetes/k8s-nginx-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes nginx ingress with helm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
                <link href="https://devopstales.github.io/kubernetes/openshift-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Helm" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-tillerless-helm/</id>
            
            
            <published>2019-07-23T00:00:00+00:00</published>
            <updated>2019-07-23T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>It looks like it is not so hard to have Tillerless Helm. So let me go to more details.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>Since Helm v2, helm got a server part called The Tiller Server which is interacts with the helm client, and the Kubernetes API server. By default helm init installs a Tiller deployment to Kubernetes clusters and communicates via gRPC.</p>
<p><img src="/img/include/tiller1.png" alt="Example image"  class="zoomable" /></p>
<p>The community voted that Helm v3 should be Tillerless. If we can run tiller localli we can achieve the same goal.</p>
<p><img src="/img/include/tiller2.png" alt="Example image"  class="zoomable" /></p>
<p>There is a helm plugin for this same purpose.</p>
<pre tabindex="0"><code>$ helm plugin install https://github.com/rimusz/helm-tiller
Installed plugin: tiller
</code></pre><h3 id="use-this-plugin-locally">Use this plugin locally</h3>
<pre tabindex="0"><code>helm tiller start
</code></pre><p>It will start the tiller locally and kube-system namespace will be used to store helm releases but you can change the name of the namespace if you want:</p>
<pre tabindex="0"><code>helm tiller start my-team-namespace

# stop tiller
helm tiller stop
</code></pre><h3 id="how-to-use-this-plugin-in-cicd-pipelines">How to use this plugin in CI/CD pipelines</h3>
<pre tabindex="0"><code>helm tiller start-ci
export HELM_HOST=localhost:44134
</code></pre><p>Then your helm will know where to connect to Tiller and you do not need to make any changes in your CI pipelines.</p>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes Ceph RBD for dynamic provisioning]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-ceph/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/linux/install-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Install Ceph cluster" />
                <link href="https://devopstales.github.io/linux/ceph-block-device/?utm_source=atom_feed" rel="related" type="text/html" title="Use Ceph Block Device" />
                <link href="https://devopstales.github.io/linux/ceph-cephfs/?utm_source=atom_feed" rel="related" type="text/html" title="Use Ceph CephFS" />
                <link href="https://devopstales.github.io/kubernetes/k8s-nginx-ingress/?utm_source=atom_feed" rel="related" type="text/html" title="Kubernetes nginx ingress with helm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-ceph/</id>
            
            
            <published>2019-07-18T00:00:00+00:00</published>
            <updated>2019-07-18T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can you use CEPH RBD for persistent storagi on Kubernetes.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="environment">Environment</h3>
<pre tabindex="0"><code># openshift cluster
192.168.1.41  kubernetes01 # master node
192.168.1.42  kubernetes02 # frontend node
192.168.1.43  kubernetes03 # worker node
192.168.1.44  kubernetes04 # worker node
192.168.1.45  kubernetes05 # worker node

# ceph cluster
192.168.1.31    ceph01
192.168.1.32    ceph02
192.168.1.33    ceph03
</code></pre><h3 id="prerequirement">Prerequirement</h3>
<p>RBD volume provisioner needs admin key from Ceph to provision storage. To get the admin key from Ceph cluster use this command:</p>
<pre tabindex="0"><code>sudo ceph --cluster ceph auth get-key client.admin

nano ceph-admin-secret.yaml
apiVersion: v1
data:
  key: QVFBOFF2SlZheUJQRVJBQWgvS2cwT1laQUhPQno3akZwekxxdGc9PQ==
kind: Secret
metadata:
  name: ceph-admin-secret
  namespace: kube-system
type: kubernetes.io/rbd
</code></pre><p>I will also create a separate Ceph pool for</p>
<pre tabindex="0"><code>sudo ceph --cluster ceph osd pool create k8s 1024 1024
sudo ceph --cluster ceph auth get-or-create client.k8s mon &#39;allow r&#39; osd &#39;allow rwx pool=k8s&#39;
sudo ceph --cluster ceph auth get-key client.k8s

nano ceph-secret-k8s.yaml
apiVersion: v1
data:
  key: QVFBOFF2SlZheUJQRVJBQWgvS2ctS2htOFNSZnRvclJPRk1jdXc9PQ==
kind: Secret
metadata:
  name: ceph-secret-k8s
  namespace: kube-system
type: kubernetes.io/rbd
</code></pre><pre tabindex="0"><code># on all openshift node
wget http://download.proxmox.com/debian/proxmox-ve-release-5.x.gpg \
-O /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg
chmod +r /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg

echo deb http://download.proxmox.com/debian/ceph-luminous $(lsb_release -sc) main \
&gt; /etc/apt/sources.list.d/ceph.list

apt-get update
apt-get install ceph-common -y
</code></pre><pre tabindex="0"><code>cat &lt;&lt;EOF &gt; rbd-provisioner.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: rbd-provisioner
rules:
  - apiGroups: [&#34;&#34;]
    resources: [&#34;persistentvolumes&#34;]
    verbs: [&#34;get&#34;, &#34;list&#34;, &#34;watch&#34;, &#34;create&#34;, &#34;delete&#34;]
  - apiGroups: [&#34;&#34;]
    resources: [&#34;persistentvolumeclaims&#34;]
    verbs: [&#34;get&#34;, &#34;list&#34;, &#34;watch&#34;, &#34;update&#34;]
  - apiGroups: [&#34;storage.k8s.io&#34;]
    resources: [&#34;storageclasses&#34;]
    verbs: [&#34;get&#34;, &#34;list&#34;, &#34;watch&#34;]
  - apiGroups: [&#34;&#34;]
    resources: [&#34;events&#34;]
    verbs: [&#34;list&#34;, &#34;watch&#34;, &#34;create&#34;, &#34;update&#34;, &#34;patch&#34;]
  - apiGroups: [&#34;&#34;]
    resources: [&#34;services&#34;]
#    resourceNames: [&#34;kube-dns&#34;]
    verbs: [&#34;list&#34;, &#34;get&#34;]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: rbd-provisioner
subjects:
  - kind: ServiceAccount
    name: rbd-provisioner
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: rbd-provisioner
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: Role
metadata:
  name: rbd-provisioner
rules:
- apiGroups: [&#34;&#34;]
  resources: [&#34;secrets&#34;]
  verbs: [&#34;get&#34;]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: rbd-provisioner
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: rbd-provisioner
subjects:
- kind: ServiceAccount
  name: rbd-provisioner
  namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rbd-provisioner
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: rbd-provisioner
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: rbd-provisioner
    spec:
      containers:
      - name: rbd-provisioner
        image: &#34;quay.io/external_storage/rbd-provisioner:v1.0.0-k8s1.10&#34;
        env:
        - name: PROVISIONER_NAME
          value: ceph.com/rbd
      serviceAccount: rbd-provisioner
EOF

kubectl create -n kube-system -f rbd-provisioner.yaml
kubectl get pods -l app=rbd-provisioner -n kube-system
</code></pre><p>Please check that <code>quay.io/external_storage/rbd-provisioner:latest</code> image has the same Ceph version as your Ceph cluster.</p>
<pre tabindex="0"><code>docker pull quay.io/external_storage/rbd-provisioner:latest
docker history quay.io/external_storage/rbd-provisioner:latest | grep CEPH_VERSION

# pfroxmox ceph use luminous so I&#39;will use v1.0.0-k8s1.10
docker history quay.io/external_storage/rbd-provisioner:v1.0.0-k8s1.10 | grep CEPH_VERSION
&lt;missing&gt;           13 months ago       /bin/sh -c #(nop)  ENV CEPH_VERSION=luminous    0B
</code></pre><pre tabindex="0"><code># on one openshift master node
nano  k8s-storage.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: &#34;true&#34;
  name: k8s
parameters:
  adminId: admin
  adminSecretName: ceph-admin-secret
  adminSecretNamespace: kube-system
  imageFeatures: layering
  imageFormat: &#34;2&#34;
  monitors: 192.168.1.31.xip.io:6789, 192.168.1.32.xip.io:6789, 192.168.1.33.xip.io:6789
  pool: k8s
  userId: k8s
  userSecretName: ceph-secret-k8s
provisioner: ceph.com/rbd
reclaimPolicy: Delete
volumeBindingMode: Immediate
allowVolumeExpansion: true


kubectl apply -f ceph-admin-secret.yaml
kubectl apply -f ceph-secret-k8s.yaml
kubectl apply -f k8s-storage.yaml
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                             
                                <category scheme="debian" term="debian" label="Debian" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Kubernetes nginx ingress with helm]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-nginx-ingress/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install kubernetes with kubeadm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-copy-secret/?utm_source=atom_feed" rel="related" type="text/html" title="Copying Kubernetes Secrets Between Namespaces" />
                <link href="https://devopstales.github.io/kubernetes/k8s-helm-rbac/?utm_source=atom_feed" rel="related" type="text/html" title="RBAC permissions for Helm" />
                <link href="https://devopstales.github.io/kubernetes/kubectl-multi-cluster-config/?utm_source=atom_feed" rel="related" type="text/html" title="Configure kubectl for multiple clusters" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-nginx-ingress/</id>
            
            
            <published>2019-07-14T00:00:00+00:00</published>
            <updated>2019-07-14T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can you use install IngressControllert on Kubernetes with helm.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<h3 id="environment">Environment</h3>
<pre tabindex="0"><code># openshift cluster
192.168.1.41  kubernetes01 # master node
192.168.1.42  kubernetes02 # frontend node
192.168.1.43  kubernetes03 # worker node
192.168.1.44  kubernetes04 # worker node
192.168.1.45  kubernetes05 # worker node
</code></pre><h3 id="helm-with-cluster-admin-permissions">Helm with cluster-admin permissions</h3>
<pre tabindex="0"><code>at &lt;&lt;EOF&gt; helm-cluster-admin.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller-admin
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: tiller-admin
  namespace: kube-system
EOF
</code></pre><h3 id="init-helm">Init Helm</h3>
<pre tabindex="0"><code>kubectl create -f helm-cluster-admin.yaml

helm init --service-account helm
kubectl get po --all-namespaces | grep tiller
</code></pre><h3 id="tag-node-for-ingress">Tag node for ingress</h3>
<pre tabindex="0"><code>kubectl get nodes --show-labels
kubectl label nodes kubernetes02 node-role.kubernetes.io/frontend= --overwrite=true

helm install stable/nginx-ingress \
    --name nginx-ingress \
    --namespace=nginx-ingress \
    --set rbac.create=true \
    --set controller.kind=DaemonSet \
    --set controller.hostNetwork=true \
    --set controller.daemonset.useHostPort=true \
    --set controller.nodeSelector.&#34;node-role\.kubernetes\.io/frontend&#34;= \
    --set controller.stats.enabled=true \
    --set controller.metrics.enabled=true

kubectl --namespace nginx-ingress get services -o wide -w nginx-ingress-controller
kubectl create secret tls default-ingress-tls --key /path/to/private.pem --cert /path/to/cert.pem --namespace nginx-ingress
</code></pre><pre tabindex="0"><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta1/aio/deploy/recommended.yaml

kubectl create secret tls default-ingress-tls --key /path/to/private.pem --cert /path/to/cert.pem --namespace kubernetes-dashboard

cat &lt;&lt;EOF&gt; dashboard_ingress.yml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: kubernetes-dashboard-ingress
  namespace: kubernetes-dashboard
  annotations:
    kubernetes.io/tls-acme: &#39;true&#39;
    ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-passthrough: &#34;true&#34;
    nginx.ingress.kubernetes.io/secure-backends: &#34;true&#34;
    ingress.kubernetes.io/ssl-redirect: &#34;true&#34;
    ingress.kubernetes.io/force-ssl-redirect: &#34;true&#34;
spec:
  tls:
  - hosts:
    - dashboard.devopstales.intra
    secretName: default-ingress-tls
  rules:
  - host: dashboard.devopstales.intra
    http:
     paths:
     - backend:
         serviceName: kubernetes-dashboard
         servicePort: 443
EOF

kubectl apply -f dashboard_ingress.yml
</code></pre><pre tabindex="0"><code>kubectl create serviceaccount dashboard-admin-sa
kubectl create clusterrolebinding dashboard-admin-sa --clusterrole=cluster-admin --serviceaccount=default:dashboard-admin-sa

kubectl get secrets
NAME                  TYPE                                  DATA   AGE
dashboard-admin-sa-token-XXXXX   kubernetes.io/service-account-token   3      22h

kubectl describe secret dashboard-admin-sa-token-XXXXX
Name:         dashboard-admin-sa-token-bq9cr
...
token:      XXXXXXXXXXXXXXXXXXXXXXXXXX

# use this token to login
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                             
                                <category scheme="debian" term="debian" label="Debian" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install kubernetes with kubeadm]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-install/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/k8s-copy-secret/?utm_source=atom_feed" rel="related" type="text/html" title="Copying Kubernetes Secrets Between Namespaces" />
                <link href="https://devopstales.github.io/kubernetes/k8s-helm-rbac/?utm_source=atom_feed" rel="related" type="text/html" title="RBAC permissions for Helm" />
                <link href="https://devopstales.github.io/kubernetes/kubectl-multi-cluster-config/?utm_source=atom_feed" rel="related" type="text/html" title="Configure kubectl for multiple clusters" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-install/</id>
            
            
            <published>2019-07-12T00:00:00+00:00</published>
            <updated>2019-07-12T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Kubeadm is a tool that helps you bootstrap a simple Kubernetes cluster and simplifies the deployment process.</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<pre tabindex="0"><code>192.168.1.41  kubernetes01 # master node
192.168.1.42  kubernetes02 # frontend node
192.168.1.43  kubernetes03 # worker node
192.168.1.44  kubernetes04 # worker node
192.168.1.45  kubernetes05 # worker node

# hardware requirement
4 CPU
16G RAM
</code></pre><h3 id="install-docker">Install Docker</h3>
<pre tabindex="0"><code>apt-get update
apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -
add-apt-repository &#34;deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable&#34;
apt-get update
apt-get install docker-ce docker-ce-cli containerd.io
systemct start docker
systemct enable docker
</code></pre><h3 id="configuuration">Configuuration</h3>
<pre tabindex="0"><code>cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
EOF

echo &#39;1&#39; &gt; /proc/sys/net/ipv4/ip_forward
echo &#39;1&#39; &gt; /proc/sys/net/bridge/bridge-nf-call-iptables
</code></pre><h3 id="disable-swap">Disable swap</h3>
<pre tabindex="0"><code>free -h
swapoff -a
swapoff -a
sed -i.bak -r &#39;s/(.+ swap .+)/#\1/&#39; /etc/fstab
free -h
</code></pre><h3 id="install-kubeadm">Install kubeadm</h3>
<pre tabindex="0"><code>apt-get install ebtables ethtool apt-transport-https

curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF

apt-get update &amp;&amp; apt-get install -y kubelet kubeadm kubectl
apt-mark hold kubelet kubeadm kubect
systemctl enable kubelet &amp;&amp; systemctl start kubelet
kubeadm config images pul
</code></pre><h3 id="init-master">Init master</h3>
<pre tabindex="0"><code>kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.1.41


mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config


kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml
</code></pre><h3 id="join-workers-to-cluster">Join workers to cluster</h3>
<pre tabindex="0"><code>kubeadm join 192.168.1.41:6443 --token XXXXXXXX \
    --discovery-token-ca-cert-hash sha256:XXXXXXXX
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="debian" term="debian" label="Debian" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Ansible Operator Overview]]></title>
            <link href="https://devopstales.github.io/kubernetes/ansible-operator-overview/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/ansible-openshift-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-add-node/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: Add Nodes to a Cluster" />
                <link href="https://devopstales.github.io/kubernetes/openshift-letsencrypt/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Letsencrypt certificates" />
                <link href="https://devopstales.github.io/kubernetes/openshift-hostalreadyclaimed/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Error: HostAlreadyClaimed" />
                <link href="https://devopstales.github.io/kubernetes/openshift-gitlabrunner/?utm_source=atom_feed" rel="related" type="text/html" title="Install Gitlab runner on Openshift" />
            
                <id>https://devopstales.github.io/kubernetes/ansible-operator-overview/</id>
            
            
            <published>2019-07-10T00:00:00+00:00</published>
            <updated>2019-07-10T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Operators make it easy to manage complex stateful applications on top of Kubernetes. In this pos I will show you how to read an ansible based Openshift operator.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="why-an-operator">Why an Operator?</h3>
<p>Operators make it easy to manage complex stateful applications on top of Kubernetes. However writing an operator today can be difficult because of challenges such as using low level APIs, writing boilerplate, and a lack of modularity which leads to duplication.</p>
<h3 id="what-is-an-ansible-operator">What is an Ansible Operator?</h3>
<p>Ansible Operator is one of the available types of Operators that Operator SDK is able to generate. Operator SDK can create an operator using with Golang, Helm, or Ansible.
It is a collection of building blocks from Operator SDK that enables Ansible to handle the reconciliation logic for an Operator.</p>
<h3 id="how-ansible-operator-works">How Ansible Operator works?</h3>
<p>We want to trigger this Ansible logic when a Custom Resource changes. The Ansible Operator uses a Watches file, written in YAML, which holds the mapping between Custom Resources and Ansible Roles/Playbooks. The Operator expects this mapping file in a predefined location: <code>/opt/ansible/watches.yaml</code></p>
<p>Each mapping within the Watches file has mandatory fields:</p>
<ul>
<li>group: Group of the Custom Resource that you will be watching.</li>
<li>version: Version of the Custom Resource that you will be watching.</li>
<li>kind: Kind of the Custom Resource that you will be watching.</li>
<li>role (default): Path to the Role that should be run by the Operator for a particular Group-Version-Kind (GVK). This field is mutually exclusive with the &ldquo;playbook&rdquo; field.</li>
<li>playbook (optional): Path to the Playbook that should be run by the Operator.</li>
</ul>
<h3 id="initialize-new-operator-template">Initialize new operator template</h3>
<pre tabindex="0"><code># istall sdk client
brew install operator-sdk

# generate base temlate
operator-sdk new memcached-operator --type=ansible --api-version=cache.example.com/v1alpha1 --kind=Memcached --skip-git-init
cd memcached-operator
</code></pre><p>The sdk cli generated the base structure for all the componets. The main parts are the <code>watches.yaml</code> the Dockerfile in <code>build/Dockerfile</code> and the ansible role in <code>roles/</code><br> folder. Fore this tutorial I will use this role <a href="https://github.com/dymurray/memcached-operator-role">https://github.com/dymurray/memcached-operator-role</a>.<br>
In the role we must use k8s ansible module to deploy kubernetes compnets to the cluster.<br></p>
<pre tabindex="0"><code>nano roles/memcached/tasks/main.yml
---
- name: start memcached
  k8s:
    definition:
      kind: Deployment
      apiVersion: apps/v1
      metadata:
        name: &#39;{{ meta.name }}-memcached&#39;
        namespace: &#39;{{ meta.namespace }}&#39;
      spec:
        replicas: &#34;{{size}}&#34;
        selector:
          matchLabels:
            app: memcached
        template:
          metadata:
            labels:
              app: memcached
          spec:
            containers:
            - name: memcached
              command:
              - memcached
              - -m=64
              - -o
              - modern
              - -v
              image: &#34;memcached:1.4.36-alpine&#34;
              ports:
                - containerPort: 11211
</code></pre><p>You can use variables in ansible Jinja temlate from the CR spec or from kubernetes enviroment like namespace: <code>{{ meta.namespace }}</code>.<br>
Add default value to the <code>{{size}}</code> variable:</p>
<pre tabindex="0"><code>nano roles/memcached/defaults/main.yml
---
size: 1
</code></pre><h4 id="variable-sharing-example">Variable sharing Example</h4>
<pre tabindex="0"><code>apiVersion: &#34;foo.example.com/v1alpha1&#34;
kind: &#34;Foo&#34;
metadata:
  name: &#34;example&#34;
annotations:
  ansible.operator-sdk/reconcile-period: &#34;30s&#34;
  name: &#34;example&#34;
spec:
  message: &#34;Hello world 2&#34;
  newParameter: &#34;newParam&#34;
# associates GVK with Role
role: /opt/ansible/roles/Foo
</code></pre><pre tabindex="0"><code>- debug:
    msg: &#34;message value from CR spec: {{ message }}&#34;

- debug:
    msg: &#34;newParameter value from CR spec: {{ new_parameter }}&#34;

- debug:
    msg: &#34;name: {{ meta.name }}, namespace: {{ meta.namespace }}&#34;
</code></pre><p>The Openshidt SDK created a simple Dockerfile in <code>build/Dockerfile</code> to run the newly created ansible role. We nead to build a docker image from this Dockerfile and use this image in our memcached-operator deployment.</p>
<pre tabindex="0"><code># buid image
operator-sdk build memcached-operator:v0.0.1

# Edit deploy/operator.yaml to use the newly created memcached-operator:v0.0.1 docker image
sed -i &#39;s|{{ REPLACE_IMAGE }}|memcached-operator:v0.0.1|g&#39; deploy/operator.yaml

# If we did not want to download the image (besause we build it on the worker or it is representid on all of my workes) we can disable image pulling.
sed -i &#34;s|{{ pull_policy\|default(&#39;Always&#39;) }}|Never|g&#34; deploy/operator.yaml
</code></pre><h3 id="creating-the-operator-from-deploy-manifests">Creating the Operator from deploy manifests</h3>
<pre tabindex="0"><code>oc create -f deploy/crds/cache_v1alpha1_memcached_crd.yaml

oc new-project tutorial
oc create -f deploy/service_account.yaml
oc create -f deploy/role.yaml
oc create -f deploy/role_binding.yaml
oc create -f deploy/operator.yaml

oc get deployment
</code></pre><p>Now that we have deployed our Operator, let&rsquo;s create a CR and deploy an instance of memcached.
There is a sample CR in the scaffolding created as part of the Operator SDK. Inspect <code>deploy/crds/cache_v1alpha1_memcached_cr.yaml</code>, and then use it to create a Memcached custom resource.</p>
<pre tabindex="0"><code>oc create -f deploy/crds/cache_v1alpha1_memcached_cr.yaml



$ oc get deployment
NAME                 DESIRED CURRENT UP-TO-DATE AVAILABLE AGE
memcached-operator   1       1       1          1         2m
example-memcached    3       3       3          3         1m

#Check the pods to confirm 3 replicas were created:

$ oc get pods
NAME                                READY STATUS   RESTARTS AGE
example-memcached-6cc844747c-2hbln  1/1   Running  0        1m
example-memcached-6cc844747c-54q26  1/1   Running  0        1m
example-memcached-6cc844747c-7jfhc  1/1   Running  0        1m
memcached-operator-68b5b558c5-dxjwh 1/1   Running  0        2m
</code></pre><h3 id="removing-memcached-from-the-cluster">Removing Memcached from the cluster</h3>
<pre tabindex="0"><code># First, delete the &#39;memcached&#39; CR, which will remove the 4 Memcached pods and the associated deployment.
oc delete -f deploy/crds/cache_v1alpha1_memcached_cr.yaml

# Then, delete the memcached-operator deployment.
oc delete -f deploy/operator.yaml
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="k8s-operators" term="k8s-operators" label="k8s Operators" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="operator" term="operator" label="Operator" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Openshift: Add Nodes to a Cluster]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-add-node/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-letsencrypt/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Letsencrypt certificates" />
                <link href="https://devopstales.github.io/kubernetes/openshift-hostalreadyclaimed/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Error: HostAlreadyClaimed" />
                <link href="https://devopstales.github.io/kubernetes/openshift-gitlabrunner/?utm_source=atom_feed" rel="related" type="text/html" title="Install Gitlab runner on Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-extregistry/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: External registry" />
                <link href="https://devopstales.github.io/kubernetes/openshift-cert/?utm_source=atom_feed" rel="related" type="text/html" title="Change Certificates in Openshift" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-add-node/</id>
            
            
            <published>2019-06-27T00:00:00+00:00</published>
            <updated>2019-06-27T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Add Nodes to an existing Cluster.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<p>In the last post I used the basic htpasswd authentication method for the installatipn.<br>
But I can use Ansible-openshift to configure an LDAP backed at the install for the authentication.</p>
<h3 id="environment">Environment</h3>
<pre tabindex="0"><code>192.168.1.40    deployer
192.168.1.41    openshift01 # master node
192.168.1.42    openshift02 # infra node
192.168.1.43    openshift03 # worker node
192.168.1.44    openshift04 # new-worker node
192.168.1.45    openshift00 # new-master node
</code></pre><h3></h3>
<pre tabindex="0"><code>useradd origin
passwd origin
echo -e &#39;Defaults:origin !requiretty\norigin ALL = (root) NOPASSWD:ALL&#39; | tee /etc/sudoers.d/openshift
chmod 440 /etc/sudoers.d/openshift

# if Firewalld is running, allow SSH

firewall-cmd --add-service=ssh --permanent
firewall-cmd --reload

yum -y install centos-release-openshift-origin36 docker
vgcreate vg_origin01 /dev/sdb1

Volume group &#34;vg_origin01&#34; successfully created
echo VG=vg_origin01 &gt;&gt; /etc/sysconfig/docker-storage-setup
systemctl start docker
systemctl enable docker
</code></pre><h3 id="configurate-installer">Configurate Installer</h3>
<pre tabindex="0"><code>nano /etc/ansible/hosts
# add into OSEv3 section

[OSEv3:children]
masters
nodes
new_nodes
new_masters
new_etcd

[new_nodes]
openshift04.devopstales.intra openshift_node_group_name=&#39;node-config-compute&#39;
openshift00.devopstales.intra openshift_node_group_name=&#39;node-config-master&#39;

[new_masters]
openshift00.devopstales.intra openshift_node_group_name=&#39;node-config-master&#39;

[new_etcd]
openshift00.devopstales.intra containerized=true
</code></pre><h3 id="run-the-installer">Run the Installer</h3>
<p>Run Ansible Playbook for scaleout the Cluster.</p>
<pre tabindex="0"><code># deployer
cd /usr/share/ansible/openshift-ansible/

ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-node/scaleup.yml
ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-master/scaleup.yml
ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/openshift-etcd/scaleup.yml
</code></pre><h3 id="configurate-installer-1">Configurate Installer</h3>
<p>After finishing to add new Nodes, Open [/etc/ansible/hosts] again and move new definitions to existing [nodes] section like follows.</p>
<pre tabindex="0"><code>nano /etc/ansible/hosts
# add into OSEv3 section

[OSEv3:children]
masters
nodes
new_nodes
new_masters

[nodes]
openshift00.devopstales.intra openshift_node_group_name=&#39;node-config-master&#39;
openshift01.devopstales.intra openshift_node_group_name=&#39;node-config-master&#39;
openshift02.devopstales.intra openshift_node_group_name=&#39;node-config-infra&#39;
openshift03.devopstales.intra openshift_node_group_name=&#39;node-config-compute&#39;
openshift04.devopstales.intra openshift_node_group_name=&#39;node-config-compute

[new_nodes]

[masters]
openshift00.devopstales.intra openshift_node_group_name=&#39;node-config-master&#39;
openshift01.devopstales.intra openshift_node_group_name=&#39;node-config-master&#39;

[new_masters]

[etcd]
openshift01.devopstales.intra containerized=true
openshift00.devopstales.intra containerized=true

[new_etcd]
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Openshift Letsencrypt certificates]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-letsencrypt/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-hostalreadyclaimed/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Error: HostAlreadyClaimed" />
                <link href="https://devopstales.github.io/kubernetes/openshift-gitlabrunner/?utm_source=atom_feed" rel="related" type="text/html" title="Install Gitlab runner on Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-extregistry/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: External registry" />
                <link href="https://devopstales.github.io/kubernetes/openshift-cert/?utm_source=atom_feed" rel="related" type="text/html" title="Change Certificates in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-vmware/?utm_source=atom_feed" rel="related" type="text/html" title="Configure Openshift In-Tree vSphere Cloud Provider" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-letsencrypt/</id>
            
            
            <published>2019-05-28T00:00:00+00:00</published>
            <updated>2019-05-28T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Thanks to Tomáš Nožička developed openshift-acme as an ACME Controller for OpenShift and Kubernetes clusters. <br>
It automatically provision certficates</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="environment">Environment</h3>
<pre tabindex="0"><code>192.168.1.40    deployer
192.168.1.41    openshift01 # master node
192.168.1.42    openshift02 # infra node
192.168.1.43    openshift03 # worker node
</code></pre><h3 id="deploy-route">Deploy route</h3>
<pre tabindex="0"><code>oc project default

oc label node openshift02.devopstales.intra &#34;router=letsencrypt&#34;
oc get node --show-labels

oc adm policy add-scc-to-user hostnetwork -z router
oc adm router router-letsencrypt --replicas=0 --ports=&#34;8080:8080,8443:8443&#34; --stats-port=1937 --selector=&#34;router=letsencrypt&#34; --labels=&#34;router=letsencrypt&#34;

oc set env dc/router-letsencrypt \
NAMESPACE_LABELS=&#34;router=letsencrypt&#34; \
ROUTER_ALLOW_WILDCARD_ROUTES=true \
ROUTER_SERVICE_HTTP_PORT=8080 \
ROUTER_SERVICE_HTTPS_PORT=8443 \
ROUTER_TCP_BALANCE_SCHEME=roundrobin

oc set env dc/router NAMESPACE_LABELS=&#34;router != letsencrypt&#34;

oc scale dc/router-letsencrypt --replicas=3
</code></pre><h3 id="deploy-letsencrypt">Deploy letsencrypt</h3>
<pre tabindex="0"><code>GIT_REPO=https://raw.githubusercontent.com/devopstales/openshift-examples
GIT_PATH=/master/letsencrypt
oc new-project letsencrypt
oc create -f$GIT_REPO/$GIT_PATH/{clusterrole,serviceaccount,imagestream,deployment}.yaml
oc adm policy add-cluster-role-to-user openshift-acme -z openshift-acme
</code></pre><h1 id="demo">Demo</h1>
<pre tabindex="0"><code>oc new-project test
oc label namespace test router=letsencrypt
oc new-app centos/ruby-25-centos7~https://github.com/sclorg/ruby-ex.git
oc expose svc/ruby-ex

oc patch route ruby-ex \
    -p &#39;{&#34;metadata&#34;:{&#34;annotations&#34;:{  &#34;kubernetes.io/tls-acme&#34; : &#34;true&#34;   }}}&#39;
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="keycloak" term="keycloak" label="Keycloak" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Openshift Error: HostAlreadyClaimed]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-hostalreadyclaimed/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-gitlabrunner/?utm_source=atom_feed" rel="related" type="text/html" title="Install Gitlab runner on Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-extregistry/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: External registry" />
                <link href="https://devopstales.github.io/kubernetes/openshift-cert/?utm_source=atom_feed" rel="related" type="text/html" title="Change Certificates in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-vmware/?utm_source=atom_feed" rel="related" type="text/html" title="Configure Openshift In-Tree vSphere Cloud Provider" />
                <link href="https://devopstales.github.io/kubernetes/openshift-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Helm" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-hostalreadyclaimed/</id>
            
            
            <published>2019-05-05T00:00:00+00:00</published>
            <updated>2019-05-05T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>How to solvee Openshift Error: HostAlreadyClaimed</p>
<p>I created a new route for a service and the rout not created. Get this error:</p>
<pre tabindex="0"><code>Name:			keycloak-gatekeeper
Namespace:		phpmyadmin
Created:		17 minutes ago
Labels:			app=keycloak-gatekeeper
Annotations:		&lt;none&gt;
Requested Host:		phpmyadmin.devopstales.intra
			  rejected by router router: HostAlreadyClaimed (36 seconds ago)
			    route phpmyadmin/phpmyadmin-phpmyadmin has host phpmyadmin.devopstales.intra
Path:			&lt;none&gt;
TLS Termination:	edge
Insecure Policy:	Redirect
Endpoint Port:		http

Service:	keycloak-gatekeeper
Weight:		100 (100%)
Endpoints:	10.130.2.149:3000
</code></pre><p>So I listed all the routes but I dod not found this route. In the end the force delete solved my problem.</p>
<pre tabindex="0"><code>oc delete route --grace-period=0 --force=true --ignore-not-found=true -n phpmyadmin phpmyadmin-phpmyadmin
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Copying Kubernetes Secrets Between Namespaces]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-copy-secret/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Helm" />
                <link href="https://devopstales.github.io/kubernetes/k8s-helm-rbac/?utm_source=atom_feed" rel="related" type="text/html" title="RBAC permissions for Helm" />
                <link href="https://devopstales.github.io/kubernetes/kubectl-multi-cluster-config/?utm_source=atom_feed" rel="related" type="text/html" title="Configure kubectl for multiple clusters" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-copy-secret/</id>
            
            
            <published>2019-05-03T00:00:00+00:00</published>
            <updated>2019-05-03T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>A simple way of copying common secret data between namespaces</p>
<pre tabindex="0"><code>kubectl get secret private-registry --namespace=dev1 --export -o yaml |\
   kubectl apply --namespace=dev2 -f -
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install Gitlab runner on Openshift]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-gitlabrunner/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-extregistry/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift: External registry" />
                <link href="https://devopstales.github.io/kubernetes/openshift-cert/?utm_source=atom_feed" rel="related" type="text/html" title="Change Certificates in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-vmware/?utm_source=atom_feed" rel="related" type="text/html" title="Configure Openshift In-Tree vSphere Cloud Provider" />
                <link href="https://devopstales.github.io/kubernetes/openshift-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Helm" />
                <link href="https://devopstales.github.io/kubernetes/openshift-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Ceph RBD for dynamic provisioning" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-gitlabrunner/</id>
            
            
            <published>2019-04-20T00:00:00+00:00</published>
            <updated>2019-04-20T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will configure a gtlab rubber for Openshift.</p>
<h3 id="creating-a-service-account">Creating a Service Account</h3>
<pre tabindex="0"><code>oc new-project gitlab-rubber
oc create sa gitlab-ci
oc policy add-role-to-user edit system:serviceaccount:gitlab-rubber:gitlab-ci

oc get sa
NAME         SECRETS   AGE
builder      2         2d
default      2         2d
deployer     2         2d
gitlab-ci    2         2d

oc describe sa gitlab-ci
Name:           gitlab-ci
Namespace:      constellation
Labels:         &lt;none&gt;
Annotations:    &lt;none&gt;

Image pull secrets:     gitlab-ci-dockercfg-q5mj9

Mountable secrets:      gitlab-ci-token-gvvkv
                        gitlab-ci-dockercfg-q5mj9

Tokens:                 gitlab-ci-token-gvvkv
                        gitlab-ci-token-tfsf7

oc describe secret gitlab-ci-token-gvvkv
...
token:          eyJ...&lt;very-long-token&gt;...-cw

oc login --token=eyJ...&lt;very-long-token&gt;...-cw
</code></pre><h3 id="edit-gitlab-ci-config">Edit Gitlab-ci config</h3>
<pre tabindex="0"><code>nano  .gitlab-ci.yml
image: ebits/openshift-client

stages:
  - deployToOpenShift

variables:
  OPENSHIFT_SERVER: https://master.openshift.devopstales.intra:443
  OPENSHIFT_DOMAIN: openshift.devopstales.intra
  # Configure this variable in Secure Variables:
  OPENSHIFT_TOKEN: eyJ...&lt;very-long-token&gt;...-cw

.deploy: &amp;deploy
  before_script:
    - oc login &#34;$OPENSHIFT_SERVER&#34; --token=&#34;$OPENSHIFT_TOKEN&#34; --insecure-skip-tls-verify
  # login with the service account
    - oc project &#34;slides-openshift&#34;
  # enter into our slides project on OpenShift
  script:
    - &#34;oc get services $APP 2&gt; /dev/null || oc new-app . --name=$APP&#34;
  # create a new application from the image in the OpenShift registry
    - &#34;oc start-build $APP --from-dir=. --follow || sleep 3s&#34;
  # start a new build
    - &#34;oc get routes $APP 2&gt; /dev/null || oc expose service $APP --hostname=$APP_HOST&#34;
  # expose our application

develop:
  &lt;&lt;: *deploy
  stage: deployToOpenShift
  tags:
    - docker
  variables:
    APP: slides-openshift
    APP_HOST: demo-slides.$OPENSHIFT_DOMAIN
  environment:
    name: develop
    url: http://demo-slides.$OPENSHIFT_DOMAIN
  except:
    - master
</code></pre><h3 id="create-a-kubernetes-runner-in-openshift-from-template">Create a kubernetes runner in Openshift from template:</h3>
<pre tabindex="0"><code>wget https://raw.githubusercontent.com/devopstales/openshift-examples/master/template/gitlab-runner-template.yml
oc deploy gitlab-runner-template.yml
</code></pre><p>Deploy the template from the gui:</p>
<pre tabindex="0"><code>oc adm policy add-scc-to-user privileged system:serviceaccount:gitlab-rubber:&lt;application-name&gt;-user
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="openshift-4" term="openshift-4" label="Openshift 4" />
                             
                                <category scheme="gitlab" term="gitlab" label="Gitlab" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Openshift: External registry]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-extregistry/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-cert/?utm_source=atom_feed" rel="related" type="text/html" title="Change Certificates in Openshift" />
                <link href="https://devopstales.github.io/kubernetes/openshift-vmware/?utm_source=atom_feed" rel="related" type="text/html" title="Configure Openshift In-Tree vSphere Cloud Provider" />
                <link href="https://devopstales.github.io/kubernetes/openshift-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Helm" />
                <link href="https://devopstales.github.io/kubernetes/openshift-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/kubernetes/openshift-ldap/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift LDAP authentication" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-extregistry/</id>
            
            
            <published>2019-04-19T00:00:00+00:00</published>
            <updated>2019-04-19T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I this post I will demonstrate howyou can use an external registry in Openshift.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="configuring-openshift">Configuring Openshift</h3>
<p>From your client machine, create a Kubernetes secret object for Harbor.:</p>
<pre tabindex="0"><code>oc new-proyect registrytest

oc create secret docker-registry harbor \
--docker-server=https://harbor.devopstales.intra \
--docker-username=admin \
--docker-email=admin@devopstales.intra \
--docker-password=&#39;[your_admin_harbor_password]&#39;
</code></pre><p>If you want you can add this secret to the deafult template of the project creation.</p>
<h3 id="deploy-the-private-image-on-the-openshift-cluster">Deploy the private image on the Openshift cluster</h3>
<pre tabindex="0"><code>nano registrytest-deployment.yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  labels:
    run: nginx
  name: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      run: nginx
  template:
    metadata:
      labels:
        run: nginx
    spec:
      containers:
      - image: harbor.devopstales.intra/test/nginx:V2
        name: nginx
      imagePullSecrets:
      - name: harbor

oc apply -f kuard-deployment.yaml
oc get pods
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="harbor" term="harbor" label="Harbor" />
                             
                                <category scheme="registry" term="registry" label="registry" />
                             
                                <category scheme="vmware" term="vmware" label="vmware" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Change Certificates in Openshift]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-cert/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-vmware/?utm_source=atom_feed" rel="related" type="text/html" title="Configure Openshift In-Tree vSphere Cloud Provider" />
                <link href="https://devopstales.github.io/kubernetes/openshift-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Helm" />
                <link href="https://devopstales.github.io/kubernetes/openshift-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/kubernetes/openshift-ldap/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift LDAP authentication" />
                <link href="https://devopstales.github.io/kubernetes/ansible-openshift-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install Openshift" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-cert/</id>
            
            
            <published>2019-04-17T00:00:00+00:00</published>
            <updated>2019-04-17T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can you chnage certificate in Openshift.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="configure-certs">Configure certs:</h3>
<p>If you want to configure your Openshift cluster to use your own certificate you can do that wit this configuration.<br>
In my case the certificate files is MyCert.crt MyCert.key and the root CA is ccca.pem.</p>
<pre tabindex="0"><code>nano /ec/ansible/hosts
openshift_master_overwrite_named_certificates=true
openshift_hosted_router_certificate={&#34;certfile&#34;: &#34;/root/cert/MyCert.crt&#34;, &#34;keyfile&#34;: &#34;/root/cert/MyCert.key&#34;, &#34;cafile&#34;: &#34;/root/cert/ccca.pem&#34;}
openshift_master_named_certificates=[{&#34;names&#34;: [&#34;master.openshit.devopstales.intra&#34;],&#34;certfile&#34;: &#34;/root/cert/MyCert.crt&#34;, &#34;keyfile&#34;: &#34;/root/cert/MyCert.key&#34;, &#34;cafile&#34;: &#34;/root/cert/ccca.pem&#34;}]

openshift_redeploy_openshift_ca=true
openshift_certificate_expiry_fail_on_warn=false

# registry
openshift_hosted_registry_routecertificates={&#34;certfile&#34;: &#34;/root/cert/MyCert.crt&#34;, &#34;keyfile&#34;: &#34;/root/cert/MyCert.key&#34;, &#34;cafile&#34;: &#34;/root/cert/ccca.pem&#34;}
openshift_hosted_registry_routetermination=reencrypt
</code></pre><h3 id="run-the-installer">Run the Installer</h3>
<p>If your certificate is renewd you can cahge the certificate in the cluster with this playbooks.</p>
<pre tabindex="0"><code>oc get csr | grep Pending | awk &#39;{print $1}&#39; | xargs oc adm certificate approve

ansible-playbook -i hosts /usr/share/ansible/openshift-ansible/playbooks/redeploy-certificates.yml

ansible-playbook -i hosts /usr/share/ansible/openshift-ansible/playbooks/openshift-master/redeploy-openshift-ca.yml
ansible-playbook -i hosts /usr/share/ansible/openshift-ansible/playbooks/openshift-etcd/redeploy-ca.yml
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Configure Openshift In-Tree vSphere Cloud Provider]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-vmware/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-helm/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Helm" />
                <link href="https://devopstales.github.io/kubernetes/openshift-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/kubernetes/openshift-ldap/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift LDAP authentication" />
                <link href="https://devopstales.github.io/kubernetes/ansible-openshift-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install Openshift" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-vmware/</id>
            
            
            <published>2019-04-16T00:00:00+00:00</published>
            <updated>2019-04-16T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can you use vmware for persistent storagi on Openshift.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="vsphere-configuration">vSphere Configuration</h3>
<ul>
<li>Create a folder for all the VMs in vCenter</li>
<li>In the navigator, select the data center</li>
<li>Right-click and select the menu option to create the folder.</li>
<li>Select All vCenter Actions &gt; New VM and Template Folder.</li>
<li>Move Openshift vms to this folder</li>
<li>The name of the virtual machine must match the name of the nodes for the OpenShift cluster.</li>
</ul>
<p><img src="/img/include/k8s-vmware.png" alt="Example image"  class="zoomable" /></p>
<h3 id="set-up-the-govc-environment">Set up the GOVC environment:</h3>
<pre tabindex="0"><code># on deployer
curl -LO https://github.com/vmware/govmomi/releases/download/v0.20.0/govc_linux_amd64.gz
gunzip govc_linux_amd64.gz
chmod +x govc_linux_amd64
cp govc_linux_amd64 /usr/bin/govc
echo &#34;export GOVC_URL=&#39;vCenter IP OR FQDN&#39;&#34; &gt;&gt; /etc/profile
echo &#34;export GOVC_USERNAME=&#39;vCenter User&#39;&#34; &gt;&gt; /etc/profile
echo &#34;export GOVC_PASSWORD=&#39;vCenter Password&#39;&#34; &gt;&gt; /etc/profile
echo &#34;export GOVC_INSECURE=1&#34; &gt;&gt; /etc/profile
source /etc/profile
</code></pre><p>Add <code>disk.enableUUID=1</code> for all VM:</p>
<pre tabindex="0"><code>govc vm.info &lt;vm&gt;
govc ls /Datacenter/kubernetes/&lt;vm-folder-name&gt;
# example:
govc ls /Datacenter/kubernetes/okd-01

govc vm.change -e=&#34;disk.enableUUID=1&#34; -vm=&#39;VM Path&#39;
# example:
govc vm.change -e=&#34;disk.enableUUID=1&#34; -vm=&#39;/datacenter/kubernetes/okd-01/okd-m01&#39;
</code></pre><p>VM Hardware should be at version 15 or higher. Upgrade if needed:</p>
<pre tabindex="0"><code>govc vm.option.info &#39;/datacenter/kubernetes/okd-01/okd-m01&#39; | grep HwVersion

govc vm.upgrade -version=15 -vm &#39;/datacenter/kubernetes/okd-01/okd-m01&#39;
</code></pre><h3 id="create-the-required-roles">Create the required Roles</h3>
<ul>
<li>Navigate in the vSphere Client - Menu &gt; Administration &gt; Roles</li>
<li>Add a new Role and select the permissions required. Repeat for each role.</li>
</ul>
<table>
  <thead>
      <tr>
          <th style="text-align: center">Roles</th>
          <th style="text-align: center">Privileges</th>
          <th style="text-align: center">Entities</th>
          <th style="text-align: center">Propagate to Children</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">vcp-manage-okd-node-vms</td>
          <td style="text-align: center">Resource.AssignVMToPoolVirtualMachine.Config.AddExistingDisk, VirtualMachine.Config.AddNewDisk, VirtualMachine.Config.AddRemoveDevice, VirtualMachine.Config.RemoveDisk, VirtualMachine.Config.SettingsVirtualMachine.Inventory.Create, VirtualMachine.Inventory.Delete</td>
          <td style="text-align: center">Cluster, Hosts, VM Folder</td>
          <td style="text-align: center">Yes</td>
      </tr>
      <tr>
          <td style="text-align: center">vcp-manage-okd-volumes</td>
          <td style="text-align: center">Datastore.AllocateSpace, Datastore.FileManagement (Low level file operations)</td>
          <td style="text-align: center">Datastore</td>
          <td style="text-align: center">No</td>
      </tr>
      <tr>
          <td style="text-align: center">vcp-view-okd-spbm-profile</td>
          <td style="text-align: center">StorageProfile.View (Profile-driven storage view)</td>
          <td style="text-align: center">vCenter</td>
          <td style="text-align: center">No</td>
      </tr>
      <tr>
          <td style="text-align: center">Read-only (pre-existing default role)</td>
          <td style="text-align: center">System.Anonymous, System.Read, System.View</td>
          <td style="text-align: center">Datacenter, Datastore Cluster, Datastore Storage Folder</td>
          <td style="text-align: center">No</td>
      </tr>
  </tbody>
</table>
<h3 id="create-a-service-account">Create a service account</h3>
<ul>
<li>Create a vsphere user, or add a domain user, to provide access and assign the new roles to.</li>
</ul>
<h3 id="configure-ansible-installer">Configure ansible installer</h3>
<pre tabindex="0"><code>nano /etc/hosts
openshift_master_dynamic_provisioning_enabled=true
openshift_cloudprovider_kind=vsphere
openshift_cloudprovider_vsphere_username=&lt;vCenter User&gt;
openshift_cloudprovider_vsphere_password=&lt;vCenter Password&gt;
openshift_cloudprovider_vsphere_host=&lt;vCenter IP OR FQDN&gt;
openshift_cloudprovider_vsphere_datacenter=&lt;Datacenter&gt;
openshift_cloudprovider_vsphere_datastore=&lt;Datastore&gt;
openshift_cloudprovider_vsphere_folder=&lt;vm-folder-name&gt;
</code></pre><h3 id="add-providerid">Add providerID</h3>
<pre tabindex="0"><code>nano openshift-vmware-pacher.sh
DATACENTER=&#39;&lt;Datacenter&gt;&#39;
FOLDER=&#39;&lt;vm-folder-name&gt;&#39;
for vm in $(govc ls /$DATACENTER/vm/$FOLDER ); do
  MACHINE_INFO=$(govc vm.info -json -dc=$DATACENTER -vm.ipath=&#34;$vm&#34; -e=true)
  # My VMs are created on vmware with upper case names, so I need to edit the names with awk
  VM_NAME=$(jq -r &#39; .VirtualMachines[] | .Name&#39; &lt;&lt;&lt; $MACHINE_INFO | awk &#39;{print tolower($0)}&#39;)
  # UUIDs come in lowercase, upper case then
  VM_UUID=$( jq -r &#39; .VirtualMachines[] | .Config.Uuid&#39; &lt;&lt;&lt; $MACHINE_INFO | awk &#39;{print toupper($0)}&#39;)
  echo &#34;Patching $VM_NAME with UUID:$VM_UUID&#34;
  # This is done using dry-run to avoid possible mistakes, remove when you are confident you got everything right.
  kubectl patch node $VM_NAME -p &#34;{\&#34;spec\&#34;:{\&#34;providerID\&#34;:\&#34;vsphere://$VM_UUID\&#34;}}&#34;
done

chmod +x openshift-vmware-pacher.sh
./openshift-vmware-pacher.sh
</code></pre><h3 id="run-the-installer">Run the Installer</h3>
<pre tabindex="0"><code># deployer
cd /usr/share/ansible/openshift-ansible/
sudo ansible-playbook -i inventory/hosts.localhost playbooks/prerequisites.yml
sudo ansible-playbook -i inventory/hosts.localhost playbooks/deploy_cluster.yml

# If installastion failed or went wrong, the following uninstallation script can be run, and running installation can be tried again:
sudo ansible-playbook -i inventory/hosts.localhost playbooks/adhoc/uninstall.yml
</code></pre><h3 id="create-vsphere-storage-class">Create vSphere storage-class</h3>
<pre tabindex="0"><code>nano vmware-sc.yml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: &#34;true&#34;
  name: &#34;vsphere-standard&#34;
provisioner: kubernetes.io/vsphere-volume
parameters:
    diskformat: zeroedthick
    datastore: &#34;NFS&#34;
reclaimPolicy: Delete

oc aplay -f vmware-sc.yml
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="vmware" term="vmware" label="vmware" />
                             
                                <category scheme="vsphere" term="vsphere" label="vSphere" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Openshift Helm]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-helm/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/kubernetes/openshift-ldap/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift LDAP authentication" />
                <link href="https://devopstales.github.io/kubernetes/ansible-openshift-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install Openshift" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-helm/</id>
            
            
            <published>2019-04-15T00:00:00+00:00</published>
            <updated>2019-04-15T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I this post I will demonstrate the basic configuration of Helm on Openshift.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="helm">Helm</h3>
<p>Helm is a package manager and teplating engine for Kubernetes. It based on tree main components:</p>
<ul>
<li>the helm cli client</li>
<li>the helm server called tiller</li>
<li>the template pcakage called halm chart</li>
</ul>
<h3 id="install-helm-cli">Install helm cli</h3>
<pre tabindex="0"><code># https://github.com/helm/helm/releases
curl -s https://storage.googleapis.com/kubernetes-helm/helm-v2.9.1-linux-amd64.tar.gz | tar xz
cd linux-amd64
cp helm /usr/bin
</code></pre><h3 id="helm-with-cluster-admin-permissions">Helm with cluster-admin permissions</h3>
<pre tabindex="0"><code>nano helm-cluster-admin.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller-admin
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: tiller-admin
  namespace: kube-system
</code></pre><h3 id="init-helm">Init helm</h3>
<pre tabindex="0"><code>oc login master.openshift.devopstales.intra:443
kubectl apply -f helm-cluster-admin.yaml
helm init --service-account tiller-admin
</code></pre><h3 id="test-hem">Test hem</h3>
<pre tabindex="0"><code>oc new-project myapp
helm install stable/ghost -n blog

oc get pods -n myapp
export APP_HOST=$(kubectl get svc --namespace myapp blog-ghost --template &#34;{{ range (index .status.loadBalancer.ingress 0) }}{{ . }}{{ end }}&#34;)
export APP_PASSWORD=$(kubectl get secret --namespace myapp blog-ghost -o jsonpath=&#34;{.data.ghost-password}&#34; | base64 --decode)
export APP_DATABASE_PASSWORD=$(kubectl get secret --namespace myapp blog-mariadb -o jsonpath=&#34;{.data.mariadb-password}&#34; | base64 --decode)
helm upgrade blog stable/ghost --set service.type=LoadBalancer,ghostHost=$APP_HOST,ghostPassword=$APP_PASSWORD,mariadb.db.password=$APP_DATABASE_PASSWORD

oc get pods -n myapp
echo Password: $(kubectl get secret --namespace myapp blog-ghost -o jsonpath=&#34;{.data.ghost-password}&#34; | base64 --decode)
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[RBAC permissions for Helm]]></title>
            <link href="https://devopstales.github.io/kubernetes/k8s-helm-rbac/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/kubectl-multi-cluster-config/?utm_source=atom_feed" rel="related" type="text/html" title="Configure kubectl for multiple clusters" />
            
                <id>https://devopstales.github.io/kubernetes/k8s-helm-rbac/</id>
            
            
            <published>2019-04-14T00:00:00+00:00</published>
            <updated>2019-04-14T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I this post I will demonstrate the basic mechanism of helm and Role-based access control (RBAC).</p>


<H3>Parts of the Kubernetes series</H3>
<ul>
     <li>Part1a: <a href="../../kubernetes/ansible-k8s-install/">Install K8S with ansible</a></li>
     <li>Part1b: <a href="../../kubernetes/k8s-install/">Install K8S with kubeadm</a></li>
     <li>Part1c: <a href="../../kubernetes/k8s-install-containerd/">Install K8S with kubeadm and containerd</a></li>
     <li>Part1d: <a href="../../kubernetes/k8s-install-with-swap/">Install K8S with kubeadm and allow swap</a></li>
     <li>Part1e: <a href="../../kubernetes/k8s-kubeadm-ha/">Install K8S with kubeadm in HA mode</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb/">Intall metal-lb with K8S</a></li>
     <li>Part2: <a href="../../kubernetes/k8s-metallb-bgp-pfsense/">Intall metal-lb with BGP</a></li>
     <li>Part3: <a href="../../kubernetes/k8s-nginx-ingress/">Install Nginx ingress to K8S</a></li>
<!--      <li>Part3b: k8s-multiple-nginx-ingress -->
<!--      <li>Part3c: k8s-contour-ingress -->
     <li>Part4: <a href="../../kubernetes/k8s-cert-manager/">Install cert-manager to K8S</a></li>
<!-- local folder (+ autoprovisioning ) -->
     <li>Part5a: <a href="../../kubernetes/k8s-local-pv/">Use local persisten volume with K8S</a></li>
     <li>Part5b: <a href="../../kubernetes/k8s-ceph/">Use ceph persisten volume with K8S</a></li>
     <li>Part5c: <a href="../../kubernetes/k8s-ceph-storage-with-csi-driver/">Use ceph CSI persisten volume with K8S</a></li>
     <li>Part5d: <a href="../../kubernetes/k8s-cephfs-storage-with-csi-driver/">Kubernetes CephFS volume with CSI driver</a></li>
     <li>Part5e: <a href="../../kubernetes/k8s-longhorn/">Use Project Longhorn as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/k8s-install-openebs/">Use OpenEBS as persisten volume with K8S</a></li>
     <li>Part5f: <a href="../../kubernetes/kk8s-vmware/">vSphere persistent storage for K8S</a></li>
     <li>Part6: <a href="../../kubernetes/k8s-ceph-csi-extand/">Kubernetes volume expansion with Ceph RBD CSI driver</a></li>
<!-- Kadalu (based on glustergs) -->
<!-- linstore (based on drbd) -->
<!-- kubernetes netwoking caliko vs ... -->
     <li>Part7a: <a href="../../kubernetes/k8s-ipvs/">Install k8s with IPVS mode</a></li>
     <li>Part7b: <a href="../../kubernetes/k8s-calico-ebpf/">Install k8s with IPVS mode</a></li>
     <li>Part8: <a href="../../kubernetes/k8s-helm-rbac/">Use Helm with K8S</a></li>
     <li>Part9: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless helm2 install</a></li>
     <li>Part10: <a href="../../sso/k8s-dasboard-auth/">Kubernetes Dashboard SSO</a></li>
     <li>Part11: <a href="../../sso/k8s-kuberos/">Kuberos for K8S</a></li>
     <li>Part12: <a href="../../sso/k8s-gangway/">Gangway for K8S</a></li>
<!-- istio-install.md -->
     <li>Part13a: <a href="../../kubernetes/k8s-velero-backup/">Velero Backup for K8S</a></li>
     <li>Part13b: <a href="../../kubernetes/k8s-git-backup/">How to Backup Kubernetes to git?</a></li>
<!-- grafana loki -->
     <li>Part14a: <a href="../../kubernetes/k8s-prometheus-stack/">K8S Logging And Monitoring</a></li>
     <li>Part14b: <a href="../../kubernetes/helm3-loki/">Install Grafana Loki with Helm3</a></li>
<!-- logs to graylog -->
</ul>



<p>I whant to use helm on Openshift but firt I startid with the basics of helm and Role-based access control (RBAC) on a simple Kubernestes cluster. Most people seem to be running Helm with their own credentials or a dedicated service account with cluster-admin permissions. This isn’t very good from a security perspective, especially so if it’s being run within CI/CD.</p>
<h3 id="helm">Helm</h3>
<p>Helm is a package manager and teplating engine for Kubernetes. It based on tree main components:</p>
<ul>
<li>the helm cli client</li>
<li>the helm server called tiller</li>
<li>the template pcakage called halm chart</li>
</ul>
<h3 id="helm-with-cluster-admin-permissions">Helm with cluster-admin permissions</h3>
<pre tabindex="0"><code>nano helm-cluster-admin.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller-admin
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: tiller-admin
  namespace: kube-system
</code></pre><h3 id="helm-with-namespace-permissions">Helm with namespace permissions</h3>
<p>We are granting permissions on only the API groups and resources that Tiller needs to deploy and manage releases in its namespace.</p>
<pre tabindex="0"><code>nano helm-dev-namespace.yaml
kind: Namespace
apiVersion: v1
metadata:
  name: dev
---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: tiller
  namespace: dev
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: tiller-manager
  namespace: dev
rules:
- apiGroups: [&#34;&#34;, &#34;batch&#34;, &#34;extensions&#34;, &#34;apps&#34;]
  resources: [&#34;*&#34;]
  verbs: [&#34;*&#34;]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: tiller-binding
  namespace: dev
subjects:
- kind: ServiceAccount
  name: tiller
  namespace: dev
roleRef:
  kind: Role
  name: tiller-manager
  apiGroup: rbac.authorization.k8s.io
</code></pre><pre tabindex="0"><code>nano helm-prod-namespace.yaml
kind: Namespace
apiVersion: v1
metadata:
  name: prod
---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: tiller
  namespace: prod
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: tiller-manager
  namespace: prod
rules:
- apiGroups: [&#34;&#34;, &#34;batch&#34;, &#34;extensions&#34;, &#34;apps&#34;]
  resources: [&#34;*&#34;]
  verbs: [&#34;*&#34;]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: tiller-binding
  namespace: prod
subjects:
- kind: ServiceAccount
  name: tiller
  namespace: prod
roleRef:
  kind: Role
  name: tiller-manager
  apiGroup: rbac.authorization.k8s.io
</code></pre><pre tabindex="0"><code>kubectl create -f helm-dev-namespace.yaml
kubectl create -f helm-prod-namespace.yaml

kubectl -n dev get sa
kubectl -n prod get sa

helm init --service-account tiller --tiller-namespace dev
helm init --service-account tiller --tiller-namespace prod
</code></pre><h3 id="helm-with-minimal-cluster-permissions">Helm with minimal cluster permissions</h3>
<pre tabindex="0"><code>nano helm-cluster-role.yml
kind: Namespace
apiVersion: v1
metadata:
  name: helm
---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: helm
  namespace: helm
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: helm-clusterrole
rules:
  - apiGroups: [&#34;&#34;]
    resources: [&#34;pods/portforward&#34;]
    verbs: [&#34;create&#34;]
  - apiGroups: [&#34;&#34;]
    resources: [&#34;pods&#34;]
    verbs: [&#34;list&#34;, &#34;get&#34;]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: helm-clusterrolebinding
roleRef:
  kind: ClusterRole
  apiGroup: rbac.authorization.k8s.io
  name: helm-clusterrole
subjects:
  - kind: ServiceAccount
    name: helm
    namespace: helm
</code></pre><h3 id="generate-a-kubeconfig-file-from-the-helm-service-account">Generate a Kubeconfig file from the Helm Service Account</h3>
<p>Credit to Ami Mahloof for this script.</p>
<pre tabindex="0"><code>NAMESPACE=helm
# Find the secret associated with the Service Account
SECRET=$(kubectl -n $NAMESPACE get sa helm -o jsonpath=&#39;{.secrets[].name}&#39;)
# Get the token from the secret
TOKEN=$(kubectl get secrets -n $NAMESPACE $SECRET -o jsonpath=&#39;{.data.token}&#39; | base64 -D)
# Get the CA from the secret
kubectl get secrets -n $NAMESPACE $SECRET -o jsonpath=&#39;{.data.ca\.crt}&#39; | base64 -D &gt; ca.crt

CONTEXT=$(kubectl config current-context)
CLUSTER_NAME=$(kubectl config get-contexts $CONTEXT --no-headers=true | awk &#39;{print $3}&#39;)
SERVER=$(kubectl config view -o jsonpath=&#34;{.clusters[?(@.name == \&#34;${CLUSTER_NAME}\&#34;)].cluster.server}&#34;)
KUBECONFIG_FILE=config
USER=helm
CA=ca.crt

# Set up config
kubectl config set-cluster $CLUSTER_NAME \
--kubeconfig=$KUBECONFIG_FILE \
--server=$SERVER \
--certificate-authority=$CA \
--embed-certs=true

kubectl config set-credentials $USER \
--kubeconfig=$KUBECONFIG_FILE \
--token=$TOKEN

kubectl config set-context $USER \
--kubeconfig=$KUBECONFIG_FILE \
--cluster=$CLUSTER_NAME \
--user=$USER

kubectl config use-context $USER \
--kubeconfig=$KUBECONFIG_FILE
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                             
                                <category scheme="helm2" term="helm2" label="helm2" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Openshift Ceph RBD for dynamic provisioning]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-ceph/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-ldap/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift LDAP authentication" />
                <link href="https://devopstales.github.io/kubernetes/ansible-openshift-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install Openshift" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-ceph/</id>
            
            
            <published>2019-04-12T00:00:00+00:00</published>
            <updated>2019-04-12T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>In this post I will show you how can you use CEPH RBD for persistent storagi on Openshift.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="environment">Environment</h3>
<pre tabindex="0"><code># openshift cluster
192.168.1.41    openshift01 # master node
192.168.1.42    openshift02 # infra node
192.168.1.43    openshift03 # worker node

# ceph cluster
192.168.1.31    ceph01
192.168.1.32    ceph02
192.168.1.33    ceph03
</code></pre><h3 id="prerequirement">Prerequirement</h3>
<p>RBD volume provisioner needs admin key from Ceph to provision storage. To get the admin key from Ceph cluster use this command:</p>
<pre tabindex="0"><code>sudo ceph --cluster ceph auth get-key client.admin | base64
QVFBOFF2SlZheUJQRVJBQWgvS2cwT1laQUhPQno3akZwekxxdGc9PQ==

nano ceph-admin-secret.yaml
apiVersion: v1
data:
  key: QVFBOFF2SlZheUJQRVJBQWgvS2cwT1laQUhPQno3akZwekxxdGc9PQ==
kind: Secret
metadata:
  name: ceph-admin-secret
  namespace: kube-system
type: kubernetes.io/rbd
</code></pre><p>I will also create a separate Ceph pool for</p>
<pre tabindex="0"><code>sudo ceph --cluster ceph osd pool create k8s 1024 1024
sudo ceph --cluster ceph auth get-or-create client.k8s mon &#39;allow r&#39; osd &#39;allow rwx pool=k8s&#39;
sudo ceph --cluster ceph auth get-key client.k8s | base64
QVFBOFF2SlZheUJQRVJBQWgvS2ctS2htOFNSZnRvclJPRk1jdXc9PQ==

nano ceph-secret-k8s.yaml
apiVersion: v1
data:
  key: QVFBOFF2SlZheUJQRVJBQWgvS2ctS2htOFNSZnRvclJPRk1jdXc9PQ==
kind: Secret
metadata:
  name: ceph-secret-k8s
  namespace: kube-system
type: kubernetes.io/rbd
</code></pre><pre tabindex="0"><code># on all openshift node
yum install -y ceph-common

# on one openshift master node
nano  k8s-storage.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: &#34;true&#34;
  name: k8s
parameters:
  adminId: admin
  adminSecretName: ceph-admin-secret
  adminSecretNamespace: kube-system
  imageFeatures: layering
  imageFormat: &#34;2&#34;
  monitors: 192.168.1.31:6789, 192.168.1.32:6789, 192.168.1.33:6789
  pool: k8s
  userId: k8s
  userSecretName: ceph-secret-k8s
provisioner: kubernetes.io/rbd
reclaimPolicy: Delete
volumeBindingMode: Immediate


oc create -f ceph-admin-secret.yaml
oc create -f ceph-secret-k8s.yaml
oc create -f k8s-storage.yaml
</code></pre><h3 id="add-secrets-to-existng-namespaces">Add secrets to existng namespaces</h3>
<pre tabindex="0"><code># on one openshift master node
oc project default
oc apply -f ceph-secret-k8s.yaml

oc project management-infra
oc apply -f ceph-secret-k8s.yaml

oc project openshift-infra
oc apply -f ceph-secret-k8s.yaml

oc project openshift-logging
oc apply -f ceph-secret-k8s.yaml

oc project openshift-metrics-server
oc apply -f ceph-secret-k8s.yaml

oc project openshift-monitoring
oc apply -f ceph-secret-k8s.yaml
</code></pre><h3 id="add-secret-to-template">Add secret to template</h3>
<p>If we add the secret to the template iw will be present in all of the newly created namespaces.</p>
<pre tabindex="0"><code># on one openshift master node
su - origin
oc adm create-bootstrap-project-template -o yaml &gt; template.yaml
# add secrets to  the yml without namespace
nano template.yaml
...
- apiVersion: v1
  data:
    key: QVFBOFF2SlZheUJQRVJBQWgvS2ctS2htOFNSZnRvclJPRk1jdXc9PQ==
  kind: Secret
  metadata:
    name: ceph-secret-k8s
  type: kubernetes.io/rbd
...
oc create -f template.yaml -n default

# on all the openshift master nodes
nano /etc/origin/master/master-config.yaml
...
projectConfig:
  projectRequestTemplate: &#34;default/project-request&#34;
...

master-restart api
master-restart controllers
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                             
                                <category scheme="ceph" term="ceph" label="Ceph" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Openshift LDAP authentication]]></title>
            <link href="https://devopstales.github.io/kubernetes/openshift-ldap/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
                <link href="https://devopstales.github.io/kubernetes/openshift-ceph/?utm_source=atom_feed" rel="related" type="text/html" title="Openshift Ceph RBD for dynamic provisioning" />
                <link href="https://devopstales.github.io/kubernetes/ansible-openshift-install/?utm_source=atom_feed" rel="related" type="text/html" title="Install Openshift" />
            
                <id>https://devopstales.github.io/kubernetes/openshift-ldap/</id>
            
            
            <published>2019-04-12T00:00:00+00:00</published>
            <updated>2019-04-12T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Configure Openshift Cluster to use LDAP as a user backend for login with Ansible-openshift</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<p>In the last post I used the basic htpasswd authentication method for the installatipn.<br>
But I can use Ansible-openshift to configure an LDAP backed at the install for the authentication.</p>
<h3 id="environment">Environment</h3>
<pre tabindex="0"><code>192.168.1.40    deployer
192.168.1.41    openshift01 # master node
192.168.1.42    openshift02 # infra node
192.168.1.43    openshift03 # worker node
</code></pre><p>With Ansible-openshift you can not change the authetication method after Install !! If you installed the cluster with htpasswd, then change to LDAP the playbook trys to add a second authentication methot for the config. It is forbidden to add a second type of identity provider in the version 3.11 of Ansible-openshift so choose wisely.</p>
<h3 id="configurate-installer">Configurate Installer</h3>
<pre tabindex="0"><code># deployer
nano /etc/ansible/ansible.cfg
# use HTPasswd for authentication
#openshift_master_identity_providers=[{&#39;name&#39;: &#39;htpasswd_auth&#39;, &#39;login&#39;: &#39;true&#39;, &#39;challenge&#39;: &#39;true&#39;, &#39;kind&#39;: &#39;HTPasswdPasswordIdentityProvider&#39;}]

# LDAP
openshift_master_identity_providers=[{&#39;name&#39;: &#39;email_jira_ldap&#39;, &#39;challenge&#39;: &#39;true&#39;, &#39;login&#39;: &#39;true&#39;, &#39;kind&#39;: &#39;LDAPPasswordIdentityProvider&#39;, &#39;attributes&#39;: {&#39;id&#39;: [&#39;mail&#39;], &#39;email&#39;: [&#39;mail&#39;], &#39;name&#39;: [&#39;displayName&#39;], &#39;preferredUsername&#39;: [&#39;mail&#39;]}, &#39;bindDN&#39;: &#39;CN=ldapbrowser,DC=mydomain,DC=myintra&#39;, &#39;bindPassword&#39;: &#39;*******&#39;, &#39;insecure&#39;: &#39;true&#39;, &#39;url&#39;: &#39;ldap://ldap01.mydomain.myintra/dc=mydomain,dc=myintra?mail?sub?(objectClass=*)&#39;}]
</code></pre><h3 id="run-the-installer">Run the Installer</h3>
<pre tabindex="0"><code># deployer
cd /usr/share/ansible/openshift-ansible/
sudo ansible-playbook -i inventory/hosts.localhost playbooks/prerequisites.yml
sudo ansible-playbook -i inventory/hosts.localhost playbooks/deploy_cluster.yml
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Install Openshift]]></title>
            <link href="https://devopstales.github.io/kubernetes/ansible-openshift-install/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://devopstales.github.io/kubernetes/ansible-openshift-install/</id>
            
            
            <published>2019-03-12T00:00:00+00:00</published>
            <updated>2019-03-12T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>Ansible-openshift is a pre made ansible playbook for Openshift installation. In this Post I will show you how to use to install a new Openshift cluster.</p>


<H3>Parts of the Openshift series</H3>
<ul>
     <li>Part1: <a href="../../kubernetes/ansible-openshift-install/">Install Opeshift</a></li>
     <li>Part2: <a href="../../kubernetes/openshift-auto-approval-csr/">How to Enable Auto Approval of CSR in Openshift v3.11</a></li>
     <li>Part3: <a href="../../kubernetes/openshift-add-node/">Add new workers to Openshift cluster</a></li>
     <li>Part4: <a href="../../kubernetes/openshift-cert/">Chane the certificates of the Openshift cluster</a></li>
     <li>Part5: <a href="../../kubernetes/openshift-ldap/">LDAP authentication for Openshift</a></li>
     <li>Part6: <a href="../../sso/openshift-sso/">Keycloak SSO authentication for Openshift</a></li>
     <li>Part7: <a href="../../sso/openshift-sso2/">Gitlab SSO authentication for Openshift</a></li>
     <li>Part8a: <a href="../../kubernetes/openshift-ceph/">Ceph persistent storage for Openshift</a></li>
     <li>Part8b: <a href="../../kubernetes/openshift-vmware/">vSphere persistent storage for Openshift</a></li>
     <li>Part9: <a href="../../kubernetes/openshift-helm/">Helm on Openshift</a></li>
     <li>Part10: <a href="../../kubernetes/k8s-tillerless-helm/">Tillerless Helm on Openshift</a></li>
     <li>Part11: <a href="../../kubernetes/openshift-extregistry/">Use external docker registry on Openshift</a></li>
     <li>Part12: <a href="../../kubernetes/openshift-secondary-router/">Secondary router on Openshift</a></li>
     <li>Part13a: <a href="../../kubernetes/openshift-letsencrypt/">Use Letsencrypt on Openshift</a></li>
     <li>Part13b: <a href="../../kubernetes/openshift-cert-manager/">Install cert-managger on Openshift</a></li>
     <li>Part14: <a href="../../kubernetes/ansible-operator-overview/">Create Openshift operators</a></li>
     <li>Part15: <a href="../../kubernetes/openshift-kompose/">Convert docker-compose file to Opeshift</a></li>
     <li>Part16a: <a href="../../kubernetes/openshift-elasticsearch-error/">Opeshift elasticsearch search-guard error</a></li>
     <li>Part16b: <a href="../../kubernetes/openshift-log4shell/">Openshift: Log4Shell - Remote Code Execution (CVE-2021-44228) (CVE-2021-4104)</a></li>
</ul>



<h3 id="environment">Environment</h3>
<pre tabindex="0"><code>192.168.1.40    deployer
192.168.1.41    openshift01 # master node
192.168.1.42    openshift02 # infra node
192.168.1.43    openshift03 # worker node

# hardware requirement
4 CPU
16G RAM
</code></pre><h3 id="dns-config">DNS config</h3>
<pre tabindex="0"><code>master.openshift     300 IN  A 192.168.1.41
openshift            300 IN  A 192.168.1.42
*.openshift            300 IN  A 192.168.1.42
</code></pre><h3 id="prerequirement">Prerequirement</h3>
<pre tabindex="0"><code># deployer
yum install epel-release centos-release-openshift-origin311
yum --disablerepo=* --enablerepo=centos-ansible26 install ansible
yum install openshift-ansible nano

echo &#34;exclude=ansible&#34; &gt;&gt; /etc/yum.conf

nano ~/.ssh/config
Host openshift01
    Hostname openshift01.devopstales.intra
    User origin

Host openshift02
    Hostname openshift02.devopstales.intra
    User origin

Host openshift03
    Hostname openshift03.devopstales.intra
    User origin
</code></pre><pre tabindex="0"><code># on all openshift hosts
hostnamectl set-hostname openshift01
yum -y update
yum -y install centos-release-openshift-origin311 epel-release docker git pyOpenSSL

useradd origin
passwd origin
echo -e &#39;Defaults:origin !requiretty\norigin ALL = (root) NOPASSWD:ALL&#39; | tee /etc/sudoers.d/origin
chmod 440 /etc/sudoers.d/origin
reboot

# Disable swap permanently
nano /etc/fstab
#/dev/mapper/centos_openshift01-swap swap                    swap    defaults        0 0

sudo swapoff -a

sudo lvremove -Ay /dev/centos/swap
sudo lvextend -l +100%FREE centos/root
sudo xfs_growfs /

sudo nano /etc/default/grub
GRUB_TIMEOUT=5
GRUB_DEFAULT=saved
GRUB_DISABLE_SUBMENU=true
GRUB_TERMINAL_OUTPUT=&#34;console&#34;
# GRUB_CMDLINE_LINUX=&#34;rd.lvm.lv=centos/root rd.lvm.lv=centos/swap crashkernel=auto rhgb quiet&#34;
GRUB_CMDLINE_LINUX=&#34;rd.lvm.lv=centos/root crashkernel=auto rhgb quiet&#34;
GRUB_DISABLE_RECOVERY=&#34;true&#34;

dracut --regenerate-all -f
grub2-mkconfig -o /boot/grub2/grub.cfg
</code></pre><h3 id="configurate-installer">Configurate Installer</h3>
<pre tabindex="0"><code># deployer

nano /etc/ansible/hosts
[OSEv3:children]
masters
nodes
etcd

[OSEv3:vars]
# admin user created in previous section
ansible_ssh_user=origin
ansible_become=true
openshift_deployment_type=origin
os_firewall_use_firewalld=True
openshift_clock_enabled=true

# use HTPasswd for authentication
openshift_master_identity_providers=[{&#39;name&#39;: &#39;htpasswd_auth&#39;, &#39;login&#39;: &#39;true&#39;, &#39;challenge&#39;: &#39;true&#39;, &#39;kind&#39;: &#39;HTPasswdPasswordIdentityProvider&#39;}]

# define default sub-domain for Master node
openshift_master_default_subdomain=openshift.devopstales.intra
osm_default_subdomain=openshift.devopstales.intra

# allow unencrypted connection within cluster
openshift_docker_insecure_registries=172.30.0.0/16

openshift_master_cluster_hostname=master.openshift.devopstales.intra
openshift_master_cluster_public_hostname=master.openshift.devopstales.intra
openshift_public_hostname=master.openshift.devopstales.intra

openshift_master_api_port=443
openshift_master_console_port=443

[masters]
openshift01 containerized=true openshift_public_hostname=master.openshift.devopstales.intra

[etcd]
openshift01 containerized=true

[nodes]
# defined values for [openshift_node_group_name] in the file below
# [/usr/share/ansible/openshift-ansible/roles/openshift_facts/defaults/main.yml]
openshift01 openshift_node_group_name=&#39;node-config-master&#39;
openshift02 openshift_node_group_name=&#39;node-config-infra&#39;
openshift03 openshift_node_group_name=&#39;node-config-compute&#39;
</code></pre><h3 id="run-the-installer">Run the Installer</h3>
<pre tabindex="0"><code># deployer
cd /usr/share/ansible/openshift-ansible/
sudo ansible-playbook playbooks/prerequisites.yml
sudo ansible-playbook playbooks/deploy_cluster.yml

# If installastion failed or went wrong, the following uninstallation script can be run, and running installation can be tried again:
sudo ansible-playbook playbooks/adhoc/uninstall.yml
</code></pre><h3 id="user-management">User management</h3>
<pre tabindex="0"><code># on openshift master

cd /etc/origin/master/
# add user
htpasswd [/path/to/users.htpasswd] [user_name]
htpasswd htpasswd devopstales

# delete user
htpasswd -D [htpasswd/file/path/]  [user-name] [password]
htpasswd -D htpasswd devopstales Password1

# it will remove only the username from the htpasswd file by default it won’t remove user identity
oc delete  identity htpasswd_auth:user
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift-3.11" term="openshift-3.11" label="Openshift 3.11" />
                             
                                <category scheme="ansible" term="ansible" label="Ansible" />
                             
                                <category scheme="centos" term="centos" label="CentOS" />
                            
                        
                    
                
            
        </entry>
    
        
        <entry>
            <title type="html"><![CDATA[Configure kubectl for multiple clusters]]></title>
            <link href="https://devopstales.github.io/kubernetes/kubectl-multi-cluster-config/?utm_source=atom_feed" rel="alternate" type="text/html" />
            
            
                <id>https://devopstales.github.io/kubernetes/kubectl-multi-cluster-config/</id>
            
            
            <published>2019-03-11T00:00:00+00:00</published>
            <updated>2019-03-11T00:00:00+00:00</updated>
            
            
            <content type="html"><![CDATA[<p>I use a multiple Kubernetes clusters on a daily basis, so keeping my configs organized is important to don’t confuse myself.</p>
<p>kubectl looks at an environment variable called KUBECONFIG to hold a colon-separated list of paths to configuration files, so I can use multiple cluster config files.</p>
<h3 id="download-kubernetes-config">Download kubernetes config</h3>
<pre tabindex="0"><code>scp root@DEV_SERVER:/etc/kubernetes/admin.conf ~/.kube/dev-config
scp root@TST_SERVER:/etc/kubernetes/admin.conf ~/.kube/tst-config
scp root@UAT_SERVER:/etc/kubernetes/admin.conf ~/.kube/uat-config
scp root@PROD_SERVER:/etc/kubernetes/admin.conf ~/.kube/prod-config
</code></pre><h3 id="edit-config-files">Edit config files</h3>
<pre tabindex="0"><code>nano ~/.kube/dev-config
...
- cluster:
    server: https://1.1.1.1:6443
  name: dev-config
...
contexts:
- context:
    cluster: dev-config
    user: dev-admin
  name: dev-config
...
users:
- name: dev-admin
...
</code></pre><h3 id="use-config-files-in-kubeconfig-variable">Use config files in KUBECONFIG variable</h3>
<pre tabindex="0"><code>nano ~/.bashrc
export KUBECONFIG=$HOME/.kube/dev-config:$HOME/.kube/tst-config:$HOME/.kube/uat-config:$HOME/.kube/prod-config

echo $KUBECONFIG

/home/ME/.kube/dev-config:/home/ME/.kube/tst-config:/home/ME/.kube/uat-config:/home/ME/.kube/prod-config

source ~/.bashrc
</code></pre><h3 id="use-clusters-with-kubectl">Use clusters with kubectl</h3>
<pre tabindex="0"><code># get the current context
kubectl config current-context

# use a different context
kubectl config use-context work-dev
</code></pre>]]></content>
            
                 
                    
                         
                        
                            
                             
                                <category scheme="openshift" term="openshift" label="Openshift" />
                             
                                <category scheme="kubernetes" term="kubernetes" label="Kubernetes" />
                            
                        
                    
                 
                    
                 
                    
                         
                        
                            
                             
                                <category scheme="kubernetes" term="kubernetes" label="kubernetes" />
                             
                                <category scheme="openshift" term="openshift" label="openshift" />
                            
                        
                    
                
            
        </entry>
    
</feed>
